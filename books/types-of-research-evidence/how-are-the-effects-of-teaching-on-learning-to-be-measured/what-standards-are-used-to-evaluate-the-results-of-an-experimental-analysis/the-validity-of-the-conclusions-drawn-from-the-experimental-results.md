---
has_children: false
layout: default
nav_order: 3
title: 'The validity of the conclusions drawn from the experimental results '
---
# The validity of the conclusions drawn from the experimental results 


::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-da76939063444d01a244c29f54fedd73}
The third question which may be asked of an experiment is the question
"Are the conclusions which have been drawn by the researcher valid
conclusions given the way in which the experiment was designed and the
nature of the conditions under which it was undertaken?" In particular,
is it possible to conclude that the learning which was observed was a
function of the experimental manipulation and not a function of any
other variable which was operating during the course of the experiment?
This question is most commonly referred to as the *internal validity*
question and its answer requires a complex chain of reasoning which
considers the accuracy of the observation or measurement procedures
used, the way in which the experimental treatments were administered and
controlled, the identification of any extraneous variables which may
have been operating, the length of time over which the experimental
treatments operated, the size of the difference between the rates of
learning observed while each experimental condition was operating, and
the number of replications which the investigator obtained for each
experimental effect (Campbell & Stanley, 1963; Johnston & Pennypacker,
1993; Krathwohl, 1985).

An experimenter may devise a set of experimental procedures which
operate reliably and for a sufficient length of time to produce a
reasonably accurate measure of treatment effects but still draw invalid
conclusions from the results obtained.

The greatest threat to the internal validity of an experiment is the
operation of confounding or extraneous variables which also have an
effect on learning -- an effect which is unrecognised by the
experimenter. Beginning with the seminal work of Campbell and Stanley
(1963), most educational research methods texts attempt to list at least
some of the extraneous variables which can threaten the internal
validity of experiments into teaching and learning. Some of the more
common threats to the internal validity of an experiment are as follows.

-   *Unnoticed extra-experimental instruction, teaching, practice, or
    experience.* Social scientists refer to this threat to the internal
    validity of an experiment as the *history* threat. For example, an
    experimenter who attempts to measure the effects of training
    children to use a particular metacognitive skill during an
    experimental learning task, but who fails to notice that the
    children are also using this new metacognitive skill on the control
    task may well arrive at an invalid conclusion regarding the effects
    of training in the metacognitive skill.
-   *Unnoticed differences in learning tasks.* An experimenter who
    attempts to measure the effects of two teaching conditions using two
    different tasks but who fails to notice that one task is easier than
    the other may well arrive at an invalid conclusion regarding the
    effects of the two training procedures.
-   *Unnoticed differences between the previously acquired skills of
    experimental group and control group learners.* Social scientists
    refer to this threat to the internal validity of an experiment as
    the *selection* threat. For example, an experimenter who uses
    separate experimental and control groups but who fails to recognise
    that, prior to the experiment, the children in the experimental
    group were more knowledgeable, or more skilled, than the children in
    the control group may well arrive at an invalid conclusion regarding
    the effects of the experimental treatment.
-   *Unnoticed differences in the administration of experimental
    treatments*. When experimental treatments are administered by
    teachers or research assistants (as is often the case) there are
    plenty of opportunities for both control group teachers and
    experimental group teachers to depart from instructions regarding
    what is to be taught and how it is to be taught. In experiments
    which last for many weeks or months, such departures become
    increasingly likely. If treatment administration is poorly
    monitored, the experimenter may end up attributing differences in
    student learning to a set of instructional conditions which were
    not, in fact, provided by the teachers who were involved in the
    experiment.
-   *Unnoticed effects on the motivation of control group subjects.* In
    experiments where the control group subjects and the experimental
    subjects attend the same class or school, there is a high likelihood
    that the control group subjects will notice that the experimental
    subjects are receiving lessons or practice activities or incentives
    which they are not receiving. This knowledge can have unpredictable
    effects. Sometimes it may motivate the control group subjects to
    find out what the experimental subjects are learning so that they
    can learn it too. It may even motivate control group subjects to
    study harder than would otherwise be the case so that they can keep
    up with and do as well as their experimental group peers on any
    post-tests. This effect, which is sometimes referred to as the *John
    Henry effect*, may completely mask the effect of the experimental
    treatment. Sometimes the subjects in the control group become
    demoralised because they have been declined access to the new
    materials which the experimental subjects have access to and, as a
    consequence, perform less well on post-tests than would otherwise be
    the case.

It can be seen that designing an experiment in which differences in rate
of learning can be unambiguously attributed to particular experimental
treatments (and not to any other variable which operated during the
course of the experiment) is not a simple matter. It requires
considerable attention to detail not only during the design and
execution of the experiment but also when trying to interpret the data
generated by the experiment.
:::

::: referencesList
#### References

-   Campbell, D. T., & Stanley, J. C. (1963). Experimental and
    quasi-experimental designs for research on teaching. In N. Gage
    (Ed.), Handbook of research on teaching (pp. 171-246). Chicago: Rand
    McNally.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Krathwohl, D. R. (1985). Social and behavioral science research: A
    new framework for conceptualising, implementing and evaluating
    research studies. San Francisco: Jossey-Bass Publishers.
:::
