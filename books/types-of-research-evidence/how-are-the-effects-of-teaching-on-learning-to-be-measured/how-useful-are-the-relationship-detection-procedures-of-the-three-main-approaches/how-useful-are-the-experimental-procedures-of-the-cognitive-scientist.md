---
layout: default
title: "How useful are the experimental procedures of the cognitive scientist? 
"
nav_order: Howusefularetheexperimentalproceduresofthecognitivescientist
has_children: false
---
# How useful are the experimental procedures of the cognitive scientist? 


::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b7087b60b8a843fda9bb5d18a24d1d80}
Between-groups experimental procedures and the statistical procedures
which have to be mastered in order to interpret the results of such
experiments remain the staple content of research methods textbooks and
research methods courses around the world. Experiments using one or
another of the between-groups designs also dominate the published
research literature on learning. However, these procedures have a number
of important shortcomings when learning is the subject-matter of
investigation. One of these has already been mentioned and that is the
fact that learning involves a process of change (a transition) and that,
when a number of learners are observed or tested just once, this
observation catches each learner at a different point in this
transition. Aggregating these observations to calculate a mean score
makes absolutely no logical sense.

Another major shortcoming of the between-groups methodology arises as a
result of the fact that the experimental and the control treatments are
*experienced by different individuals*. This means that the effects of
experimental treatments are *always contaminated by learning history
effects.* This is because individual learners always bring different
skills and capabilities with them to a between-groups experiment and,
hence, are differently affected by any experimental treatment. "Each
subject typically experiences only one of the conditions being compared.
This means that comparisons of the effects of independent variable and
control conditions must involve different subjects, which confounds the
effects of treatment conditions with between subject variability"
(Johnston & Pennypacker, 1993, p. 183).

Of course, the experimental and control treatments do not *necessarily*
have to be applied to different individuals. They could be applied to
the same individuals using one of the repeated measures, within-groups
procedures designed for this purpose. In practice, however, 86 per cent
of the experiments reported by social and cognitive scientists are
experiments in which different groups of subjects have received the
experimental and control treatments (Church, 1998). This preference
seems to have arisen as a result of the requirements of the significance
testing procedure routinely used by social scientists to evaluate the
results of their experiments. One of the assumptions underlying the use
of procedures such as analysis of variance is that the groups of scores
must be uncorrelated. Between-groups designs meet this assumption
whereas within-groups designs do not.

For the student of learning and teaching, this confounding of
experimental effects with learning history effects creates two very
serious problems.

First, one of the primary aims of a science is to look for order in the
variability of the science\'s subject matter. In chemistry, for example,
the variability in naturally occurring compounds has been reduced by
scientific investigation to a finite number of chemical elements. In the
field of learning and teaching the variability to be understood and
explained is differences in the rate of learning and the accomplishments
of individuals. However, this is not the subject matter of cognitive
science. Cognitive scientists treat differences between individuals as a
source of error, refer to it as "error variance" or "chance variability"
and, instead of studying its origins, treat it as the error term against
which treatment effects are to be evaluated.

To some experimenters, chance is simply a name for the combined effects
of uncontrolled variables. If such variables are, in fact, controllable,
then chance in this sense is simply an excuse for sloppy
experimentation. . . . If the uncontrolled variables are actually
unknown, then chance is . . . a synonym for ignorance. Science is
presumably dedicated to stamping out ignorance, but statistical
evaluation of data against a baseline whose characteristics are
determined by unknown variables constitutes a passive acceptance of
ignorance (Sidman, 1960, p. 45).

Secondly, the confounding of treatment effects and learning history
effects places a severe restriction on the independent variables which
can actually be studied using this method. It means that the
between-groups methodology *can only be used to study the effects of
independent variables which have a greater effect* than the effect of
differences in prior learning history. Because differences in learning
history have extremely powerful effects, this places a severe limitation
on the teaching conditions and learning experiences which can actually
be studied using this methodology.

It also makes it difficult to see the effects of experimental treatments
which only have small effects. A number of investigators have studied
the power (the sensitivity) of samples of psychological experiments and
have concluded that the power of the typical between-groups experiment
is about .5 or .6. That is, the likelihood of the typical between-groups
experiment detecting a treatment effect when there is one, is about 60
per cent and the likelihood of two separate replications of the same
experiment both detecting a treatment effect when there is one is about
.6 x .6 or 36 per cent. This, say the critics of social science
experimentation, is one of the major reasons why even lengthy series of
investigations into the same topic so often fail to generate any kind of
conclusion or consensus about the answer to the question under
examination (Rossi, 1997; Schmidt & Hunter, 1997).
:::

::: referencesList
#### References

-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N.Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Rossi, J. S. (1997). A case study in the failure of psychology as a
    cumulative science: The spontaneous recovery of verbal learning.
    In L. L. Harlow, S. A. Mulaik, & J. H. Steiger (Eds.), What if there
    were no significance tests? (pp. 176-197). Mahwah, N.J.: Lawrence
    Erlbaum Associates
-   Schmidt, F. L. & Hunter, J. E. (1997). Eight common but false
    objections to the discontinuation of significance testing in the
    analysis of research data. In L. L. Harlow, S. A. Mulaik, & J. H.
    Steiger (Eds.), What if there were no significance tests? (pp.
    38-64). Mahwah, N.J.: Lawrence Erlbaum Associates.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::
