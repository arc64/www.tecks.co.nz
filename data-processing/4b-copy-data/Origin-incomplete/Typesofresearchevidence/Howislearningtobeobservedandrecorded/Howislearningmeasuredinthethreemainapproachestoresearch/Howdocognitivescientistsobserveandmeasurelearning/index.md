---
has_children: false
layout: default
nav_order: 1
title: 'How do cognitive scientists observe and measure learning? '
---
# How do cognitive scientists observe and measure learning? 


::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7a70ac4fc3c94f2788ff2cba6c01667b}
**The focus of individual investigations***.* Decisions regarding the
particular variables which are to be observed are almost always made by
cognitive scientists before the investigation begins. Typically the
researcher specifies not only the particular variable or variables which
are to be observed, but also an hypothesis regarding the relationship
which is presumed to exist between each of these variables. Commonly
this hypothesis is expressed in null form, that is, in the form of a
prediction that there is no detectable relationship between the two
variables.

**Sampling procedures.** The social science methodology requires the
cognitive scientist to draw samples of subjects or participants from the
population of interest. Because the performance of the sample of
subjects will be analysed statistically, the composition of these groups
is a matter of some importance.

First, the samples must of sufficient size. It is widely agreed
(although not universally agreed) amongst social scientists that each
group should contain at least 30 individuals because it is at about this
sample size that "the magnitude of student\'s *t* critical values for
small samples approach the *z* critical values of the normal probability
table for large samples" (Best & Kahn, 1993, p. 19).

Secondly, the samples must be representative of the larger population to
which the researcher will be seeking to generalise any relationships
which are observed in the research sample. Methods textbooks argue that
the most satisfactory way of achieving this requirement is by drawing a
random sample of subjects from the population which is of interest.

Thirdly, where the performance of two or more groups is going to be
compared, the researcher must create groups which are equivalent or
comparable at the outset of the investigation. The creation of
equivalent groups is most commonly achieved by assigning individual
subjects at random to each of the comparison groups or treatment groups
taking part in the investigation. Random assignment is used so that the
researcher can "assume that the groups are approximately equal in all
possible independent variables. The larger the groups, the safer the
assumption" (Kerlinger, 1964, p. 56).

**Observation procedures.** To measure subjects\' relative positions on
the variables selected for study, the cognitive scientist constructs
tests, rating scales, questionnaires, interviews and observation
schedules. Level of reading comprehension, for example, might be
measured using a reading comprehension test. Teaching style might be
measured using a rating scale or an observational schedule. Attitude
towards mathematics might be measured using a questionnaire or interview
containing items about the respondent\'s liking for various mathematics
activities.

Because cognitive scientists have been attempting to devise measures of
their constructs for almost a century, they have devised a very large
number of tests, rating scales and self report instruments of various
kinds. Many of these instruments have been standardised using large
samples of learners and their reliability evaluated. Lists of published
tests and self-report instruments will be found in publications such as
*Tests in Print* (Murphy, Conoley & Impara, 1994).

Social scientists use both direct and indirect measures of performance.
However, the cognitive scientist\'s desire to measure the performance of
groups of subjects frequently results in the use of indirect measures of
performance. Rather than observing directly the metacognitive skills,
the study skills, or the level of persistence of participants (for
example), the cognitive scientist commonly substitutes participant
self-reports on metacognitive awareness scales, study inventories,
achievement motivation scales, and so on. Direct observation procedures
are used, but they are used much less often than self-reports.

The tests and rating scales of the cognitive scientist typically
generate measurement scales (sets of scores) which have no true zero.
They are ordinal scales which simply rank the performances of
individuals on a scale from "low" to "high".

Intelligence, aptitude, and personality test scores are . . . ordinal.
They indicate with more or less accuracy not the *amounts* of
intelligence, aptitude, and personality traits of individuals, but
rather the *rank-order positions* of the individuals. . . . ordinal
scales do not possess the desirable characteristics of equal intervals
or absolute zeros. Intelligence test scores are examples. It is not
possible to say that an individual has zero intelligence. . . . there is
no absolute zero on an intelligence scale (Kerlinger, 1964, p. 425).

Cognitive scientists do not draw a clear distinction between idemnotic
and vaganotic measures. The use of vaganotic measures is so entrenched
that almost all standardised social science instruments are vaganotic
measures of performance.

**Duration of the investigation***.* Much cognitive science research
involves a single administration of a battery of tests or measures
(typically two to six) to each of the subjects in the investigation
sample. These investigations last only as long as it takes to administer
the several tests. The purpose of these investigations is to calculate
the correlation (within the sample) between the variables measured by
each of the tests.

Repeated measures of performance are occasionally collected by cognitive
scientists and researchers working within this tradition have devised a
set of experimental designs (the repeated measures designs) which are
capable of handling multiple observations of the performance of the
individuals within an experimental group. By far the most commonly used
practice, however, is that of observing or testing the experimental
subjects just once (or twice) during the course of a particular
investigation. This means that the cognitive and social science research
has tended to focus on educational achievements, outcomes, and products
rather than teaching and learning processes which involve change over
time. "Traditional experimental designs . . . tend to focus more on the
behavioral result or product of the treatment being studied. Fewer
measurements are usually taken in investigations using traditional
experimental approaches. The method . . . involves formulation of the
sample, administration of a treatment, and assessment of treatment
effects" (Drew, 1976, p. 36).

**Conclusions.** There are a number of features of the measurement
procedures used by cognitive scientists which make them less than
completely satisfactory measures of learning.

First, cognitive scientists routinely employ indirect measures (such as
self-reports) when measuring behaviours and performances which could be
observed directly. Like the qualitative researcher, social scientists
have developed no agreed procedure for evaluating the veracity or
accuracy of self-report responses on questionnaires and other kinds of
scales, in spite of their widespread use.

Secondly, cognitive scientists routinely employ ordinal, rather than
interval, scale measures of human performance. Cognitive scientists like
to argue that their approach is scientific. This requires measurement
scales which generate scores which can be manipulated mathematically.
Cognitive science decision making often involves the use of inferential
statistics. This also requires scores which can be manipulated
mathematically. But the ordinal measures typically used by the cognitive
scientist do not meet this requirement. Rather than solving this
problem, educational researchers typically *ignore* it. "The best
procedure would seem to be to treat ordinal measurements as though they
were interval measurements but to be constantly alert to the possibility
of gross inequality of intervals. .. It is unlikely that the educational
researcher will be seriously led astray by heeding this advice, if he is
knowledgeable and careful in applying it" (Kerlinger, 1964, p. 427-428).

Thirdly, most cognitive science measures are vaganotic, which means that
the measurement results obtained from one investigation to the next
cannot be directly compared (unless the standard deviations of the score
distributions are identical). "Many people who have become accustomed to
measuring their own weight in pounds and their consumption of
electricity in kilowatt hours have difficulty comprehending a measure of
their child\'s academic achievement given in terms of other children\'s
academic achievement " (Johnston & Pennypacker, 1993b, p. 38). We can
find no precedent in the natural sciences for this method of defining
phenomena and their units of measurement. The use of procedures wherein
the phenomena being measured or the units of measurement are defined in
terms of (the) variability characterizing a set of otherwise direct
observations seems peculiar to the social sciences. This is one of the
most fundamental differences between the natural and social sciences
(Johnston & Pennypacker, 1993, p. 29).
:::

::: referencesList
#### References

-   Best, J. W., & Kahn, J. V. (1993). Research in education (7th ed.).
    Boston: Allyn and Bacon.
-   Drew, C. J. (1976). Introduction to designing research and
    evaluation. Saint Louis, MO: The C.V. Mosby Company.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Murphy, L. L., Conoley, J. C., & Impara, J. C. (Eds.). (1994). Tests
    in print IV: an index to tests, test reviews, and the literature on
    specific tests Volumes 1 & 2. Lincoln: Buros Institute of Mental
    Measurements of the University of Nebraska, Lincoln.
:::
