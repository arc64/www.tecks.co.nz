---
layout: default
title: "Levels of empirical support 
"
nav_order: Levelsofempiricalsupport
has_children: false
---
# Levels of empirical support 


::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-002b2675da69484aa9e3aa27653f5dcc}
Education researchers have engaged in little discussion of the amount of
empirical evidence which would be required in order to justify a claim
that a given practice qualified as "evidence based". This changed in
1994 when the members the Clinical Child Psychology section of Division
12 (the Clinical Psychology division) of the American Psychological
Association established a task force to examine the evidence regarding
the effectiveness of various psychosocial interventions for children.
This task force decided to classify the interventions which are
currently being used to treat children with depression, anxiety
disorders, behaviour problems and autism into three general categories:
(a) not yet empirically validated, (b) probably efficacious, and (c)
well-established. These criteria were first published as the lead
article in an entire issue of the *Journal of Clinical Psychology*
devoted to reviews of empirically supported interventions for children
(Lonigan, Elbert & Johnson, 1998). In compiling these reviews, the
following definitions were used.

**Not yet empirically validated**

This classification is reserved for interventions which do not yet meet
the criterion for a probably efficacious intervention. This
classification does not mean that the intervention is ineffective. It
means either (a) that few or no controlled evaluations of the
intervention have been published, or (b) the number of controlled
evaluations is less than that required for probably efficacious status,
or (c) the controlled evaluations which have been undertaken to date
fail to demonstrate that the intervention is an effective intervention.

**Probably efficacious**

The criteria to be met before an effective intervention can be
classified as *probably efficacious* (from Lonigan et al., 1998) are as
follows:

1.*Either* the existence of two randomised groups evaluations which meet
the criteria for a well established intervention but conducted by the
same investigators.

*Or* the existence of at least two randomised groups evaluations showing
that the intervention is more effective than a no-treatment or waiting
list comparison group.

2.*Or* the existence of at least 4 well designed single-case experiments
which compare the intervention to another intervention.

3.The existence of a treatment manual for the intervention is preferred
but not required.

4.The characteristics of the children in each trial have been clearly
specified.

**Well established**

The criteria to be met before an intervention can be classified as
*well-established* are as follows:

1.*Either* the existence of at least two well-conducted randomised
groups evaluations (with adequate statistical power), conducted by
different research teams, showing the intervention to be either superior
to a placebo or alternative intervention or else as effective as some
other well established intervention.

2.*Or* the existence of at least 10 well designed single-case
experiments which compare the intervention to another intervention.

3.The existence of a treatment manual for the intervention is preferred
but not required.

4.The characteristics of the children in each trial have been clearly
specified.

**Comments**

Since its introduction, there has been some discussion of the merits of
this scheme. A summary of the main points of contention will be found in
Fonagy, Target, Cottrell, Phillips and Kurtz (2002). The main
observation which needs to be made is that the criterion for
between-groups evaluations seems to have been set very low (only two
studies are required) whereas the criterion for within-subject
evaluations seems to have been set very high (at least 10 studies). In
addition the within-subject experiments cannot just measure
effectiveness by introducing the intervention, they must compare the
effectiveness of the intervention under investigation against the
effectiveness of some other intervention. This almost never happens in
behaviour analysis research (a) because measuring the effects of
introducing a new intervention provides a better measure of
effectiveness than trying to compare the relative rates of improvement
under two alternating intervention conditions in a child and (b) because
once the effects of an intervention have been replicated three or four
times investigators inevitably move on to systematic replication studies
designed to explore the generality of the effect, that is, to find out
who the intervention works for and under what conditions. By requiring
conditions which are never met in practice, the Task Force has set up a
situation in which only randomised groups evaluations can contribute to
the decision as to whether or not a particular intervention qualifies as
empirically supported either at the probably efficacious level or at the
well established level.
:::

::: referencesList
#### References

-   Fonagy, P., Target, M., Cottrell, D., Phillips, J., & Kurtz, Z.
    (2002). What works for whom? A critical review of treatments for
    children and adolescents. New York: The Guilford Press.
-   Lonigan, C. J., Elbert, J. C., & Johnson, S. B. (1998). Empirically
    supported psychosocial interventions for children: An overview.
    Journal of Clinical Child Psychology, 27, 138-145.
:::
