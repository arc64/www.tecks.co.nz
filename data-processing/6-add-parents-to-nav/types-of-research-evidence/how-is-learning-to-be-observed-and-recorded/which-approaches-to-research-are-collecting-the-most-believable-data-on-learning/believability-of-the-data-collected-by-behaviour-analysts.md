---
grand_parent: 'How is learning to be observed and recorded? '
great_grand_parent: 'Types of research evidence '
great_great_grand_parent: 'Welcome to Teacher Education''s Core Knowledge and Skills.'
has_children: false
layout: default
nav_order: 1
parent: 'Which approaches to research are collecting the most believable data on learning? '
title: 'Believability of the data collected by behaviour analysts '
---
# Believability of the data collected by behaviour analysts 


::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b197ce3469bb47199abdc233a89af1b5}
Behaviour analysts have developed a well defined set of terms which they
use when considering data quality issues. Behaviour analysts routinely
distinguish between (i) the adequacy of a measurement *procedure* and
(ii) the adequacy of a measurement *result* (that is, the data resulting
from the application of that procedure) and they routinely distinguish
between (i) the steps taken to ensure that a recording procedure is
producing accurate data and (ii) the steps taken to *evaluate* or assess
the adequacy of the recording procedure which is being used.

**Accuracy of the data collected**

Behaviour analysts treat issues of reliability and accuracy very
seriously, and routinely take a number of steps to ensure that their
recording procedures are reliable procedures which will produce accurate
measures of behaviour and behaviour change. These steps include:
providing a careful definition of the behaviour of interest before
beginning an investigation, using direct (rather than indirect)
observation procedures, ensuring that observers are adequately trained,
making repeated observations of the behaviour of interest, and building
in procedures for assessing the reliability of the recordings which are
being made as they are being made.

Behaviour analysts argue that the reliability and accuracy of measures
of behaviour should never be taken for granted and must always be
demonstrated. The great majority of reports of behaviour analysis
experiments include data evaluation information so that the reader can
make a judgement about the believability of the data which is being
presented. The most commonly used data quality assessment procedure
involves (a) the employment of a second independent observer, marker or
coder during a sample of the observational sessions, (b) calculation of
the percentage of agreement between the records of the two observers,
and (c) reporting of the levels of agreement which were obtained. The
results of these assessments are referred to as measures of
*interobserver agreement* (Cooper, Heron & Heward, 1987).

Behaviour analysts consider the collection of measurement evaluation
data mandatory for reports which are intended for publication and would
have difficulty in getting a report accepted for publication if it did
not contain data evaluation information.

**Validity of the conclusions which are being drawn from the data**

The behaviour analyst is not normally concerned with issues of
measurement validity. Behaviour analysts tend to argue that validity is
achieved by the use of direct observation procedures to study relatively
specifically defined classes of performance. "If the behavior under
study is directly measured, no question about validity exists. Direct
measurement is automatically valid" (Johnston & Pennypacker, 1993, p.
142). Behaviour analysts do, however, sample observational *occasions*
so questions can always be asked about the validity (the
representativeness) of the sample of occasions selected for observation.

**Evaluation of the quality assurance procedures used by behaviour
analysts**

Behaviour analysts routinely distinguish between procedures designed to
*collect* accurate data and procedures designed to *evaluate* the
accuracy of the data which is being collected. (This is one of the major
differences between behaviour analysis research and ethnographic
research.) Behaviour analysts also distinguish between the reliability
of a measurement procedure and the accuracy of a measurement result.

Behaviour analysts routinely assess the reliability of their measurement
procedures and report the results of their data quality assessments.
Furthermore, the results of these assessments are expected to
demonstrate that adequate standards of accuracy and/or reliability were
achieved. In addition to this, the reliability of the observation
procedure selected for use is routinely evaluated *during the course* of
most behaviour analysis experiments so that corrective action can be
taken if the accuracy of the data being collected falls below
conventional standards. (This requirement is not one which ethnographers
and social scientists have to meet.)

The procedure most commonly used by behaviour analysts to assess the
reliability of observation and coding procedures is the
two-independent-observers procedure. The main weakness of the use of
inter-observer agreement as the data evaluation measure is that, while a
high level of interobserver agreement enhances the believability of data
by providing evidence of consensual validity, it does not, strictly
speaking, provide a measure of either observer reliability or the
accuracy of the data which have been collected (Johnston & Pennypacker,
1993).

Behaviour analysts do not attempt to generalise from single cases to
populations so subject sampling errors cannot function as a threat to
the validity of the behaviour analyst\'s conclusions. Behaviour analysts
avoid problems of content validity by studying changes in small,
functionally delineated and carefully defined response classes (such as
reading accuracy, or reading fluency) so item sampling bias cannot
function as a threat to content validity.

However, behaviour analysts do select samples of observation occasions,
or tests, over time and bias in the sampling of occasions can be a
threat to the validity of the behaviour analyst\'s conclusions. This is
recognised by behaviour analysts who have conducted a number of
investigations of the accuracy of the estimates provided by different
occasion sampling procedures (see, for example, Powell, Martindale &
Kulp, 1975). Behaviour analysts attempt to avoid occasion sampling
errors by making sufficient observations of the behaviour of interest
within each experimental phase to provide a reliable estimate of the
level of change or the rate of change occurring within each experimental
phase.

Behaviour analysis journals routinely require the authors of reports of
behaviour analysis experiments to include data which assess the level of
reliability achieved during the operation of the observation and/or
testing and/or coding procedures used to measure behaviour change during
the course of the experiment. The fact that behaviour analysts employ
measurement procedures and experimental procedures which are likely to
generate accurate measurement results, institute regular reliability
checks, and must report the results of these data quality evaluations as
a condition of publication represents a very considerable advance over
the data quality assurance procedures employed by both qualitative
researchers and social science researchers.
:::

::: referencesList
#### References

-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Powell, J., Martindale, A., & Kulp, S. (1975). An evaluation of
    time-sample measures of behavior. Journal of Applied Behavior
    Analysis, 8, 463-469.
:::
