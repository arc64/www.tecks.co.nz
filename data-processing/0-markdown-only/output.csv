File Path,Content
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchingeneralorjustthescientificresearch/Whatistocountasevidenceinthemovetoevidence-basedpractice/index.md","# What is to count as evidence in the move to evidence-based practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f45abb2c4047452a9a356e3f08b368ad}
Teaching research of all types varies widely with respect to quality.
Some investigations have measured learning, some have measured only
achievement and some have measured neither learning nor achievement.
Some results have been replicated and many have not. This means that we
need to be clear about whether the research base for teaching is to
include the results of all empirical investigations or just those which
meet certain quality criteria. If the research base is to be limited to
research which meets certain standards, we will also need to be clear
about just what those standards are.

In answering this question, we will argue that teaching practice is such
an important activity (with such profound long term effects on the
children being taught) that the research base must be limited to
empirical results and empirically derived theoretical propositions in
which we can be reasonably confident. This limits the research base to
the results of investigations which meet conventional standards of
measurement accuracy, internal validity, and generalisability.

Since we are only interested in the research base for learning and
teaching we will argue that this research base should be limited to
investigations which (1) address a question about the conditions
necessary for learning or the effects of teaching on learning, (2)
address a question to which the answer is not yet known, (3) employ a
research procedure which could, if appropriately applied, answer the
question which has been asked, (4) use a measure of learning which
provides an accurate record of the learning which occurred in each of
the individual learners, and (5) demonstrate that the measure of
learning is likely to have produced an accurate measurement result. As a
general (although not universal) rule, the research base should also be
limited to investigations which (6) employ an experimental procedure
which could, if appropriately applied, produce an accurate measure of
the effects of the independent variable on the learning of each of the
learners, (7) demonstrate much the same experimental effect across
several direct replications, (8) describe the research procedures,
research results, and theoretical explanations using terms with agreed
meanings, and (9) interpret the results in a language which is
relatively free of pre-scientific concepts and pre-scientific forms of
explanation.

**1. The research addresses a question about learning and/or teaching**

Far too much so-called teaching research is not actually research about
teaching, it is research about teacher qualifications, teacher
personality, teacher stress, the characteristics of effective teachers,
the characteristics of effective schools, the characteristics of
classroom life, and so on. Much is also practitioner research, that is,
research which describes some kind of professional development activity,
teaching activity or classroom practice garnished with the writer's
views regarding the value of these activities but with no reference to
student learning. These are all interesting research topics. But they
are not studies of the conditions necessary for learning or studies of
the relationship between teaching and learning. So they cannot be
included in a research base for *teaching* practice.

We suggest that the research base for learning and teaching should
consist primarily of research into the external conditions which are
necessary in order for specified kinds of learning to occur in students
with stated learning histories, and research into teaching or coaching
or mentoring or classroom practice, or teaching materials, or teaching
programmes and their effects on the learning of students with stated
learning histories.

**2. The research addresses a question with an unknown answer**

Far too much educational research addresses and re-addresses questions
which we already know the answer to. Consider for example the hundreds
of research studies which have sought to measure the correlation between
intelligence and different types of achievement. These studies
invariably find that student performance on generalised achievement
tests such as IQ tests is correlated with student performance on more
specific achievement tests such as tests of reading. While the first
dozen or so of these studies were probably interesting at the time, the
many hundreds of subsequent studies simply amount to wasted effort.

We suggest that the research base for learning and teaching should
contain only research which has attempted to answer questions for which
the answer is not already known. (This includes research which attempts
to explore the limits of a particular effect.) This means that the
research must address questions which cannot be answered simply by
making a few telephone calls and it must address questions which cannot
be answered by engaging in a literature search designed to identify
reports of previous research into the question of interest.

**3. The research uses a research procedure which could possibly answer
the question**

Far too much educational research employs completely inappropriate
research procedures, that is, research procedures which could never
provide an answer to the question which has been asked. An extremely
common example is the cognitive science or social science researcher who
uses a between-groups design with a single post-treatment measure of
achievement to test an hypothesis about one of the changes which we
refer to as learning. Another extremely common example is the
qualitative researcher who seeks, on the basis of a single ethnographic
study of three or four individuals to make generalisations about \"boys\",
or \"junior high school students\", or \"low achieving students\" in
general. A third example is the repeated use of descriptive and
correlational methods to address questions about the origins or *causes*
of certain levels of motivation, certain kinds of attitudes or certain
types of learning.

We suggest that the research base for learning and teaching should
operate a rule which results in the exclusion of all investigations
which have employed a research method which could not possibly have
answered the question which was asked. This will limit the research base
to those studies employing a research method which, if appropriately
applied, could have answered the question which was asked.

**4. The research measures learning in a way which is known to produce
an accurate result**

Because learning involves a transition (e.g. from not being able to
perform some task to being able to complete that task, or from correct
but slow to correct and fast performance of a task) it is clear that an
adequate measure of learning must be a repeated measure because only
repeated observation allows us to detect the point at which a transition
occurs. In addition, children arrive at learning and teaching
experiments with different levels of prior learning and expertise. This
means that the measure of learning must also be one which charts the
improvement or change in each individual learner. Thirdly, some measures
of learning produce more accurate measurement results than others. We
suggest, therefore that the research base for learning and teaching be
limited to those investigations which have employed a measure of
learning which is likely to have produced an accurate measure of the
change which occurred in each of the learners who took part in the
investigation.

Strict adherence to this rule would, of course, rule out all
investigations which have used only a measure of achievement and all
investigations which have reported only aggregate measures (e.g. means
and standard deviations) of change. It may therefore be necessary to
include some randomised groups evaluations in the research base, at
least for an interim period, that is, at least until those studying a
particular question begin to report the results of their experiments on
the learning of individual learners. It will still be important, even in
these cases, to ensure that accurate measures of learning outcomes have
been employed.

**5. The accuracy of the data on learning is demonstrated**

It is actually quite difficult to obtain accurate measures of
performance change in individual learners. This is because learning
takes time and this requires the expenditure of time, effort and money
on observation (or repeated testing) by the researcher. However, it is
clear from previous research that the accuracy of a measure of any of
the changes which we refer to as learning cannot be taken for granted.
Measurement accuracy must, therefore, always be demonstrated.

Accordingly we suggest that the research base for learning and teaching
should be limited to those investigations in which the researcher
provided some evidence of the degree of reliability of the measurement
procedure used or the degree of accuracy of the measurement result which
was obtained. This includes cases where the measurement instrument is a
standardised test or scale which is known to be reliable, that is, a
test or scale with a test administration manual which includes data on
test reliability.

**6. The research measures the effects of some kind external event using
an experimental method which is known to produce an accurate measure of
treatment effects**

Most research into learning and teaching measures the effect of
something on learning. In the great majority of cases these
investigations use some kind of experimental procedure because it is
almost always possible to devise an experiment to measure the effects of
external events on learning and experiments provide the most unambiguous
measures of the effects of environmental variables and conditions on
learning.

Some experimental designs provide relatively accurate measures of the
effects of a change in teaching conditions on student learning and some
do not. We suggest, therefore, that the research base for learning and
teaching be limited to the results of experimental analyses using
research designs which are known to provide relatively reliable measures
of the effects of external conditions on learning (and other types of
change) in individual students.

Strict adherence to this suggestion would, of course, rule out the
results of all randomised groups evaluations of teaching programmes,
teaching materials, and teaching procedures no matter how well
controlled or how well designed the evaluation. This we cannot afford to
do at the present time because these between groups experiments
collectively make up more than half the knowledge base. It will be
necessary, therefore, at least during an interim period, to allow the
inclusion of randomised between-groups evaluations which meet
conventional standards of measurement reliability, experimental control,
and internal validity. While there is a place, at least initially, for
the results of well-controlled between groups measures of the effects of
teaching variables, such experiments can only contribute to the
knowledge base if the size of the treatment effect is reported. We
suggest therefore, that the randomised groups experiments which are
admitted to the knowledge base for teaching be limited to those in which
the effect size has been calculated using a conventional statistic such
as Cohen's *d*, or those which provide data sufficient to enable
calculation of the effect size for each experimental treatment
(Thompson, 2002).

**7. The accuracy of the data on effects is demonstrated**

The accuracy of measures of experimental effect can never be taken for
granted. This is because the design and administration of an internally
valid experiment is a complex task which can go wrong in many different
ways, and because drawing conclusions from an experiment involves a
complex chain of inferences which is also prone to error. The simplest
way of demonstrating the accuracy of a measure of experimental effect is
to build several direct replications into the investigation. Direct
replication involves repeating the experiment with, for example, several
different learners, or several different learning tasks, or several
different teachers. When the same experiment is undertaken several times
and results in much the same level of change or rate of change in each
case, this provides reasonably compelling evidence that the measure of
effect is probably an accurate measure of effect.

We suggest therefore that the research base for teaching give more
weight to experiments with results which have been replicated than to
experiments with results which have not been replicated. Because most
randomised groups experiments have never been replicated this rule will
tend to give greater weight to within-subject experimental analyses of
learning and teaching than to one-off randomised groups evaluations of
teaching procedures and programmes.

**8. The research procedure and research result are described in terms
with agreed meanings**

There can be no scientific research base in the field of learning and
teaching until such time as teaching researchers and learning
researchers begin to adopt a common set of organising concepts (and
concept definitions) which are referred to using agreed terms. At the
present time this simply is not occurring, and this failure is the
single greatest impediment to the development of a science of learning
and the development of a technology of teaching. Such a development is
not impossible. Behaviour analysts have demonstrated that it is possible
to develop a coherent set of concepts by defining learning and teaching
events in terms of their observed functions instead of their structural
characteristics and that it is possible for a group of researchers to
reach agreement on concepts, terms, theoretical principles, and rules
for admitting new concepts in the same way that biological scientists
and medical scientists do.

This demonstration suggests that we should tag investigations in which
the research procedures, research results, and theoretical explanations
have described using terms with agreed meanings. This will enable
reviewers to distinguish between investigations which are part of a
programme of research into a particular question and investigations
which are \"one-off' studies of a particular question and to give greater
weight to the former.

**9. The report is relatively free of pre-scientific concepts and forms
of explanation**

There are many aspects of our current thinking about learning and
teaching which constitute major impediments to the development of a
science of learning (and a technology of teaching). Of these, three
currently operate as major barriers to a move towards a scientific
analysis of learning. These are (a) the myth that a science of learning
will be able to be written in everyday language, (b) our continued use
of constructs which have no agreed meanings or operational definitions,
and (c) our inability to distinguish between pre-scientific and
scientific forms of explanation.

None of the established sciences are written in everyday language. All
have had to develop a technical vocabulary in order to make distinctions
between concepts and events which cannot be distinguished using the
terms and concepts of everyday language. While a developing research
base for teaching will inevitably include some investigations which have
been written up in everyday language (because they have generated
interesting results), such reports will need to be marked as destined
for eventual deletion from the research base in order to provide an
incentive for investigators to make the move towards an agreed technical
vocabulary when describing learning and teaching events.

Much of the research on learning to date involves studies of constructs
which have no agreed meaning and no agreed operational definition.
Common examples include such constructs as \"intelligence\", \"long term
memory\", \"visuo-spatial scratchpad\", \"achievement motivation\",
\"automaticity\", \"phonemic awareness\", \"lexical awareness\",
\"understanding\", \"the construction of meaning\", \"self-esteem\",
\"self-efficacy\", \"depression\", \"learning disability\", \"scaffolding\",
\"discovery learning\", and so on, together with all of the variants of
these constructs. Constructs which have no agreed meaning and no agreed
operational definition pose a very serious impediment to the development
of a science of learning because, although these constructs will almost
certainly never be admitted into a mature science of learning, their
continued use hinders emergence of the realisation that these constructs
are essentially useless. Generally speaking, reports of research into
learning and/or teaching which are about constructs which have no agreed
meaning or no agreed operational definition should not be admitted to
the research base for learning and teaching unless there is some
compelling reason for doing do. A compelling reason might be that the
experiment has generated a particularly important or interesting result
and the result is one which can be readily translated into terms which
do have agreed meanings.

Pre-scientific forms of explanation in the research into learning and
teaching are extremely common at the present time. Included under this
heading are all those research reports in which changes in performance,
motivation, attitude or competence are explained using intentional
idioms (e.g. beliefs, desires, attitudes, and so on) and all those
research reports in which changes are explained in terms of the
operation of some unobservable internal disposition (e.g. explaining a
change in productivity in terms of a change in internal motivation, or
explaining an inadequate performance in terms of some kind of
psychopathology, or explaining the acquisition of a new concept in terms
of meaning construction, etc.). Generally speaking reports of research
into learning and/or teaching which employ intentional explanations,
explanations involving reification and other pre-scientific forms of
explanation should not be admitted to the research base for learning and
teaching unless there is some compelling reason for doing do. A
compelling reason might be that the experiment has generated a
particularly important or interesting result and the explanation
provided by the investigator, although pre-scientific, is simply
irrelevant.
:::

::: referencesList
#### References

-   Thompson, B. (2002). What future quantitative social science
    research could look like: Confidence intervals for effect sizes.
    Educational Researcher, 31, 25-32.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchingeneralorjustthescientificresearch/Isthesocialscienceapproachascientificapproach/index.md","# Is the social science approach a scientific approach? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-aa2a37ee5f9e4c42a46ededa58b04661}
Researchers who use the social science methodology routinely refer to
themselves as social *scientists*, as cognitive *scientists,* and so on.
Almost every social science methods text book starts with a chapter
about the nature of science and scientific inquiry. For more than half a
century, the social science methodology has been marketed to students of
psychology and education as a scientific endeavour. But is it?

One of the primary aims of a science is to discover order in the
variability of the science's subject matter. In the field of learning
and teaching this is individual variability in rate of learning and in
responsiveness to teaching. However, this variability cannot be studied
or understood using a methodology in which individual variability is
treated as the product of chance or as random error. Mendel took the
variability in peas as something to be explained and the science of
genetics was the end result. Galton, however, took variability in human
characteristics for granted and what has come to be known as social
\"science\" was the result (Johnston & Pennypacker, 1993, p. 39).

One of the characteristics of a natural science is that it has a
procedure for classifying the main elements of its subject matter.
Cognitive scientists have yet to develop an agreed taxonomy for
classifying the different kinds of changes customarily included under
the heading of learning and they have yet to develop any kind of common
procedure for classifying the different kinds of experiences which might
be considered to be necessary for learning. Cognitive scientists
continually invent new constructs without reference to their
experimental utility and continue to use old constructs even although
they have never been demonstrated to be lawfully related to anything.
There is no sign of the emergence of a common terminology which can be
used to describe various kinds of learning outcomes, various kinds of
teaching events, or the important features of educational environments.

All of the natural sciences initially restricted their attention to the
study of observable phenomena. Cognitive scientists, however, include,
within their subject matter, numerous mentalisms and dispositions, that
is, hypothetical constructs which are in practice unobservable.

One of the characteristics of a developing science is the development of
standard and absolute measures of change which can be directly compared
from one investigation to the next. However, cognitive scientists have
yet to develop standard and absolute measures of behaviour, performance,
skill level, behaviour change or automaticity. The great majority of
their measures are vaganotic measures in which the size of the
measurement unit depends upon the measurement variability observed
during the course of a particular study. Without standard and absolute
measures of change, \"the discovery and communication of lawful relations
becomes virtually impossible\" (Johnston and Pennypacker, 1993, p. 38).

Although they have developed procedures for doing so, cognitive
scientists do not routinely assess the reliability of the measurement
procedures used in individual investigations and do not routinely assess
and report the accuracy of the data which they have collected. Nor are
measurement accuracy and reliability data required by journal editors as
a condition of acceptance for publication.

Whereas the aim of a science is to discover reproducible relationships
(by undertaking numerous experiments using reproducible procedures) the
cognitive scientist typically undertakes a single experiment and asks us
to believe, on the basis of a statistical test, that these results will
be reproducible. Individual experiments are almost never replicated, and
cognitive science journals do not require replication as a condition of
publication, so the reliability of experimental effects remains unknown
in the great majority of cases.

The decision to study the performance of groups means that measures of
behaviour change (learning) are always contaminated by the effects of
prior learning history. This means that variables which have a lesser
effect than the effects of differences in prior learning history cannot
be studied using this method. \"I should like to argue that the
statistical assumptions on which our research practice is so firmly
founded are often demonstrably false, and consequently that they
misguide much of our efforts to find patterns of behavior, particularly
of the behavior of individuals\" (Thorngate, 1986, p. 73).

Most importantly of all, the application of the between-groups
methodology to the search for conditions which are necessary for
learning has identified few consistent and reproducible relationships
between experiential variables and rate of learning which are applicable
at the level of the individual learner and social science and cognitive
science research has stimulated few technological developments in
teaching practice. \"Between groups designs and inferential statistics .
. . are inherently inappropriate for the task of learning about behavior
in any fundamental or analytical sense . . . and their dominance in
psychology lies at the root of psychology\'s continuing failure to build
an importantly useful science and technology\" (Johnston & Pennypacker,
1993b, p. 190-191).

The widespread use of metaphorical constructs, the lack of consensus
regarding definitions, the continual generation of theories which cannot
be tested, experimental irrelevance, and the failure to arrive at any
kind of theoretical consensus have led a number of observers (e.g.
Bauer, 1992; Gellner, 1984; Johnston & Pennypacker, 1993; Machado,
Lourenço & Silva, 2000) to conclude that cognitive science is not, in
fact, a scientific activity at all.
:::

::: referencesList
#### References

-   Bauer, H. H. (1992). Scientific literacy and the myth of scientific
    method. Chicago: University of Illinois Press.
-   Gellner, E. (1984). The scientific status of the social sciences.
    International Social Science Journal, 36, 567-586.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Machado, A., Lourenço, O., & Silva, F.J. (2000). Facts, concepts and
    theories: The shape of psychology\'s epistemic triangle. Behavior
    and Philosophy, 28, 1-40.
-   Thorngate, W. (1986). The production, detection, and explanation of
    behavioral patterns. In J. Valsiner (Ed.), The individual subject
    and scientific psychology (pp. 71-96). New York: Plenum Press.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchingeneralorjustthescientificresearch/Argumentsforandagainstusingonlytheresultsofscientificresearch/index.md","# Arguments for and against using only the results of scientific research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-989244dba8af493da6940b736ba466b9}
By and large, classroom teaching is not based on the results of research
-- of any type. This has not gone unnoticed by critics. \"It is quite
commonplace in education to see methods, programs, and techniques
employed for which the data on effectiveness is minimal, non-existent,
or even contrary. . . . Imagine the outcry if new miracle wonder drugs
were released to an unsuspecting public without extensive, experimental
clinical trials testifying to their efficacy. But in education this is
precisely what typically happens.\" (Wheldall, 2005, pp. 578-579). This
means that there are few constraints on the kinds of classroom practice
which are included in teacher education programmes. \"In contrast to
other professions, education has no publicly agreed upon process for
identifying practices that should be included in or excluded from
pre-service and in-service teacher training programmes\" (Greenwood,
2001, p. 37). It also leaves teachers, schools, and school systems open
to capture by the purveyors of each new theory which comes along. \"When
one has an education system that is based on a loose combination of
theory and fact, where there are no proper standards for trials before
changes are made in the system, then the system is wide open to
intrusion from trendy theories of all kinds in all areas\" (Marsh, 2005,
p. 702).

This is not to say that teacher educators do not engage in research.
They engage in large amounts of research -- but it is research of a
particular type. An examination of research reports both here in New
Zealand and overseas suggests that the majority of teacher educators are
electing to invest their research time in descriptive and interpretive
inquiry rather than in experimental or scientific research. In a survey
of the research reports published in 1995, Church (1998) found that
approximately half of all of the research into teaching published that
year involved a narrative, descriptive, or ethnographic method, and a
high proportion of these were based on an interpretive methodology. An
examination of the papers presented to the annual conference of the New
Zealand Association for Research in Education indicates that, in 1987,
28% of the papers presented used a descriptive research method, and 23%
employed a correlational or experimental method (Church 1988). By 2005,
70% of papers presented at this conference used a descriptive method and
only 12% used a correlational or experimental method. This change
corresponds closely to the increase in the number of teacher educators
joining NZARE over this period.

At the same time that teacher educators have been moving away from
empirical analyses of teaching-learning relationships into narrative
inquiry, ethnographic inquiry and practitioner research, other groups of
educational researchers have been arguing that only well controlled
empirical research can identify effective teaching practices and lead to
improvements in classroom practice. \"Reform in American education
depends on a movement toward evidence-based practice, using the findings
of rigorous research to guide educational practices and policies\"
(Slavin, 2005). \"To improve the results achieved by schools, the
instructional practices that are shared widely across the profession
should be limited to those that are most likely to produce better
results. Scientific research is the best method for predicting the
results that different practices are likely to produce\" (Grossen, 2001).
\"Before any instructional interventions are formally endorsed for public
consumption, they should be carefully scrutinized with respect to their
evidence credibility . . . on the basis of some type of educational
research vetting process\" (Levin, 2005, p. 5). \"Just as it would be
unimaginable to administer untested drugs to patients or, worse, to fail
to administer life-saving treatments in favour of unproven ones, so it
should become unimaginable to forego proven methods in education\"
(Reyna, 2005, p. 39).

The idea that teaching should be based on scientific research is not a
new idea. \"The efficiency of any profession depends in large measure
upon the degree to which it becomes scientific. The profession of
teaching will improve . . . as the leaders in education direct their
choices of methods by the results of scientific investigation rather
than general opinion\" (E. L. Thorndike, 1906, p. 206 cited in Mayer,
2005).

Recently, two clearinghouses have been established to produce and
disseminate reviews of research in educational policy and practice.
These are the What Works Clearinghouse in the US and the Evidence for
Policy and Practice Information and Coordinating Centre (EPPI) in the
UK. It is clear from the operations manuals of these two centres that
reviews will be limited to evaluations which meet a list of well defined
quality control standards.

Perhaps the most contentious development has been the passing in 2001 of
the *Reauthorisation of the* *Elementary and Secondary Education Act* in
the US -- an act which has come to be known as the *No Child Left
Behind* *Act*. Not only does this legislation argue that teacher
education programmes and teaching practices must be based on \"scientific
research\", the legislation will channel federal funds to programmes
which are based on scientific research and not to programmes which do
not meet this requirement. \"The bottom line . . . is that research in
education must now satisfy the canons of science just as scientific
research in other fields has done for some time. . . . The *No Child
Left Behind Act* mandates determining what educational programs and
practices have been clearly demonstrated to be effective through
rigorous scientific research. Federal funding will then be targeted to
support the programs and teaching methods that improve student learning
and achievement\" (Reyna, 2005, p. 44).

For some educational researchers, the passing of the *No Child Left
Behind Act* represents an historic step forward for educational
research, educational policy formulation and teaching practice.

At the dawn of the 21st century, education is finally being dragged,
kicking and screaming, into the 20th century. The scientific revolution
that utterly transformed medicine, agriculture, transportation,
technology and other fields early in the 20th century almost completely
bypassed the field of education. If Rip Van Winkle had been a physician,
a farmer, or an engineer, he would be unemployable if he awoke today. If
he had been a good elementary school teacher in the 19th century, he
would probably be a good elementary school teacher today. . . . The most
important reason for the extraordinary advance in medicine, agriculture
and other fields is the acceptance by practitioners of evidence as the
basis for practice\" (Slavin, 2002, p. 16).

For many teaching researchers however, the *No Child Left Behind Act*
represents an historic step backwards. Criticism of the idea that
educational practice should be based on the results of scientific
research into learning and teaching has a long history and passage of
the *No Child Left Behind Act* resulted, predictably, in a re-airing of
many of these criticisms. Classroom practice, it is argued, cannot be
based on the results of scientific research because this approach:
\"overlooks questions and issues central to teachers' work\" (Roulston,
Legette, Deloach & Pitman, 2005, p. 169), because it \"undervalues and
marginalizes the contributions of the arts and humanities to our
understanding of education aims and practices\" (Erickson, 2005), and
because it eliminates \"the possibility that the federal government will
support research and evaluation projects that propose multiple views of
knowledge and multiple research strategies to obtain that knowledge\"
(Lincoln, 2004, p. 1).

What many of the critics of the *No Child Left Behind Act* have noticed
is that the authors of the Act, like the authors of the report
*Scientific research in education* (National Research Council, 2002)
which preceded it, appear to have assumed that \"based on the results of
scientific research\" is equivalent to \"based on the results of
randomised groups evaluations of educational programmes\". \"The move
towards 'evidence-based policy and practice' oversimplifies complex
problems and is being used to warrant . . . governmental incursion into
legislating scientific method in the realm of educational research\"
(Lather, 2004). This raises two questions. Is the social science
approach to research actually an example of science? And should
legislators have the power to prescribe research method by prescribing
the investigative methods which will and will not be funded? \"For many,
the key question is whether legislators or scientists should ultimately
decide issues of research method\" (Feuer, Towne & Shavelson, 2002, p.
5).

So, is teaching practice to be based on any kind of information
collected by any kind of research method, or is the research base to be
limited to that research which meets conventional standards of
measurement reliability, internal validity, and generalisability?

As many educational researchers have noted, the developments of the past
century in medical and surgical diagnosis, practice, and technology were
all preceded by scientific research. In other words, a transition from
natural philosophy to natural science marked not only the emergence of
the physical sciences but also the rapid 20th century explosion of
knowledge about biological processes, human development, disease
transmission, public health, anaesthesia, medical practice, and so on.

Secondly, if teaching practice is to become more \"research-based\" then
surely the research which is being used as a guide to practice will need
to be something more than an endless recycling of descriptions of
existing practices and the stories which are used to justify those
practices. Nuthall argues persuasively that \"reflective practice\" (as
the term is currently used) cannot identify effective and ineffective
teaching practices because teachers can only reflect upon what they
already know. He further argues (Nuthall, 2005, p. 924) that
\"ethnographic studies that are based on teachers' perceptions and
self-reports of their own teaching serve to elaborate and justify the
routines and the myths that support them.\" Practitioner research cannot
identify either effective or ineffective practices and it most certainly
cannot generate new knowledge.

In the final analysis we need a procedure which will perform the
functions so concisely described by Margaret Eisenhart (2005, p. 57).
\"We need principles that rule things in and out of research and we need
principles of quality that distinguish weak from strong research,
depending on the research question and the research design. Unless we
are able to tell policy makers and the public what constitutes good
research on a given topic, we will continue to have trouble convincing
them of the value of \[even\] our best work.\"

If there is one thing which sets a scientific approach apart from all
other approaches to the study of learning and teaching it is that
\"science is self-correcting, so that unproductive theories eventually
can be discarded on the basis of mounting evidence and reasoned
argument\" (Mayer, 2001, p. 30). Of all the methods currently available,
a scientific approach is the only one which allows us to reliably \"rule
things in and rule things out.\" Narrative and descriptive accounts
cannot perform this function. \"The facts care little about how
beautiful, compelling, or coherent our stories are\" (Reyna, 2005, p.
45).

A scientific approach cannot answer all questions relating to learning
and teaching. It remains however, the only approach so far developed
which has the potential to identify cause and effect relationships
between teaching practices and learning outcomes and, hence, to enable
the development of a theory of learning and teaching which teachers can
use to discriminate between teaching practices which are, and are not
likely to facilitate the development of different kinds of skills and
understandings in different kinds of learners. The use of a scientific
approach to questions about what works, for whom, and under what
conditions does not rule out other questions and it does not rule out
the use of other methods of inquiry into the diverse matters which are
included under the heading \"education\".

We are, of course, only at the beginning of the journey towards
discovering what works for whom, why, and under what circumstances. In
order for this journey to occur, the history of science suggests that a
number of changes will need to occur more or less in parallel.

One of these is the development of distinctions and, eventually, a
taxonomy of events which allow for the identification of cause and
effect relationships within the subject matter of learning and teaching
(Rosenberg, 1995). In all of the sciences this has involved a gradual
recognition that the scientific taxonomy cannot be given in the concepts
of everyday language because the concepts of everyday language divide
teaching into classes of teaching events on the basis of appearance and
not on the basis of function or effect.

A second change is the gradual move from endless theorising and
conjecture to systematic observation of the subject matter together with
a concomitant move from reliance on currently held beliefs to a greater
reliance on the results of controlled and systematic observation
(Carnine, 2000). This shift has to occur not only in the mindsets of
researchers but also in the mindsets of practitioners as was the case
when increasing numbers of medical practitioners began to adopt the
ideas of the new \"clinical science\" during the first half of the 20th
century (Le Fanu, 1999). \"Early in the 20th century, the practice of
medicine was at a similar point. For example, research had long since
identified the importance of bacteria in disease, and by 1865 Joseph
Lister had demonstrated the effectiveness of antiseptic procedures in
surgery. . . . Yet it took 30 years to convince tradition-bound
physicians to use sterile procedures. If he dropped a scalpel, a
physician in 1910 was as likely as not to give it a quick wipe and carry
on. Today, of course, the linkage between research and practice in
medicine is so tight than no physician would dream of ignoring the
findings of rigorous research\" (Slavin, 2002, p. 16).

A third change which has to occur is the development of measuring
instruments and a research methodology which permit detection of the
cause-and-effect relationships which exist within the subject matter
-- such as, for example, identification of the conditions which are
necessary in order for a particular type of learner to learn and
remember a particular kind of skill (Johnston & Pennypacker, 1993). This
leads us to our next question. Which of the three most common approaches
to research into learning and teaching can be considered to be
\"scientific\"?
:::

::: referencesList
#### References

-   Carnine, D. (2000). Why education experts resist effective
    practices. Retrieved December 17, 2001 from
    http://www.edexcellence.net/library/carnine.html
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N.Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Eisenhart, M. (2005). Science plus: A response to the responses to
    Scientific Research in Education. Teachers College Record, 107,
    52-58.
-   Erickson, F. (2005). Arts, humanities, and sciences in educational
    research and social engineering in federal education policy.
    Teachers College Record, 107, 4-9.
-   Feuer, M. J., Towne, L., & Shavelson, R. J. (2002). Scientific
    culture and educational research. Educational Researcher, 31, 4-14.
-   Greenwood, C. R. (2001). Science and students with learning and
    behavioral problems. Behavioral Disorders, 27, 37-52
-   Grossen, B. (2001). What does it mean to be a research-based
    profession? Retrieved 29 June, 2001, from
    http://darkwing.uoregon.edu/\~bgrossen/resprf.htm.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Lather, P. (2004). Scientific research in education: A critical
    perspective. British Educational Research Journal, 30, 759-772.
-   Le Fanu, J. (1999). The rise and fall of modern medicine. London:
    Abacus.
-   Levin, J. R. (2005). Randomized classroom trials on trial. In G. D.
    Phye, D. H. Robinson, & J. R. Levin (Eds.), Empirical methods for
    evaluating educational interventions (pp. 3-27). Burlington, MA:
    Elsevier Academic Press.
-   Lincoln, Y. S. (2004). Scientific research in education/evidence
    matters: Randomized trials in education research. Academe. Retrieved
    10 October, 2006, from http://findarticles.com/p/articles/mi_qa3860/
    is_200411/ai_n9470394.
-   Marsh, R. (2005). Evidence-based practice for education? Educational
    Psychology, 25, 701-704.
-   Mayer, R. E. (2001). Resisting the assault on science: The case for
    evidence-based reasoning in educational research. Educational
    Researcher, 30, 29-30.
-   Mayer, R. E. (2005). The failure of educational research to impact
    educational practice: Six obstacles to educational reform. In G. D.
    Phye, D. H. Robinson, & J. R. Levin (Eds.), Empirical methods for
    evaluating educational interventions (pp. 67-81). Burlington, MA:
    Elsevier Academic Press.
-   National Research Council. (2002). Scientific research in education.
    Washington, DC: National Academic Press.
-   Nuthall, G. A. (2005). The cultural myths and realities of classroom
    teaching and learning: A personal journey. Teachers College Record,
    107, 895-934.
-   Reyna, V. F. (2005). The No Child Left Behind Act, scientific
    research and federal educational policy: A view from Washington, DC.
    In G. D. Phye, D. H. Robinson, & J. R. Levin (Eds.), Empirical
    methods for evaluating educational interventions (pp. 29-52).
    Burlington, MA: Elsevier Academic Press.
-   Rosenberg, A. (1995). Philosophy of social science (2nd ed.).
    Boulder, CO: Westview Press.
-   Roulston, K., Legette, R., Deloach, M., & Pitman, C. B. (2005). What
    is 'research' for teacher-researchers? Educational Action Research,
    13, 169-190.
-   Slavin, R. E. (2002). Evidence-based education policies:
    Transforming educational practice and research. Educational
    Researcher, 31, 15-21.
-   Slavin, R. E. (2005) Evidence-based reform: Advancing the education
    of students at risk. Retrieved 10 October, 2006 from
    http://www.americanprogress.org/issues/kfiles/ b492641.html.
-   Wheldall, K. (2005). When will we ever learn? Educational
    Psychology, 25, 573-584.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchingeneralorjustthescientificresearch/index.md","# Research in general or just the scientific research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-333772304e9c43a984f77dbb38e52541}
Some of the research into learning and teaching is narrative and
descriptive, some is normative and statistical, and some is experimental
and scientific. During the past 100 years, the fields in which knowledge
and technology have advanced most rapidly (e.g. public health) are those
where investigators have taken a scientific approach to their study of
their field and this implies that the field of learning and teaching
might advance most rapidly if it too focussed on the scientific research
into learning and teaching.

This is a position which is being taken by an increasing number of
learning and teaching researchers, it is the position which was taken by
the National Research Council Committee on Scientific Principles for
Educational Research which produced *Scientific Research in Education*
(National Research Council, 2002), it is the position taken by the What
Works clearing house in the US and the EPPI clearing house in the UK,
and it is the position taken by the US Congress during the passage of
the *No Child Left Behind* *Act* in the US -- legislation which requires
that only those methods and programmes which have been shown to be
effective by scientifically based research are to be included in school
reform programmes. Underlying each of these initiatives is the belief
that if teaching is to be considered a profession, \"there should, at the
very least, be some commonly agreed notion of what the job actually
entails, a body of shared agreed knowledge of best practice which can
withstand critical scrutiny, a body of key skills learned to a high
level of competence if not mastery, and agreed criteria by which it can
readily be seen that progress toward completion of the job is being
made\" (Wheldall, 2005, p. 583).

It needs to be clearly understood, however, that this view (that
teaching practice should be based on the results of scientific research)
remains controversial. In this section, therefore, we summarise this
debate and attempt to come to an appropriate conclusion. We then examine
the degree to which each of the main approaches to educational research
qualify as scientific. Thirdly, we develop a set of specification to
describe the methodological characteristics of the research studies
which are providing the most believable evidence about the conditions
necessary for different kinds of learning outcomes and the relative
effectiveness of various teaching practices.
:::

::: referencesList
#### References

-   National Research Council. (2002). Scientific research in education.
    Washington, DC: National Academic Press.
-   Wheldall, K. (2005). When will we ever learn? Educational
    Psychology, 25, 573-584.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchingeneralorjustthescientificresearch/Istheethnographicapproachascientificapproach/index.md","# Is the ethnographic approach a scientific approach? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f2b1ee69eb7048d4867e78ed095d8c67}
It is hard to tell whether ethnographers intend that their research
efforts should be regarded as scientific efforts. Qualitative
researchers of the interpretivist persuasion usually argue that research
into human affairs is more like an artistic exercise than a scientific
one. \"The activity of construing human behaviour in social science
cannot be modelled on the parallel attempt to account for natural
events\" (Macdonald & Pettit, 1981, p. 103). \"Social science, insofar as
its concern is the explanation of social behaviour, begins to look like
a discipline which belongs with the humanities rather than the sciences\"
(Macdonald & Pettit, 1981, p. 104).

Other qualitative researchers argue that qualitative research can meet
scientific standards. \"Scientific research involves rigorous and
systematic empirical inquiry that is data-based. Qualitative research
meets these requirements\" (Bogdan & Biklen, 1992, p. 43). However, an
examination of the reports of qualitative inquiries suggests that
qualitative studies rarely, if ever, meet the conventionally expected
requirements of scientific research.

Ethnographers have yet to develop an agreed taxonomy for classifying the
different kinds of changes customarily included under the heading of
learning and they have yet to develop any kind of common procedure for
classifying the different kinds of experiences which might be considered
to be necessary for learning. There is no sign of the emergence of a
common terminology which can be used to describe the various kinds of
learning outcomes, the various kinds of teaching events, or the
important features of educational sites and their activities.

Ethnographers have yet to develop a set of standard procedures for
measuring and describing those changes in competence, motivation, and so
on which are included under the heading of learning. Qualitative
researchers do not distinguish between direct and indirect measures of
actions and perspectives, they do not distinguish between interval scale
and nominal scale measures of behaviour, and they do not distinguish
between idemnotic and vaganotic measures of change. Textbooks on
qualitative research methods simply ignore all of these matters.

Ethnographers do not routinely assess the reliability of their
observational procedures or the credibility (accuracy) of the data which
these procedures generate and, in fact, disagree amongst themselves as
to how either of these goals might be achieved. Individual studies are
almost never replicated so the qualitative literature includes no data
which could be used to evaluate the reliability of the procedures which
are being used and no information regarding the generality of the
conclusions which are being drawn from each study.

Ethnographers are currently limited to a descriptive methodology. They
have yet to develop any kind of procedure for measuring the effects of
teaching and other kinds of experiences on learning. Because they have
yet to develop any kind of experimental methodology, they have no way of
checking the validity of the relationships which they believe they have
identified. Furthermore, ethnographers have yet to consider any of the
methodological questions regarding how one might set about identifying
factors which affect learning, how one might measure the effects of
particular teaching practices on particular learning outcomes, or how
one might evaluate the relative effectiveness or efficiency of different
instructional provisions.

Most importantly of all, qualitative research is failing to identify
relationships between particular kinds of experiences and particular
kinds of learning outcomes, failing to generate any kind of generalised
knowledge which could be used by teachers, and hence failing to generate
improvements in our understanding of either learning or teaching
processes. That this is so is demonstrated by the fact that there are no
textbooks summarising the agreed findings of the qualitative research
(into learning and teaching) which has been undertaken over a period of
more than 30 years.

In 1979, Reichardt and Cook predicted that \"once qualitative methods
have been put to the test as thoroughly as quantitative procedures have
been in the past, the qualitative methods will be found to be just as
fallible and feeble\" (Reichardt & Cook, 1979, p. 26). Twenty-five years
later it appears that this prediction has turned out to be true.
:::

::: referencesList
#### References

-   Bogdan, R. C., & Biklen, S. K. (1998). Qualitative research for
    education: An introduction to theory and methods (3rd ed.). Boston:
    Allyn and Bacon.
-   Macdonald G., & Pettit, P. (1981). Semantics and social science.
    London: Routledge & Kegan Paul.
-   Reichardt, C. S., & Cook, T. D. (1979). Beyond qualitative vs.
    quantitative methods. In T. D. Cook & C. S. Reichardt (Eds.),
    Qualitative and quantitative methods in evaluation research (pp.
    7-32). Beverly Hills, CA: Sage.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchingeneralorjustthescientificresearch/Isthebehaviouranalysisapproachascientificapproach/index.md","# Is the behaviour analysis approach a scientific approach? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-356cc76ebadc497498958451d09f10e8}
Behaviour analysts like to argue that their approach to the study of
learning and teaching is an example of a natural science.

It is characterized by a degree of internal coherence unmatched by other
subdisciplines. Its subject matter is carefully defined and generally
agreed upon by researchers within the field. Its methods of data
collection, analysis, and interpretation are also agreed upon to an
extent not found in other areas . . . Second, it is distinct from the
contemporary mainstream of experimental psychology in that its
historical influences have led to the development of a descriptive,
observational, and integrative system of inductively derived principles,
in contrast to the theory-driven, hypothetico-deductively derived,
statistical principles of most branches of experimental psychology
(Chiesa, 1994, p. 7).

The degree to which a discipline\'s experimental methods are judged
*scientific*, must first be based on the degree to which the discipline
explains, predicts, and controls its subject matter. The measurement and
analysis procedures used in both the experimental and applied branches
of the science of behavior have produced a large and growing body of
empirically sound, reliable data that are used regularly to predict and
control increasingly complex human behaviour of a wide ranging
topography and function. Therefore, it would seem that the methods
employed to produce those data be properly designated as scientific
(Heward & Cooper, 1992, p. 352).

One of the distinguishing characteristics of a natural science is that
it has an agreed procedure for classifying the main elements of its
subject matter. An examination of published behaviour analysis research
indicates that, unlike interpretive researchers and cognitive
scientists, behaviour analysts have developed an agreed procedure for
identifying and classifying (a) different types of behaviour change and
(b) elements of learner interactions which are critical for learning.
They have also developed an agreed set of terms (with agreed meanings)
for referring to the aspects of learning and teaching which they study.
Those relationships between learning history variables and behaviour
change which have been identified as recurring regularities have also
been given agreed upon names. The classifications of the behaviour
analyst may not be the \"right\" ones, or even the most useful ones, but
they are at least agreed upon by the great majority of behaviour
analysts. Nor, of course, do the classifications of the behaviour
analyst encompass all the different kinds of performances,
understandings, beliefs and feelings of which human beings are capable.
But this is also true of the constructs of cognitive science.

Another characteristic of a scientific approach is the development of
absolute scales of measurement and the development of measurement
procedures of known accuracy. Behaviour analysts distinguish between
direct and indirect measures of actions and feelings and they
distinguish between idemnotic and vaganotic measures of change.
Behaviour analysts prefer direct measures of behaviour change (because
the accuracy of these can be assessed) and they prefer idemnotic
measures of behaviour change (because such procedures generate
measurement results which can be compared directly from one study to the
next). Behaviour analysis methods texts always deal with these matters
in some detail.

The reliability and accuracy of the behaviour analyst's observations are
routinely assessed during the course of an investigation and are
routinely reported in research reports so that readers can draw their
own conclusion regarding the believability of the data being reported.
Behaviour analysts prefer experimental modes of analysis since these are
more likely to identify the conditions upon which learning depends than
are descriptive or correlational modes of analysis. Behaviour analytic
experiments are routinely replicated and the results of these
replication attempts are routinely reported in research reports so that
readers can draw their own conclusions regarding the believability of
the effects which have been described in the experimental report.

Hillix and Marx (1974, p. 264) following their review of psychological
theories came to the conclusion that behaviour analysis is \"the closest
thing to a school or paradigm among all modern positions.\" Unlike the
cognitive scientist, the behaviour analyst is \"consistent in attending
only to physical phenomena -- events that are known or at least strongly
suspected to exist. Furthermore, they attempt to explain physical
phenomena only in terms of other physical phenomena\" (Johnston &
Pennypacker, 1993, p. 4). It is this factor, more than any other which
marks behaviour analysis as an example of a natural science.

William Verplanck who worked with B. F. Skinner, the father of behaviour
analysis, has written:

In the long run, the single-subject methodology of behavior analysis
will be accepted by others in the behavioral sciences because it works.
This will take time; how long will depend upon the quality and the
quantity of research done by behavior analysts doing their
single-subject thing. There are few sets of data in behavior-analytic
work to which inferential statistical methods can properly be employed.
And the group experimental methodology now dominant will be left to the
science of epidemiology, sociology, and the like which deal with the
behavior of groups and necessarily neglect the identity and
individuality of the individuals who are members of that group
(Verplanck, November 1998).

A similar view has been expressed by the author of one of the most
influential behaviour analysis textbooks. \"The success of behavior
analysis will be measured by its survival in the behavior of those who
practice it and by the effectiveness of the behavior syntheses that
follow from it\" (Catania, 1998, p. 376).
:::

::: referencesList
#### References

-   Catania, A. C. (1998). Learning (4th ed.). New York: Prentice Hall.
-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Hillix, W. A., & Marx, M. H. (Eds.). (1974). Systems and theories in
    psychology: A reader. St. Paul, MN: West.
-   Verplanck, W. (12 November, 1998). Post to the Behavior Analysis
    List. (Now discontinued.)
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Progressindevelopinganempiricaltheoryoflearning/index.md","# Progress in developing an empirical theory of learning \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8b988c31a98e4b3994870dc31bc61c75}
There are many different kinds of theories about the relationship
between teaching and learning and some of these allow us to make
predictions about what works, and some do not. From a practitioner's
point of view, a theory which allows the teacher to make accurate
predictions is clearly a much more useful theory than one which does
not. Teachers need to be able to determine, from amongst the available
courses of action, those which are most likely to result in the
development of particular kinds of learning in particular kinds of
students.

This means that we need an answer to the question \"Which of the many
approaches to research have actually succeeded in identifying
reproducible relationships between teaching and learning?\" One way of
answering this question is to identify the extent to which each of the
main approaches to research has succeeded in developing a coherent
theory of learning and teaching, that is, a set of empirically validated
\"principles\" which can be used to make predictions about the effects of
different kinds of teaching events on particular kinds of learning
outcomes and/or to make predictions about the conditions under which
different kinds of learning are, and are not, likely to occur.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Progressindevelopinganempiricaltheoryoflearning/Progressmadebycognitivescientistsindevelopinganexplanatorytheory/index.md","# Progress made by cognitive scientists in developing an explanatory theory \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-96b40c768bad4ecbb7417da210ea6ecc}
Studies of learning and teaching based on cognitive theorising and using
a social science methodology have been appearing in research journals
for over 100 years. Notwithstanding recent developments in both
qualitative and behaviour analysis methods, social science procedures
remain the dominant research procedures which are being used to study
learning and teaching (Church, 1998).

First impressions of the social science research into learning and
teaching suggest that this kind of research has been relatively
productive. Somewhere between 25,000 and 50,000 manuscripts a year are
submitted to 350 separate psychology journals (Machado, Lourenço &
Silva, 2000). Several dozen meta-analyses of the research into various
teaching variables have been published and there now exist several
reviews of these meta-analyses (e.g. Lipsey & Wilson, 1993; Walberg,
1986; Walberg & Wang, 1987). The social science research in a number of
fields (child development, special education, teaching, teacher
education, and so on) has been summarised in encyclopaedia length
treatments (e.g. Damon, 1998; Wang, Reynolds & Walberg, 1987; Wittrock,
1986). And the most popular educational psychology textbooks (which rely
primarily on the results of the social science research into learning
and teaching) are substantial text books which have been through many
editions (e.g. Gage & Berliner, 1998; Slavin, 1999; Elliott, Kratochwill
& Cook, 1999).

Closer reading of these encyclopaedias and textbooks, however, reveals a
number of features which are not immediately apparent. To a large
extent, the encyclopaedias of research are not so much summaries of
research as discussions of the various competing theories which have
been advanced to account for perception, cognitive processing, memory,
learning, and the development of different kinds of competencies. In the
educational psychology textbooks, the material on teaching consists
primarily of common sense notions of how to teach buttressed from time
to time by reference to a research study which supports that common
sense notion. As in the encyclopaedias, material on learning is almost
always presented from a variety of theoretical orientations:
developmental views of learning, behaviour-analytic views of learning,
information processing views of learning, and so on. Thirdly, an
analysis of the research citations in both the encyclopaedias and the
textbooks indicates that where research based generalisations are being
advanced, they are often based upon the results of very small number of
empirical investigations - sometimes just a single investigation. In
short, \"voluminous productivity should not be confused with progress\"
(Machado, Lourenço & Silva, 2000).

A number of observers (e.g. Heward & Cooper, 1992; Johnston &
Pennypacker, 1993; Mouly, 1970; Phillips, 1980) have noted that only
very modest progress in theory development has occurred in cognitive
science with multiple conflicting theories being the norm. This is a
fairly modest accomplishment - given that social and cognitive
scientists have been studying the effects of different teaching
variables and procedures, and have been trying to identify the variables
of which learning is a function, for almost a century. (It certainly
falls well short of the social scientist's aim to develop general
theories of learning and of teaching.) As several critics have noted,
research into learning using the methods of social science has resulted
in the collection of a large amount of data but absolutely no consensus
regarding theory (or even the organising concepts) which might be used
to integrate all that data (Bauer, 1992; Gellner, 1984; Machado,
Lourenço & Silva, 2000).
:::

::: referencesList
#### References

-   Bauer, H. H. (1992). Scientific literacy and the myth of scientific
    method. Chicago: University of Illinois Press.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin, New Zealand.
-   Damon, W. (Ed.). (1997). Handbook of child psychology (5th ed.). New
    York: John Wiley & Sons.
-   Elliott, S. N., Kratochwill, T. R., & Cook, J. L. (1999).
    Educational psychology: Effective teaching, effective learning (3rd
    ed.). New York: McGraw Hill Higher Education.
-   Gage, N. L. & Berliner, D. C. (1998). Educational psychology (6th
    ed.). Boston: Houghton Mifflin Company.
-   Gellner, E. (1984). The scientific status of the social sciences.
    International Social Science Journal, 36, 567-586.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Lipsey, M. W. & Wilson, D. B. (1993). The efficacy of psychological,
    educational and behavioral treatment. American Psychologist, 48,
    1181-1209.
-   Machado, A., Lourenço, O., & Silva, F.J. (2000). Facts, concepts and
    theories: The shape of psychology's epistemic triangle. Behavior and
    Philosophy, 28, 1-40.
-   Mouly, G. J. (1970). The science of educational research (2nd ed.).
    New York: Van Nostrand Reinhold Company.
-   Phillips, D. C. (1980). What do the researcher and the practitioner
    have to offer each other? Educational Researcher, 9(11), 17-20.
-   Slavin, R. E. (1999). Educational psychology: Theory and practice
    (6th ed.). Needham Heights, MA: Allyn & Bacon.
-   Walberg, H. J. (1986). Syntheses of research on teaching. In M. C
    Wittrock (Ed.), Handbook of research on teaching (3rd ed., pp.
    214-229). New York: Macmillan Publishing Co.
-   Walberg, H. J., & Wang, M. C. (1987). Effective educational
    practices and provisions for individual differences. In M. C.
    Wang, M. C. Reynolds & H. J. Walberg (Eds.), Handbook of special
    education research and practice, Vol 1 (pp. 113-128). Oxford,
    England: Pergamon Press.
-   Wang, M. C., Reynolds., M. C., & Walberg, H. J. (Eds.). (1987).
    Handbook of special education research and practice, Vol. 1. Oxford,
    England: Pergamon Press.
-   Wittrock, M. C. (Ed.). (1986). Handbook of research on teaching (3rd
    ed.). New York: Macmillan Publishing Co.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Progressindevelopinganempiricaltheoryoflearning/Progressmadebyqualitativeresearchersindevelopinganexplanatorytheory/index.md","# Progress made by qualitative researchers in developing an explanatory theory \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d25eeea6e4944d4cb434726dfd810878}
Qualitative studies of educational sites such as classrooms have been
undertaken for more than 40 years. In 1995 approximately 17 per cent of
the research published in leading journals in learning and teaching were
reports of qualitative studies (Church, 1998). In the teacher education
journals published that year, over half of all published studies were
studies which had used a qualitative methodology.

This research effort has been singularly unproductive. The student of
learning and teaching will find that there are no textbooks summarising
the results of qualitative research into learning and teaching. As far
as can be ascertained, there are not even any review articles
summarising the results of qualitative research into particular aspects
of learning or particular aspects of teaching. The teacher who looks to
the results of qualitative research into learning and teaching will find
nothing in this corpus of research other than the craft knowledge of
other teachers describing what they do and why they do it. The teacher
who examines the qualitative research into learning and teaching will
discover no generalisations which can be used to guide decision making
with respect to motivating students, teaching different kinds of skills
and understandings, or the design of more effective teaching materials.

In part this lack of productivity is due to the fact that qualitative
inquiry was not specifically designed to study learning and teaching.
Because qualitative researchers have developed no agreed categories for
classifying learning outcomes (or the instructional events upon which
these learning outcomes might depend) the results of individual studies
can rarely be compared. Because qualitative researchers have developed
no experimental procedures, they are unable to test the relationships
between teaching events and learning outcomes which are suggested by
their studies.

In part, this lack of productivity is probably due to the fact that
while there is an increasing amount of qualitative research being
undertaken, it is being reported in a way which prevents any evaluation
of the accuracy of the data or the validity of the conclusions. \"There
are few agreed-upon procedures for the reporting of humanistic research.
As a consequence, the quality of such research cannot be verified
because information on the methods employed is lacking\" (Keeves &
Sowden, 1997).

This lack of productivity is probably also due, in part, to the relative
inefficiency of qualitative inquiry as a research method. A single study
may involve several months in the field. For each day spent in the
field, the ethnographer is usually advised to allow at least one day
writing up field notes, transcribing interviews, reflecting upon the
notes and interviews, and deciding what should be looked at next. For
each day spent in the field, the ethnographer is counselled to allow at
least twice that amount of time, following data collection, for data
coding, analysis, interpretation and report writing. \"Effective analysis
requires at least double the time expended on collection of data\"
(LeCompte & Preissle, 1993, p. 239). Not only is qualitative inquiry
enormously time consuming, qualitative researchers routinely collect
\"more data than they can ever analyze. The data for a typical
dissertation study usually runs 700 to 1,500 pages of field notes or
interview transcripts\" (Bogdan & Biklen, 1992, p. 68). \"One researcher
complained that his team of investigators had generated over 25,000
pages of classroom protocols alone\" (LeCompte & Preissle, 1993, p. 239).
The expenditure of such huge amounts of effort for so little return
raises serious questions about why this research method suddenly became
so popular amongst teaching researchers.
:::

::: referencesList
#### References

-   Bogdan, R. C., & Biklen, S. K. (1992). Qualitative research for
    education: An introduction to theory and methods. (2nd ed.). Boston:
    Allyn and Bacon.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin, New Zealand.
-   Keeves, J. P., & Sowden, S. (1997). Descriptive data, Analysis of.
    In J. P. Keeves (Ed.), Educational research, methodology, and
    measurement: An international handbook (2nd ed., pp. 296-306).
    Oxford, England: Pergamon/Elsevier Science Inc.
-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego, CA: Academic
    Press.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Progressindevelopinganempiricaltheoryoflearning/Progressmadebybehaviouranalystsindevelopinganexplanatorytheory/index.md","# Progress made by behaviour analysts in developing an explanatory theory \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-51c8f4a020024a079c3800885be2e539}
Behaviour analytic studies of learning and teaching first began to
appear in the educational literature in 1964 and, over the intervening
period of not much more than 40 years, behaviour analysts have made good
progress in developing a useful procedure for classifying both different
types of learning and different types of variables which affect
learning. Both of these classifications are functional classifications.
Particular classes of events, experiences, and teaching variables are
admitted as classes of events which are worth distinguishing only when
they have been shown (as a result of experimental analysis) to have
predictable effects on the motivation, the performance, or some aspect
of the learning of individuals (Catania, 1998; Johnston & Pennypacker,
1993). (This is a key difference between the development of behaviour
analysis and the development of cognitive science.)

In 1990 some 60,223 people belonged to the American Psychological
Association while only 2,121 (less than 4%) belonged to the Association
for Behaviour Analysis (Heward & Cooper, 1992). In spite of their
relatively small numbers, behaviour analysts have made good progress in
identifying a number of elements of an inductively derived theory of
learning. In behaviour analysis, the integrating statements which have
been developed to date are usually referred to as *principles of
behaviour*. These principles of behaviour, together with examples of the
research from which they are derived, constitute the central content of
most behaviour analysis textbooks (e.g. Catania, 1998; Cooper, Heron &
Heward, 1987; Grant & Evans, 1994; Malott, Whaley & Malott, 1993). The
reader who compares the content of behaviour analysis textbooks will
find that the references in these textbooks are mostly references to
primary sources (that is, to actual experiments) rather than references
to secondary sources and theoretical works as is the case in most
cognitively oriented educational psychology texts. There is also a very
close degree of agreement across all recently written behaviour analysis
textbooks with respect to the technical terms employed, the way in which
these terms are defined, and the way in which they are used.

Thirdly, a cumulative development is occurring within behaviour analysis
research. There is an evolutionary progression in behaviour analysis
textbooks with later textbooks covering a wider set of behaviour
principles than earlier textbooks. Textbooks, written by behaviour
analysts, have appeared for students of child development (e.g.
Schlinger, 1995), students of psychology (e.g. Schlinger & Poling,
1998), student teachers (e.g. Sulzer-Azaroff & Mayer, 1991), and special
education teachers (e.g. Wolery, Bailey & Sugai, 1988). In not much more
than 40 years, behaviour analysts have succeeded in identifying a number
of the variables which affect motivation, the acquisition of new
behaviours and skills, and the retention of new skills over time; and
they have begun to delineate the conditions under which these variables
operate.

Because behaviour analytic theory is an inductively derived theory (that
is, a theory derived from the data) and the principles of behaviour are
generalisations about the functional relationships which exist between
environmental events and behaviour change, it comes as no surprise to
find that behaviour analysts have been very productive in designing
effective procedures for motivating people, for teaching people new
skills and understandings, for helping people overcome fears and
anxieties, for managing inappropriate behaviour and antisocial
behaviour, for accelerating the development of people with disabling
conditions, and so on. For example, the most effective interventions for
helping people overcome phobias and anxieties involve procedures like
systematic desensitisation which have been derived from basic research
into the respondent conditioning process (Barlow, 1988; Ollendick &
King, 1998). The contingency management procedures which have been found
to be most effective in teaching children to respond in prosocial rather
than antisocial ways in their interactions with others have been derived
by behaviour analysts from basic research into differential
reinforcement processes (Brestan & Eyberg, 1998; Church, 2003). Many of
the teaching procedures which have been found to be most effective in
accelerating the progress of low achieving children and children with
learning disabilities have been designed by behaviour analysts (Lloyd,
1988). The names of behaviour analysts also figure prominently in
discussions of cures for stuttering (Gillon & Schwartz, 1998; Onslow,
Menzies & Packman, 2001), cures for toilet training failures (e.g. Foxx
& Azrin, 1973), and so on. Mention should also be made of the many
innovative practices developed by behaviour analysts to accelerate the
development of children with intellectual disabilities (Snell, 1997) and
children with autism spectrum disorders (Rogers, 1998).
:::

::: referencesList
#### References

-   Barlow, D. H. (1988). Anxiety and its disorders: The nature and
    treatment of anxiety and panic. New Work: The Guilford Press.
-   Brestan, E. V. & Eyberg, S. M. (1998). Effective psychosocial
    treatments of conduct-disordered children and adolescents: 29 years,
    82 studies, and 5,272 kids. Journal of Clinical Child Psychology,
    27, 180-189.
-   Catania, A. C. (1998). Learning (4th ed.). New York: Prentice Hall.
-   Church, R. J. (2003). The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Report to the Ministry of Education. University of
    Canterbury: School of Education.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Foxx, R. M., & Azrin, N. H. (1973). Dry pants: A rapid method of
    toilet training children. Behavior Research and Therapy, 11,
    435-442.
-   Gillon, G., & Schwarz, I. (1998). An international literature review
    of best practices in speech and language therapy August, 1998.
    Christchurch, New Zealand: University of Canterbury, Department of
    Speech and Language Therapy.
-   Grant, L., & Evans, A. (1994). Principles of behavior analysis. New
    York: HarperCollins College Publishers.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Lloyd, J. W. (1988). Direct academic interventions in learning
    disabilities. In M. C. Wang, M. C. Reynolds & H. J. Walberg (Eds.),
    Handbook of special education research and practice Vol 2: Mildly
    handicapping conditions (pp. 345-366). Oxford: Pergamon.
-   Malott, R. W., Whaley, D. L., & Malott, M. E. (1993). Elementary
    principles of behavior (2nd ed.). Englewood Cliffs, NJ: Prentice
    Hall.
-   Ollendick, T. H. & King, N. J. (1998). Empirically supported
    treatments for children with phobic and anxiety disorders: Current
    status. Journal of Clinical Child Psychology, 27, 156-167.
-   Onslow, M., Menzies, R. G., & Packman, A. (2001). An operant
    intervention for early stuttering. Development of the Lidcombe
    program. Behavior Modification, 25, 116-139.
-   Rogers, S. J. (1998). Empirically supported comprehensive treatments
    for young children with autism. Journal of Clinical Child
    Psychology, 27, 168-179.
-   Schlinger, H. D. (1995). A behavior analytic view of child
    development. New York: Plenum Press.
-   Schlinger, H. D. & Poling, A. (1998). Introduction to scientific
    psychology. New York: Plenum Press.
-   Snell, M. E. (1997). Teaching children and young adults with mental
    retardation in school programs: Current research. Behaviour Change,
    14, 73-105.
-   Sulzer-Azaroff, B. & Mayer, G. R. (1991). Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart and Winston.
-   Wolery, M., Bailey, D. B. & Sugai, G. M. (1988). Effective teaching:
    Principles and procedures of applied behavior analysis with
    exceptional students. Boston: Allyn and Bacon Inc.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Arediscoveriestodatesufficienttojustifyamovetoevidence-basedpractice/Isthereacorpusofresearchwhichcouldbeusedtoguidedevelopmentsinteachingpractice/index.md","# Is there a corpus of research which could be used to guide developments in teaching practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a9fbffadcc0542ada614018a15290055}
Educational researchers have been studying learning and teaching for
more than 100 years -- since Ebbinghaus's 1885 studies of memory and
Edgar Rice's 1895 studies of the effects of time spent on spelling
practice. During this time, a number of important learning conditions
have been identified and a number of discoveries have been made with
respect to the kinds of teaching procedures which are, and are not,
likely to result in the learning and remembering of new skills and
understandings. Later sections of this website will explore these
discoveries (and the level of empirical support which exists for them)
in greater detail. In the meantime it is sufficient to observe that
there is much which has been discovered but which has yet to become part
of the working knowledge of classroom teachers.

**Contributions from cognitive and social science research**

The earliest contributions to a knowledge base for learning and teacher
were made by social scientists and cognitive scientists. These
contributions are described in most conventional educational psychology
textbooks (e.g. Gage & Berliner, 1998; Slavin, 1999) and have been
summarised in many meta-analyses and reviews of meta-analyses (e.g.
Lipsey & Wilson, 1993). The best indication of what has been found out
as a result of the application of social science methods (as distinct
from the application of common sense) is provided by the meta-analyses.
These reviews list a number of variables which have been found to have
measurable and reproducible effects on remembering - variables such as
the age of the learner, recency, list length, amount of practice,
meaningfulness of the material to be remembered, the quality of the
explanations provided by the teacher, the provision of learning goals
and study questions, procedures which sustain active engagement by the
learner, conditions which motivate self-rehearsal of the material to be
learned, spaced rehearsal, corrective feedback following errors,
explicit or direct teaching, teaching to mastery, the setting and
evaluation of homework, certain types of co-operative learning
procedures, the teaching of certain types of study skills, the teaching
of grapheme and word recognition skills in reading, and so on (Lipsey &
Wilson, 1993; National Reading Panel, Walberg, 1986; Walberg & Wang,
1987; Wittrock, 1986).

It needs to be remembered, however, that these findings refer to the
effects of certain variables *on the average performance of groups of
learners*. The extent to which these findings apply to individual
learners, the kinds of individuals to whom they apply, and the
conditions under which they operate to determine the learning of
individual students cannot be ascertained from the research literature
because these questions have not been studied by researchers who use the
social science methodology.

**Research into behaviour management**

One of the things which drives more teachers out of the teaching
profession than anything else is a lack of skill in motivating poorly
motivated children and managing the behaviour of disruptive and/or
antisocial children (e.g. Brouwers & Tomic, 2000). This does not need to
continue. During the past 35 years, there has been more scientific
research into motivation and behaviour management than there has been
into any other aspect of classroom practice (e.g. Church, 2003). As a
result of this research we now have an extensive and well documented set
of motivational techniques which are known to be highly effective both
in preventing and in remedying all of the commonly occurring types of
classroom behaviour problems (e.g. Alberto & Troutman, 1999; Church,
1999, 2003; Martella, Nelson & Marchand-Martella, 2002). Senior
researchers (e.g. Greenwood, 2001) continue to express amazement that
this knowledge is not part of the working knowledge of all classroom
teachers and is not even part of the curriculum of many teacher
education programmes.

**Research into matching teaching procedures to desired learning
outcomes**

As a result of scientific research we have discovered that there are
different kinds of learning outcomes which teachers need to distinguish
between. This is because different kinds of teaching and practice
conditions need to be provided before the learning and remembering of
different kinds of skills and understandings can occur (e.g. Church,
1999; Engelmann & Carnine 1991). For example, behaviour analysts are
studying the conditions necessary for language development (e.g. Hart &
Risley, 1995; Sidman, 1994); the conditions necessary for the
development of meaning (DeGrandpre, 2000; Sidman, 1994; Skinner, 1957;
Staats, 1968); the conditions necessary for the development of various
kinds of motor skills (e.g. Koop, & Martin, 1983; Ward, Crouch, &
Patrick, 1998), the conditions necessary for the development of
mathematical competencies (e.g. Blankenship & Baumgartner, 1982; Paine,
Carnine, White, & Walters, 1982) and the conditions necessary for the
development of literacy skills including reading (e.g. Carnine &
Silbert, 1979; Gersten, Keating, & Becker, 1988), reading comprehension
(e.g. Bigler, 1984; Bruce & Chan, 1991), handwriting (e.g. Stowitschek,
Ghezzi, & Safely, 1987), spelling (e.g. Dixon, 1993; Okyere, Heron, &
Goddard, 1997), and compositional writing (e.g. Hopman & Glynn, 1988).
Behaviour analysts are also studying the development of self-control
(e.g. Brown, & Frank, 1990; Watson & Tharp, 2002) and creativity (e.g.
Winston & Baker, 1985).

An understanding of the conditions which are necessary in order for
children to acquire different kinds of learning outcomes is essential
knowledge for anyone who is involved in instructional design at any
level.

**Research into adapting instruction to prevent learning failures**

As a result of scientific research we have discovered how to track, from
lesson to lesson, the improvements in new skills and/or understandings
which are occurring during the course of instruction (e.g. Church, 1996;
Deno & Fuchs, 1987; Shapiro, 1996) and we have discovered that the
children of teachers who have mastered these skills learn more (because
their teachers make better adaptive teaching decisions) than the
children of teachers who have not mastered these skills (e.g. Stecker &
Fuchs, 2000).

**Research into maintaining motivation in all children**

We have identified many of the variables which affect motivation. We
have discovered that it is the consequences of student effort (not the
interest level of the activity) which is the most important variable. We
have developed a number of procedures which work to motivate even the
most poorly motivated learners (e.g. Alberto & Troutman, 2002; Martella,
Nelson & Marchand-Martella, 2002; Sulzer-Azaroff & Mayer, 1991) and we
long ago discovered that the children of teachers who have mastered
these procedures learn more (because they get more done) than the
children of teachers who have not mastered these procedures (e.g.
Broughton & Lahey, 1978; Lovitt, Guppy & Blattner, 1969).

**Research into the appropriate level of structure during instruction**

We have discovered that loosely structured teaching arrangements (such
as discovery learning and constructivist learning arrangements) result
in lower levels of understanding and slower rates of mastery for the
great majority of children than do more carefully structured teaching
arrangements (Adams & Engelmann, 1996; Chall, 2002; Church, 1976;
Hermann, 1969; Mayer, 2004). The results of controlled experimental
research stand in stark contrast to the beliefs of classroom teachers
and teacher educators regarding the efficacy of discovery learning.

We have discovered that co-operative learning activities can facilitate
learning but only if each child's learning is monitored and there is
some kind of incentive for group members to tutor each other in an
effective manner (Slavin, 1990). This is a major departure from the way
in which these procedures are currently used by classroom teachers.

**Research into the number of learning opportunities and their
scheduling in time**

We have discovered not only that learning activities must be within the
child's zone of proximal development, but also that it is the number of
times that a child comes into contact with a particular word, fact,
concept or idea which is the most important determinant of whether or
not it will be remembered (e.g. Church, 1976; Greenwood, Delquadri &
Hall, 1984; Greenwood, Hart, Walker & Risley, 1994; Hart & Risley, 1995;
Heward, 1994; McWilliams, 2006; Nuthall, 1999).

Not only have we discovered that the number of learning opportunities is
critical but also that their distribution in time is critical as well.
During knowledge learning tasks, a new item of knowledge is only
remembered if the child gets to work with that idea on at least four
occasions with no more than two days between each learning opportunity
(Nuthall, 1999). This is essential knowledge for anyone who is
responsible for ensuring that children learn and remember particular
skills and understandings.

**Research into the conditions necessary for the development of new
understandings and the avoidance of misunderstandings**

We have identified the critical teaching conditions which must be
provided in order for children to master new understandings and have
developed procedures for explaining and teaching new concepts and rules
which are much more effective than the classroom procedures currently in
use (e.g. Church, 1999; Engelmann & Carnine, 1991; Muthukrishna,
Carnine, Grossen, & Miller, 1993). Of particular importance is the
research into the relative efficiency of different kinds of explanations
and example sequencing operations. This knowledge is essential knowledge
for anyone who is involved in subject matter teaching or instructional
design.

**Research into prompting procedures during the teaching of new skills
and operations**

We have identified many of the critical teaching conditions which must
be provided in teaching new skills and have developed prompting and
scaffolding procedures (for teaching new skills, procedures, and
metacognitive skills) which are much more effective than the procedures
currently used by classroom teachers (e.g. Pressley, Harris & Guthrie,
1992; Wolery, Bailey & Sugai, 1988).

**Research into the conditions necessary for remembering**

We have discovered that recall speed (i.e. level of fluency) is the best
predictor of long term retention. We have developed procedures for
measuring recall speed which are both accurate and simple enough for
everyday classroom use and we are making good progress in identifying
the kinds of practice procedures which are most effective in helping
students achieve a level of fluency sufficient to ensure that essential
skills and understandings are not forgotten (e.g. Binder, Haughton &
Bateman, 2002; Church, 1999; Johnson & Layng, 1994; White and Haring,
1980; Wolery, Bailey & Sugai, 1988). The results of the research into
fluency and fluency building, although essential for planning effective
teaching-practice cycles is almost completely unknown to classroom
teachers.
:::

::: referencesList
#### References

-   Adams, G. L., & Engelmann, S. (1996). Research on Direct
    Instruction: 25 years beyond DISTAR. Seattle, WA: Educational
    Achievement systems.
-   Alberto, P. A., & Troutman, A. C. (1999). Applied behavior analysis
    for teachers (5th ed.). Upper Saddle River, NJ: Prentice-Hall.
-   Bigler, J. K. (1984). Increasing inferential comprehension scores of
    intermediate-age mildly retarded students using two direct teaching
    procedures. Education and Training of the Mentally Retarded, 19,
    132-140.
-   Binder, C., Haughton, E., & Bateman, B. (2002). Fluency: Achieving
    true mastery in the learning process. Retrieved January, 2004, from
    http://www.haughtonlearningcenter.com
-   Blankenship, C. S., & Baumgartner, M. D. (1982). Programming
    generalization of computational skills. Learning Disability
    Quarterly, 5, 152-162.
-   Broughton, S. F., & Lahey, B. J. (1978). Direct and collateral
    effects of positive reinforcement, response cost, and mixed
    contingencies for academic performance. Journal of School
    Psychology, 16, 126-136.
-   Brouwers, A., & Tomic, W. (2000). A longitudinal study of teacher
    burnout and perceived self-efficacy in classroom management.
    Teaching and Teacher Education, 16, 239-253.
-   Brown, D., & Frank, A. R. (1990). \"Let me do it\" - Self-monitoring
    in solving arithmetic problems. Education and Treatment of Children,
    13, 239-248.
-   Bruce, M. E., & Chan, L. K. S. (1991). Reciprocal teaching and
    transenvironmental programming: A program to facilitate the reading
    comprehension of students with reading difficulties. Remedial and
    Special Education, 12, 44-54.
-   Carnine, D., & Silbert, J. (1979). Direct instruction reading.
    Columbus, OH: Charles E. Merrill.
-   Chall, J. S. (2002). The academic achievement challenge: What really
    works in the classroom? New York, NY: Guilford Press.
-   Church, R. J. (1976). A study of the components of an effective
    teaching strategy. Unpublished doctoral dissertation. University of
    Canterbury: Education Department.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North, New Zealand: New
    Zealand Association for Research in Education.
-   Church, R. J. (1999). Instructional Processes. Christchurch, New
    Zealand: University of Canterbury, Education Department.
-   Church, R. J. (2003). The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Christchurch, New Zealand: University of Canterbury,
    Education Department.
-   DeGrandpre, R. J. (2000). A science of meaning: Can behaviorism
    bring meaning to psychological science? American Psychologist, 55,
    721-739.
-   Deno, S. L., & Fuchs, D. (1987). Developing curriculum-based
    measurement systems for data-based special education problem
    solving. Focus on Exceptional Children, 19, 1-16.
-   Dixon, R. C. (1993). The surefire way to better spelling. New York:
    St Martin\'s Press.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications. Eugene, OR: ADI Press.
-   Gage, N. L. & Berliner, D. C. (1998). Educational psychology (6th
    ed.). Boston: Houghton Mifflin Company.
-   Gersten, R., Keating, T., & Becker, W. (1988). The continued impact
    of the direct instruction model: Longitudinal studies of Follow
    Through students. Education and Treatment of Children, 11, 318-327.
-   Greenwood, C. R. (2001). Science and students with learning and
    behavioral problems. Behavioral Disorders, 27, 37-52.
-   Greenwood, C. R., Delquadri, J. C., & Hall, R. V. (1984).
    Opportunity to respond and student academic performance. In W. L.
    Heward, T. E. Heron, D. S. Hill, & J. Trap-Porter (Eds.) Focus on
    behavior analysis in education (pp. 58-88). Columbus: Charles E.
    Merrill Publishing Co.
-   Greenwood, C. R., Hart, B., Walker, D., & Risley, T. (1994). The
    opportunity to respond and academic performance revisited: A
    behavioral theory of developmental retardation and its prevention.
    In R. Gardner, D. M. Sainato, J. O. Cooper, Y. E. Heron, W. L.
    Heward, J. W. Eshleman et al. (Eds.), Behavior analysis in
    education: Focus on measurably superior instruction (pp. 213-223).
    Pacific Grove, CA: Brooks/Cole Publishing Co.
-   Hart, B., & Risley, T. R. (1995). Meaningful differences in the
    everyday experience of young American children. Baltimore: Brookes.
-   Hermann, G. (1969). Learning by discovery: A critical review of
    studies. Journal of Experimental Education, 38, 58-72.
-   Heward, W. L. (1994). Three \"low-tech\" strategies for increasing the
    frequency of active student response during group instruction. In R.
    Gardner, D. M. Sainato, J. O. Cooper, Y. E. Heron, W. L.
    Heward, J. W. Eshleman et al. (Eds.), Behavior analysis in
    education: Focus on measurably superior instruction (pp. 283-320).
    Pacific Grove, CA: Brooks/Cole Publishing Co.
-   Hopman, M., & Glynn, T. (1988). Behavioural approaches to improving
    written expression. Educational Psychology, 8, 81-100.
-   Johnson, K. R., & Layng, T. V. J. (1994). The Morningside model of
    generative instruction. In In R. Gardner, D. M. Sainato, J. O.
    Cooper, Y. E. Heron, W. L. Heward, J. W. Eshleman et al. (Eds.),
    Behavior analysis in education: Focus on measurably superior
    instruction (pp. 173-197). Pacific Grove, CA: Brooks/Cole Publishing
    Co.
-   Koop, S., & Martin, G. L. (1983). Evaluation of a coaching strategy
    to reduce swimming stroke errors with beginning age-group swimmers.
    Journal of Applied Behavior Analysis, 16, 447-460.
-   Lipsey, M. W., & Wilson, D. B. (1993). The efficacy of
    psychological, educational and behavioral treatment. American
    Psychologist, 48, 1181-1209.
-   Lovitt, T. C., Guppy, T. E. & Blattner, J. E. (1969). The use of a
    free-time contingency with fourth graders to increase spelling
    accuracy. Behavior Research and Therapy, 7, 151-156.
-   Martella, R. C., Nelson, J. R., & Marchand-Martella, N. E. (2002).
    Managing disruptive behaviour in the schools: A schoolwide,
    classroom, and individualized social learning approach. Boston:
    Allyn & Bacon.
-   Mayer, R. E. (2004). Should there be a three-strikes rule against
    pure discovery learning? American Psychologist. 59, 14-19.
-   McWilliams, K. G. (2006). An analysis of variables affecting
    instructional efficiency. Unpublished doctoral dissertation.
    Christchurch, New Zealand: University of Canterbury, School of
    Education.
-   Muthukrishna, N., Carnine, D., Grossen, B., & Miller, S. (1993).
    Children\'s alternative frameworks: Should they be directly
    addressed in science instruction. Journal of Research in Science
    Teaching, 30, 233-248.
-   National Reading Panel. (2000). Teaching children to read: An
    evidence-based assessment of the scientific research literature on
    reading and its implications for reading instruction. Retrieved 17
    December, 2001 from National Institute of Child Health & Human
    Development Website: http://www.nichd.nih.gov/ publications/nrp
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Okyere, B. A., Heron, T. E., & Goddard, Y. (1997). Effects of
    self-correction on the acquisition, maintenance, and generalization
    of the written spelling of elementary school children. Journal of
    Behavioral Education, 7, 51-69.
-   Paine, S. C., Carnine, D. W., White, W. A. T., & Walters, G. (1982).
    Effects of fading teacher presentation structure (covertization) on
    acquisition and maintenance of arithmetic problem-solving skills.
    Education and Treatment of Children, 5, 93-107.
-   Pressley, M., Harris, K. R., & Guthrie, J. T. (Eds.). (1992).
    Promoting academic competence and literacy in school. San Diego, CA:
    Academic Press Inc.
-   Shapiro, E. S. (1996). Academic skills problems: Direct assessment
    and intervention (2nd ed.). New York: The Guilford Press.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
-   Skinner, B. F. (1957). Verbal behavior. Englewood Cliffs, NJ:
    Prentice-Hall.
-   Slavin, R. E. (1990). Cooperative learning: Theory, research and
    practice. Englewood Cliffs, NJ: Prentice-Hall.
-   Slavin, R. E. (1999). Educational psychology: Theory and practice
    (6th ed.). Needham Heights, MA: Allyn & Bacon.
-   Staats, A. W. (1968). Learning, language, and cognition. New York:
    Holt, Rinehart and Winston, Inc.
-   Stecker, P. M. & Fuchs, L. S. (2000). Effecting superior achievement
    using curriculum-based measurement: The importance of individual
    progress monitoring. Learning Disabilities: Research and Practice,
    15, 128-134.
-   Stowitschek, J. J., Ghezzi, P. M., & Safely, K. N. (1987). \"I\'d
    rather do it myself:\" Self-evaluation and correction of handwriting.
    Education and Treatment of Children, 10, 209-224.
-   Sulzer-Azaroff, B., & Mayer, G. R. (1991). Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart and Winston.
-   Walberg, H. J. (1986). Syntheses of research on teaching. In M. C
    Wittrock (Ed.), Handbook of research on teaching (3rd ed., pp.
    214-229). New York: Macmillan Publishing Co.
-   Walberg, H. J., & Wang, M. C. (1987). Effective educational
    practices and provisions for individual differences. In M. C.
    Wang, M. C. Reynolds & H. J. Walberg (Eds.), Handbook of special
    education research and practice, Vol. 1 (pp. 113-128). Oxford,
    England: Pergamon Press.
-   Ward, P., Crouch, D. W., & Patrick, C. A. (1998). Effects of
    peer-mediated accountability on opportunities to respond and correct
    skill performance by elementary school children in physical
    education. Journal of Behavioral Education, 8, 103-114.
-   Watson, D. L., & Tharp, R. G. (2002). Self-directed behavior:
    Self-modification for personal adjustment (8th ed.), Belmont, CA:
    Wadsworth/Thomson Learning
-   White, O. R., & Haring, N. G. (1980). Exceptional teaching.
    Columbus, OH: Charles E. Merrill Publishing Co.
-   Winston, A. S., & Baker, J. E. (1985). Behavior analytic studies of
    creativity: A critical review. The Behavior Analyst, 8, 191-205.
-   Wittrock, M. C. (Ed.). (1986). Handbook of research on teaching (3rd
    ed.). New York: Macmillan Publishing Co.
-   Wolery, M., Bailey, D. B., & Sugai, G. M. (1988). Effective
    teaching: Principles and procedures of applied behavior analysis
    with exceptional students. Boston: Allyn and Bacon Inc.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Arediscoveriestodatesufficienttojustifyamovetoevidence-basedpractice/index.md","# Are discoveries to date sufficient to justify a move to evidence-based practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-237abb4cceb84f13bbb83725eb47b735}
There is little point in arguing that \"teaching should be based on
research\" if there is little or no reliable research-based data into how
children acquire different kinds of skills and understandings and how
these kinds of learning might best be facilitated by teachers. This
raises the question of whether our research endeavours have reached the
point where we have accumulated sufficient reliable, research-based
knowledge about learning and teaching to begin the transition from
teaching practices based solely on classroom experience, to teaching
practices which are informed by both research and experience. Have we
yet made sufficient progress in identifying the conditions necessary for
learning to use this knowledge to guide the development of effective
teaching practice? Has our understanding of the conditions necessary for
learning reached the point where this understanding is stimulating
technological advances in teaching methods, materials, and programmes?
Has our ability to explain (and hence predict) teaching effects
developed to the point where we could possibly make research-based
decisions regarding the kinds of classroom teaching activities which
will work best to foster the mastery of different curriculum goals by
individual children at different levels of development?
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Arediscoveriestodatesufficienttojustifyamovetoevidence-basedpractice/Isscientificresearchstimulatingtechnologicaldevelopmentsinteaching/index.md","# Is scientific research stimulating technological developments in teaching \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-859377143cf140cdb6364c2923b3d965}
Not only has the scientific research into learning identified many of
the conditions upon which learning depends, it has also stimulated very
considerable research into the development of teaching programmes which
are more effective and which work for larger numbers of students than is
the case with current classroom teaching programmes. Much of this
technological development can be attributed to the applied research of
behaviour analysts. \"Perhaps in the history of education or psychology,
no other comparatively small minority of scientists/scholars has made
such advancements in practical applications to significant human
behavior within such a short time\" (Heward & Cooper, 1992, p. 357).
Scientifically-based technological developments in teaching include
programmes which result in more rapid progress across all learners than
is currently the case, reading programmes which are effective in
teaching almost all children to read in a timely fashion, maths
programmes which are more effective in teaching maths to all children,
interventions which are effective in treating anxiety disorders,
interventions which are effective in treating disruptive and antisocial
behaviour disorders in children, and so on.

**Technological developments which accelerate progress through the
curriculum**

By combining the discoveries listed in the preceding section in novel
ways, scientifically oriented educational researchers have developed
instructional systems which are much more effective than anything
previously reported in the educational research literature (e.g. Gardner
et al., 1994; Moran & Malott, 2004). These measurably superior teaching
arrangements include Classwide Peer Tutoring (Greenwood, Delquadri &
Hall, 1989; Greenwood et al., 1987), Direct Instruction (Binder &
Watkins, 1990; Kinder & Carnine, 1991), Precision Teaching (Binder &
Watkins, 1990; Lindsley, 1991), Generative Instruction (Johnson & Layng,
1994), the Comprehensive Application of Behaviour Analysis to Schooling
(CABAS) programme (Greer, 1994; Lam & Greer, 1991; Selinske, Greer &
Lodhi, 1991), decision rule systems (Liberty & Haring 1990; Fuchs, Fuchs
and Hamlet, 1994), and the Personalised System of Instruction (Sherman,
Ruskin & Semb, 1982).

Each of these teaching programmes has produced large gains for the
children taking part. Two- to four-fold increases in the rates of
progress of individual students are commonly reported (e.g. Greer, 1994;
Johnson & Layng, 1994). Each of these programmes has produced large
gains across individual learners, across teachers, and across time.

**Teaching programmes which are effective for** ***all*** **children**

More importantly, both behaviour analysts and cognitive scientists have
demonstrated that it is possible to design programmes to teach reading,
maths, and so on which are effective for almost all children. For
example there are now a number of reading programmes which result in 95%
of children learning to read in a timely fashion rather than the 80%
which currently occurs in New Zealand, and reading programmes which
reduce the need for one-to-one tutoring from 20% of the Year 2 cohort to
5% (Church, 2005). Programmes which have proven effective for all
children (including low achieving children and children from
impoverished environments) include the Direct Instruction Reading
programmes (Adams & Engelmann, 1996) and the Success for All Reading
programme (Hopkins, Youngman, Harris & Wordsworth, 2000; Slavin &
Madden, 2001).

**Technological developments in teaching children with special teaching
needs**

The 1998 issue of the *Journal of Clinical Child Psychology* which
reviewed the then current state of development in remedial treatments
for children with special needs showed that very considerable progress
had been made with respect to the design of effective treatments for
children with special teaching needs. In that particular issue, Kaslow
and Thompson (1988) identified a number of probably efficacious
interventions for children and teenagers with depression, Ollendick and
King (1998) identified a number of well established treatments for
children with anxiety disorders, Brestan and Eyberg (1998) identified
several well-established treatments for children with disruptive and
antisocial behaviour difficulties, and Rogers (1998) reviewed the
research into the effectiveness of various teaching programmes for
children with autism. Not only were effective interventions identified
for each of these groups of children, many qualified as well
established, and all had been derived by behaviour analysts from basic
research into the conditions responsible for the development of these
types of developmental problems.

Other reviewers have identified effective interventions for children
with intellectual disabilities (Snell, 1997), for children with
stuttering and other types of speech disorders (Gillon & Schwartz, 1998)
and have extended the findings of the 1998 reviews to identify effective
interventions for children with antisocial behaviour difficulties at
various age levels (Church, 2005).

**Research which demonstrates the possibility of scientifically oriented
clinical teaching research**

One of the defining characteristics of the within-subject approach to
experimentation is that it is a method which can be situated *in*
teaching and used to evaluate the effects of particular teaching methods
on learning *during the course of teaching* (Church, 1975, 1996). In
other words, the repeated measures, within-subject experimental
procedures are ideally suited for scientifically oriented clinical
teaching research in the classroom. This makes it the most powerful of
the various research methods currently available to teachers.

For the first time in the history of research on teaching it is now
possible for classroom teachers to move beyond the action research, the
narrative research and the qualitative research to which they have been
limited and for them to develop forms of practitioner research which are
more closely akin to the clinical research and clinical experimentation
which characterises the more mature professions such as medicine. Unlike
previous forms of practitioner research which were largely narrative and
descriptive, the new clinical teaching research can be experimental and
this creates considerable potential to stimulate improvements in
teaching practice.

Single subject methodology is well suited for teacher research in
schools since it can be situated in ongoing instruction. In fact, it is
employed as an evaluation strategy in just that way in many special
education programs. Data from these evaluations, collected by teachers
in their classrooms with their students, influences choices about
program planning for individuals and for overall curriculum design. . .
. This methodology provides practice-oriented ways for field-based
personnel to learn more about what is effective - and what is not - in
what they do (Neuman & McCormick, 1995, p. 29).
:::

::: referencesList
#### References

-   Adams, G. L., & Engelmann, S. (1996). Research on Direct
    Instruction: 25 years beyond DISTAR. Seattle, WA: Educational
    Achievement systems.
-   Binder, D., & Watkins, C. L. (1990). Precision Teaching and Direct
    Instruction: Measurably superior instructional technology in
    schools. Performance Improvement Quarterly, 3(4), 74-96.
-   Brestan, E. V., & Eyberg, S. M. (1998). Effective psychosocial
    treatments of conduct-disordered children and adolescents: 29 years,
    82 studies, and 5,272 kids. Journal of Clinical Child Psychology,
    27, 180-189.
-   Church, R. J. (1975). Could teachers be doing worthwhile research?
    set, Number 1, Item 5.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North, New Zealand: New
    Zealand Association for Research in Education.
-   Church, R. J. (2005, December). The origins and treatment of delayed
    development in learning to read: A review of research. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin, New Zealand.
-   Fuchs, L. S., Fuchs, D., & Hamlett, C. L. (1994). Strengthening the
    connection between assessment and instructional planning with expert
    systems. Exceptional Children, 61, 138-146.
-   Gardner, R., Sainato, D. M., Cooper, J. O., Heron, T. E., Heward, W.
    L., Eshleman, J, & Grossi, T. A. (Eds.). (1994). Behavior analysis
    in education: Focus on measurably superior instruction. Pacific
    Grove, CA: Brooks/Cole Publishing Co.
-   Gillon, G., & Schwarz, I. (1998). An international literature review
    of best practices in speech and language therapy August, 1998.
    Christchurch, New Zealand: University of Canterbury, Department of
    Speech and Language Therapy.
-   Greenwood, C. R., Delquadri, J. C. & Hall, R.V. (1989). Longitudinal
    effects of classwide peer tutoring. Journal of Educational
    Psychology, 81, 371-383.
-   Greenwood, C. R., Dinwiddie, G., Bailey, V., Carta, J. J.,
    Kohler, F. W., Nelson, C. et al. (1987). Field replication of
    classwide peer tutoring. Journal of Applied Behavior Analysis, 20,
    151-160.
-   Greer, R .D. (1994). The measure of a teacher. In R. Gardner et al.
    (Eds.), Behavior analysis in education: Focus on measurably superior
    instruction (pp. 161-171). Pacific Grove, CA: Brooks Cole.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Hopkins, D., Youngman, M., Harris, A., & Wordsworth, J. (2000).
    Evaluation of the initial effects and implementation of Success For
    All in England. Journal of Research in Reading, 22, 257-270.
-   Johnson, K. R., & Layng, T. V. J. (1994). The Morningside model of
    generative instruction. In R. Gardner et al. (Eds.), Behavior
    analysis in education: Focus on measurably superior instruction (pp.
    173-197). Pacific Grove, CA: Brooks/Cole Publishing Co.
-   Kaslow, N. J., & Thompson, M. P. (1998). Applying the criteria for
    empirically supported treatments to studies of psychosocial
    interventions for child and adolescent depression. Journal of
    Clinical Child Psychology, 27, 146-155.
-   Kinder, D., & Carnine, D. (1991). Direct instruction: What it is and
    what it is becoming. Journal of Behavioral Education. 1: 193-213.
-   Lam, N., & Greer, R. D. (1991). A systematic replication and a
    comparative analysis of CABAS. Journal of Behavioral Education, 1:
    427-444.
-   Liberty, K. A., & Haring, N. G. (1990). Introduction to decision
    rule systems. Remedial and Special Education, 11(1), 32-41.
-   Lindsley, O. R. (1991). Precision teaching's unique legacy from B.F.
    Skinner. Journal of Behavioral Education, 1, 253-266.
-   Moran, D. J., & Malott, R. W. (Eds.). (2004). Evidence-based
    educational methods. San Diego, CA: Elsevier Academic Press.
-   Neuman, S. B. & McCormick, S. (Eds.). (1995). Single subject
    experimental research: Applications for literacy. Newark, NJ:
    International Reading Association.
-   Ollendick, T. H., & King, N. J. (1998). Empirically supported
    treatments for children with phobic and anxiety disorders: Current
    status. Journal of Clinical Child Psychology, 27, 156-167.
-   Rogers, S. J. (1998). Empirically supported comprehensive treatments
    for young children with autism. Journal of Clinical Child
    Psychology, 27, 168-179.
-   Selinske, J. E., Greer, R. D., & Lodhi, S. (1991). A functional
    analysis of the comprehensive application of behavior analysis to
    schooling. Journal of Applied Behavior Analysis, 24, 107-117.
-   Sherman, J. G., Ruskin, G., & Semb, G. B. (Eds.). (1982). The
    Personalised System of Instruction: 48 seminal papers. Lawrence, KS:
    TRI Publications.
-   Slavin, R. E., & Madden, N. A. (Eds.). (2001). One million children:
    Success for all. Thousand Oaks, CA: Corwin Press
-   Snell, M. E. (1997). Teaching children and young adults with mental
    retardation in school programs: Current research. Behaviour Change,
    14, 73-105.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Howmuchscientificevidenceisrequiredtojustifyachangetoevidence-basedteachpractice/index.md","# How much scientific evidence is required to justify a change to evidence-based teach practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-14f2ddb3934c4fd8bd02ef67c895bb86}
Some generalisations about the conditions necessary for learning, or the
effects of a given teaching practice on learning have no research
support, some are supported by the results of a single investigation and
some are supported by the results of many investigations by different
teams of researchers. This raises the question of many times a research
finding result needs to be replicated before it is admitted to the
research base for teaching practice.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Howmuchscientificevidenceisrequiredtojustifyachangetoevidence-basedteachpractice/Levelsofempiricalsupport/index.md","# Levels of empirical support \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-002b2675da69484aa9e3aa27653f5dcc}
Education researchers have engaged in little discussion of the amount of
empirical evidence which would be required in order to justify a claim
that a given practice qualified as \"evidence based\". This changed in
1994 when the members the Clinical Child Psychology section of Division
12 (the Clinical Psychology division) of the American Psychological
Association established a task force to examine the evidence regarding
the effectiveness of various psychosocial interventions for children.
This task force decided to classify the interventions which are
currently being used to treat children with depression, anxiety
disorders, behaviour problems and autism into three general categories:
(a) not yet empirically validated, (b) probably efficacious, and (c)
well-established. These criteria were first published as the lead
article in an entire issue of the *Journal of Clinical Psychology*
devoted to reviews of empirically supported interventions for children
(Lonigan, Elbert & Johnson, 1998). In compiling these reviews, the
following definitions were used.

**Not yet empirically validated**

This classification is reserved for interventions which do not yet meet
the criterion for a probably efficacious intervention. This
classification does not mean that the intervention is ineffective. It
means either (a) that few or no controlled evaluations of the
intervention have been published, or (b) the number of controlled
evaluations is less than that required for probably efficacious status,
or (c) the controlled evaluations which have been undertaken to date
fail to demonstrate that the intervention is an effective intervention.

**Probably efficacious**

The criteria to be met before an effective intervention can be
classified as *probably efficacious* (from Lonigan et al., 1998) are as
follows:

1.*Either* the existence of two randomised groups evaluations which meet
the criteria for a well established intervention but conducted by the
same investigators.

*Or* the existence of at least two randomised groups evaluations showing
that the intervention is more effective than a no-treatment or waiting
list comparison group.

2.*Or* the existence of at least 4 well designed single-case experiments
which compare the intervention to another intervention.

3.The existence of a treatment manual for the intervention is preferred
but not required.

4.The characteristics of the children in each trial have been clearly
specified.

**Well established**

The criteria to be met before an intervention can be classified as
*well-established* are as follows:

1.*Either* the existence of at least two well-conducted randomised
groups evaluations (with adequate statistical power), conducted by
different research teams, showing the intervention to be either superior
to a placebo or alternative intervention or else as effective as some
other well established intervention.

2.*Or* the existence of at least 10 well designed single-case
experiments which compare the intervention to another intervention.

3.The existence of a treatment manual for the intervention is preferred
but not required.

4.The characteristics of the children in each trial have been clearly
specified.

**Comments**

Since its introduction, there has been some discussion of the merits of
this scheme. A summary of the main points of contention will be found in
Fonagy, Target, Cottrell, Phillips and Kurtz (2002). The main
observation which needs to be made is that the criterion for
between-groups evaluations seems to have been set very low (only two
studies are required) whereas the criterion for within-subject
evaluations seems to have been set very high (at least 10 studies). In
addition the within-subject experiments cannot just measure
effectiveness by introducing the intervention, they must compare the
effectiveness of the intervention under investigation against the
effectiveness of some other intervention. This almost never happens in
behaviour analysis research (a) because measuring the effects of
introducing a new intervention provides a better measure of
effectiveness than trying to compare the relative rates of improvement
under two alternating intervention conditions in a child and (b) because
once the effects of an intervention have been replicated three or four
times investigators inevitably move on to systematic replication studies
designed to explore the generality of the effect, that is, to find out
who the intervention works for and under what conditions. By requiring
conditions which are never met in practice, the Task Force has set up a
situation in which only randomised groups evaluations can contribute to
the decision as to whether or not a particular intervention qualifies as
empirically supported either at the probably efficacious level or at the
well established level.
:::

::: referencesList
#### References

-   Fonagy, P., Target, M., Cottrell, D., Phillips, J., & Kurtz, Z.
    (2002). What works for whom? A critical review of treatments for
    children and adolescents. New York: The Guilford Press.
-   Lonigan, C. J., Elbert, J. C., & Johnson, S. B. (1998). Empirically
    supported psychosocial interventions for children: An overview.
    Journal of Clinical Child Psychology, 27, 138-145.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/index.md","# Is a move to evidence-based teaching practice feasible at this time? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0f0bb88dd7f4490b9b6b8ed51c0f93e4}
It is increasingly being argued that \"teaching should be based on
research\" (e.g. Darling-Hammond & Bransford, 2005; Kameenui, Carnine,
Dixon, Simmons & Coyne, 2002). However, education researchers sometimes
ask cause and effect questions and sometimes do not, sometimes use an
appropriate research method to examine questions about learning and
teaching and sometimes do not, and sometimes collect believable data
about the effects of teaching on learning and sometimes do not. This
variability in the research methods which are being used to study
learning and teaching gives rise to all sorts of methodological debates
and all sorts of questions about whether a move to evidence-based
teaching practice is feasible at this time. In this chapter we examine
some of these questions from the point of view of what has, and has not,
been achieved to date.

In Section 1 we examine the questions about the extent to which
education researchers are selecting appropriate research methods --
appropriate in the sense that they could conceivably answer the question
which is being asked.

In Section 2 we ask whether the move to evidence based practice should
be based on the entire corpus of research into learning and teaching or
just the scientific research and identify some of the characteristics
which research would need to meet before it could be said to support a
move to evidence based practice.

In Section 3 we discuss the question of how much research evidence would
be needed to justify a move from a particular craft-based practice to an
evidence-based version of that practice.

Section 4 addresses the question of whether our discoveries to date are
sufficient to justify a move to evidence-based teaching practice in
certain areas.

Section 5 asks what progress, if any, has been made in developing an
empirical theory of the conditions necessary in order for various kinds
of learning to occur.
:::

::: referencesList
#### References

-   Darling-Hammond, L. & Bransford, J. (Eds.). (2005). Preparing
    teachers for a changing world: What teachers should learn and be
    able to do. San Francisco, CA: Jossey-Bass.
-   Kameenui, E. J., Carnine, D. W., Dixon, R. C., Simmons, D. C., &
    Coyne, M. D. (2002). Effective teaching strategies that accommodate
    diverse learners (2nd ed.). Columbus, OH: Merrill.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchinwhichthequestionaskeddeterminestheresearchmethod/Questionswhichcanandcannotbeaddressedbybehaviouranalysismethods/index.md","# Questions which can and cannot be addressed by behaviour analysis methods \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-016768dec73242beb066a24a1c789b4c}
Unlike the social science procedures, behaviour analysis research
procedures were specifically designed to study behaviour change
(learning) in individual learners. At the present time, therefore, it is
clearly the method of choice for the researcher who seeks to answer
questions about changes over time in the motivation, performance,
language use, competence, understandings, feelings, or beliefs of
individual children and adults.

Secondly, the direct observation and functional analysis procedures
developed by behaviour analysts are the appropriate procedures to use
when seeking the answer to diagnostic questions such as why a particular
individual is behaving in a particular way, or having difficulty in
mastering a particular new skill or understanding, or failing to make
the progress which is expected, or feeling unmotivated, or experiencing
debilitating levels of anxiety in certain situations, and so on.

Behaviour analytic observation procedures are the most appropriate
procedures to use when monitoring or measuring the rate of progress of
individual learners towards a particular teaching or therapeutic goal.
This kind of information is often needed by parents, teachers and
therapists who must make decisions about whether a particular teaching
procedure or programme is working and, if not, whether it should be
changed and, if so, how it should be changed. This kind of information
is also essential for the teacher or student teacher who seeks to engage
in reflective practice. Without an accurate knowledge of what individual
children have and have not learned as a result of a teaching activity
there is nothing to reflect upon.

Fourthly, the within-subject experimental procedures of the behaviour
analyst are the research procedures which are most likely to make a
contribution to our developing understanding of the factors upon which
motivation, attitude, learning and retention depend. They are the
research procedures of choice for any teacher, teacher educator, or
researcher who is interested in questions about whether a given kind of
experience or teaching variable has a particular kind of effect on
motivation or learning and, if so, the conditions under which this is
the case. In other words, behaviour analysis research procedures are the
most appropriate procedures for measuring the relative effectiveness of
particular teaching procedures in assisting particular types of learners
to achieve particular kinds of learning outcomes.

Behaviour analysis research methods were developed by researchers who
were interested in meeting conventional scientific standards of data
accuracy and reproducibility. So they are the research methods of choice
for the scientific study of how and when learning occurs. This includes
questions about the conditions which are necessary in order for a
particular kind of learning to occur and questions about the generality
of previously discovered environment-behaviour and teaching-learning
relationships.

As with any research method there are, of course, many questions which
cannot be studied using the single case, time series research procedures
of behaviour analysis. These procedures cannot be used to find the
answer to epidemiological or prevalence questions, they cannot be used
for large scale programme evaluations, and they have not been designed
to provide in-depth descriptions of the activities, beliefs and social
conventions of those who live, work, or learn together in a particular
setting.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchinwhichthequestionaskeddeterminestheresearchmethod/Questionswhichcanandcannotbeaddressedbyethnographicmethods/index.md","# Questions which can and cannot be addressed by ethnographic methods \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-19a988fbda7e4f6e9a58b57f14bb0314}
Ethnographic research methods have a smaller role to play in the study
of settings in which learning and teaching occur. They are, however,
well suited to answering certain kinds of questions about these
settings. Ethnographic procedures are often appropriate when seeking an
answer to the question \"What is going on here?\" Ethnographic research
can provide information about what people do, how they interact with
each other, and what the consequences are of different courses of action
in particular settings. This information can serve as a base for
speculation regarding the particular events which need to be examined in
greater detail in future investigations.

Secondly, ethnographic procedures can also be appropriate when seeking
answers to questions about what is important in a particular setting.
For example, \"What are the questions which we need to ask?\" or \"What are
the key variables which are operating in this setting?\"

Thirdly, ethnographic procedures can be appropriate when seeking answers
to questions about what a person needs to know in order to function
effectively in a particular setting. Ethnography can often answer
questions about the social rules, the conventions and the contingencies
which operate in a particular setting. This kind of information is of
particular interest to behaviour analysts who are interested in
discovering how it is that people learn to engage in certain behaviours
but not others in particular settings. Fourthly, ethnographic research
can provide useful information regarding the perspectives of the
individuals who live or work in a particular context -- information
about whether, for example, they like or dislike what they are expected
to do, or what is happening to them, and why this might be the case.

There are also many kinds of questions which *cannot* be addressed using
ethnographic research procedures. Because ethnography examines only the
actions, meanings, and perspectives of individuals it cannot be used to
answer questions about the prevalence of particular beliefs, behaviours,
practices, or contingencies within a particular society or social group,
it cannot be used to identify the way in which resources are being
distributed across social groups, and it cannot be used to measure the
outcomes which are being achieved by groups or populations of learners,
teachers, classrooms, or schools. To answer these kinds of questions,
the researcher must employ the sampling procedures of the social
scientist.

In addition, ethnographic research is always descriptive. So it cannot
be used to answer questions which require an experimental analysis. It
cannot be used to answer questions about how learning occurs, questions
about the relative effectiveness of different kinds of teaching
materials or teaching procedures, or questions about the relationships
between particular teaching variables and particular learning outcomes.
Most importantly it cannot be used to answer questions about whether a
particular teaching programme or procedure is working and, if not, why
it is not working or how it could be made more effective.

Because the accuracy of the data collected during an ethnographic study
(and the validity of the conclusions drawn from that data) are always
open to question, ethnographic research cannot be used as the primary
methodology in any kind of high stakes research. It cannot be used to
measure the achievements of students or to collect data which may affect
the promotion, grading, or qualifications of students. It cannot be used
to measure teacher effectiveness or to collect data which may affect the
promotion, credentialing or employment conditions of teachers. And it
cannot be used to measure the effectiveness of particular kinds of
educational programmes or curricula or to collect data which may affect
the funding or the provision of the educational programmes being
provided to particular groups of students. In other words, ethnographic
research should not be used in any situation where the results of that
research could conceivably be used to support a case for a change in the
curriculum, a change in teaching materials, a change in the teaching
resources available for learners, or a change in the employment
conditions of teachers.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchinwhichthequestionaskeddeterminestheresearchmethod/index.md","# Research in which the question asked determines the research method? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-61fa762972e5472aa6c3f7deee163a5e}
Research begins with the selection of an appropriate question. Research
into learning and teaching begins with the selection of an appropriate
question about the conditions which are necessary in order to bring
about a particular kind of learning outcome in children at a particular
point in their development. The best questions are those which are based
on a detailed knowledge of what has and has not yet been discovered
about the conditions governing learning.

Once a worthwhile question has been selected, the next task is to select
an appropriate research method, that is, the research method which is
most likely to provide a believable answer to the question. In order to
make this decision we need to be very clear about the kinds of questions
which can and cannot be addressed by the various methods available. All
too often teaching researchers first select a research method (e.g. the
one that they learned about in their research methods course) and then
hunt around for a question which can be studied using that method. To
avoid this mistake, teaching researchers need to be very clear about the
questions which can and cannot be addressed by within-subjects,
randomised groups and ethnographic methods.
:::"
".//Typesofresearchevidence/Isamovetoevidence-basedteachingpracticefeasibleatthistime/Researchinwhichthequestionaskeddeterminestheresearchmethod/Questionswhichcanandcannotbeaddressedbysocialscienceresearch/index.md","# Questions which can and cannot be addressed by social science research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4299d0e65d5d416688877abe7d9a6c51}
The group-statistical methods of the social scientist also have a useful
role to play in research into learning and teaching. Because social
scientists study the performance of groups of people, the social science
methodology is well suited to finding the answers to questions about
groups or populations of learners, teachers, classrooms, or schools.

The research procedures of the social scientist are the appropriate
procedures to use when seeking the answer to epidemiological and
prevalence questions. A social science procedure would be the
appropriate procedure for finding out the proportion of children who
engage in antisocial or disruptive behaviour in the classroom, or the
proportion of children who are more than two years delayed in learning
to read, for example.

Social science procedures can also be used to compare the prevalence of
a particular characteristic in various subgroups of learners (to compare
the prevalence of children with behaviour problems at different age
levels, for example); or to compare the prevalence of particular
characteristics at various points in time (to compare the prevalence of
first grade children with behaviour problems at 10 year intervals, for
example); or to compare the prevalence of a particular characteristic
across different settings or geographical locations (to compare the
literacy levels of 13-year olds in England, France and the USA, for
example).

Social science procedures are the appropriate procedures to use when
measuring the degree of correlation, in a particular population, between
two or more aspects of performance (such as the correlation between
behaviour problems and below average progress in learning to read, for
example) and when measuring the degree of correlation between system
variables (such as family income) and outcome variables (such as level
of achievement in reading, for example).

The group-statistical procedures of the social scientist are also the
most appropriate procedures for policy and programme evaluations. They
are well suited to providing answers to questions about the average
effect on the performance of learners and/or teachers of changes in
policy, changes in resources, changes in teaching materials, changes in
teaching procedures, and such like, at the school, district, or national
level. It would be appropriate to use a social science methodology to
evaluate the impact of a new remedial reading programme for 7-year olds
by measuring the relative rates of progress in reading of stratified
random samples of reading delayed 7-year olds who had, and had not, been
assigned to the new remedial programme, for example.

There are also many kinds of questions which *cannot* be addressed using
the group-statistical procedures of the social scientist.

The social science methodology cannot be used to study learning. This is
because learning occurs in individuals, because learning involves a
change (over time) in motivation, behaviour, understanding, skill level,
feelings, or belief, and because the research methods of the social
scientist were not designed to observe and record transition states in
individuals.

Because the group-statistical methods of the social scientist cannot be
used to study learning, they cannot be used to answer questions about
the conditions upon which motivation, learning, understanding and
retention depend, they cannot be used to answer diagnostic questions
about why particular individuals respond in the way that they do to
particular social or instructional cues, and they cannot be used to
answer questions about whether a particular motivational, teaching, or
practice procedure is working and, if not, why it is not working for
particular learners.

Nor are social science research procedures appropriate for measuring the
effects of particular teaching practices, teaching materials or
therapeutic interventions on the performance, understanding or beliefs
of individual learners. This is because, in a between-groups comparison,
the effects of treatment variables and the effects of learning history
variables are always confounded.

In spite of 100 years of effort, the social science methodology has been
found to be a less than satisfactory procedure for generating useful
theories of learning, motivation, or remembering. This is partly because
the constructs of cognitive science tend to be defined structurally and
operationally (rather than functionally), partly because cognitive
scientists spend the bulk of their time engaged in premature theorising
(rather than in observing changes in motivation, competence and recall)
and partly because social and cognitive scientists ignore the
individuals in which these changes are occurring.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whattypesofexplanationaresoughtbythethreemainapproachestoresearch/Thetypesofexplanationsoughtbyethnographers/index.md","# The types of explanation sought by ethnographers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3ddc7da42a4f4ccb8b7f46296ba46311}
Ethnographers typically use the word *theory* to refer to the set of
generalisations or assertions which appear to be warranted with respect
to the data collected during the course of a particular ethnographic
study. That is, they use the word theory to refer to the grounded theory
which emerges from the analysis of a field work database. Grounded
theory is a local theory, that is, \"an aggregate of local
understandings\" (Lincoln & Guba, 1985, p. 205).

Ethnographers seem to be ambivalent about the utility of grounded
theory. For some the theory (that is, the assertions or conclusions)
which result from a particular study cannot and should not be
generalised. For others, these conclusions can function in much the same
way as the hypotheses of the social scientist. Theory \"is open-ended and
can be extended indefinitely; . . . it can also be used to predict and
to generate hypotheses for test. Grounded theory can play the role of
conventional theory for any subsequent study (one need not return to
\'ground zero\' in each new inquiry)\" (Lincoln & Guba, 1985, p. 206).

Regarding the question of whether or not qualitative research might
eventually discover cause and effect relationships, ethnographers have
expressed a variety of conflicting views. Some qualitative researchers
argue that one of the central aims of ethnographic research *is* to
identify enduring generalisations. \"The search is . . . for *concrete
universals*, arrived at by studying a specific case in great detail and
then comparing it with other cases studied in equally great detail. The
assumption is that when we see a particular instance of a teacher
teaching, some aspects of what occurs are absolutely generic, that is,
they apply cross culturally and across human history to all teaching
situations\" (Erickson, 1986, p. 130).

Some qualitative researchers argue that the aim of qualitative inquiry
is not to discover big generalisations but simply to identify little
generalisations or working hypotheses. \"The aim of inquiry is to develop
an idiographic body of knowledge in the form of \'working hypotheses\'
that describe the individual case\" (Lincoln & Guba, 1985, p. 38).

A third group of qualitative researchers take the position that any
search for generalisations is bound to fail, that there can be no
generalisations regarding human learning which hold up over time and
place, and that any search for functional relationships,
cause-and-effect relationships, or laws of learning must therefore be a
fruitless search. \"The interpretive-idealist approach to research
rejects the possibility that laws will ever be found\" (Smith, 1983, p.
12). Guba and Lincoln (1997, p. 87) argue that \"Human relationships are
caught up in such an interacting web of factors, events, and processes
that the hope that \'the\' cause-effect chain can be sorted out is vain;
the best the enquirer can hope to establish are plausible patterns of
influence.\" One implication of this position is that the effect of
particular instances of teaching (or any other type of educational
intervention) can never be predicted. \"Interventions can be mounted, but
without any assurance, *regardless of prior evaluation,* that they will
in fact produce the outcomes hoped for\" (Lincoln & Guba, 1985, p. 157).

Most ethnographers are interested in explaining the events which they
have observed. \"Naturalists as well as other varieties of
postpositivists retain a need for *explanation*\" (Lincoln & Guba, 1985,
p. 151). Explanations are sought in the meanings which individuals
attribute to their actions. \"From the interpretive-idealist perspective,
the purpose of investigation should be . . . interpretive understanding
. . . the investigator seeks to understand the nature of the activity
and the meaning that the actor assigns to his or her own actions - the
\'why\' of the activity\" (Smith, 1983, p. 12). Interpretation of the
reasons why participants have behaved in the way that they have requires
the researcher also to identify the explicit and the implicit social
rules which operate in the setting under examination. In order to
understand human action \"We need to identify the rules under which it
falls because they are what give its meaning. The rules under which
actions fall are reflected in the intensional content of the desires and
beliefs that lead to them. That is why desires and beliefs explain
action. Human action is thus a matter of following rules, and the aim of
social science is to uncover these rules\" (Rosenberg, 1995, p. 93).
Rosenberg further notes that this is \"not a new thesis; indeed, Plato
argues explicitly in the *Phaedo* . . . that human action can only be so
understood\" (Rosenberg, 1995, p. 91).

For some qualitative researchers, meanings, purposes, perspectives, and
so on exist in a *causal* relationship to behaviour. Qualitative
researchers refer to these intentional explanations as *interpretations*
and refer to their mode of explanation as interpretivist or
hermeneutical. (These two words mean the same thing.) \"If people take
action on the grounds of their interpretations of the actions of others,
then meaning-interpretations themselves are causal for humans\"
(Erickson, 1986, p. 127).

For other qualitative researchers, the meaning of an action is simply
part of its description - the meaning of an action has no causal status
(a position which is closely similar to that taken by behaviour
analysts). \"In seeking to uncover the meanings of action, Verstahen
explanations do not regard intentions, purposes and motives as some
\'inner\' mental event that somehow causes overt physical behaviour to
occur. Rather, it recognizes that \'intentions\' and \'motives\' refer .
. . to what it is that permits the actions being observed to be
described as actions of a particular sort. Intentions and motives are
not \'behind\' actions, functioning as their invisible mental \'cause\'.
Motives and intentions are intrinsically related to actions as part of
their definition and meaning\" (Carr & Kemmis, 1986, p. 90).

This preference for intentional explanations is usually justified by
arguing either (a) that intentional explanations provide a sufficient
explanation for human conduct, or else by arguing (b) that, in human
affairs, functional relationships have not been (and could not ever be)
identified. The first claim, that intentional explanations are
sufficient to provide an explanation of human conduct is open to at
least six criticisms.

1\. If intentional explanations explain anything at all, they explain
only a part of human conduct. A considerable portion of human behaviour
is not intentional; it is reflex, it is automatic, it occurs as a
reaction to events. If a person acts in a shocked manner after an
accident it makes no sense to inquire into the intention or purpose of
the disoriented behaviour and racing heart. If a person acts in a
depressed manner following the loss of a close friend it makes no sense
to inquire into the intention or purpose of the depressed behaviour. If
a person suddenly recalls a conversation held earlier in the week it
makes no sense to inquire into the intention or purpose of the sudden
recollection. Likewise it makes no sense to advance intentional
explanations for breathing, for talking one\'s native language, for
turning to see who has called your name, or for feeling elated or
frightened or sick, to give just a few examples.

2\. Actions not only have purposes, they also have outcomes or effects
(consequences) and these effects are often quite different from the
intended purpose of an action. A teacher takes a particular lesson in a
particular way with the aim or intention of developing a particular
understanding on the part of the children but the *effect* of the lesson
is to leave the children as confused as they were before the lesson.
Accounts which ignore the effects or consequences of human action ignore
a factor which has a most powerful effect on how someone handles a
particular situation on future occasions.

3\. It is fairly clear that intentional explanations cannot be used to
explain (account for) human learning (the development of new
competencies). *Improvements* in performance are a function of
experience and practice (amongst other things). Asking someone to
explain why they engaged in a particular action provides no explanation
of where the ability to perform that action came from in the first
place, how the ability to perform that action was acquired, how the
informant learned to respond in that particular fashion rather than in
some other fashion, or why that particular way of behaving continues to
be used. Critics argue that finding the answers to these latter
questions is actually more important than asking individuals why they
have engaged in particular acts.

4\. Very young children are unable to answer questions about the meaning
or purpose of the things which they do. The ability to give verbal
justifications for particular behaviours in terms of intentions and
purposes is a learned skill. How we learn the intentional idioms of
everyday language (how we learn to justify what we do both to ourselves
and to others) is one of the things which needs to be explained. \"If . .
. a belief causes a response, then one must ask where the belief came
from\" (Baum & Heath, 1992, p. 1315). \"The interpretive model neglects
questions about the origins, causes and results of actors adopting
certain interpretations of their actions and social life\" (Carr &
Kemmis, 1986, p. 95). In fact, some critics (e.g., Lee, 1988) argue that
what needs to be explained is both the behaviour and its purpose
together as a single unit. To be useful, an explanation must provide a
plausible account not only of where the behaviour came from but where
the accompanying belief in the effectiveness of that particular
behaviour came from.

5\. It is hard to see how an improved understanding of learning and
teaching could ever result from a research activity which is limited to
simply reproducing the interpretations (that is, the everyday
explanations) which ordinary people already give for what they do. If
research has a purpose the purpose must be to take us beyond what we can
find out simply by canvassing people\'s opinions of how learning occurs.

6\. Finally, it is important to remember that the once universal role
played by intentional explanations has been steadily diminishing for
more than half a century. \"The moral of the story is that the appeal to
intentions has been as ruthlessly read out of biology has it was cast
out of physics. . .. This leaves only the social sciences as the last
refuge of an explanatory strategy that started, over two thousand years
ago, as the ruling paradigm in all science\" (Rosenberg, 1995, p. 64). It
can be argued that, since the physical, biological and medical sciences
have dispensed with intentional explanations, so too should the
cognitive sciences. \"Who would seriously suggest that evolutionary
biologists should have held onto the intentional idioms that were common
before the theory of natural selection? The objection hardly ever comes
up because almost everyone sees that getting rid of intentional idioms
represented an advance for biology. If it is absurd to hold onto
intentional idioms in biology, it is equally absurd to hold onto them in
psychology\" (Baum & Heath, 1992, p. 1317).

The second claim, that, when it comes to human affairs, functional
relationships are in principle unidentifiable simply ignores both common
sense and the results of 90 years research into learning and teaching.
The claim that there are no known regularities of human conduct is
clearly not true as far as learning research is concerned. It is clear
from reviews of the experimental literature that a number of enduring
and reproducible relationships between experience and learning have been
identified both by cognitive scientists (e.g., Lipsey & Wilson, 1993)
and by behaviour analysts (e.g., Cooper, Heron & Heward, 1987). When
appropriate research procedures are employed, reproducible relationships
can even be identified by applying a qualitative methodology. For
example, the decision by Nuthall and Alton Lee to record everything
which happened during sets of classroom lessons led to the
identification of relatively clear-cut relationships between the number
and timing of the learning interactions experienced by individual
children and what was learned and remembered by those children. This
research further demonstrated that these relationships exist across
learners, across classrooms, and across different curriculum topics
(see, for example, Nuthall, 1999). The Nuthall results provide a
powerful disconfirmation of the often-voiced claim that classroom life
is too complex to permit the discovery of reproducible relationships
between children\'s experience and children\'s learning.

The claim that there are no known relationships between experience and
human conduct is not even true at the level of everyday experience. If
there were no regularities in human conduct, then conversation and
communication would be impossible, social organisation would be
pointless, and schooling would be a total waste of money. Everyday
experience provides multiple examples of predictability in human
affairs. This predictability occurs both at the level of particulars
(people say that they will meet you at a particular time and this
prediction frequently turns out to be true) and at the level of
generalisations (children learn to speak the language of their parents,
listeners are able to understand and to respond to speakers, children
become more competent in the skills which they practise than in skills
which they do not, and so on).

Thirdly, *even if no relationships had been found between experience and
learning*, this does not mean that such relationships cannot be
discovered. It simply means that no such relationships have been
discovered yet. This could be because we have been using the wrong
research method, or because the research effort has been insufficient,
or because the research is being undertaken by people who believe that
generalisations regarding human learning are unlikely to be identified
and that there is, therefore, little point in looking for them.

It is true that intentional explanations are often used in everyday
speech and that they are often accepted as legitimate reasons
(justifications) during ordinary conversations. However, they cannot be
used as scientific explanations for, while they may appear to explain
why someone engaged in a particular action, they provide no explanation
for classes of actions and no explanation for those changes in behaviour
which we refer to as learning.
:::

::: referencesList
#### References

-   Baum, W. M., & Heath, J. L. (1992). Behavioral explanations and
    intentional explanations in psychology. American Psychologist, 47,
    1312-1317.
-   Carr, W., & Kemmis, S. (1986). Becoming critical: Education,
    knowledge and action research. London: The Falmer Press.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Erickson, F. (1986). Qualitative methods in research on teaching.
    In M. C. Wittrock (Ed.), Handbook of research on teaching (3rd ed.,
    pp. 119-161). New York: Macmillan.
-   Guba, E. G., & Lincoln, Y. S. (1997). Naturalistic and rationalistic
    enquiry. In J.P. Keeves (Ed.), Educational research, methodology,
    and measurement: An international handbook (2nd ed., pp. 86-90).
    Oxford, England: Pergamon/Elsevier Science Inc.
-   Lee, V. L. (1988). Beyond behaviorism. Hillsdale, NJ: Lawrence
    Erlbaum Associates.
-   Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly
    Hills, CA: Sage Publications.
-   Lipsey, M. W., & Wilson, D. B. (1993). The efficacy of
    psychological, educational and behavioral treatment. American
    Psychologist, 48, 1181-1209.
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Rosenberg, A. (1995). Philosophy of social science (2nd ed.).
    Boulder, CO: Westview Press.
-   Smith, J. K. (1983). Quantitative vs. qualitative research: An
    attempt to clarify the issue. Educational Researcher, 15(1), 4-12.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whattypesofexplanationaresoughtbythethreemainapproachestoresearch/Thetypesofexplanationsoughtbybehaviouranalysts/index.md","# The types of explanation sought by behaviour analysts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9668643d8228489d93dcccba2c8ba1dc}
The primary aim of behaviour analysis research is to identify functional
relationships between behaviour and the physical and social environments
in which it occurs.

Because behaviour analysts from Skinner onwards have argued against the
hypothetico-deductive method of theory building it is often assumed that
behaviour analysts are uninterested in theory development. This is not
true. Skinner was committed to the development of theory. \"A theory is
essential to the scientific understanding of behavior as a subject
matter\" (Skinner, 1947/1961, p. 230). What behaviour analysts have
avoided is theorising which attempts to explain behaviour in terms of
\"events taking place somewhere else, at some other level of observation,
described in different terms, and measured, if at all, in different
dimensions\" (Skinner, 1950/1961, p. 39).

The theory which is of interest to behaviour analysts is not the
speculative theory of the cognitive scientist but an inductively derived
theory, that is, theory which arises as a way of summarising the results
of large numbers of controlled observations. This approach to theory has
been summarised by Zuriff in the following way. \"A formulation using a
minimal number of terms to represent a large number of experimental
facts is a theory. As the theory develops, it integrates more facts in
increasingly more economical formulations. Theoretical concepts thus
merely collate observations and do not refer to nonbehavioral processes.
A Skinnerian theory is, therefore, a simple, comprehensive, and abstract
description of a corpus of data\" (Zuriff, 1985, p. 89). Behaviour
analytic theory, that is, the set of statements concerning the
relationships between particular classes of environmental events and
particular classes of behaviour are referred to by behaviour analysts as
*principles of behaviour*.

Behaviour analysts (like most natural scientists) work on the assumption
that the natural phenomena in which they are interested (behavioural
variability in individuals) is determined and that a search for the
determinants of behavioural variability is, therefore, a worthwhile
research endeavour. Determinism is assumed because, unless this is the
case, functional relationships cannot be discovered and research is
pointless. \"If we are to use the methods of science in the field of
human affairs, we must assume behavior is lawful and determined. We must
expect to discover what a man does is the result of specifiable
conditions and that once these conditions have been discovered, we can
anticipate and to some extent determine his actions\" (Skinner, 1953, p.
6).

For behaviour analysts, an account does not meet the definition of an
explanation unless it allows the scientist to predict future instances
of learning and to control future instances of learning (for example, to
control instructional variables to produce a particular kind of learning
outcome). The aim of behaviour analysis is to \"predict and control the
behavior of the individual organism. This is our \'dependent
variable\' - the effect for which we are to find the cause\" (Skinner,
1953, p. 35). The pursuit of this goal requires the behaviour analyst to
look for the causes of behaviour change amongst those events which might
allow both prediction and control, that is amongst the external
conditions of which behaviour may be a function (Hayes & Brownstein,
1986).

For the behaviour analyst, the development of particular ways of
behaving, thinking and feeling occurs, in part, as a result of biology
(the genetic template transmitted at conception) and, in part, as a
result of experience during the life of the individual. \"Behavior is a
joint function of *phylogenic contingencies*, those that operated in
ancestral environments during the evolution of a species, and *ontogenic
contingencies*, those that operated during interactions between an
organism and its environment within its own lifetime\" (Catania, 1998, p.
39). \"Some aspects of behavior are highly determined by evolutionary
factors (e.g., the human vocal apparatus) and others by experience
(e.g., the human language one speaks)\" (Catania, 1998, p. 371).

The origins of learned behaviours are conceptualised in evolutionary or
historical terms. For the behaviour analyst, the development of new
behaviours is a function of past experiences - especially the models
provided by other individuals and the contingencies of reinforcement and
punishment which have operated when particular kinds of responses have
been made in the past. Behaviour analysts assume that how a person
responds today (including the choices which he or she makes) is
determined by past experiences. \"Behavior analysts think of the shaping
of behavior as working in just the same way as the evolution of the
species. Just as differences in reproductive success (fitness) shape the
composition of a population of genotypes, so reinforcement and
punishment shape the composition of an individual\'s behavior\" (Baum,
1994, p. 64).

According to the behaviour analyst, the shaping of behaviour over time
is possible because (a) we engage in particular actions on many
occasions with the passage of time, (b) each time we engage in a
particular action there is some variation in its performance, and (c)
different versions of the same action are more or less successful (i.e.
result in different levels of reinforcement or punishment). In order to
study the shaping of behaviour, therefore, the investigator must (a)
monitor or track repeated instances of a given action over time (in
order to see whether it is being shaped), and (b) track the outcomes
(the success of that behaviour) each time it is performed (in order to
identify the events which are always present when particular kinds of
behaviour change occur). Elements of an individual\'s learning history
can only be studied by direct observation, they cannot be studied by,
say, interviewing the individual because individuals are unable to
recall (describe) each of the hundreds of interactions (and their
outcomes) which occurred during the shaping of a particular skill,
understanding, belief, or feeling.

Baum (1994) argues that, just as the theory of natural selection
provided the first scientific account of evolution and gradually
replaced pre-scientific explanations in terms of God\'s design,
intelligence, or purpose, so the historical explanations of the
behaviour analyst attempt to provide a scientific account of the origins
of behaviour and to replace pre-scientific explanations couched in terms
of individual design, intelligence, purpose, intention, soul, or mind.

The historical explanations of the behaviour analyst are quite different
from the intentional explanations of the interpretive researcher and the
intentional explanations of everyday language. They are also quite
different from the immediate cause, dispositional and mechanistic
explanations of the social scientist. Behaviour analysts take particular
care to avoid the practice, common in both everyday language and in much
psychological theorising, of attributing particular actions to internal
events, cognitions, traits, mediating processes, and other unobservable
fictions. Sometimes we say

that an idea, a feeling or a hunch led someone to do something. The
behaviorist doesn\'t dispute the existence of ideas, feelings and
hunches, but rather criticizes their invocation as causes of behavior. .
. . it isn\'t enough to say that someone did something because of an
idea, a feeling or a hunch. Ideas, feelings and hunches are about the
world and therefore must have their origins in our experiences with the
world. We must look further, to these past experiences . . . to account
for what we do. If we\'re successful, we may also have something useful
to say about the origins of our ideas, feelings and hunches (Catania,
1998, p. 4).

The historical explanations of the behaviour analyst have a number of
advantages for the researcher who is interested in the study of learning
and teaching. Historical explanations focus the investigator\'s
attention on the experiences and interactions which are likely to be
generating improvements in learner performance and understanding.
Historical explanations generate relational statements which can be
studied experimentally in an attempt to determine when, where, and to
whom they apply. Historical explanations of known generality can be used
to make predictions of the form that \"if I provide such-and-such a set
of experiences then such-and-such a change in what this student can do
will result.\"

The behaviour analyst\'s historical explanations in a physical
vocabulary refer to observable events which teachers can do something
about. Because they enable predictions with respect to individual
learners, they are of far greater use to teachers than either
intentional explanations or mechanistic explanations. Teachers cannot
arrange for a child to have a particular perspective, mental structure,
memory, or mind. But they can arrange for a child to have a particular
set of experiences. So if particular kinds of learning turn out to be a
function of particular kinds of experiences then, once these
relationships have been identified, teachers will be able to arrange the
kinds of experiences which result in particular kinds of learning
outcomes with a much greater degree of certainty than they can at
present.

The search for historical explanations for learning \"directs attention
toward functional school variables that can be modified by teachers
rather than toward hypothetical in-child (or family) dysfunctions and
\'causes\' that cannot\" (Leach, 1996, p. 9).

Historical explanations are often difficult to grasp when first
encountered because they are so different from the intentional and
mentalistic accounts provided by the structure and concepts of everyday
language. Everyday language predisposes us \"toward seeking explanations
in causes present at the moment of action. . . people are unaccustomed
to grouping actions along the lines of function - that is, along the
lines of what they accomplish, rather than how they look\" (Baum, 1994,
p. 72). Just as mastery of the technical language of behaviour analysis
requires a certain amount of training so too does mastery of the ability
to look for the causes of behaviour change, not in the mind, memory or
perspective of the learner, but in the history of previous interactions
involving the skills, understandings and beliefs which are of interest.
:::

::: referencesList
#### References

-   Baum, W. M. (1994). Understanding behaviorism: Science, behavior and
    culture. New York: HarperCollins College Publishers.
-   Catania, A. C. (1998). Learning (4th ed.). New York: Prentice Hall.
-   Hayes, S .C., & Brownstein, A. J. (1986). Mentalism,
    behavior-behavior relations, and a behavior-analytic view of the
    purposes of science. The Behavior Analyst, 9, 175-190.
-   Leach, D. L. (1996). Applying behavioural psychology in education:
    Contributions and barriers to the implementation of effective
    instruction. Behaviour Change, 13, 3-19.
-   Skinner, B. F. (1947/1961). Current trends in experimental
    psychology. In B. F. Skinner, Cumulative record (Enlarged ed., pp.
    223-241). New York: Appleton-Century-Crofts.
-   Skinner, B. F. (1950/1961) Are theories of learning necessary?
    In B. F. Skinner, Cumulative record (Enlarged ed., pp. 39-69). New
    York: Appleton-Century-Crofts.
-   Skinner, B. F. (1953). Science and human behavior. New York: The
    Macmillan Co.
-   Zuriff, G. E. (1985). Behaviorism: A conceptual reconstruction. New
    York: Columbia University Press.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whattypesofexplanationaresoughtbythethreemainapproachestoresearch/index.md","# What types of explanation are sought by the three main approaches to research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ae2b4e9a47fe4085b38774cdf070a661}
Causal explanations tend to be the most useful kinds of explanations
because they enable prediction and, hence, can be used as a guide to
action. In the social sciences, causal explanations are often referred
to as functional explanations and the search for causes is often
referred to as the search for functional relationships. \"The goal of
experimentation is to learn enough about the effects of the independent
variable on the dependent variable to be able to show that the dependent
variable depends on or is a function of the independent variable and
nothing else. When this goal has been fully accomplished, it is called a
*functional relation*\" (Johnston & Pennypacker, 1993, p. 238).
:::

::: referencesList
#### References

-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whattypesofexplanationaresoughtbythethreemainapproachestoresearch/Thetypesofexplanationsoughtbycognitivescientists/index.md","# The types of explanation sought by cognitive scientists \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e3b6401407dd48b9a2a9cbb2a33532b6}
Most cognitive scientists work on the presumption \"that there are
general laws that hold across individuals\" (Borg & Gall, 1989, p. 24)
and that the aim of research into an area such as learning and teaching
should be to develop theories which integrate all of the known facts
about these phenomena. Cognitive scientists use the term *theory* to
refer to a set of statements which identify the relationships between
the various constructs which go to make up their subject matter. \"The
basic aim of science is to find general explanations of natural events.
Such general explanations are called theories\" (Kerlinger, 1964, p. 10).
The discovery of such generalisations is considered to be important
because they permit prediction and control of the events which are of
interest (human behaviour). \"The purpose of science is to establish
functional relationships among phenomena with a view to predicting and,
if possible, to controlling their occurrence\" (Mouly, 1970, p. 39). The
types of generalisations which are of primary interest to the cognitive
scientist are generalisations regarding causal relationships (sometimes
referred to as functional relationships) at the population level. Social
scientists are relatively uninterested in the performance of
individuals.

When social scientists study effects, they study the effects of two main
kinds of variables: treatment variables and attribute variables.
\"Treatment variables are those factors that the experimenter manipulates
and to which he or she assigns subjects\" (Best & Kahn, 1993, p. 137).
Attribute variables are also referred to as organismic variables or as
assigned variables. \"Attribute variables are those characteristics that
cannot be altered by the experimenter. Such independent variables as
age, sex, race, and intelligence level have already been determined, but
the experimenter can decide to include them or remove them as variables
to be studied\" (Best & Kahn, 1993, p. 137). The use of attribute
variables as independent variables is a key difference between cognitive
science and behaviour analysis. For the cognitive scientist, variability
in a measure of performance (such as level of motivation) can function
as either a dependent variable (the variable to be explained) or as an
independent variable (a possible explanation). For the behaviour analyst
variability in a measure of performance can only function as a dependent
variable (the phenomenon to be explained).

Generally speaking the explanatory theories of cognitive scientists take
the form of immediate cause theories in a non-physical vocabulary. Two
types of explanation are common: dispositional explanations, and
mechanistic explanations.

**Dispositional explanations.** To account for the fact that the same
external event or stimulus may be responded to in different ways by
different individuals, the cognitive scientist often invents
hypothetical constructs which take the form of internal dispositions,
traits, motivations, and so on. These traits are introduced to bridge
the gap between experience and subsequent performance. \"The scientist .
. . in order to study motivation . . . cannot measure it directly
because it is an in-the-head variable, an intervening variable, an
unobservable entity. Other men have invented the construct to stand for
\'something\' *presumed to be* inside the individual, \'something\'
prompting him to behave in such and such manner\" (Kerlinger, 1964, p.
44). All explanations which attribute differences in performance to
differences in intelligence, ability, achievement motivation,
self-esteem, self-efficacy, locus of control, and so on are explanations
of this type.

**Mechanistic explanations.** An even more common way of accounting for
differences in human performance under test conditions is to use some
kind of mental structure or cognitive processing variable to bridge the
gap between experience and subsequent performance. This type of
explanation frequently takes the form of an attempt to build some kind
of mental *model.*

Many of these explanatory models are models of memory. Atkinson and
Shiffrin (1968), for example, hypothesised that performance on recall
tests depends upon the operation of a sensory register, a short term
store, a long term store, and a number of transient control processes.
The effect of past experience is to leave a trace, representation, or
memory in the long term store so that when the learner faces a similar
problem, the mind is activated, and the response is recalled.

Also popular are information processing models which assume that what is
recalled is a function of various mental processing activities which
occur during the input, processing, storage, and retrieval of new
information. \"Most work in cognitive science assumes that the mind has
mental representations analogous to computer data structures, and
computational procedures similar to computational algorithms. Cognitive
theorists have proposed that the mind contains such mental
representations as logical propositions, rules, concepts, images, and
analogies, and that it uses mental procedures such as deduction, search,
matching, rotating, and retrieval\" (Thagard, 1996). The aim of all of
these mental models is to explain

a behavioural system by specifying the component parts of its structure
just as a person examining a car would readily explain its action by an
appeal to its component parts. . . .The conditions that gave rise to
this structure or the ways we can manipulate it are irrelevant to the
description of the operation of the machine and predictions based upon
this description. . . . Thus, for mechanists, description and
theoretical prediction form an adequate basis for explanation (Hayes &
Brownstein, 1986, p. 180).

All explanations which attempt to account for changes in human
performance in terms of memory structures or processes, cognitive
structures or processes, mental structures or processes, or brain
structures or processes are of this type.

The main weakness of a mechanistic explanation is that, while it may
provide an adequate description of how the car (or remembering)
operates, it provides no explanation of how the car (or the memories)
came into existence in the first place. If the aim is to build a car (or
a learner who can do or remember certain things) then a structural or
mechanistic theory is insufficient.

If the aim is to develop a theory of learning, then structural models
also send us searching for the causes of behaviour change in the wrong
place: inside the head of the learner instead of in the interaction
between behaviour and the environment in which it is occurring.
\"Behaving organisms, human or otherwise, are not mechanical structures
to be likened to telephone exchanges and networks, information
processing systems, computer storage banks and so on. They are
biological organisms that operate within a context that affects their
behavior and which they in turn have an effect upon and that are changed
by their experience in that context\" (Chiesa, 1992, p. 1296). Ulric
Neisser, who has been sharply critical of behaviour analysis, has come
to much the same conclusion. \"I think that \'memory\' in general does
not exist . . . It is a concept left over from a medieval psychology
that partitioned the mind into independent faculties: \'thought\', and
\'will\' and \'emotion\' and many others, with \'memory\' among them.
Let\'s give it up and begin to ask our questions in different ways\"
(Neisser, 1982, p. 12). For Neisser, more useful questions would be
questions about the naturally occurring conditions under which people do
and do not remember different kinds of performances and understandings.

More importantly, the mental models of the cognitive scientist often
consist of mental structures and processes which cannot be observed,
even by the learner. Explanations which make use of mentalistic
constructs pose a particular difficulty for those who seek to apply
scientific methods to the study of learning. Mental fictions \"offer for
study objects that cannot be observed. Neither memory nor mind can be
observed. How shall we study them?\" (Baum & Heath, 1992, p. 1313). No
other science employs explanatory constructs couched in a non-physical
vocabulary. The use of hypothetical constructs which cannot be observed
creates numerous problems.

1\. The use of constructs which cannot be observed means that the
cognitive scientist is free to generate whatever constructs he or she
desires. Chiesa uses the example of research into remembering. When
observations of remembering revealed phenomena that were inconsistent
with the short-term/long term memory constructs, researchers such as
Baddeley and Hitch (1974) simply created additional constructs: the
central executive, the visuo-spatial scratchpad, the articulatory loop,
and so on (Chiesa, 1992, p. 1297).

2\. When instances of a construct cannot be observed, the social
scientist is free to attribute to the construct whatever properties he
or she desires. Referring to the Baddeley and Hitch model of
remembering, Chiesa observes that \"Since all of the constructs of the
model are hypothetical, they may take on whatever features or properties
the scientist decides\" (Chiesa, 1994, p. 156). This often results in the
construct being used to serve several different functions. For example,
cognitive scientists often fail to state whether they are using the name
of a particular construct to refer to (a) a particular category of
behaviours (e.g., \"we measured *memory* for lesson content by . . .\", or
(b) a particular process (e.g., \"*memory* for lesson content is affected
by the meaning which the child constructs . . .\"), or (c) a particular
structure or location (e.g., \"this information is then transferred to
long-term *memory . . .*\"), or (d) a cause, that is, the reason why
people engage in particular behaviours (e.g., \"the learner is able to
recall lesson content more accurately when *memory* consists of a rich
network of connections\").

3\. When a hypothetical construct takes the form of a mentalism it can
be (and often is) used not only as the name of a class of performances
but also as an explanation for that class of performances. \"This is what
we did with the construct *instinct* years ago. We spoke of maternal
instinct as if it explained maternal behavior when, in reality, we had
simply exchanged one level of verbal ignorance for another - we had
described what we were alleging to explain\" (Mouly, 1970, p. 60).

4\. It can be argued that the introduction of a mentalism serves no
scientific purpose. It violates the parsimony principle by complicating
rather than simplifying the scientist\'s account; it \"increases the
mystery, rather than decreasing it\" (Hineline, 1992, p. 1284). Let us
say that a researcher is interested in the question of whether the use
of concrete examples results in higher scores on tests of conceptual
understanding. If a series of experiments find this to be the case,
nothing is added to our understanding of this relationship by arguing
that the concrete examples produce stronger memory traces and that it is
these stronger memory traces which produce the higher average scores on
tests of conceptual understanding.

5\. It can also be argued that the introduction of a mentalism serves no
practical purpose. It introduces an hypothetical entity over which
parents, teachers, and therapists can have no influence. How is reading
to be improved if \"the source of the problem is said to lie in a
malfunctioning articulatory loop? How would a . . . teacher restore to
full and proper functioning a hypothetical component?\" (Chiesa, 1992, p.
1297).

The use of mental models and invisible mental processes as \"causes\" of
ability and disability has a particularly unfortunate side effect when
used in education.

When children regularly fail to meet expected academic standards, they
direct the attention of teachers and support staff towards a search for
explanations and causes for the \'failure\' that lie amongst children\'s
psychological, neurological, or information processing abilities. . . .
In isolation, they often lead to restatements of problems in global
categorical terms describing hypothetical dysfunctional syndromes (e.g.,
dyslexia, attention deficit disorder, learning disability). They rarely
lead to better decision-making, nor to more effective instructional
design and delivery for individual students . . . . Indeed, their net
result is to focus the attention of educators away from critical
analyses of their instructional practices and programs (Leach, 1996, p.
11).

Finally, the immediate cause explanations of the cognitive scientist
frequently involve a mediating entity which is a disposition or trait
which has been inferred from behaviour. These dispositional explanations
almost always involve a form of circular reasoning commonly referred to
as *reification*. First an aspect of performance is observed (e.g., a
lower than expected level of reading competence). Then the behaviour is
renamed (e.g., dyslexia). Then the new name is used as an explanation
for the originally observed performance. (This student has a lower than
expected level of reading competence *because* of his dyslexia.) Since
the dyslexia has been inferred *from the reading performance* this
explanation is tautological. (We might as well say that \"the reason why
this student is reading at a low level is because I have seen him
reading poorly.\")
:::

::: referencesList
#### References

-   Atkinson, R. C., & Shiffrin, R. M. (1968). Human memory: A proposed
    system and its control processes. In K. W. Spence & J. T. Spence
    (Eds.), The psychology of learning and motivation: Advances in
    research and theory (Vol. 2) pp. 89-105. New York: Academic Press.
-   Baddeley, A. D., & Hitch, G. J. (1974) Working memory. In G. H.
    Bower (Ed.), Recent advances in learning and motivation (pp. 47-89).
    London: Academic Press.
-   Baum, W. M., & Heath, J. L. (1992). Behavioral explanations and
    intentional explanations in psychology. American Psychologist, 47,
    1312-1317.
-   Best, J. W., & Kahn, J. V. (1993). Research in education (7th ed.).
    Boston: Allyn and Bacon.
-   Borg, W. R., & Gall, M. D. (1989). Educational research: An
    introduction (5th ed.). New York: Longman.
-   Chiesa, M. (1992). Radical behaviorism and scientific frameworks:
    From mechanistic to relational accounts. American Psychologist, 47,
    1287-1299.
-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Hayes, S .C., & Brownstein, A.J. (1986). Mentalism,
    behavior-behavior relations, and a behavior-analytic view of the
    purposes of science. The Behavior Analyst, 9, 175-190.
-   Hineline, P. N. (1992). A self-interpretive behavior analysis.
    American Psychologist, 47, 1274-1286.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Leach, D. L. (1996). Applying behavioural psychology in education:
    Contributions and barriers to the implementation of effective
    instruction. Behaviour Change, 13, 3-19,
-   Mouly, G. J. (1970). The science of educational research (2nd ed.).
    New York: Van Nostrand Reinhold Company.
-   Neisser, U. (1982). Memory observed: Remembering in natural
    contexts. San Francisco: W.H. Freeman & Co.
-   Thagard, P. (1996). Cognitive Science. In N. Zalta (Ed.), Stanford
    Encyclopedia of Philosophy. Retrieved 15 January, 2001 from
    http://plato.stanford.edu/entries/cognitive-science/
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whatunitsofanalysisareusedbythethreemainapproachestoresearch/Theunitsofanalysisemployedbycognitivescientists/index.md","# The units of analysis employed by cognitive scientists \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b1a28bb011f04628a52b3b005fc7f385}
Cognitive scientists divide human abilities, performances, attitudes,
beliefs, and so on into classes, which they refer to as constructs or
variables, for the purposes of study and analysis. The kinds of
constructs which have been of interest to cognitive scientists may be
found by consulting any dictionary of psychological terms (e.g., Reber,
1995). Some of the constructs of cognitive science refer to performances
or performance qualities, for example, aggression, motivation, teaching
style, and so on. Some constructs refer to skills and abilities, for
example, phonemic awareness, spatial ability, reading comprehension,
metacognitive skills, recall, and so on. Some constructs refer to
attainments or achievements, for example, oral language development,
reading level, mathematics achievement, examination performance, and so
on. Some constructs refer to traits or personal qualities, for example,
attachment, anxiety, hostility, conservativism, intelligence, locus of
control, learning style, self-efficacy, self-esteem, and so on. And some
refer to external or environmental conditions, for example,
socioeconomic status, preschool attendance, discovery teaching methods,
co-operative teaching methods, and so on.

As can be seen from the preceding examples, the constructs employed by
cognitive scientists are similar to the concepts of everyday language.
Just as natural language categories tend to distinguish between
different classes of behaviour on the basis of their form, topography or
structure, so do the constructs of the cognitive scientist.

Some of the constructs studied by cognitive scientists are used both as
dependent variables (measures of learning) and as independent variables
(factors thought to affect learning). \"The student should be alert to
the possibility of a variable being an independent variable in one study
and a dependent variable in another\" (Kerlinger, 1964, p. 410). To
illustrate this point Kerlinger describes two studies, one which seeks
to measure the effects of certain testing procedures on anxiety (anxiety
level is the dependent variable), and one which seeks to measure the
effects of anxiety on examination performance (anxiety level is the
independent variable).

The constructs of cognitive science can serve this dual function (as
both dependent and as independent variables) because the methodology
allows the use of organismic variables as independent variables in the
search for those factors which affect learning and achievement. \"Any
property of an individual, any characteristic or attribute, is an
organismic variable. . . . Organismic variables are those
characteristics that individuals have in varying degrees when they come
to the research situation\" (Kerlinger, 1964, p. 42n).

Like the constructs of social science in general, the constructs used by
cognitive scientists tend to refer to highly generalised attributes,
that is, to very large classes of behaviour. There are hundreds of
thousands of questions which could be used to measure a person\'s level
of mathematics achievement (at the upper levels) and literally millions
of problem solving questions which could be used to measure a person\'s
level of intelligence. The cognitive scientist attempts to solve this
problem by the use of operational definitions. \"Operational definitions
are those in which a concept is defined by the operations used to
measure it\" (Sax, 1968, p. 123).

The importance of operational definitions cannot be overemphasised. They
are indispensable ingredients of scientific research because they enable
researchers to measure variables and because they are bridges between
the theory-hypothesis-construct level and the level of observation.
There can be no scientific research without observations, and
observations are impossible without clear and specific instructions on
what and how to observe. Operational definitions are such instructions
(Kerlinger, 1964, p. 35).

Advances in the natural sciences have resulted from the realisation that
the concepts of everyday language are not the concepts which are
required in order to make sense of the natural world. In the social
sciences, however, almost all analyses are undertaken using the concepts
contained in everyday language.

There has been almost universal agreement that the descriptive
categories common sense has used since the dawn of history are the right
ones. Traditionally, what we have wanted to know in social science is
the causes and consequences of our actions and we hold that these
actions are determined by our desires and our beliefs. Accordingly
social scientists have long searched for models, generalizations and
ultimately laws connecting actions, beliefs and desires (Rosenberg,
1995, p. 15).

A particular grouping of behaviours, or motives, or beliefs, is only
useful as a scientific construct if it can be shown to be related in
some lawful fashion to other constructs or events. However, much
cognitive science research \"fails to note that the mere identification
of a variable is no guarantee that it is going to be of any use. New
measuring instruments in the behavioral sciences can be developed very
easily. The great difficulty is to discover and develop variables that
have predictive value. This . . . does not result from any mechanical
procedure\" (Travers, 1978, p. 312).

Critics of the social scientist's use of constructs derived from
everyday language argue that the majority of social science constructs
fail this critical test. They have never been shown to be closely
related to any other construct or event. They argue that

The basic categories of social science are wrong. The reason no laws
have been uncovered is that the categories of action, desire, belief and
their cognates have prevented us from discovering the laws. . . . the
terms \"desire,\" \"belief,\" \"action,\" do not name natural kinds. They just
do not carve nature at the joints. Like our example \"fish,\" every
generalization that employs those terms is so riddled with exceptions
that there are no laws we can discover stated in these terms. . . The
social sciences are rather like chemistry before Lavoisier: trying to
describe combustion in terms of \"phlogiston,\" instead of \"oxygen,\" and
failing because there is no such thing as \"phlogiston\" (Rosenberg, 1995,
pp. 15-16).

When a series of investigations arrives only at a relatively trivial and
unfalsifiable generalisation, this often signals investigation into a
construct of no scientific value. Take, for example, the conclusion that
such-and-such is multiply determined, e.g., \"the research into
aggression suggests that aggressive responses are multiply determined.\"
This kind of conclusion almost always hides the fact that there are
probably different kinds of, say, aggression, that each of these
different types of aggression is under the control of a different set of
variables, and that the important research into these different types of
aggression has yet to be undertaken.

Like the concepts of everyday language, the constructs of cognitive
science tend to refer to rather large classes of competencies. This
means that they cannot be studied until they have been operationalised,
that is, until a suitable test has been decided upon. This in turn
presents social scientists with a number of practical difficulties.

First, it leads to disputes regarding the particular tests which should
be used to measure a given construct. Should intelligence be measured
using a general intelligence test, a non-verbal intelligence test, a
culture fair intelligence test, or what?

Secondly it leads to disputes regarding the nature of the construct. Is
there just one kind of intelligence, or are there several kinds of
intelligence? If there are several kinds of intelligence what are they?
Much cognitive and social science writing consists of theoretical
discussions of how many different instincts there are, how many
different kinds of intelligence there are, how many different motives
there are, how many different kinds of memory there are, and so on.

Thirdly, it leads to disputes about the validity of the measures which
have been used in particular investigations. Readers who believe that a
particular construct should be measured using a particular test may
disregard the results of investigations which measure that construct
using other kinds of tests - because, in their view, these other tests
do not provide a valid measure of the construct of interest. These
disputes tend to remain unresolved because social scientists have never
developed any kind of procedure for resolving them.

Fourthly, the use of different tests to measure the \"same\" construct
makes the task of collating and summarising research extremely
difficult. If the research on self-esteem has used 15 different measures
of self esteem, how should this problem be handled? Logically, the use
of 15 different self-esteem scales implies 15 separate reviews since
each of the different measures generates a different dependent variable.
However, the normal practice in social science is to group all of these
studies together simply because they have given the same name to each of
the constructs measured by each of the 15 different instruments.

Fifthly, cognitive science constructs, like the everyday language
concepts from which they are derived tend to be differentiated on the
basis of differences in structure (rather than on the basis of
differences in function or differences in controlling variables).
However, this leaves researchers free to create new constructs whenever
they wish. The researcher who is interested in aggression, for example,
is free to generate new constructs such as physical aggression, verbal
aggression, emotional aggression, and so on simply by noting that these
take different forms. One of the characteristics of cognitive science
which distinguishes it from other sciences is that cognitive scientists
have no agreed rules for deciding whether or not a new construct should
be admitted to their science. This has resulted in an enormous
proliferation of constructs (see, for example, Reber, 1995).
:::

::: referencesList
#### References

-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Reber, A. S. (1995). The Penguin dictionary of psychology (2nd ed.).
    London: Penguin Books.
-   Rosenberg, A. (1995). Philosophy of social science (2nd ed.).
    Boulder, CO: Westview Press.
-   Sax, G. (1968). Empirical foundations of educational research.
    Englewood Cliffs, NJ: Prentice-Hall Inc.
-   Travers, R. M. W. (1978). An introduction to educational research
    (4th ed.). New York: Macmillan Publishing Co.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whatunitsofanalysisareusedbythethreemainapproachestoresearch/index.md","# What units of analysis are used by the three main approaches to research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-acebb35ba90740929b8dda741dd7f676}
The history of science teaches us that the concepts and distinctions
which are embedded in everyday language and which we use in everyday
life are never sufficient to describe the results of scientific study of
natural phenomena.

Thus the Newtonian revolution was the result of realizing that common
sense notions about change, forces, motion and the nature of space
needed to be replaced if we were to uncover the real laws of motion. We
had to give up our common sense suppositions that there is a preferred
direction in space, that the earth is at rest, that if something is
moving there must be a force acting on it. Instead we must view motion
at constant velocity as the absence of net forces, consider \"down\" as
just the direction toward the strongest source of gravity, and accept
that the Earth is moving at about 700 feet per second (Rosenberg, 1995,
p. 15.)

What we learn from the history of science is that one of the early
outcomes of scientific investigation is the development of a technical
vocabulary which can be used to make the new distinctions which
systematic observations suggest will need to be made in order for the
science to progress.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whatunitsofanalysisareusedbythethreemainapproachestoresearch/Theunitsofanalysisemployedbybehaviouranalysts/index.md","# The units of analysis employed by behaviour analysts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a76ad6c03e2047aabbcf439359fa2874}
Behaviour analysts consider the selection of an appropriate unit of
analysis to be an extremely important matter and have written at length
regarding the most appropriate units of analysis for a science of
learning (Johnston & Pennypacker, 1993a; Lee, 1995). \"In behavior
analysis, as in the other natural sciences, the key to the emergence of
scientific laws has been the discovery of basic units of analysis\"
(Schlinger, 1995, p. 34).

Behaviour analysts argue that responses should be grouped together on
the basis of their common purpose or function because behaviour is
adaptive, because responses which are successful in achieving a
particular purpose or outcome are more likely to be used again in the
future than responses which are unsuccessful, and because a
classification in terms of function is more likely to lead to discovery
of the variables which are responsible for behaviour change than a
classification in terms of form, structure, or theoretical conjecture.
\"The behavior analyst distinguishes between *movements*, responses
defined by their form or the musculature used, and *actions*, responses
defined by their relations to the environment. We\'ll find that actions
are more important for our purposes. Consider how often we speak of
doing things, going places or manipulating objects, without regard to
the details of how these actions are performed\" (Catania, 1998, p. 11).

Behaviour analysts refer to the particular actions in a given response
class as *responses*, and to the antecedents and consequences of those
responses as *stimuli*. \"When we observe an organism, we see properties
of its environment and properties of its behavior. We call these
properties *stimuli* and *responses*. But neither a stimulus or a
response is of interest by itself. An experimental analysis determines
what kinds of relations exist between stimuli and responses, and how
these relations can come about\" (Catania, 1998, p. 7).

The idea that responses should be grouped together on the basis of their
common purpose or function rather than on the basis of their form,
structure, developmental progression, or value as evidence of some
theoretical construct was first suggested by B.F. Skinner. \"He defined
stimuli and responses (i.e. environment and behavior), not as
independent structural units, but as functional classes. Thus stimuli
were not defined by their physical energy, and responses were not
defined by their form or topography. Rather both were defined by their
respective effects on one another\" (Schlinger, 1995, p. 34).

Behaviour analysts argue that a functional classification is preferable
to a classification based on topography, form, or structure because two
seemingly similar behaviours may serve quite different purposes, that
is, similar looking behaviours may be the result of quite different
environmental variables. \"Typically, we assign a particular act to a
functional class on the basis of both its effect and its context. . . .
We may consider \'compliance with a threat\' an operant because its
members occur in a certain context (a \'threat\') and have historically
had a certain effect (removal of the threat). Handing my wallet to my
wife for her to remove money is a different operant from handing my
wallet to a mugger\" (Baum, 1994, p. 77).

The behaviour analyst argues that the distinction between functionally
and structurally defined response classes is fundamental. For the
behaviour analyst, the aim of scientific analysis is to detect and
describe those relationships between behaviour and its context which
exist in nature. This cannot be achieved if the investigator selects
(for study) groupings of responses (such as those suggested by the
concepts of natural language, or the constructs of the social scientist)
which include responses from a number of different functional classes
each of which has been learned as a result of a different set of
experiences and each of which is under the control of a different set of
antecedents and/or consequences.

Behaviour analysts take the same approach to the analysis of the
environment. In contrast to the social scientist who might classify
environments in terms of \"household income\" or \"parenting style\", the
behaviour analyst classifies environments at the level of particular
interactions. Environmental events are also classified according to
function (not form or structure). \"For behavior analysts, the
environment is not defined prior to the study of behavior or by what it
looks like, but rather after functional relations have been established,
that is, by how it functions\" (Schlinger, 1995, p. 36). An environmental
event comes to be defined as a stimulus only when it has been found to
affect the responses in a particular class of responses in a consistent
and predictable manner.

Behaviour analysts distinguish between several different classes of
behaviour-environment relationships.

**1. Respondents.** The simplest of these is a class of
environment-behaviour relationships which the behaviour analyst refers
to as *respondents*. Observation of a respondent relationship involves
observation of the reflex response which is of interest (e.g., the
startle reflex) and the particular antecedent stimuli which elicit the
reflex (e.g., a sudden loud noise).

**2. Operants***.* Next in order of complexity is a class of
behaviour-environment relationships which behaviour analysts refer to as
*operants.* Observation of an operant relationship involves observation
of the responses which are of interest and the common purpose which they
serve (that is, the outcome or consequence which their performance
generates). Behaviour analysts distinguish between a number of different
kinds of operant relationships: those which make the responses in a
given response class more likely to be used again in the future (the
positive reinforcement, negative reinforcement, and recovery
relationships), and those which make the continued use of a given class
of responses less likely in the future (the positive punishment,
negative punishment, and extinction relationships).

**3. Three-term contingencies.** Thirdly, behaviour analysts study a
class of environment-behaviour-environment relationships which they
refer to as *discriminated operants* or as *three term contingencies*.
Observation of a discriminated operant involves observation of the
antecedent stimulus which consistently evokes the response, the response
itself, and the consequence which results when the antecedent stimulus
is responded to in this way. Each of the following S-\>R-\>S sequences
(repeated as time passes) are examples of discriminated operants:

-   the phone rings--\> I answer it --\> and a conversation (usually)
    follows,
-   an example of a particular kind of maths problem is presented -\>
    the student says or writes an answer -\> the teacher provides
    feedback regarding the adequacy of the answer.

**4. Four-term contingencies.** Fourthly, behaviour analysts study
conditional discriminations or *four term contingencies*. A conditional
discrimination is one in which responses to examples of a particular
class of stimuli have one kind of outcome in one context but a different
kind of outcome in another context. The following is an example of a
conditional discrimination. The teacher displays a 4 cm stick and an 8
cm stick and asks \"Which one is longer?\", the child points to the 8 cm
stick, and the teacher says \"Yes\". Then the teacher displays an 8 cm
stick and a 12 cm stick and asks \"Which one is longer?\", the child
points to the 8 cm stick, and the teacher says \"No.\" In this case (the
conditional discrimination *longer*), selection of the 8 cm stick may be
either a correct response or an incorrect response depending upon the
context (the length of the second or comparison stick).

Unlike the qualitative researcher who groups events into the categories
of everyday language, or the social scientist who groups behaviours
according to topography or form, the behaviour analyst classifies
environment-behaviour *relationships* and classifies these relationships
according to *function*. For example, behaviour-consequence
relationships which function to increase the probability of occurrence
of behaviour (motivate the continued use of behaviour) are grouped
together under the heading *reinforcement contingencies*. This procedure
has been found to have a number of advantages.

First, it has resulted in a taxonomy which consists of a relatively
small number of relatively well defined classes of environment-behaviour
relationships. See, for example, the glossary in Catania (1998). Of
course, this taxonomy is constantly evolving. During the past 40 years,
new relationships have been added, and the definitions of existing
relationships have been adjusted to bring the distinctions which are
being made into line with new research findings.

Secondly, it means that the behaviour analysis research community has a
procedure for deciding whether or not a new category term should be
added to the existing taxonomy. Only when a group of researchers have
demonstrated that they have isolated a new environment-behaviour
relationship do they win the right to add a new category term to the
existing taxonomy. Most recently this has occurred with respect to the
term *equivalence relations* (and their defining features of
reflexivity, symmetry, and transitivity) during oral and written
language learning (Sidman, 1994).

Thirdly, it means that all behaviour analysts are describing the results
of their investigations in a common (albeit technical) language. As a
consequence, each behaviour analysis research report is immediately
comprehensible to the entire behaviour analysis research community and
the results of each investigation are directly comparable with the
results of the great majority of the investigations which have preceded
it.

Fourthly, particular environment-behaviour relationships, once they have
been identified, tend to be the focus of many hundreds of further
experiments designed to explore the generality of the presumed
relationship, its technical applications, and so on. See, for example,
the replication history described by Barlow and Hersen (1984) for the
operation *differential attention*. As a result of the differential
attention research, it is now possible to predict (with more accuracy
than previously) the conditions under which differential attention will
and will not function to motivate behaviour change in children.

The development of a taxonomy of environment-behaviour relationships
each with its own technical name is not without its disadvantages. For
example, it means that reports of behaviour analysis research are not
immediately comprehensible to readers with no training in the language
of behaviour analysis. One of the first things which the student of
behaviour analysis discovers is that there is a technical vocabulary to
be mastered. It takes some \"study and practice to learn to talk about
behavior in proper scientific terminology, just as it takes years of
study in other natural sciences to talk fluently about other natural
phenomena\" (Johnston & Pennypacker, 1993a, p. 32).

Behaviour analysts are sometimes criticised for using the specialised
descriptive language which they have developed. Heward and Cooper (1992,
p. 454) note, however, that \"we do not expect an atomic physicist or
botanist to give up his or her technical vocabulary when engaging in
scientific description or dialogue, so why should we do so when human
behavior is the subject of scientific discussion?\"
:::

::: referencesList
#### References

-   Barlow, D. H., & Hersen, M. (1984). Single case experimental
    designs: Strategies for studying behavior change (2nd ed.). New
    York: Pergamon.
-   Baum, W. M. (1994). Understanding behaviorism: Science, behavior and
    culture. New York: HarperCollins College Publishers.
-   Catania, A. C. (1998). Learning (4th ed.). New York: Prentice Hall.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Johnston, J. M., & Pennypacker, H. S. (1993a). Strategies and
    tactics of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence
    Erlbaum Associates.
-   Lee, V. L. (1995). What is a psychological unit? Behaviour Change,
    12, 98-108.
-   Rosenberg, A. (1995). Philosophy of social science (2nd ed.).
    Boulder, CO: Westview Press.
-   Schlinger, H. D. (1995). A behavior analytic view of child
    development. New York: Plenum Press.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whatunitsofanalysisareusedbythethreemainapproachestoresearch/Theunitsofanalysisemployedbyethnographers/index.md","# The units of analysis employed by ethnographers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-39b5fb092c5148169fb679fa45bf83ad}
Ethnographers do not consider their subject matter to consist of parts
or elements. In fact, ethnographers often argue that the context or site
which is being investigated must be studied as a whole and that the aim
of the investigation is to provide a holistic account of the culture at
that site. This point of view is supported by arguing that, in a social
context, the whole is often more than the sum of its parts, and that any
attempt to study just certain parts of a social organisation precludes
development of an understanding of the organisation and functioning of a
social group as a social group.

Notwithstanding this argument, qualitative researchers do, in fact,
employ units of analysis and the procedure for creating these units is
described in most qualitative methods texts. The procedure (which is
often referred to as *unitising*) involves the division of field notes,
interview transcripts and written documents into text fragments. These
text fragments tend to be relatively small (phrases, sentences, or
paragraphs) which are meaningful on their own. So it can be seen that
qualitative researchers do divide their subject matter into elements,
the elements being single topic descriptive statements or single topic
participant statements.

Once the field notes and interview transcripts have been unitised, these
units are normally coded. However, these units are not coded or grouped
into any kind of agreed or standard categories. The qualitative
researcher is free to generate whatever kinds of groupings or categories
he or she considers to be appropriate to the current investigation.

Because there are no rules regarding the classification of text
passages, qualitative researchers tend to group the elements of their
subject matter into categories which are mostly natural language
categories. LeCompte and Preissle (1993) give the following as examples
of the kinds of categories that might be used: classes of behaviour
(e.g., behaviour, knowledge, opinion, sensory, feeling, demographic),
classes of meaning (e.g., descriptive, constructs, comparisons,
interpretations), and classes of events (e.g., acts, activities,
meanings, participation, relationships, settings). Bogdan and Biklen
(1998) discuss coding categories under the following headings: setting,
world view, perspectives of the participants, ways of thinking about
people and objects, processes (sequences of events), activities
(recurring types of behaviour), events, strategies (the way people get
things done), relationships and roles, and methods (researcher
comments). These examples suggest that the categories used by
qualitative researchers are primarily everyday language categories and
that they are primarily structural categories rather than functional
categories.

Could the unitising and coding procedures of the qualitative researcher
conceivably operate to generate new insights regarding the different
kinds of learning which need to be distinguished, or the events,
experiences, or elements of teaching practice which need to be provided
on order for individual learners to achieve particular kinds of learning
outcomes? This seems extremely unlikely.

First, the units of the qualitative researcher are pieces of text
(usually descriptions of actions or events) which are meaningful or
interpretable without further information. These units do not need to
include information about the context of the action, its purpose, or its
consequences. Using this criterion on its own means that any event, no
matter how trivial, could be captured for analysis by a qualitative
researcher, for example, \"At 10.32 a.m. Mary gazed out the window.\"
Without some criteria for selecting units (types of events) which are
*likely* to be related to learning, it is difficult to envisage how this
procedure could possibly identify events which are *in fact* important
for learning.

Secondly, qualitative researchers have developed no agreed procedures
for grouping or categorising different kinds of learning outcomes or for
grouping or categorising events which might be related to learning. The
qualitative researcher is free to select whatever categories seem most
appropriate at the time. This failure to develop standard or agreed
categories has resulted in a set of uniquely organised research reports
none of which can be compared directly with the results of any other.
Each report may be interesting in its own right, but the corpus or
library of reports do not add up to produce an improved understanding of
educational practice. \"Comparative researchers have been hampered by the
tendency of investigators to proceed idiosyncratically, studying
whatever interests them without specifying the perceptual and analytic
units which guide their data collection and analysis\" (LeCompte &
Preissle, 1993, p. 241).

Thirdly, qualitative researchers have developed no agreed set of
taxonomic terms which can be used to refer to the categories of events
described in their reports. This greatly hinders the identification of
shared insights, commonalties, or generalisations across individual
investigations. \"Is it reasonable to expect the findings of research to
accumulate when the research is conducted under the aegis of different
theories, using different core concepts and different instruments to
measure or describe the variables?\" (Eisner, 1991, p. 209).

In short, the analytic units of the qualitative researcher are the most
primitive of all the analytic units currently used by educational
researchers. It seems highly unlikely that a procedure which identifies
social events without reference to learning or teaching and then
classifies these events in whatever manner the researcher chooses, could
conceivably result in generalisations about learning and/or teaching or
any other kind of knowledge which will be of enduring use to teachers.
:::

::: referencesList
#### References

-   Bogdan, R. C., & Biklen, S. K. (1998). Qualitative research for
    education: An introduction to theory and methods (3rd ed.). Boston:
    Allyn and Bacon.
-   Eisner, E. W. (1991). The enlightened eye: Qualitative inquiry and
    the enhancement of educational practice. New York: Macmillan
    Publishing Co.
-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego, CA: Academic
    Press.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/index.md","# Approaches to research into learning and teaching \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8d9e1b9932bd425091d32974018208b4}
Chapter 1 consists of 5 sections. Section 1 identifies the most common
approaches to research in education. Section 2 examines the extent to
which each of these approaches to research have learning and/or teaching
as their primary subject matter. Section 3 examines the units of
analysis which are being used in research into learning. Section 4
identifies the different types of explanation which are possible and
Section 5 asks which of the several approaches to the study of learning
and teaching is most likely (a) to identify the conditions necessary in
order for different kind of learning to occur and hence most likely (b)
to identify the teaching procedures which are effective in developing
different kinds of learning outcomes in different kinds of learners
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Typesofexplanation/Explanationsinaphysicalvocabularyandinanon-physicalvocabulary/index.md","# Explanations in a physical vocabulary and in a non-physical vocabulary \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-1663d57661de4d63a32723d52abd8b71}
Some researchers insist that attempts to explain must be framed in a
physical vocabulary, that is, they must point to a cause or an
independent variable which can be seen, heard, or felt - even if only by
the actor (Baum & Heath, 1992). Explaining an improvement in performance
in terms of teaching which has been provided, or practice activities
which have been completed, or a drug which has been ingested, are
examples of explanations in a physical vocabulary. Teaching can be
observed, practising can be observed, and taking a drug can be observed.

Other researchers allow that explanations can be framed in a
non-physical vocabulary, that is, that they may refer to entities or
processes which are not observable and which could not ever be observed.
Explaining improvements in performance in terms of a short term memory
process and a long term memory process, for example, are instances of
explanations in a non-physical vocabulary. This is because mental
processes are in principle unobservable. No one, not even the actor, can
see or sense the transfer of information from short term memory to long
term memory. The word \"memory\" is used as a metaphor, not as a pointer
to an observable physical process or an observable location in the
learner's brain.
:::

::: referencesList
#### References

-   Baum, W. M., & Heath, J. L. (1992). Behavioral explanations and
    intentional explanations in psychology. American Psychologist, 47,
    1312-1317.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Typesofexplanation/Immediatecauseexplanationsandhistoricalexplanations/index.md","# Immediate cause explanations and historical explanations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bc548813f4c84e3193aaca17fc54f704}
Explanations may be framed in terms of immediate causes, that is, in
terms of events immediately preceding the behaviour change which is of
interest, or in terms of historical causes, that is in terms of
experiences which occurred some time ago. Immediate cause explanations
are referred to by biologists as proximate cause explanations (Alessi,
1992). A variety of different kinds of immediate cause explanations are
regularly employed both in everyday discourse and in the discourse of
educational and psychological research. Because these are so common,
they are described separately in the section which follows.

Immediate cause explanations may be given in either a physical
vocabulary or in a non-physical vocabulary. Immediate causes of the
first type refer to immediately prior events which are observable or
which are in principle observable. For example, \"a single explanation
was sufficient to show each of the children how to solve the problem.\"
(Teacher explanations are observable.) Immediate cause explanations of
the second type refer to internal or mental events or structures which
are in principle unobservable. For example, \"once the explanation had
been transferred to long term memory, the child was able to solve the
problem.\" (We cannot observe the transfer of anything to long term
memory.) Immediate cause explanations which refer to unobservable mental
processes or mental structures are commonly referred to as *mentalistic
explanations*.

Explanations may also be framed in terms of historical causes, that is,
by pointing to the past experiences of the learner. This kind of
explanation sometimes occurs in everyday discourse (e.g., \"Because the
teacher succeeded in motivating him to prepare for the test, Tim\'s
scores increased from one test to the next\"). This kind of explanation
is variously referred to as *historical explanation* (Baum & Heath,
1992), *selectionist explanation* (Palmer & Donahoe, 1992), and ultimate
causation (Alessi, 1992). Historical explanations attempt to address the
question: \"What were the conditions which led to the acquisition,
development, or evolution of this particular skill, understanding, or
belief in this particular individual?\" They accept, as causes, events
which have occurred well before the behaviour change which is of
interest (events which are distant in time from the change).

Historical explanations may be given in either a physical vocabulary
(e.g., by pointing to past experiences) or they may be given in a
non-physical vocabulary. The link between cigarette smoking and the
(much later) development of lung cancer is an example of an historical
explanation (for lung cancer) given in a physical vocabulary. (A history
of smoking can be observed). \"Hand of God\" accounts are examples of
historical explanations in a non-physical vocabulary as the following
account illustrates: \"Imagine what must be going on in the brain of a
pianist playing a difficult musical composition . . . this incredibly
complex operation . . . is made possible only because musical capability
was pre-programmed into the human brain from birth. . . . Is it not
evident that man\'s intellectual qualities mirror those of a Supreme
Intellect?\" (Watchtower Bible and Tract Society of Pennsylvania, 1985).
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Typesofexplanation/index.md","# Types of explanation \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-67401f836d104d0fbf207137fe7cce30}
Why engage in research on learning? Presumably one of the major aims of
such research is to identify the conditions on which learning depends
or, more accurately, to identify the sets of conditions on which
different kinds of learning depend. The pursuit of this aim requires a
clear understanding regarding those events which are likely to be
affecting learning and a clear understanding of the kinds of behaviour
change (learning) which are likely to be affected by such events. One of
the measures of success with respect to this endeavour will be the
development of explanatory theory.

Explanation normally involves pointing to a cause. The concept of cause
is built into the language. Every use of the word \"because\" implies a
causal statement, explanation, or reason for the action preceding the
\"because\". Causal explanation is prized because it enables prediction.
Prediction is also built into the language. The future tense is the
prediction tense. Most causal statements (e.g., \"practice enhances
retention\") can be turned into predictions (e.g., \"If practice is
required, then this skill will be remembered\". \"If . . . then\"
statements of this kind are useful because they can be used as a guide
for action. In other words, developments in explanatory theory result in
improvements in our ability to predict when particular kinds of learning
are and are not likely to occur. They may also result in improvements in
our ability to control learning, that is, improvements in our ability to
help people to learn.

The search for explanations is a search for understanding, and the kind
of understanding which is most useful is the understanding which can be
used as a guide for future action. However, researchers bring to the
research task different beliefs regarding what counts as an adequate
explanation. These beliefs influence what is looked for and, hence, what
is found as a result.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Typesofexplanation/Somecommontypesofimmediatecauseexplanations/index.md","# Some common types of immediate cause explanations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4336fe0f389a4efab14bdc0faef57e9a}
The most common types of immediate cause explanation found in the
educational and psychological research literature are intentional
explanation, dispositional explanation, and mechanistic explanation.

**Intentional explanations***.* Sometimes researchers attempt to explain
behaviour change in terms of the wishes, desires or intentions of the
learner. Such explanations are quite common in everyday language and are
often accepted as adequate explanations. \"'I decided to take a short
walk' is accepted as an explanation of why you were seen at the beach at
midnight\" (Hospers, 1990, p. 163). Intentional explanations are also
referred to as purposive explanations, teleological explanations,
interpretive explanations, and hermeneutical explanations. Researchers
who favour intentional explanations tend to argue that people are
impelled by ideas, knowledge, hopes, wants, desires, intentions, and so
on, and that to understand (that is, explain) actions, the investigator
must uncover the purpose of these actions, how the actors interpret the
situations they are in, and how they see the options which are open to
them (given their social beliefs).

**Dispositional explanations***.* Sometimes researchers attempt to
explain behaviour changes by referring to certain presumed
characteristics, traits, or dispositions of the learner. This kind of
explanation is extremely common in everyday discourse (e.g., \"She is
making rapid progress in maths because she is highly motivated\") and
almost as common in psychology. \"We tend to account for the behaviour of
others by appealing to their dispositional characteristics such as
moods, attitudes, motivations, hopes, or expectations\" (Hineline, 1992,
p. 1278). Someone who is observed to be working hard is said to being
doing so because they are \"motivated\". Someone who is doing very little
is said to be lethargic because they are \"depressed\".

**Mechanistic explanations***.* Sometimes researchers attempt to
describe a particular behaviour change by referring to events which
occurred immediately prior to instances of the new behaviour (e.g.,
\"Following this flash of insight, Alex quickly solved the problem\").
Explanations which refer to immediately preceding events or forces which
are acting on the individual are most commonly referred to as
*mechanistic explanations*. A mechanistic explanation may be given in a
physical vocabulary. Chiesa (1992) gives the following example:
administration of a drug is followed by a change in the constitution of
blood, which is followed by a change in the activity of nerve endings,
which is followed by a reduction in pain. More commonly, however,
mechanistic explanations in psychology are given in a non-physical
vocabulary. This is true of all immediate cause explanations which are
couched in terms of information processing, cognitive processes, memory
processes, and mental structures.

Mechanistic explanation has a long history in educational psychology. It
was the form of explanation favoured by Watsonian behaviourists.
\"Classical behaviorism took a mechanistic or materialistic view of
psychology . . . and conceptualized the data language of psychology in
terms of stimulus-response units (Simkins, 1969, p. 39). Modern day
descendants of the classical behaviourists, the cognitive scientists,
employ a closely similar type of explanation. The effect of past
experience is to leave a trace, a representation, or a memory in the
mind so that when the learner faces a similar problem, the mind is
activated and the response recalled, with the mental recall producing
(causing) the correct response. Cognitive theories are basically
stimulus-response theories to which have been added some kind of
mediating mental process. The mediating mental process functions to
bridge the gap between an earlier experience (stimulus input) and a
later behaviour (response output) (Chiesa, 1992, p. 1290).
:::

::: referencesList
#### References

-   Alessi, G. (1992). Models of proximate and ultimate causation in
    psychology. American Psychologist, 47, 1359-1370.
-   Baum, W. M., & Heath, J. L. (1992). Behavioral explanations and
    intentional explanations in psychology. American Psychologist, 47,
    1312-1317.
-   Chiesa, M. (1992). Radical behaviorism and scientific frameworks:
    From mechanistic to relational accounts. American Psychologist, 47,
    1287-1299.
-   Hineline, P. N. (1992). A self-interpretive behavior analysis.
    American Psychologist, 47, 1274-1286.
-   Hospers, J. (1990). An introduction to philosophical analysis (3rd
    ed.). London: Routledge.
-   Palmer, D. C., & Donahoe, J. W. (1992). Essentialism and
    selectionism in cognitive science and behavior analysis. American
    Psychologist, 47, 1344-1358.
-   Simkins, L. D. (1969). The basis of psychology as a behavioral
    science. Waltham, MA: Blaisdell Publishing Co.
-   Watchtower Bible and Tract Society of Pennsylvania. (1985). Life -
    How did it get here? By evolution or by creation? Brooklyn, New
    York: Watchtower Bible and Tract Society of New York.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whichapproachestoresearchhavelearningastheirsubjectmatter/Whatisthesubjectmatterofcognitivescience/index.md","# What is the subject matter of cognitive science? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-25e2fbd72a544bf3a5c06f3aa81e621b}
The subject matter of cognitive science is the interrelationship between
overt performance and mental processing. Performance on different kinds
of tasks is assumed to be a function of previously acquired mental
structures and processes, and the performance of different groups of
learners (such as novices and experts) on particular tasks is studied in
an attempt to elucidate the mental processes which are involved in
performing that kind of task. Cognitive scientists use the methods of
social science to build models of the underlying mental structures and
processes which may be operating to regulate perception, understanding
and remembering in human learners (Stillings et al., 1987).

Most cognitive scientists employ a social science methodology. Cognitive
scientists are not the only students of human behaviour who employ a
social science methodology. Measurement psychologists use social science
methods to study the correlations which exist between sets of scores on
various measures of ability, achievement, motivation, self-esteem, and
so on within defined groups of children and adults. Developmental
psychologists use social science methods to describe the average or
typical developmental trajectory which occurs with respect to different
kinds of skills and mental processes from one age level to the next.
Evaluation researchers use the methods of social science to study the
average effects on achievement, motivation, self-esteem, and so on which
result from various types of teaching procedures, teaching materials,
and other kinds of educational provisions.

One of the defining characteristics of cognitive science research is
that, like the other social sciences, it studies the abilities,
achievements, beliefs, and so on of groups of subjects. Cognitive
scientists are limited to the study of the average or typical responses
of groups of people because the statistical procedures which they use to
interpret the results of their investigations are procedures which can
only be applied to *sets* of scores. This is one of the key differences
between cognitive science and behaviour analysis. Behaviour analysts
collect data on the performance of individual learners and are very
interested in the reasons why different individuals respond to the same
task in different ways. Social scientists collect data on the aggregate
performance (e.g., the mean performance) of groups of learners.
Variability between the performances of individuals is of little
interest to the cognitive scientist - of so little interest that such
variability is most commonly referred to as \"error variance\".

The subject matter of social science includes both the verbal behaviour
of groups of learners (e.g., the average of the test scores obtained by
a sample of children) and the non-verbal behaviour of groups of learners
(e.g., the average time on task of the children in a classroom). It also
includes both overt behaviour (as in the two preceding examples) and the
mental processes which are presumed to govern or direct that overt
behaviour.

The subject matter of cognitive science includes the study of
performance change over time. For example, much child development
research involves studying the improvements in cognitive performance
which occur as the child becomes older. Most commonly, however,
cognitive scientists employ measures of recall, retention or achievement
which are administered just once or twice, rather than making repeated
observations of performance while new skills and understandings are
being acquired.

The research methods of cognitive science, like the research methods of
social scientists in general, have a number of shortcomings which make
these methods less than completely suitable for the scientific study of
learning and teaching.

First, learning involves change over time. Tracking change over time
requires repeated observations of the aspect of performance which is of
interest. The social science methodology, however, is ill suited to the
measurement of change. \"The bulk of the design models that have evolved
from the groups comparison tradition become awkward and unmanageable in
the face of continuous measurement\" (Johnston & Pennypacker, 1993, p.
97). As a consequence, cognitive scientists have shown little interest
in studying the processes of change. This is not because the study of
change is *impossible* with this method, but because obtaining repeated
measures of the performance of a large number of learners tends to be
*impractical*. By restricting observations of learning to just a single
observation, however, the cognitive scientist can never be sure just
what it is that has been measured. \"Different subjects take different
amounts of time to respond to a new condition. A single observation may
catch one subject early in this transition but another after the
transition is complete. The result is two different pictures of the
effects of the condition, and averaging these pictures does not make it
any clearer\" (Johnston & Pennypacker, 1993b, p. 184).

Secondly, learning involves changes in the performance and motivations
of individuals. But social science research methods were not developed
to study the performance of individuals. They were developed for an
entirely different purpose, to study population genetics, agricultural
yields, and industrial quality control - where the behavior of
individual members of the class is of little concern (Johnston &
Pennypacker, 1993b). This means that the social science methodology
cannot be used to study questions about behaviours and achievements
which are unique to a particular individual - the child who has a
special talent for music, the child who has a serious learning
disability in maths, or the child who has developed a unique kind of
phobia, for example. It also means that the methodology cannot be used
to study the effects of particular kinds of teaching or motivational
procedures on the development of individual learners. Neuman and
McCormick put it this way:

Say, for example, that a group investigation includes fifth grade
students who have literacy problems, and in that group there are pupils
whose reading achievement ranges from approximately first grade level to
third grade level. When post-intervention behaviors are averaged we
might find on the whole that an improvement has been shown, but, of
course, inherent in any average are scores falling below and above the
mean. . . . Unfortunately, too often findings are reported as general
conclusions: \'The *xyz* technique was effective with fifth grade
disabled readers.\' But application of *xyz* to Susan, who had the
lowest score in the group, or to others with learning levels and
behaviors similar to Susan, may be quite ineffectual. A teacher using
the *xyz* technique with Susan and her counterparts might be doing
little to foster the learning of these children (Neuman & McCormick,
1995, p. 4).

To summarise, the subject matter of cognitive science research tends to
overlap only to some degree with the subject matter which is of interest
to teachers, teacher educators and teaching researchers. Because the
method can only be used to study the characteristics of groups of
people, social scientists have shown relatively little interest in
questions about the origins and causes of differences between learners,
in questions about the effects of particular teaching strategies on
individual learners, or in questions about how particular teaching
strategies should be adapted to meet the needs of individual learners -
even although these are the questions which are of most interest to
practitioners. \"Empirical research based upon large populations and
involving a massive investment in . . . time and effort does not
generate information which can be of assistance to teachers. . . \[who\]
must be responsive to the particular errors of particular children\"
(Macdonald & Pettit, 1991, p. 401).
:::

::: referencesList
#### References

-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale:
    Lawrence Erlbaum Associates.
-   Macdonald G., & Pettit, P. (1981). Semantics and social science.
    London: Routledge & Kegan Paul.
-   Neuman, S. B., & McCormick, S. (Eds.). (1995). Single subject
    experimental research: Applications for literacy. Newark:
    International Reading Association.
-   Stillings, N. A., Feinstein, M. H., Garfield, J. L., Rissland, E.
    L., Rosenbaum, D. A., Weisler, S. E., & Baker-Ward, L. (1987).
    Cognitive science: An introduction. Cambridge, MA: The MIT Press.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whichapproachestoresearchhavelearningastheirsubjectmatter/Whatisthesubjectmatterofqualitativeresearch/index.md","# What is the subject matter of qualitative research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cd15dfba4ea9442dadce2d1b6946a965}
For educational ethnographers, interpretive researchers and most other
qualitative researchers, the subject matter - the phenomena to be
observed and described - are the actions, interactions, choices, beliefs
and perspectives of the individuals who live or work in the context or
setting selected for examination. \"Researchers who use this approach are
interested in the ways different people make sense out of their lives. .
. . They focus on such questions as: What assumptions do people make
about their lives? What do they take for granted?\" (Bogdan & Biklen,
1992, p. 32).

Qualitative researchers argue that the same act (when performed on
different occasions) can have different meanings. \"A crucial . . .
distinction in interpretive research is that between *behavior*, the
physical act, and *action*, which is the physical behavior plus the
meaning interpretations held by the actor\" (Erickson, 1986, p. 126-127).
As used by ethnographers, the term *action* includes not only the
actions of individuals but also their interactions with others, and it
includes not only physical actions and interactions but also verbal
actions and interactions (such as conversations). The actions and
meanings which are of primary interest are the actions and meanings of
individuals rather than the average actions and meanings of groups of
people. It may be noted that the subject matter of the qualitative
researcher (\"action-and-meaning\") is similar in a number of respects to
the subject matter of the behaviour analyst (\"behaviour-and-purpose\").

Interpretive researchers use the terms *meanings* and *interpretations*
to refer to a variety of things: the goal or intention of the actor; the
perspective of the actor; the way in which the actor interprets,
explains, or justifies his or her actions; the actor's beliefs,
attitudes, and understandings with respect to the situation they are a
part of; their understanding of the social rules which govern behaviour
in the setting of interest, and their beliefs with respect to what they
see as the courses of action which are open to them. \"Actions . . . can
only be interpreted by reference to the actor\'s motives, intentions or
purposes in performing the action. To identify these motives and
intentions correctly is to grasp the subjective meaning the action has
to the actor\" (Carr & Kemmis, 1986, p. 88).

Interpretation of an action involves more than simply identifying the
reason which the actor gives for that action. It also involves
identifying the social norms, rules, and expectations which operate in
the setting in which the action is performed. These norms and rules of
social behaviour are often referred to as the culture of the social
group. \"Another task of an \'interpretive\' social science is to uncover
the set of social rules which give point to a certain kind of social
activity\" (Carr & Kemmis, 1986, p. 89).

Most qualitative researchers are aware that actions tend to recur with
the passage of time and that the form and course of particular types of
action vary from one occasion to the next, e.g., \"Today\'s enactment of
breakfast in a family differs from yesterday\'s\" (Erickson, 1986, p.
129). In this they have much in common with behaviour analysts.

Research into learning and teaching has the potential to identify the
kinds of experiences which need to be provided in order for individual
learners to achieve particular kinds of learning outcomes. However, this
subject matter has been, by and large, of little interest to qualitative
researchers.

First, qualitative researchers have been relatively uninterested in
identifying factors which give rise to the actions and the meanings
which they so assiduously describe. For example, qualitative researchers
do not distinguish between purposes and effects and routinely ignore the
effects of engaging in particular classes of action - even although
these effects, more than any other single factor, operate to shape what
people do in particular contexts, their beliefs about what they should
do, and the language which they use to justify what they do. \"What
interpretivism neglects is the causal component - the origins of
behaviour as well as its consequences . . . external and social factors
which shape behaviour are ignored\" (Clark, 1997, p. 40). Carr and Kemmis
come to much the same conclusion.

The interpretive model neglects questions about the origins, causes and
results of actors adopting certain interpretations of their actions and
social life . . . Social structure, as well as being the product of the
meanings and actions of individuals, itself produces particular
meanings, ensures their continuing existence, and thereby limits the
kinds of actions that it is reasonable for individuals to perform. It is
appropriate, therefore for social science to examine not only the
meanings of particular forms of social action, but also the social
factors that engender and sustain them (Carr & Kemmis, 1986, p. 95).

Secondly, ethnographers are relatively uninterested in questions about
the effects or effectiveness of different teaching practices. \"In and of
themselves, ethnographic accounts do not . . . give clues as to what
should be done differently, nor do they suggest how best to proceed. . .
. ethnography does not point out the lessons to be gained or the action
that should be taken\" (Wolcott, 1988, p. 203).

Thirdly, ethnography is a descriptive research procedure and a
descriptive procedure cannot be used to identify the factors which are
of greatest interest to teachers and to students of learning, that is,
the factors on which learning depends, the effects of prior experience
on behaviour and beliefs, and the interrelationship between teaching
events and the changes which we refer to as learning. These are
relationships and their identification requires controlled, or
experimental modes of observation.

Most importantly, the ethnographic method was developed to study
particulars and it is for the study of particulars that the method is
primarily used. However, most researchers and almost all practitioners
are interested in generalisations. It is nature\'s general rules which
are of greatest interest to the scientist, and it is the general rules
of effective teaching which are of greatest interest to teachers.
Ethnographic methods cannot generate the kind of knowledge which is
normally sought by students of learning and teaching, that is an
understanding of the factors which influence learning (or which
influence the effects of teaching) across individuals, across contexts,
and across time. The teacher who is interested in generalisations about
what should be done to bring about particular learning outcomes will
find that ethnographic reports are almost always silent on such
questions.
:::

::: referencesList
#### References

-   Bogdan, R. C., & Biklen, S. K. (1992). Qualitative research for
    education: An introduction to theory and methods (2nd ed.). Boston:
    Allyn and Bacon.
-   Carr, W., & Kemmis, S. (1986). Becoming critical: Education,
    knowledge and action research. London: The Falmer Press.
-   Clark, J. (1997). Educational research: Philosophy, politics,
    ethics. Massey University, Palmerston North, NZ: ERDC Press.
-   Erickson, F. (1986). Qualitative methods in research on teaching.
    In M. C. Wittrock (Ed.), Handbook of research on teaching (3rd ed.,
    pp. 119-161). New York: Macmillan.
-   Wolcott, H. F. (1988). Ethnographic research in education. In R. M.
    Jaeger (Ed.), Complementary methods for research in education (pp.
    185-206). Washington, DC: American Educational Research Association.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whichapproachestoresearchhavelearningastheirsubjectmatter/Whatisthesubjectmatterofbehaviouranalysisresearch/index.md","# What is the subject matter of behaviour analysis research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d2ccb88e55a349d38a8e8f069a9b1368}
For behaviour analysts, the subject matter is *variability in the
behaviour of individuals.* Behaviour analysts argue that the behaviour
of individuals is an important subject matter because each individual
must acquire the behaviours, skills, and emotional reactions necessary
for survival during their lifetime and that there is value in coming to
understand how this occurs. \"This approach. . . is based on the
conviction that behavior is an appropriate subject matter for
investigation, not as an epiphenomenon, but in its own right. . . . The
interest in learning about how certain environmental variables may
influence the response class lies in the belief that behavior is largely
the result of environmental variables\" (Johnston & Pennypacker, 1993b,
p. 11).

The behaviour analyst defines *behaviour* as actions, engaged in by an
individual, which involve an interaction with the environment, and which
result in a detectable change in that environment. This definition
excludes such events as the \"behaviour of the stock market\" (because the
stock market is not an individual), such events as the \"behaviour of a
group\" (because groups are not individuals), and such events as \"not
calling out,\" \"receiving a reward,\" or \"getting wet\" (because these
involve no action). The definition also excludes all states such as
\"being hungry\" or \"being anxious\" and all traits such as \"positive
attitude\", \"intelligence\", or \"self-efficacy\", because these are not
references to the learner\'s interaction with his or her environment.

The subject matter of behaviour analysis includes both verbal behaviour
(e.g., conversing, answering questions, writing essays) and non-verbal
behaviour (e.g., cooking a meal, driving a car, playing chess). Like the
subject matter of qualitative research and the subject matter of
cognitive science, the subject matter of behaviour analysis includes
both public behaviours such as conversing (which can be observed by more
than one person) and private behaviours such as thinking (which can be
observed by only one person). Behaviour analysts are \"keenly interested
in all human behaviour - both the publicly detectable and the private
kind\" (Heward & Cooper, 1992, p. 349). In other words, the movement
which defines a particular behaviour may occur inside the skin or
outside the skin. Breathing and thinking are behaviours even although
they are occurring inside the skin. Behaviour analysts \"consider private
events such as thinking or sensing the stimuli produced by a damaged
tooth to be no different from public events such as oral reading or
sensing the sounds produced by a musical instrument\" (Cooper, Heron &
Heward, 1987, p. 11).

The environment, likewise, may be inside the skin or outside the skin.
Going to the toilet in response to a full bladder, and scratching an
itch are examples of behaviours where the stimulus which is being
responded to is inside the skin.

The skin is simply an arbitrary structural boundary. . . . Behavior
analysts, contrary to most reports, do not discount the role of internal
events in their analyses. Rather, they consider them to be physical and
potentially observable events that, like external physical events, can
affect behavior. . . . Rather than making inferences about cognitive and
mental events, behavior analysts assume that internal events are real
events that possess structure and, more importantly, can affect behavior
and, thus, enter into functional relations with behavior (Schlinger,
1995, p. 36-37).

The subject matter of behaviour analysis is the behaviour of
*individuals*. \"The person . . . is conceived of as a unique individual,
a conception that is worked into behavior analytic research strategies
and consequently into its scientific assertions. Persons in this system
are indivisible wholes, active in and interactive with their
environments, changing and changed by the context and the consequences
of their behavior\" (Chiesa, 1994, p. 201). Behaviour analysts draw a
careful distinction between data which describe the behaviour of
individuals and data derived from the statistical aggregation of the
performances of groups of individuals. They argue that the data from
single subject analyses and the data from statistical analyses are two
completely different subject matters and that, because the two types of
data are incomparable, the researcher must make an explicit choice to
study either one subject matter or the other (e.g., Sidman, 1960;
Johnston & Pennypacker, 1993b).

Behaviour analysts consider time to be an essential element of the
subject matter under investigation. \"Behavior must be viewed as a
continuous process that occurs through time\" (Cooper, Heron & Heward,
1987, p. 18). Not only are actions engaged in repeatedly, particular
instances of a given action exhibit variability from one performance to
the next. Even a simple action such as eating varies from one occasion
to the next with respect to what is eaten, where the eating occurs, how
quickly the eating is engaged in and so on. It is this variability which
is of primary interest to the behaviour analyst. (This interest stands
in marked contrast to the cognitive science approach where behavioural
variability is treated as measurement error.) \"All scientists share the
responsibility of investigating the variability that their measurement
of natural phenomena reveals. In the science of behavior, it is our task
to measure and explain variability in behavior\" (Johnston & Pennypacker,
1993a, p. 178).

Behaviour analysts draw a clear distinction between structural and
functional approaches to their subject matter. To date, behaviour
analysts have been most interested in questions of function (e.g., What
are the variables which led to the development of this behaviour?) than
in questions of structure (e.g., How do children solve this kind of
problem?). \"If we are interested in how and why behavior occurs, then we
need to concentrate on its function(s)\" (Schlinger, 1995, p. 18).
However this is changing as behaviour analysts come to realise that a
complete account will require the analysis of both the structure and
functions of behaviour. \"The orientation from which this book is written
deals with both function and structure\" (Catania, 1998, p. 6). \"In a
comprehensive account of behavior, both form and function are important\"
(Schlinger, 1995, p. 18).

Behaviour analysts acknowledge that a change in behaviour is likely to
be accompanied by changes in the brain and/or nervous system of the
individual. The behaviour analyst does not claim \"that learning has no
physiological basis. Of course it does, and it would be fascinating to
know what neurological changes accompany learning\" (Catania, 1998, p.
2). The behaviour analyst simply works on the assumption that changes in
behaviour can be studied *in their own right*. \"Do we ever look at an
organism\'s brain to decide whether it has learned something?\" (Catania,
1998, p. 2). We do not. Teachers constantly make judgements about
whether or not a child has learned a new skill, they make these
judgements on the basis of what they see the child doing, and they do
not reserve judgement until they have examined the child's brain to see
whether it, too, has changed. Behaviour analysts operate in a similar
fashion.

Of all the research methodologies employed by educational researchers,
the subject matter of behaviour analysis is most closely similar to the
subject matter which is of interest to teachers, teacher educators, and
teaching researchers. Unlike the cognitive scientist, the behaviour
analyst studies learning in individuals (each with their own unique
learning history). Unlike the interpretive researcher and the cognitive
scientist, the behaviour analyst studies *changes* in the abilities,
understandings, motivation, beliefs and feelings of individuals over
time. Time is part of the subject matter. Unlike the subject matters of
the interpretive researcher and the cognitive scientist, the subject
matter of behaviour analysis includes the detailed analysis of those
variables which are of greatest interest to teachers, that is, the
external conditions upon which learning depends.

A common criticism of behaviour analysis is that the subject matter of
behaviour analysis is limited to the study of physical actions or
limited to the study of relatively trivial aspects of human development
(e.g., Brophy, 1983). While there are many aspects of human learning
which have yet to be studied by behaviour analysts the same can also be
said of the learning research undertaken by interpretive researchers and
cognitive scientists.

In fact, the range of interests within behaviour analysis is already
quite wide. Behaviour analysts are studying the development of most
kinds of academic skills including reading (e.g., Carnine & Silbert,
1979; Gersten, Keating, & Becker, 1988), reading comprehension (e.g.,
Bigler, 1984; Bruce & Chan, 1991), handwriting (e.g., Stowitschek,
Ghezzi, & Safely, 1987), spelling (e.g., Dixon, 1993; Okyere, Heron, &
Goddard, 1997), compositional writing (e.g., Hopman & Glynn, 1988),
maths (e.g., Blankenship & Baumgartner, 1982; Paine, Carnine, White, &
Walters, 1982), science (e.g., Lazarus, 1991), and so on. Behaviour
analysts are studying the development of language (e.g., Sidman, 1994;
Hart & Risley, 1995) and the conditions necessary for the development of
conceptual and other kinds of understanding (e.g., Engelmann & Carnine,
1991; Muthukrishna, Carnine, Grossen, & Miller, 1993). Behaviour
analysts have studied the learning and teaching of various kinds of
self-care skills (e.g., Smeets, Lancioni, Ball, & Oliva, 1985; Yeaton &
Bailey, 1983) and various kinds of motor skills (e.g., Koop, & Martin,
1983; Ward, Crouch, & Patrick, 1998). Behaviour analysts are studying
the development of motivation, attitudes, interests, and persistence.
They are examining the development of self-control (e.g., Brown & Frank,
1990; Watson & Tharp, 2002), and creativity (e.g., Winston & Baker,
1985). Behaviour analysts are studying the origins and treatment of a
variety of learning disorders including speech disorders (e.g.,
Goldiamond, 1966), behaviour disorders (e.g., Patterson, 1982),
toileting disorders (e.g., Foxx & Azrin, 1973), eating disorders,
depression, and the anxiety disorders (e.g., Barlow, 1988). Behaviour
analysts are studying the effects on learning of a very wide range of
teaching variables including different types of prompting (scaffolding),
the timing of prompts, the selection and sequencing of teaching
examples, opportunity to respond, the scheduling of practice, the type
and frequency of assessment, types of error correction, feedback
variables, types and schedules of reinforcement and differential
reinforcement, automaticity building, mastery criteria, and so on (e.g.,
Carnine, 1989; Gardner et al., 1994; Swanson, O\'Shaughnessy, McMahon,
Hoskyn & Sachse-Lee, 1998; Van Houton, 1984; Wolery, Ault & Doyle,
1992).

Behaviour analysts have even tackled the very difficult question of how
it is that words and other symbols come to acquire meaning for the
individual. See for example, DeGrandpre (2000), Sidman (1994), Skinner
(1957), and Staats (1968). Most of these accounts attempt to show how
the operation of two-, three- and four-term contingencies could function
to \"give meaning\" to both elements of the language (such as words) and
to elements of the environment (such as objects).
:::

::: referencesList
#### References

-   Barlow, D. H. (1988). Anxiety and its disorders: The nature and
    treatment of anxiety and panic. New York: Guilford.
-   Bigler, J. K. (1984). Increasing inferential comprehension scores of
    intermediate-age mildly retarded students using two direct teaching
    procedures. Education and Training of the Mentally Retarded, 19,
    132-140.
-   Blankenship, C. S., & Baumgartner, M. D. (1982). Programming
    generalization of computational skills. Learning Disability
    Quarterly, 5, 152-162.
-   Brophy, J. E. (1983). If only it were true: A response to Greer.
    Educational Researcher, 12(1), 10-12.
-   Brown, D., & Frank, A. R. (1990). \"Let me do it\" - Self-monitoring
    in solving arithmetic problems. Education and Treatment of Children,
    13, 239-248.
-   Bruce, M. E., & Chan, L. K. S. (1991). Reciprocal teaching and
    transenvironmental programming: A program to facilitate the reading
    comprehension of students with reading difficulties. Remedial and
    Special Education, 12, 44-54.
-   Carnine, D. (1989). Designing practice activities. Journal of
    Learning Disabilities, 22, 603-607.
-   Carnine, D., & Silbert, J. (1979). Direct instruction reading.
    Columbus: Charles E. Merrill.
-   Catania, A. C. (1998). Learning (4th ed.). New York: Prentice Hall.
-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   DeGrandpre, R. J. (2000). A science of meaning: Can behaviorism
    bring meaning to psychological science? American Psychologist, 55,
    721-739.
-   Dixon, R. C. (1993). The surefire way to better spelling. New York:
    St Martin\'s Press.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications. Eugene: ADI Press.
-   Foxx, R. M., & Azrin, N. H. (1973). Dry pants: A rapid method of
    toilet training children. Behavior Research and Therapy, 11,
    435-442.
-   Gardner, R., Sainato, D. M., Cooper, J. O., Heron, T. E., Heward, W.
    L., Eshleman, J., & Grossi, T. A. (Eds.). (1994). Behavior analysis
    in education: Focus on measurably superior instruction. Pacific
    Grove, CA: Brooks/Cole Publishing Co.
-   Gersten, R., Keating, T., & Becker, W. (1988). The continued impact
    of the direct instruction model: Longitudinal studies of Follow
    Through students. Education and Treatment of Children, 11, 318-327.
-   Goldiamond, I. (1966). Stuttering and fluency as manipulable operant
    response classes. In L. Krasner & L. P. Ullmann (Eds.), Research in
    behavior modification: New developments and implications (pp.
    108-156). New York: Holt, Rinehart and Winston.
-   Hart, B., & Risley, T. R. (1995). Meaningful differences in the
    everyday experience of young American children. Baltimore: Brookes.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Hopman, M., & Glynn, T. (1988). Behavioural approaches to improving
    written expression. Educational Psychology, 8, 81-100.
-   Johnston, J. M., & Pennypacker, H. S. (1993a). Strategies and
    tactics of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence
    Erlbaum Associates.
-   Johnston, J. M., & Pennypacker, H. S. (1993b). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale:
    Lawrence Erlbaum Associates.
-   Koop, S., & Martin, G. L. (1983). Evaluation of a coaching strategy
    to reduce swimming stroke errors with beginning age-group swimmers.
    Journal of Applied Behavior Analysis, 16, 447-460.
-   Lazarus, B. D. (1991). Guided notes, review, and achievement of
    secondary students with learning disabilities in mainstream content
    courses. Education and Treatment of Children, 14, 112-127.
-   Muthukrishna, N., Carnine, D., Grossen, B., & Miller, S. (1993).
    Children\'s alternative frameworks: Should they be directly
    addressed in science instruction. Journal of Research in Science
    Teaching, 30, 233-248.
-   Okyere, B. A., Heron, T. E., & Goddard, Y. (1997). Effects of
    self-correction on the acquisition, maintenance, and generalization
    of the written spelling of elementary school children. Journal of
    Behavioral Education, 7, 51-69.
-   Paine, S. C., Carnine, D. W., White, W. A. T., & Walters, G. (1982).
    Effects of fading teacher presentation structure (covertization) on
    acquisition and maintenance of arithmetic problem-solving skills.
    Education and Treatment of Children, 5, 93-107.
-   Patterson, G. R. (1982). Coercive family process. Eugene, OR:
    Castalia.
-   Schlinger, H. D. (1995). A behavior analytic view of child
    development. New York: Plenum Press.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
-   Skinner, B. F. (1957). Verbal behavior. Englewood Cliffs, NJ:
    Prentice-Hall.
-   Smeets, P. M., Lancioni, G. E., Ball, T. S., & Oliva, D. S. (1985).
    Shaping self-initiated toileting in infants. Journal of Applied
    Behavior Analysis, 18, 303-308.
-   Staats, A. W. (1968). Learning, language, and cognition. New York:
    Holt, Rinehart and Winston, Inc.
-   Stowitschek, J. J., Ghezzi, P. M., & Safely, K. N. (1987). \"I\'d
    rather do it myself:\" Self-evaluation and correction of handwriting.
    Education and Treatment of Children, 10, 209-224.
-   Swanson, H. L., O\'Shaughnessy, T. E., McMahon, C. M., Hoskyn, M., &
    Sachse-Lee, C. M. (1998). A selective synthesis of single subject
    intervention research on students with learning disabilities.
    Advances in Learning and Behavioral Disabilities, 12, 79-126.
-   van Houten, R. (1984). Setting up performance feedback systems in
    the classroom. In W. L. Heward, T. E. Heron, D. S. Hill, & J.
    Trap-Porter (Eds.), Focus on behaviour analysis in education (pp.
    114-125). Columbus, OH: Charles E. Merrill Publishing.
-   Ward, P., Crouch, D. W., & Patrick, C. A. (1998). Effects of
    peer-mediated accountability on opportunities to respond and correct
    skill performance by elementary school children in physical
    education. Journal of Behavioral Education, 8, 103-114.
-   Watson, D. L., & Tharp, R. G. (2002). Self-directed behavior:
    Self-modification for personal adjustment (8th ed.), Belmont, CA:
    Wadsworth/Thomson Learning.
-   Winston, A. S., & Baker, J. E. (1985). Behavior analytic studies of
    creativity: A critical review. The Behavior Analyst, 8, 191-205.
-   Wolery, M., Ault, M. J., & Doyle, P. M. (1992). Teaching students
    with moderate to severe disabilities: Use of response prompting
    strategies. New York: Longman.
-   Yeaton, W. H., & Bailey, J. S. (1983). Utilization analysis of a
    pedestrian safety training program. Journal of Applied Behavior
    Analysis, 16, 203-216.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Whichapproachestoresearchhavelearningastheirsubjectmatter/index.md","# Which approaches to research have learning as their subject matter? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-895fb9c486044a758a78d8c6f602361b}
Research is always research into something. Research always has a
subject matter. The term *subject matter* refers to the events, the
classes of activities, or the phenomena which are of interest to the
investigator. Clearly, a particular approach to research will only be of
use to students of learning and teaching if it includes learning
phenomena and/or teaching phenomena within its subject matter. The first
question which needs to be addressed, therefore, is the question of
whether each of the three main approaches to educational research
include learning and/or teaching as part of their subject matter.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Naturalsciencesocialscienceandethnographicapproachestoresearch/Ethnographicapproachestoeducationresearch/index.md","# Ethnographic approaches to education research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-df50f555a86147ddb21a67177f170c7a}
For most of the 20th century, the intensive investigation of a single
site or context has been referred to as ethnography. Ethnographic
research methods were initially developed by social anthropologists
during the first two decades of the 20th century. Descriptions of the
historical development of ethnographic research methods will be found in
Bogdan & Biklen (1998), Erikson (1986), and LeCompte & Preissle (1993).
The method appears to have been first applied to the study of
educational sites in the 1950s. For two early examples of educational
ethnography, see Becker (1952) and Henry (1955).

The ethnographic approach to educational research has been referred to
using a variety of names: the humanistic approach (Walker & Evers,
1997), constructivist research (Magoon, 1977), naturalistic inquiry
(Lincoln & Guba, 1985), the symbolic approach (Popkewitz, 1984),
ethnographic research (Dobbert, 1982; LeCompte & Preissle, 1993; Taft,
1997; Wolcott, 1988), interpretive research (Carr & Kemmis, 1986;
Erickson, 1986), and qualitative research (Bogdan & Biklen, 1998;
Eisner, 1991; Glaser & Strauss, 1967; Martella, Nelson &
Marchand-Martella, 1999; Smith, 1983).

During the qualitative vs. quantitative debates of the 1980s,
ethnographic research underwent a name change and is now most commonly
referred to as *qualitative research*. This usage is unfortunate in
several respects. First, most of the research which is being published
as qualitative inquiry is, in fact, research which has used an
ethnographic or microethnographic research method and it would be more
appropriately referred to as such -- as is done by LeCompte & Preissle
(1993). Secondly, much of the research which is being published as
qualitative inquiry is research which is based upon an interpretive
theory of knowledge and it would be more appropriately referred to as
such -- as Erickson (1986) has argued. Thirdly, the great majority of
educational researchers continue to use the term *qualitative* in its
original sense, that is, to refer to a kind of *data* (non-numerical
data). Qualitative data is, of course, collected not only by
ethnographic and interpretivist researchers but also by social science
researchers and by behaviour analysts. Redefinition of the term
qualitative to refer to a research methodology may leave us with no term
which can be used to distinguish between qualitative and quantitative
data.

In order to avoid confusion, this book will follow current usage and
refer to the family of research methods which employ ethnographic
procedures as *qualitative research.* When we come to discuss the
research procedures used by qualitative researchers we will tend to
refer to these as *ethnographic procedures*. When we come to discuss
qualitative research which is based upon interpretive assumptions, we
will tend to refer to this research as *interpretive research*.

By 1995 about one-sixth of the published research into learning and
teaching was being undertaken using a qualitative methodology and about
one half of the published research into teaching was being undertaken
using a qualitative research methodology (Church, 1998).

**Definition.** Ethnographic research is research which aims primarily
to describe what is happening in a particular setting together with the
participant\'s perspectives on these events. This kind of research tends
to be broadly focused on all of the events which are occurring in a
particular setting (rather than on just one or two types of events). It
usually aims to provide a holistic picture of how a particular social
group (such as a classroom) operates, and to accomplish this by means of
direct observation and interviews with key participants. At the present
time, ethnographic research is most commonly referred to as qualitative
research. Ethnographic research which attempts to explain people's
behaviour in terms of the beliefs which people hold about their
behaviour is commonly referred to as interpretive research and this is
the most common kind of ethnographic research currently being undertaken
in classrooms.
:::

::: referencesList
#### References

-   Becker, H. S. (1952). Social-class variations in the teacher-pupil
    relationship. Journal of Educational Sociology, 25, 451-465.
-   Bogdan, R. C., & Biklen, S. K. (1998). Qualitative research for
    education: An introduction to theory and methods. (3rd ed.). Boston:
    Allyn and Bacon.
-   Carr, W., & Kemmis, S. (1986). Becoming critical: Education,
    knowledge and action research. London: The Falmer Press.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N.Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Dobbert, M. L. (1982). Ethnographic research: Theory and application
    for modern schools and societies. New York: Praeger.
-   Eisner, E. W. (1991). The enlightened eye: Qualitative inquiry and
    the enhancement of educational practice. New York: Macmillan
    Publishing Co.
-   Erickson, F. (1986). Qualitative methods in research on teaching.
    In M. C. Wittrock (Ed.), Handbook of research on teaching (3rd ed.,
    pp. 119-161). New York: Macmillan.
-   Glaser, B., & Strauss, A. (1967). The discovery of grounded theory.
    Chicago: Aldine.
-   Henry, J. (1955). Docility, or giving the teacher what she wants.
    The Journal of Social Issues, 11, 33-41.
-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego: Academic Press.
-   Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly
    Hills, CA: Sage Publications.
-   Magoon, A. J. (1977). Constructivist approaches in educational
    research. Review of Educational Research, 47, 651-693.
-   Martella, R. C., Nelson, R., & Marchand-Martella, N. E. (1999).
    Research methods: Learning to become a critical research consumer.
    Boston: Allyn and Bacon.
-   Popkewitz, T. (1984). Paradigm and ideology in educational research.
    London: Falmer Press.
-   Smith, J. K. (1983). Quantitative vs. qualitative research: An
    attempt to clarify the issue. Educational Researcher, 15(1), 4-12.
-   Taft, R. (1997). Ethnographic research methods. In J. P. Keeves
    (Ed.), Educational research, methodology, and measurement: An
    international handbook (2nd ed., pp. 71-75). Oxford, England:
    Pergamon/Elsevier Science Inc.
-   Walker, J. C., & Evers, C. W. (1997). Research in education.
    Epistemological issues. In J. P. Keeves (Ed.), Educational research,
    methodology, and measurement: An international handbook (2nd ed.,
    pp. 22-31). Oxford, England: Pergamon/Elsevier Science Inc.
-   Wolcott, H. F. (1988). Ethnographic research in education. In R. M.
    Jaeger (Ed.), Complementary methods for research in education (pp.
    185-206). Washington, DC: American Educational Research Association.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Naturalsciencesocialscienceandethnographicapproachestoresearch/Socialscienceapproachestoeducationresearch/index.md","# Social science approaches to education research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-aa5eba343e404e93b7c5708a0bc35892}
For most of the 20th century, the primary datum of educational and
psychological research has been the average of the scores of samples of
subjects on some kind of test, rating scale or self-report instrument.
Where experiments have been undertaken, these have most commonly
involved the exposure of two or more groups of subjects to different
treatments, calculation of the mean outcome score for each group, and
the use of these mean scores as the measure of treatment effects.

The results of studies using this research methodology first began to
appear in educational research publications in the early 1900s. The
first educational experiment involving a control group appears to have
been a study published by Edward Thorndike in 1901 (Woodworth &
Thorndike, 1901). The statistical rules which are commonly used to
interpret differences between the mean scores of groups of subjects were
developed during the first quarter of the 20th century.

Galton was the first to make extensive use of the normal curve to study
psychological problems. . . . In 1896, Pearson, who worked under Galton,
published the formula for the product-moment correlation coefficient. In
the first decade of the 1900s, the essentials of the correlational
method, including the theory of regression, were developed, especially
by \[the\] British statisticians, Pearson and Yule. . . . Researchers
were also aware of the statistical significance of differences. In 1908,
under the name of Student, Gossett showed how to measure the standard
error of the mean and the principle of the t-test was formulated. . . .
In 1916, McCall, a student of Thorndike . . . recommended the setting up
of random experimental and control groups. . . . The contribution of Sir
Ronald Fisher was critical. With the publication of his *Statistical
Methods for Research Workers* in 1925, small-sample inferential
statistics became known, but were not immediately utilised. . . . In
1935, Fisher published his famous *The Design of Experiments,*
originally conceived for agriculture, and not widely applied in
education research before the late 1940s (de Landsheere, 1997, p. 11).

Because means (and correlations) became the primary data in educational
and psychological research with very little debate, there has been
little discussion of what this particular approach to educational
research should be called. It has been variously referred to as
mainstream educational research (e.g., Borg & Gall, 1989), the
scientific approach (e.g., Kerlinger, 1964, Walker & Evers, 1997), the
empirical-analytic approach (Popkewitz, 1984), the normative approach
(Cohen & Manion, 1994), quantitative research (Martella, Nelson &
Marchand-Martella, 1999), positivistic research (by interpretivist
researchers), between subjects research (Reber, 1995), between-groups
research (Church, 1996), and social science research (Krathwohl, 1993).
In this book, we will use the term *social science research* to refer to
the family of research procedures which involve the selection of one or
more samples of subjects, the application of one or more measures to
these subjects, and the attempt to draw conclusions either from
correlations between the several measures or from differences between
the mean scores of subgroups of subjects.

By the 1950s, the collection of sets of scores and the interpretation of
these using correlational or inferential statistics had become the most
commonly used method for studying learning and teaching, and it
continues to be the most commonly used method to this day. In 1995, some
60% of the studies of human learning and teaching published in
educational psychology journals involved the application of some kind of
social science research procedure (Church, 1998). The social science
methodology and its assumptions are deeply entrenched in the belief
systems of educational researchers, their publication practices, and the
training programmes which they provide for novice researchers.

**Definition.** Social science research is research which aims primarily
to collect data on the performance or characteristics of groups or
samples of people. Social science research is often undertaken to test a
theory about the relationships between two or more aspects of human
ability, cognitive functioning, or teaching method, and it attempts to
accomplish this by applying one or more tests or self-report measures to
samples of subjects and by aggregating the obtained scores to produce an
average score for each of the groups of interest. The data which is
collected is almost always interpreted with the aid of descriptive,
correlational, or inferential statistics. The social science research
which is most directly relevant to the study of learning and teaching is
an area of research which has come to be known as cognitive science.
:::

::: referencesList
#### References

-   Borg, W. R., & Gall, M. D. (1989). Educational research: An
    introduction (5th ed.). New York: Longman.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North: New Zealand Association
    for Research in Education.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N.Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Cohen, L., & Manion, L. (1994). Research methods in education (4th
    ed.). London: Routledge.
-   de Landsheere, G. (1997). History of educational research. In J. P.
    Keeves (Ed.), Educational research, methodology, and measurement: An
    international handbook (2nd ed., pp. 8-16). Oxford, England:
    Pergamon/Elsevier Science Inc.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Krathwohl, D. R. (1993). Methods of educational and social science
    research: An integrated approach. New York: Longman.
-   Martella, R. C., Nelson, R., & Marchand-Martella, N. E. (1999).
    Research methods: Learning to become a critical research consumer.
    Boston: Allyn and Bacon.
-   Popkewitz, T. (1984). Paradigm and ideology in educational research.
    London: Falmer Press.
-   Reber, A. S. (1995). The Penguin dictionary of psychology (2nd ed.).
    London: Penguin Books.
-   Walker, J. C., & Evers, C. W. (1997). Research in education.
    Epistemological issues. In J. P. Keeves (Ed.), Educational research,
    methodology, and measurement: An international handbook (2nd ed.,
    pp. 22-31). Oxford, England: Pergamon/Elsevier Science Inc.
-   Woodworth, R. S., & Thorndike, E. L. (1901). The influence of
    improvement in one mental function upon the efficiency of other
    functions (1). Psychological Review, 8, 247-261.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Naturalsciencesocialscienceandethnographicapproachestoresearch/Naturalscienceapproachestoeducationresearch/index.md","# Natural science approaches to education research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d2602f2345824d3eb8adc8b3efd80e62}
The idea of a natural science approach to the study of learning and
teaching dates from the late 19th century. The earliest studies of
learning and memory used simple counting procedures to describe the
effects of particular kinds of experience on behaviour and behaviour
change.

Perhaps the first investigator to experimentally isolate the sources of
variability in counts of behavior was Hermann Ebbinghaus (1850-1901). In
1885, Ebbinghaus began using numerical frequency of verbal recall as a
measure of strength of association or memory. . . . he invented a novel
experimental independent variable, the nonsense syllable and defined and
investigated the phenomena of learning and memory in terms of simple,
direct counting procedures (number of trials to completely learn a list,
number of items recalled as a function of the passage of time, etc.).
The extension of the natural science approach to measurement . . . has
its origins in the work of E.L. Thorndike (1898) who, in pursuing an
understanding of animal intelligence, arranged puzzles for animals to
solve and recorded both the time for solution and the number and nature
of unsuccessful attempts. . . . Probably the earliest and still among
the most elegant uses of instrumentation in the measurement of animal
behavior is in the work of Pavlov. . . . Three important features
characterize the work of Wundt, Thorndike, Ebbinghaus, and Pavlov and
place it squarely in the natural scientific tradition. First their units
of measurement were standard and absolute. . . . Second, all apparently
viewed variability as the scientific window through which to observe the
workings of basic controlling relationships. The third feature that
characterizes the work of these four investigators is their shared
tactic of collecting a large number of observations from each of a
relatively small number of subjects (Johnston & Pennypacker, 1993b, p.
34-35).

However, it was not until the mid 1960s that the first analyses of
learning in children, using a natural science methodology, began to
appear in the research literature (e.g., Allen, Hart, Buell, Harris &
Wolf, 1964; Hart, Allen, Buell, Harris & Wolf, 1964). These reports
marked the appearance, in the educational literature, of a completely
new kind of educational research - research which has come to be known
as behaviour analysis research. By 1995 approximately 17 per cent of the
empirical research into learning and teaching published in leading
educational psychology journals was research using a behaviour analysis
methodology (Church 1998). Brief histories of the development of
behaviour analysis will be found in Cooper, Heron & Heward (1987),
Johnston & Pennypacker (1993b), and Pierce & Epling (1995).

This new kind of research consists of a set of research methods (now
known as *behaviour analysis)*, a rapidly developing set of research
findings (usually referred to as *principles of behaviour)*, and a
unique philosophy of science (which behaviour analysts refer to as
*radical behaviourism*).

**Definition.** Natural science approaches to the study of learning and
teaching have the following characteristics. Investigations almost
always study behaviour change (that is, learning); change is measured by
making repeated observations of the learner\'s performance or
understanding over a number of days, weeks or months; behaviour change
is studied at the level of the individual; the primary aim of the
research enterprise is to identify classes of experience which are
consistently related to particular kinds of behaviour change; and this
aim is pursued using research procedures which are nearly always
experimental. The natural science approach which is most commonly used
to study learning and teaching is the approach which has come to be
known as behaviour analysis.
:::

::: referencesList
#### References

-   Allen, B. M., Hart, K. E., Buell, J. S., Harris, F. R., &
    Wolf, M. M. (1964). Effects of social reinforcement on isolate
    behavior of a nursery school child. Child Development, 35, 511-518.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N.Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Hart, B. M., Allen K. E., Buell, J. S., Harris, F. R., & Wolf, M. M.
    (1964). Effects of social reinforcement on operant crying. Journal
    of Experimental Child Psychology, 1, 145-153.
-   Johnston, J. M., & Pennypacker, H. S. (1993b). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Pierce, W. D., & Epling, W. F. (1995). Behavior analysis and
    learning. Englewood Cliffs, NJ: Prentice Hall.
:::"
".//Typesofresearchevidence/Approachestoresearchintolearningandteaching/Naturalsciencesocialscienceandethnographicapproachestoresearch/index.md","# Natural science, social science, and ethnographic approaches to research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3f99772c66d342ee8a68bfea5bde71cd}
Research into teaching is a relatively recent activity. The earliest
reports of teaching research date from the beginning of the 20th
century. The earliest educational researchers believed that educational
research would involve the application of scientific methods of
investigation to educational phenomena such as learning and teaching and
the term research is still used in this sense in some textbooks on
educational research methods. \"Research may be defined as the systematic
and objective analysis and recording of controlled observations that may
lead to the development of generalizations, principles, or theories,
resulting in prediction and possibly ultimate control of events\" (Best &
Kahn, 1993, p. 20). The key words in Best and Kahn's definition are
\"resulting in prediction\". It is an enhanced ability to make predictions
which is the hallmark of the results of scientific research in the
traditional sense of \"scientific\".

During the course of the 20th century, however, the meaning of the
phrase \"education research\" has gradually expanded to the point where
educators now use the word \"research\" to cover many different kinds of
investigative activity. \"Although the term originally referred to
activities related to the acquisition of basic knowledge in the
sciences, humanities, and arts, its contemporary usage permits it to be
applied to the acquisition of any form of information however trivial
that information may be\" (Travers, 1978, p. 3). Reber\'s *Dictionary of
Psychology* for example, defines research as \"Any honest attempt to
study a problem systematically or to add to knowledge of a problem\"
(Reber, 1995, p. 665). McMillan and Schumacher (1989, p. 8) define
research as \"a systematic process of collecting and analyzing
information (data) for some purpose\" while Shulman defines research to
include any form of \"disciplined inquiry\". \"When we speak of research,
we speak of a family of methods which share the characteristics of
*disciplined inquiry*. . . . What is important about disciplined inquiry
is that its data, arguments, and reasoning be capable of withstanding
careful scrutiny by another member of the scientific community\"
(Shulman, 1988, p. 4-5).

Because the definition of educational research has expanded to include
almost any kind of inquiry, this creates a dilemma. It means that we
will not be able to answer the question \"What is to count as evidence?\"
simply by referring to an agreed definition of research. Instead we will
have to examine the various kinds of investigative activities engaged in
by educational researchers and identify those types of investigation
which are most likely to generate the kinds of evidence which could,
conceivably lead to improvements in our understanding of learning and
teaching processes.

Sometimes it is suggested that what is to count as evidence might be
decided by compiling findings from investigations which have used
reliable research procedures. Any attempt to list educational research
procedures, however, generates a very long list. The 1997 *International
Handbook of Educational Research, Methodology and Measurement* (Keeves,
1997b) contains chapters on cross-sectional methods, experimental
methods, longitudinal methods, simulation methods, effective schools
research, correlational methods, quasi-experimentation, hierarchical
linear modelling, log linear models, path analysis, regression analysis,
and so on.

One common way of organising research methods textbooks and handbooks is
in terms of descriptive research procedures, correlational research
procedures, and experimental research procedures. The descriptive
procedures include questionnaires, structured interviews, focus group
interviews, rating scales, achievement testing, direct observation, time
sampling, taking running records, ethnography, and so on. The
correlational procedures include regression and multiple regression,
discriminant analysis, path analysis, hierarchical linear modelling,
quasi experimentation, and so on. Experimental procedures include all
the single-subject experimental procedures (alternating conditions
designs, reversal designs, multiple baseline designs, changing criterion
designs, and so on) and all the between groups experimental procedures.
Under the heading of experimental studies, Borg and Gall (1989) describe
the pretest-posttest control group design, the post-test-only design,
the single factor multiple-treatment design, two factor and three factor
designs, aptitude treatment interaction designs, the Solomon four group
design, and the counterbalanced design.

The problem with trying to distinguish between reliable and unreliable
findings on the basis of the investigative method used is that a
particular investigative method can be applied appropriately or
inappropriately and it can be applied carefully or carelessly. So this
procedure will not work either.

The solution which we have developed in this account is first to group
the research methods which might be used to study learning and teaching
under one of three general approaches to research and then to take into
account both the approach which has been used and the adequacy of the
way in which that approach has been applied in the particular
investigation under examination. The three general approaches to
research which we will consider are (a) the natural science approach
(and in particular behaviour analysis research), (b) the social science
approach (and in particular cognitive science research) and (c) the
ethnographic approach (and in particular interpretive research). (For an
example of a research methods text organised along these lines, see, for
example, Martella, Nelson and Marchand-Martella, 1999.)
:::

::: referencesList
#### References

-   Best, J. W., & Kahn, J. V. (1993). Research in education (7th ed.).
    Boston: Allyn and Bacon.
-   Borg, W. R., & Gall, M. D. (1989). Educational research: An
    introduction (5th ed.). New York: Longman.
-   Keeves, J. P. (Ed.) (1997). Educational research, methodology, and
    measurement: An international handbook (2nd ed.). Oxford, England:
    Pergamon/Elsevier Science Inc.
-   Martella, R. C., Nelson, R., & Marchand-Martella, N. E. (1999).
    Research methods: Learning to become a critical research consumer.
    Boston: Allyn and Bacon.
-   McMillan, J. H., & Schumacher, S. (1989). Research in education: A
    conceptual introduction (2nd ed.). Glenview, IL: Scott, Foresman.
-   Reber, A. S. (1995). The Penguin dictionary of psychology (2nd ed.)
    London: Penguin Books.
-   Shulman, L. S. (1988). Disciplines of inquiry in education: An
    overview. In R. M. Jaeger (Ed.), Complementary methods for research
    in education (pp. 3-17). Washington, DC: American Educational
    Research Association.
-   Travers, R. M. W. (1978). An introduction to educational research
    (4th ed.). New York: Macmillan Publishing Co.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Thegeneralisabilityofexperimentalresults/Docognitivescientistsexplorethegeneralisabilityoftheirexperimentalfindings/index.md","# Do cognitive scientists explore the generalisability of their experimental findings? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e385b58acc174c2286c0c5f4bbf99a5e}
The types of generalisations which are of primary interest to the
cognitive scientist are generalisations regarding causal relationships
(sometimes referred to as functional relationships) at the population
level. Cognitive scientists are relatively uninterested in the
performance of individuals or in the performance of non-representative
groups of individuals. The identification of general laws
(generalisations) is to be achieved by testing hypotheses using samples
of subjects drawn from defined populations of learners.

Social science generalisations are always generalisations from a sample
to a population. \"Statistical inferences have two characteristics. One,
the inferences are usually made *from samples to populations*. When we
say that the variables A and B are related because the statistical
evidence is *r* = .67, we are inferring that because *r* = .67 in *this*
sample it is *r* = .67, or near .67 in the population from which the
sample was drawn\" (Kerlinger, 1964, p. 150). It is not possible to argue
from a sample correlation or a sample mean backwards to the individual
case. This is because an average score is an abstraction; it is a
measure of the performance of the group *as a group*. It can never be
argued that because a particular intervention had a given effect on the
mean performance of a group that it will have exactly the same effect on
any individual learners to whom it is applied.

The fact that generalisability is primarily a function of replication
has been recognised by some social science researchers (e.g. Nunnally,
1960; Meehl, 1997). There must be many replications of each experimental
test both by different observers working under the same conditions and
by different observers each working under slightly different conditions.
\"The most important property of an empirical finding is . . .
replicability, that other investigators, relying on the description of
what was done, will (almost always) make the same (or closely similar)
observations\" (Meehl, 1997, p. 423).

But this is not the way that social and cognitive scientists work. Each
published study is a new study. Individual studies are hardly ever
replicated. In fact, \"the publication of \'significant\' results tends
to stop further investigation\" (Bakan, 1967, p. 10). This is because
social science experiments with highly significant results appear to be
definitive. The end result of the social science approach to the study
of learning and teaching has been a \"catalogue of inadequately
replicated techniques (the components of which have not been analyzed),
each of which worked at least once for the investigator who published
it\" (Johnston & Pennypacker, 1993, p. 179). While this corpus of
research \"may hold the appearance of an interwoven and established
literature, . . . it will prove to be a disappointing facade that does
not live up to its seeming utility\" (Johnston & Pennypacker, 1993, p.
179).
:::

::: referencesList
#### References

-   Bakan, D. (1967). On method: Toward a reconstruction of
    psychological investigation. San Francisco: Jossey-Bass.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale:
    Lawrence Erlbaum Associates.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Meehl, P. E. (1997). The problem is epistemology, not statistics:
    Replace significance tests by confidence intervals and quantify
    accuracy of risky numerical predictions. In L. L. Harlow, S. A.
    Mulaik, & J. H. Steiger (Eds.), What if there were no significance
    tests? (pp. 394-425). Mahwah, N.J.: Lawrence Erlbaum Associates.
-   Nunnally, J. (1960). The place of statistics in psychology.
    Educational and Psychological Measurement, 20, 641-650.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Thegeneralisabilityofexperimentalresults/index.md","# The generalisability of experimental results \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a4c7cf22508f4d94876198c27fb93fd8}
It is one thing to identify a functional relationship between a
particular independent variable (such as a certain kind of practice
activity) and a particular dependent variable (such as rate of learning
to read) and quite another thing to identify the circumstances under
which this effect occurs. Does this particular independent variable
affect just a single learning outcome, or does it affect a variety of
learning outcomes and, if so, which? Does this particular cause and
effect relationship occur with just a certain type of learner or does it
occur with learners with widely different learning histories and, if so,
which learners? Does the effect occur only under certain circumstances,
or does it occur under a range of circumstances and, if so, which
circumstances? Attempts to answer these kinds of questions are attempts
to explore the *generality* of a particular functional relationship.
Generality is also referred to by many writers as *generalisability*.
These two terms are synonymous. In social science research, the
generalisability of an experimental result is often referred to as the
*external validity* of an experimental result.

In order to identify the generality of a given effect, the scientist
must engage in a systematic programme of research in an attempt to
identify the conditions under which a given effect occurs and doesn't
occur. This process is referred to as *systematic replication* (Sidman,
1960). A series of studies which have as their aim an explorations of
the conditions under which a given effect occurs and doesn't occur are
referred to as systematic replication studies. Systematic replication
involves repeating the experimental study of a particular functional
relationship in additional studies during which one or more features of
the original experiments are systematically varied. These systematic
replication studies may vary the experimenters, the circumstances, the
characteristics of the learners, the type of learning outcome and so on.
:::

::: referencesList
#### References

-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Thegeneralisabilityofexperimentalresults/Dobehaviouranalystsexplorethegeneralisabilityoftheirexperimentalfindings/index.md","# Do behaviour analysts explore the generalisability of their experimental findings? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-af6066077fe141b09f94109bb1f50df9}
Behaviour analysts have very little interest in the observation and
description of particulars. They are primarily interested in
generalisations. Behaviour analysts use the term *generality* to refer
to the generalisability of their experimental findings. \"Generality
refers to universality or replicability. . . . A broad statement of the
question raised by generality is, \'If I take part or all of the
procedures that produced a result and apply them under circumstances
that are in some degree different, will I get the same kind of
effect?\'\" (Johnston & Pennypacker, 1993b, p. 177).

Behaviour analysts have written at length about generality and
distinguish between many different kinds of generality. (See, for
example, Johnston & Pennypacker, 1993a). A set of experimental results
may have generality across different species, across different learners,
across different response classes (behaviours), across different kinds
of curriculum content, across different settings or contexts, across
time, and so on. A set of experimental results may also indicate that a
particular variable or class of events (such as a demonstration, or an
error correction procedure) has a certain degree of generality across
behaviours or individuals, or that a particular process (such as
reinforcement or extinction) has a certain degree of generality across
behaviours or individuals, or that a particular procedure (such as a
good behaviour chart or the withdrawal of a privilege) has a certain
degree of generality across behaviours or individuals, and so on.

Behaviour analysts argue that a single experiment can never provide any
information regarding the generality of the effect which has been
observed. \"Regardless of how a study is conducted, it is impossible to
know the range of conditions under which its results can be reproduced.
The only way that this range can be determined is though a series of
systematic replications of the original study\" (Poling, Methot & LeSage,
1995, p. 29). In a systematic replication the independent and dependent
variables are similar to those of earlier investigations but differ in
at least one aspect - the one which is of interest as far as generality
is concerned.

An understanding of the generality of a particular variable, process, or
procedure emerges slowly. This is because many dozens of investigations
must be completed before even an outline emerges of the conditions under
which a given effect will and will not occur. \"External validity is not
a property of studies, but a process in which consumers of research
interact with research findings\" (Blampied, 1999, p. 100).

Behaviour analysts are interested in generality because, as our
understanding of the generality of particular variables and processes
increases, we are able to make increasingly accurate predictions with
respect to the effects of new procedures and the effects of old
procedures in new contexts.

The within-subject research procedures of the behaviour analyst have
been criticised by social science researchers as lacking in
generalisability (because the results of a single within-subject
experiment cannot be generalised to any population of learners).
However, it is important to note that a between-groups investigation is
also lacking in this kind of generalisability because its results cannot
be generalised to any individual learner. Behaviour analysts argue that,
when it comes to the study of teaching and learning, establishing
generalisability across individual learners and settings is more
important than establishing generalisability from samples to
populations, that this can only be established by systematic
replication, and that this is the case regardless of whether one is
engaged in within-subject experimentation or between-groups
experimentation.
:::

::: referencesList
#### References

-   Blampied, N. M. (1999). A legacy neglected: Restating the case for
    single-case research in cognitive-behaviour therapy. Behaviour
    Change, 16, 89-104
-   Johnston, J. M., & Pennypacker, H. S. (1993a). Strategies and
    tactics of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence
    Erlbaum Associates.
-   Johnston, J. M., & Pennypacker, H. S. (1993b). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Poling, A., Methot, L. L., & LeSage, M. G. (1995). Fundamentals of
    behavior analytic research. New York: Plenum Press.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/index.md","# How are the effects of teaching on learning to be measured? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5d02a86fe4174f41ad17a451f1c558ed}
Once the learning researcher or teaching researcher has developed an
accurate and reproducible measure of learning it becomes possible to
seek the answer to many interesting questions. For example learning
researchers may seek the answer to questions such as \"What are the
conditions which must be provided in order for students with achievement
level \"z\" to learn and remember how to do \"y\"? Teaching researchers may
seek the answer to questions such as \"What is the effect of teaching
procedure \"a\" on the rate of acquisition of skill \"b\" in children with
achievement level \"c\"?

This chapter examines the kinds of research methods which can be used to
identify relationships between teaching events (and other kinds of
events) and student learning. We pay particular attention to the kinds
of research methods which can be used to identify cause-and-effect
relationships because these are the ones which are of greatest interest
to teachers. The chapter is divided into the following sections.

Section 1 examines the kinds of research questions which are possible
and groups them into a number of categories according to the research
method required in order to answer the question.

Section 2 focuses on methods which can be used to identify functional
relationships (that is, cause and effect relationships) and examines the
relationship detection methods which have been developed by behaviour
analysts, cognitive and social scientists, and ethnographers.

Section 3 evaluates the relative utility and productivity of the
experimental relationship detection procedures developed behaviour
analysts, cognitive scientists and ethnographers.

Section 4 discusses the quality characteristics which must be met if an
experimental analysis is to yield a believable result. The following
experimental design features are identified and discussed: the
reliability (reproducibility) of the experimental procedure, the
accuracy of the measure of experimental effects, the validity of the
conclusions drawn from the experimental result, and the chain of
inference which is involved in interpreting the result of an experiment
in learning (or teaching).

Section 5 examines the accuracy of the inferences which are being drawn
from the results of (a) the within-subject experiments of the behaviour
analyst and (b) the randomised groups experiments of the cognitive
scientist and identifies some of the problems arising from the way in
which significance testing procedures are currently being employed.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Typesofquestionsandtheresearchmethodsrequiredtoanswerthem/Threetypesofrelationships/index.md","# Three types of relationships \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-be77e4d14ce446dcb29bc2c9f5349be2}
Questions about relationship may be questions about differing kinds of
relationships. Consider the following questions:

1.\"If a child is receiving large numbers of negative remarks from the
teacher, does that mean that they are also receiving few positive
remarks?\"

2.\"Do students complete more work in class when they receive frequent
positive remarks from teachers?\"

3.\"Do students who frequently volunteer answers during the course of a
lesson achieve higher scores on subsequent tests of lesson content?\"

In the first case, the child is the \"subject\" (because it is they who
are experiencing the remarks). The remarks are *external* to the child.
They are part of the child's *experience*. They are part of the child's
learning environment*.* Both the positive and negative remarks are
external to the students. So the first question is a question about an
*environment-environment* relationship. It is the relationship between
two classes of environmental variables (positive and negative teacher
remarks) which is of interest.

In the second case, completing work is a student *behaviour*, and
positive remarks from teachers are external to the student. They are an
aspect of the students' learning *environment.* So the second question
is a question about an *environment-behaviour* relationship. It is the
relationship between an aspect of the learner\'s environment, and a
particular aspect of the learner\'s behaviour which is of interest.
Environment-behaviour relationships are of particular interest to
teachers because teachers have a responsibility to help children master
new behaviours, skills and understandings and are, therefore, very
interested in the environmental arrangements which need to be provided
in order to bring about these improvements in competence.

In the third case, the students are the subjects and the relationship
which is of interest is a *behaviour-behaviour* relationship. The
investigator wants to know if there is a relationship between
\"volunteering answers\" (Behaviour 1) and \"completing test questions
correctly\" (Behaviour 2). Correlational studies of behaviour-behaviour
relationships are very common in the educational research literature.
Many thousands of published studies in education have sought to discover
the size of the correlation between such behaviours as scores on IQ
tests, scores on different kinds of achievement tests, scores on
retention tests, performance on self-esteem measures, performance on
locus of control inventories, performance on learning styles
questionnaires, measures of motivation, and so on.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Typesofquestionsandtheresearchmethodsrequiredtoanswerthem/Descriptivequestionsandrelationalquestions/index.md","# Descriptive questions and relational questions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-64fa4ced6bfa43d7bd39cdfb4a8cf1c4}
The aim of research is to find the answer to questions for which the
answer is not yet known. Such questions may take a variety of forms.
Consider, for example, the following questions:

1.\"What are primary teachers\' views as to how writing should be taught
in the classroom?\"

2.\"How do teachers actually teach writing in the classroom?\"

3.\"Do more experienced teachers provide more help with corrections
during writing periods than less experienced teachers?\"

4.\"What is the effect, on the amount which a child writes, of helping a
child to correct his or her writing errors?\"

Questions 1 and 2 are questions about the current state of affairs. In
order to answer the first question, we would need to talk to teachers,
ask them about their views and then *describe* these views. In order to
answer the second question, we would need to observe teachers at work
and then *describe* the kinds of things which teachers do during writing
lessons.

We could ask similar questions about any kind of teaching or learning
activity: co-operative learning techniques, whole language approaches to
reading, accelerated learning techniques, adapting teaching to
students\' learning styles, and so on. Questions 1 and 2 may be referred
to as *descriptive questions* because they imply a descriptive research
strategy. In order to answer them, the investigator must observe what is
happening, or talk to people about what is happening, so that this can
be described.

Questions 3 and 4 are questions about *relationships*. Questions 3 asks
\"Does the amount of help with corrections which teachers give co-vary
with the teacher\'s experience?\" In other words, is there a correlation
(a relationship) between the experience of teachers and the amount of
help which they provide with corrections? Questions 4 asks \"Does the
amount which a child writes from day to day co-vary with the amount of
help which the child receives in correcting his or her writing errors?\"

To answer the second two questions, we must observe and measure *two*
factors in each case. To answer Question 3 we must find out, for each
teacher, (a) how much teaching experience they have had and (b) how much
help with corrections they give. Then we need to calculate the
*correlation* between the two measures. To answer Question 4 we would
need to find out, for each child, (a) how much help with corrections
they are receiving and (b) how much they are writing. We would then need
to calculate the correlation between these two measures. Alternatively,
we could conduct an experiment in which we varied the amount of help
provided, and observed the amount written, in an attempt to determine
whether different amounts of help result in different amounts being
written.

Questions 3 and 4 may be described as *relational questions* because
they imply a research strategy which will identify relationships between
variables, that is, relationships between recurring events. The two main
research procedures which are used to identify relationships are the
correlational procedures and the experimental procedures.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Typesofquestionsandtheresearchmethodsrequiredtoanswerthem/Between-groupsexperimentsandwithin-subjectexperiments/index.md","# Between-groups experiments and within-subject experiments \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-de02bf82f08b4acaa139b91d2e9a3b91}
In educational and psychological research, two general types of
experiment have evolved. These are (a) the between-groups experiment and
(b) the within-subject experiment.

**Between-groups experiments.** In a between-groups experiment, the
learners are divided into at least two groups, an experimental group and
a control group, and the learners in the experimental group are exposed
to the experimental treatment while the learners in the control group
are not. The effects of the experimental treatment are measured by
comparing the average post-treatment performance of the experimental
subjects against that of the control subjects. Obviously, this kind of
experimental method can only be used where a relatively large number of
students are being exposed to the same teaching procedure.

The main weakness of this procedure as a way of studying learning is
that the individual subjects in each group bring different skills and
capabilities with them to the experiment and, as a consequence, are
differently affected by the experimental treatment. As a result, it is
often impossible to draw, from this kind of experiment, any compelling
conclusions regarding the effects of the experimental treatment on the
learning of the individuals who took part in the experiment.

In addition, the results of this kind of experiment are almost always
reported in terms of changes in the *mean* scores of the learners in
each group. The mean score of a group of learners can improve even when
some of the learners in the group have learned nothing. To conclude that
a given teaching method is more effective than a second method simply
because it has produced a higher *mean* score is a highly problematic
practice because the mean score may be hiding the fact that some
students improved while some did not improve at all.

Generally speaking, the between-groups method is appropriate only where
the researcher is interested in the mean level of performance of a
particular population of learners, as would be the case during a large
scale evaluation of a particular teaching programme, or set of teaching
materials, or type of class (or school) organisation.

**Within-subject experiments.** Within-subject experiments involve the
repeated observation of the performance of individual learners over a
period of time. Treatment effects are measured by comparing the
performance changes observed in the days following the introduction of
the experimental treatment against the same subject\'s performance in
the days prior to the treatment (rather than against the performance of
some control group which has not been exposed to the treatment).

The within-subject experiment avoids many of the problems inherent in
the between-groups experiment. It can be used to measure the effects of
particular teaching procedures on the learning of individual children.
Where several children are involved, this kind of experiment provides
information about the performance changes of each individual child. And
pre-experimental differences between children are removed as possible
causes of experimental effects (because each individual learner
experiences both the \"control\" treatment and the experimental
treatment).

The within-subject experiment generates information about the
performance changes of individuals. It is, therefore, a more suitable
method for studying learning (which occurs only in individuals) and for
studying the ways in which particular teaching variables influence the
skill development of individual learners. It is also an appropriate
procedure for studying the effects of particular teaching and
therapeutic procedures on the adaptive and maladaptive behaviour of
individuals. Thirdly, the within-subject experimental analysis has
become the research method of choice amongst research scientists who are
seeking to identify functional relationships, that is, the variables
upon which human behaviour and human learning depend.

Within-subject measures of the effects of teaching on learning are a
fairly recent development in educational research and did not begin to
appear in the scientific literature until about 1968. Prior to that time
almost all measures of teaching effects used the between-groups
procedure. Because the within-subject experimental method is relatively
new, it is not always described in research methods textbooks. Because
an understanding of within-subject experimentation is essential
knowledge for teachers, teacher educators and teaching researchers, this
is a very serious omission.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Typesofquestionsandtheresearchmethodsrequiredtoanswerthem/index.md","# Types of questions and the research methods required to answer them \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-66916b21e942496b9266c6580bb07e99}
There are many different types of questions which can be asked of
learning and teaching -- ranging from \"Did any learning occur?\" through
to \"What are the conditions which need to be provided in order to
produce a competent airline pilot?\" Obviously, the research method which
is likely to provide an answer to a given research question differs from
one type of question to the next.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Typesofquestionsandtheresearchmethodsrequiredtoanswerthem/Descriptivecorrelationalandexperimentalprocedures/index.md","# Descriptive, correlational and experimental procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ac89cfcc99ba437480fafd62b49c81c0}
In order to identify relationships between particular kinds of teaching
events and particular types of learning outcomes, we need a research
procedure which is effective in detecting relationships. Not all
research procedures are procedures which can be used to detect
relationships.

**Descriptive procedures.** Descriptive research is research which aims
simply to describe some kind of naturally occurring phenomenon such as
the mathematical skills of children of different ages, or the managerial
skills of teachers, or the attitudes of teachers to a given educational
problem. Descriptive research is a useful mode of inquiry where no-one
knows what is actually happening or where people have conflicting
beliefs about what is happening. But it is not a mode of enquiry which
can be used to identify relationships.

**Correlational procedures.** Correlational research is research which
sets out to identify and describe relationships between naturally
occurring events but without going to the trouble of conducting an
experiment. In a correlational study, nothing is manipulated. There are
no experimental treatments (the participants are not exposed to
different kinds of teaching or different kinds of experiences).
Correlational studies, too, are useful in the early stages of
investigation of a new field of inquiry because they can serve as a rich
source of hypotheses for subsequent experimental studies. However,
correlational studies cannot identify cause-and-effect relationships.
This is because when we observe a correlation between two variables we
can never tell whether variation in the first is causing variation in
the second, whether variation in the second is causing variation in the
first, or whether variation in both is due to variation in some other
variable which we never collected any data on.

**Experimental procedures.** Only experimental studies can identify
cause-and-effect relationships. An experiment is a controlled
observation during which the variable of interest is manipulated so that
its effects can be measured. In a teaching experiment, it is usually
some aspect of teaching or practice which is manipulated so that its
effects on student learning can be measured.

In an experiment, the variable which is manipulated is called the
*independent variable*. In teaching and learning experiments, the
independent variable is usually some kind of instructional variable but
it can be any aspect of the learner\'s experience or any aspect of the
learner\'s interaction with their environment. An experiment measures
the effect of manipulating the independent variable. The measure of
effect is called the *dependent variable*. The measure of effect is
called the dependent variable because the measure which is obtained is
dependent upon what was done to the independent variable during the
experiment. In teaching experiments and learning experiments, the
dependent variable is usually some measure of learning, that is some
measure of change in the behaviour, knowledge, understanding, motivation
or attitude of the learner.

In education and psychology, experiments are used to detect and to
analyse *environment-behaviour* relationships. It is not possible to use
an experimental procedure to study behaviour-behaviour relationships
(because we can't change a person's behaviour without first making some
kind of change to their environment) and it makes no logical sense for
teaching researchers to conduct experiments into environment-environment
relationships (because these provide no information about how our
interaction with the environment affects our learning). In teaching
research, experimental analyses are almost always analyses of
environment-behaviour relationships because the factors which are of
most interest to teachers are the ones which they can do something about
and these factors are *external* to the learner, that is, they involve
the learner's interaction with his or her environment.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Typesofquestionsandtheresearchmethodsrequiredtoanswerthem/Distinguishingbetweenindependentvariablesanddependentvariables/index.md","# Distinguishing between independent variables and dependent variables \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e32a82076bc247b79674dbd0a3b8336a}
When the subject matter is teaching and/or learning the dependent
variable which is of primary interest is learning, that is, improvement
in the *behaviour* of the learner. Other behaviours such as intelligence
(acting intelligently), self-esteem (acting confidently), metacognition
(using appropriate learning procedures) and so on cannot be used as the
*independent variables* in an experiment because they are behaviours and
they cannot be manipulated without first manipulating the learner's
environment. If they are \"manipulated\" simply by selecting samples of
students who do and do not engage in these behaviours then this makes
the study a correlational study. If a behaviour such as \"metacognition\"
is manipulated by, say, teaching metacognitive skills, then this *can*
be studied experimentally. In this case, teaching metacognitive skills
is the independent variable (the environmental factor), and there are
two dependent variables: (a) use of the newly acquired metacognitive
skills (a behaviour), and (b) performance on the test of learning. Both
(a) and (b) are behaviours.

The distinction between independent variables (which may be having an
effect on learning) and dependent variables (the changes in behaviour or
knowledge or attitude which we refer to as learning) is a matter of very
great importance. This is because cognitive scientists routinely confuse
the two. For example, a search for cognitive science reports on
self-esteem will identify many reports in which a measure of self-esteem
is the dependent variable, that is, the learning outcome. But the same
search will identify an even larger number of reports where self-esteem
has been used as the independent variable by, for example, comparing the
performance of groups of people some of whom exhibit high levels of
behaviour indicative of self esteem and some of whom engage in low
levels of such behaviour. While this simply reflects a confusion which
is extremely common in everyday talk, it is not a confusion which would
ever be tolerated in a *scientific* study of learning processes.

In order to develop a useful theory of learning, learning researchers
must come to some agreement as to what properly constitutes an
independent variable and what properly constitutes a dependent variable.
The present practice of using learning outcomes such as reading level as
the dependent variable (the measure of learning outcome) on some
occasions and the independent variable (one of the factors presumed to
be necessary for learning) on other occasions is most unlikely to lead
to an increased understanding of the factors which are necessary for
learning.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howusefularetherelationshipdetectionproceduresofthethreemainapproaches/Howusefularethecorrelationalproceduresofthecognitivescientist/index.md","# How useful are the correlational procedures of the cognitive scientist? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-627aff15b2f24a7b8a3d4b166cbe41f4}
One of the ways in which cognitive scientists attempt to identify
relationships is by applying various kinds of correlational procedures.
In 1995, some 30 per cent of the published social science research into
learning and teaching involved the application of correlational research
methods (Church, 1998). This is surprising given that most kinds of
learning experiences (including all of the teaching content and teaching
method variables) can be manipulated experimentally, given that a
correlational study cannot identify cause-and-effect relationships, and
given that the information generated by a correlational study is
relatively trivial information. Possibly the reason for the continued
inappropriate use of the correlational study is because it is relatively
easy to administer tests, self-report scales, or instruments to a sample
of learners, to calculate the correlation between these measures, and to
write up the results of the study for a research dissertation or
publication.

As a procedure for identifying functional relationships, correlational
procedures have certain shortcomings -- shortcomings which are often
exacerbated by the widespread tendency to misinterpret the data which
can be obtained from such studies.

1\. The size of the correlation coefficient tends to increase as sample
heterogeneity increases. It is, therefore, not possible to evaluate a
reported correlation, or to compare the correlations obtained across
different studies of the same variables, unless the sample standard
deviations are reported for each of the measures which were
administered. Although essential, this information (the sample variance)
is frequently omitted from published reports of correlational studies.
This omission makes these studies uninterpretable (Cohen, 1997).

2\. The size of the correlation coefficient depends to a very large
extent on the degree of overlap between the constellation of skills,
achievements, and/or beliefs sampled by each of the measures used. Where
there is any overlap at all, a statistically significant correlation is
to be expected. It is this factor which makes the results of most
correlational studies trivial. Furthermore, interpretation of a
correlation coefficient is only possible if the researcher either
provides a detailed description of the repertoire of skills,
achievements, or beliefs assessed by each measure, or reproduces those
measures in an appendix to the research report. This information,
however, is rarely provided by the authors of correlational research
reports.

3\. Correlational methods continue to be used by social and cognitive
science researchers to test cause-and-effect hypotheses (Valsiner,
1986). This is an illegitimate use of the correlational method and is
described as such in most research methods text books. \"One cannot
impute causal relationships to such variables on the basis of the
correlation coefficient alone\" (Popham, 1967, p. 75). The use of complex
variants of the correlational method (such as linear regression or path
analysis) does not alter this fact.

4\. The correlation coefficients obtained during correlational
investigations are most commonly interpreted by applying a test of
statistical significance to the obtained correlation coefficient. Given
a reasonable number of subjects, a very small correlation coefficient
will often be sufficient to reject the null hypothesis that there is no
signficant correlation between two measures of the same subjects. In the
real world, however, a given measure of performance is of little use as
a predictor variable unless it accounts for a reasonable proportion (say
50 per cent or more) of the variance in the second variable - and it is
this criterion which should be applied in interpreting the results of
all correlational studies of learning and teaching variables.

5\. Researchers who use correlational designs frequently use them in an
attempt to measure the correlation between organismic variables (such as
intelligence, educational level, or gender) and learning outcomes, that
is, to study behaviour-behaviour relationships. The rationale behind the
use of organismic variables as independent variables is that such
variables function as adequate substitutes for the learning histories of
which they are the outcome. \"Subjects come to our studies with these
variables (characteristics) ready-made. . . . Early environment,
heredity and other circumstances have made individuals what they are\"
(Kerlinger, 1964, p. 42). The social scientist\'s use of organismic
variables as independent variables is problematic because most of the
organismic variables studied by social and cognitive scientists (reading
level, intelligence, self esteem, locus of control, and so on) are, in
fact, *classes of learning outcomes*. Eventually, a science of learning
will need to describe the origins of reading skills, intellectual
skills, self-esteem, locus of control beliefs, and so on and this can
happen only if such skills and beliefs are treated as dependent
variables, that is, only if they are treated as the phenomena which are
to be explained - perhaps by studying the learning histories which give
rise to them.
:::

::: referencesList
#### References

-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, New Zealand.
-   Cohen J. (1997). The earth is round (p\<.05). In L. L. Harlow, S. A.
    Mulaik, & J. H. Steiger (Eds.), What if there were no significance
    tests? (pp. 21-35). Mahwah, NJ: Lawrence Erlbaum Associates.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Popham, W. J. (1967) Educational statistics: Use and interpretation.
    New York: Harper & Row.
-   Valsiner, J. (1986). Between groups and individuals: Psychologists\'
    and laypersons\' interpretations of correlational findings. In J.
    Valsiner (Ed.), The individual subject and scientific methodology
    (pp.134-151). New York: Plenum Press.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howusefularetherelationshipdetectionproceduresofthethreemainapproaches/index.md","# How useful are the relationship detection procedures of the three main approaches? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b4102ee2062d46f58cb5bc4938b0fb41}
Because educational researchers use such a wide array of different
procedures in their attempts to identify functional relationships, to
measure the strength of relationships, and to measure the effects of
teaching events on learning outcomes, it must be asked whether some of
these research methods are more useful than others.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howusefularetherelationshipdetectionproceduresofthethreemainapproaches/Howusefularetheexperimentalproceduresofthecognitivescientist/index.md","# How useful are the experimental procedures of the cognitive scientist? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b7087b60b8a843fda9bb5d18a24d1d80}
Between-groups experimental procedures and the statistical procedures
which have to be mastered in order to interpret the results of such
experiments remain the staple content of research methods textbooks and
research methods courses around the world. Experiments using one or
another of the between-groups designs also dominate the published
research literature on learning. However, these procedures have a number
of important shortcomings when learning is the subject-matter of
investigation. One of these has already been mentioned and that is the
fact that learning involves a process of change (a transition) and that,
when a number of learners are observed or tested just once, this
observation catches each learner at a different point in this
transition. Aggregating these observations to calculate a mean score
makes absolutely no logical sense.

Another major shortcoming of the between-groups methodology arises as a
result of the fact that the experimental and the control treatments are
*experienced by different individuals*. This means that the effects of
experimental treatments are *always contaminated by learning history
effects.* This is because individual learners always bring different
skills and capabilities with them to a between-groups experiment and,
hence, are differently affected by any experimental treatment. \"Each
subject typically experiences only one of the conditions being compared.
This means that comparisons of the effects of independent variable and
control conditions must involve different subjects, which confounds the
effects of treatment conditions with between subject variability\"
(Johnston & Pennypacker, 1993, p. 183).

Of course, the experimental and control treatments do not *necessarily*
have to be applied to different individuals. They could be applied to
the same individuals using one of the repeated measures, within-groups
procedures designed for this purpose. In practice, however, 86 per cent
of the experiments reported by social and cognitive scientists are
experiments in which different groups of subjects have received the
experimental and control treatments (Church, 1998). This preference
seems to have arisen as a result of the requirements of the significance
testing procedure routinely used by social scientists to evaluate the
results of their experiments. One of the assumptions underlying the use
of procedures such as analysis of variance is that the groups of scores
must be uncorrelated. Between-groups designs meet this assumption
whereas within-groups designs do not.

For the student of learning and teaching, this confounding of
experimental effects with learning history effects creates two very
serious problems.

First, one of the primary aims of a science is to look for order in the
variability of the science\'s subject matter. In chemistry, for example,
the variability in naturally occurring compounds has been reduced by
scientific investigation to a finite number of chemical elements. In the
field of learning and teaching the variability to be understood and
explained is differences in the rate of learning and the accomplishments
of individuals. However, this is not the subject matter of cognitive
science. Cognitive scientists treat differences between individuals as a
source of error, refer to it as \"error variance\" or \"chance variability\"
and, instead of studying its origins, treat it as the error term against
which treatment effects are to be evaluated.

To some experimenters, chance is simply a name for the combined effects
of uncontrolled variables. If such variables are, in fact, controllable,
then chance in this sense is simply an excuse for sloppy
experimentation. . . . If the uncontrolled variables are actually
unknown, then chance is . . . a synonym for ignorance. Science is
presumably dedicated to stamping out ignorance, but statistical
evaluation of data against a baseline whose characteristics are
determined by unknown variables constitutes a passive acceptance of
ignorance (Sidman, 1960, p. 45).

Secondly, the confounding of treatment effects and learning history
effects places a severe restriction on the independent variables which
can actually be studied using this method. It means that the
between-groups methodology *can only be used to study the effects of
independent variables which have a greater effect* than the effect of
differences in prior learning history. Because differences in learning
history have extremely powerful effects, this places a severe limitation
on the teaching conditions and learning experiences which can actually
be studied using this methodology.

It also makes it difficult to see the effects of experimental treatments
which only have small effects. A number of investigators have studied
the power (the sensitivity) of samples of psychological experiments and
have concluded that the power of the typical between-groups experiment
is about .5 or .6. That is, the likelihood of the typical between-groups
experiment detecting a treatment effect when there is one, is about 60
per cent and the likelihood of two separate replications of the same
experiment both detecting a treatment effect when there is one is about
.6 x .6 or 36 per cent. This, say the critics of social science
experimentation, is one of the major reasons why even lengthy series of
investigations into the same topic so often fail to generate any kind of
conclusion or consensus about the answer to the question under
examination (Rossi, 1997; Schmidt & Hunter, 1997).
:::

::: referencesList
#### References

-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N.Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Rossi, J. S. (1997). A case study in the failure of psychology as a
    cumulative science: The spontaneous recovery of verbal learning.
    In L. L. Harlow, S. A. Mulaik, & J. H. Steiger (Eds.), What if there
    were no significance tests? (pp. 176-197). Mahwah, N.J.: Lawrence
    Erlbaum Associates
-   Schmidt, F. L. & Hunter, J. E. (1997). Eight common but false
    objections to the discontinuation of significance testing in the
    analysis of research data. In L. L. Harlow, S. A. Mulaik, & J. H.
    Steiger (Eds.), What if there were no significance tests? (pp.
    38-64). Mahwah, N.J.: Lawrence Erlbaum Associates.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howusefularetherelationshipdetectionproceduresofthethreemainapproaches/Howusefularetheexperimentalproceduresofthebehaviouranalyst/index.md","# How useful are the experimental procedures of the behaviour analyst? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-03e864bd697e4618a3ec2e9ab6ab1569}
The teacher or teacher educator who examines a sample of behaviour
analysis reports will find that most of these are reports of
within-subject experiments, that the data have been presented separately
for each learner (rather than being aggregated), that the data have been
presented graphically (rather than statistically), and that some attempt
has been made to determine whether or not the experimental effect is
reproducible either across participants or else across occasions.
Examination of the thousands of experiments undertaken to date further
reveals that most of the relationships which are being studied have been
the subject of repeated experimental analysis under a variety of
conditions and that replication is the norm rather than the exception.
As a consequence, the experimental analyses of the behaviour analyst
work in the sense that they regularly generate believable data and they
frequently generate reproducible results. These experiments are also
generating results which can be generalised to individual learners. This
makes these results much more useful to the practising teacher than the
results of between-groups experiments which cannot be generalised to
individual learners.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Therelationshipdetectionproceduresusedbythethreemainapproachestoresearch/Therelationshipdetectionproceduresoftheethnographer/index.md","# The relationship detection procedures of the ethnographer \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5613dc9069c04553a6217710363570d0}
Ethnographic research is almost always descriptive. Ethnographers rarely
undertake comparative evaluations or experiments. In fact, ethnographers
go to some pains *not* to manipulate the setting in which they are
working. \"Investigators take care to avoid purposive manipulation of
variables in the study\" (LeCompte & Preissle, 1993, p. 3). Because
researchers who engage in ethnographic and other kinds of qualitative
research do not conduct experiments, they have no way of finding out
whether an apparent relationship (e.g. between a particular kind of
classroom experience and a particular kind of attitude on the part of
the students) is a functional relationship or whether it just appeared
that way to the researcher. Because qualitative research is purely
descriptive, its only use is in developing answers to descriptive
questions of the form \"What is going on here?\" While a qualitative study
may point to possible relationships -- relationships which might be
studied by behaviour analysts or cognitive scientists, this all that
they can accomplish.
:::

::: referencesList
#### References

-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego, CA: Academic
    Press.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Therelationshipdetectionproceduresusedbythethreemainapproachestoresearch/Therelationshipdetectionproceduresusedbycognitivescientists/index.md","# The relationship detection procedures used by cognitive scientists \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-96d137d19caf4d1ea23b1ab7f0ca2418}
In their search for relationships, researchers who employ a social
science methodology make use of a variety of research designs. The 1997
*International Handbook of Educational Research, Methodology and
Measurement* (Keeves, 1997) contains chapters on cross-sectional
methods, experimental methods, longitudinal methods, simulation methods,
effective schools research, correlational methods,
quasi-experimentation, hierarchical linear modelling, log linear models,
path analysis, regression analysis, and so on. Borg and Gall (1989)
describe the following types of research methods: correlational methods,
prediction studies, multiple regression methods, discriminant analysis,
path analysis, structural equation modelling, quasi-experimental studies
and true experiments. Under the heading of experimental studies, they
describe the pretest-posttest control group design, the posttest-only
design, the single factor multiple-treatment design, two factor and
three factor designs, aptitude treatment interaction designs, the
Solomon four group design, and the counterbalanced design.

When cognitive scientists undertake experiments, these are almost always
between-groups experiments where the effect of the experimental
treatment is measured by comparing the average post-treatment retention
or achievement of experimental subjects against that of control group
subjects.

When cognitive scientists study effects, they study the effects of two
main kinds of variables: treatment variables and attribute variables.
Treatment variables are sometimes referred to as active variables
because they can be actively manipulated. \"Treatment variables are those
factors that the experimenter manipulates and to which he or she assigns
subjects\" (Best & Kahn, 1993, p. 137). Attribute variables are also
referred to as organismic variables or as assigned variables. \"Attribute
variables are those characteristics that cannot be altered by the
experimenter. Such independent variables as age, sex, race, and
intelligence level have already been determined, but the experimenter
can decide to include them or remove them as variables to be studied\"
(Best & Kahn, 1993, p. 137). The use of attribute variables as
independent variables is another key difference between cognitive
science and behaviour analysis. For the cognitive scientist and the
social scientist, variability in a measure of performance (such as level
of motivation) can function as either a dependent variable (the variable
to be explained) or as an independent variable (a possible explanation).
For the behaviour analyst variability in a measure of performance can
only function as a dependent variable (the phenomenon to be explained).
:::

::: referencesList
#### References

-   Best, J. W., & Kahn, J. V. (1993). Research in education (7th ed.).
    Boston: Allyn and Bacon.
-   Borg, W. R. & Gall, M. D. (1989). Educational research: An
    introduction (5th ed.). New York: Longman.
-   Keeves, J. P. (Ed.) (1997). Educational research, methodology, and
    measurement: An international handbook (2nd ed.). Oxford, England:
    Pergamon/Elsevier Science Inc.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Therelationshipdetectionproceduresusedbythethreemainapproachestoresearch/Therelationshipdetectionproceduresusedbybehaviouranalysts/index.md","# The relationship detection procedures used by behaviour analysts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-830d313b3b744d05a87df349068aced9}
Behaviour analysts have shown a strong preference for experimental
analysis and 95% of published behaviour analysis reports are reports of
experiments (Church, 1998). Most behaviour analysis experiments are
within-subject experiments rather than between-groups experiments. The
experimental procedures of the behaviour analyst are variously referred
to as single-case experiments (Barlow & Hersen, 1984; Martella, Nelson &
Marchand-Martella, 1999), within-subject experiments (Church, 1996;
Poling, Methot & LeSage, 1995), or behaviour analysis experiments
(Cooper, Heron & Heward, 1987).

During a within-subject experiment, the effects of a particular
environmental intervention (such as a change in teaching procedure) are
measured by observing and recording the behaviour changes of individual
learners, first, on a number of occasions prior to the intervention and,
then, on a number of occasions following the intervention. \"Discovering
or establishing baselines in the behavior of individual subjects, either
by recording data across time as it occurs prior to any intervention, or
by manipulating contingencies so that behavior develops a steady state,
behavior analysts begin with a measure of behavior for each of the
subjects involved. The effect of an independent variable is assessed
against each subject\'s individual baseline\" (Chiesa, 1994, p. 84). In
the case of experimental analyses of learning, the purpose of the
baseline condition is often to establish *rate of acquisition* prior to
introduction of the experimental teaching procedure (Church, 2004).

Most of the experimental designs used by behaviour analysts are
replication designs. These replication designs take a variety of forms:
alternating conditions designs, reversal designs, multiple baseline
designs, changing criterion designs, and so on, but all have one
characteristic in common and that is that the experimenter attempts to
obtain more than a single measure of the effect of a particular
experimental treatment on the learning outcome which is of interest. A
detailed discussion of the replication designs most commonly used in
behaviour analysis research will be found in Cooper, Heron and Heward
(1987).

Although behaviour analysis textbooks usually describe the most commonly
used kinds of experimental designs, they also counsel a flexible
approach to experimental design. \"The fact is that *there are no rules
of experimental design*. Every experiment is unique\" (Sidman, 1960). Use
of a within-subject time-series, experimental method allows the
behaviour analyst to make modifications to his or her experiment as the
experiment proceeds and, hence, to change focus during the course of an
experiment and to explore new questions in addition to the question
which initially motivated the research. For example, an experiment which
resulted in much variability in performance during the baseline or
pre-intervention phase might be modified to introduce additional
experimental controls and further (modified) baseline observations
undertaken before the experimental manipulation was introduced
(Blampied, 1999). An experimental evaluation of an intervention which
did not work might be extended to include subsequent phases documenting
the effectiveness of successive attempts to improve the effectiveness of
that intervention (e.g. Sandford, 1991).
:::

::: referencesList
#### References

-   Barlow, D. H., & Hersen, M. (1984). Single case experimental
    designs: Strategies for studying behavior change (2nd ed.). New
    York: Pergamon.
-   Blampied, N. M. (1999). A legacy neglected: Restating the case for
    single-case research in cognitive-behaviour therapy. Behaviour
    Change, 16, 89-104
-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North, New Zealand: New
    Zealand Association for Research in Education.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin, New Zealand.
-   Church, R. J. (2004) Can the reversal design be used to measure the
    effects of teaching on learning? Paper presented to the annual
    conference of the New Zealand Association for Behaviour Analysis,
    Christchurch.
-   Martella, R. C., Nelson, R., & Marchand-Martella, N. E. (1999).
    Research methods: Learning to become a critical research consumer.
    Boston: Allyn and Bacon.
-   Poling, A., Methot, L. L., & LeSage, M. G. (1995). Fundamentals of
    behavior analytic research. New York: Plenum Press.
-   Sandford, C. (1991). The effects of contingent access to a menu of
    free time activities on the reading rate of two third-form boys.
    Unpublished EDUC 650 case study project report.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Therelationshipdetectionproceduresusedbythethreemainapproachestoresearch/index.md","# The relationship detection procedures used by the three main approaches to research \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ef9e8e7ee7ed4bcb97be7a289778533b}
The existence within education and psychology of two separate
experimental research paradigms raises important questions about how
best to set about the task of identifying the factors which facilitate
and hinder learning. It is these questions which are explored in the
sections which follow. For example, have certain approaches to research
proved to be more useful and productive than others? Do some research
procedures provide more accurate and reproducible measures of teaching
effects than others? Could any of the teaching and learning research
procedures which have been developed to date be said to be scientific?
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howaccuratearewithin-subjectandbetween-groupmeasuresofexperimentaleffects/Problemsinherentinthehypothetico-deductivemethodpractisedbysocialscientists/index.md","# Problems inherent in the hypothetico-deductive method practised by social scientists \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-16aae81b183e416a956cba5a7799f85d}
One of the most common uses of the between-groups experiment is to test
experimenter-generated hypotheses about relationships between
independent and dependent variables. Hypothesis testing has an important
role to play in the development of scientific understanding. However, in
order for hypothesis testing to work - in order for it to generate
useful results - certain conditions must be met.

First, it must be possible to get either a confirmatory or
disconfirmatory result and this is possible only if there is a close
agreement between the theoretical concepts and the empirical measures of
these concepts. This is rarely the case in a between-groups experiment.
Most cognitive science constructs refer to large, poorly defined classes
of behaviour. Whenever an experiment fails to turn out as expected, the
results can be argued away by arguing that the outcome measures used
\"were not valid measures of *x*\"*.*

Secondly, as Popper (1963) has argued, experimental results which fail
to confirm a particular hypothesis are far more informative than
experimental results which confirm a particular hypothesis. This is
because an hypothesis can never be demonstrated to be true no matter how
many times it has been confirmed while a single disconfirmation may
demonstrate the hypothesis not to be true. So the primary aim of those
who seek to pursue the hypothetico-deductive method should be to conduct
experiments which subject current hypotheses to the most critical test
possible and the most valuable experimental results should be those
which fail to confirm a currently accepted hypothesis.

The most critical test is, of course, a test of the most specific
hypothesis. An example might be that instructional procedure *y* results
in a rate of acquisition which is 2.5 times greater than that produced
by a standard procedure. (This is much more specific - much riskier -
that the standard NHST hypothesis that procedure *y* results a \"faster\"
rate of acquisition.) It is the failure to reject risky hypotheses which
provides the strongest corroboration for a theory.

However, many between-groups experiments are so poorly designed that a
non-significant result usually fails to provide convincing evidence that
the tested hypothesis is false. This is because \"there are numerous
different theoretical ways that could account for some correlation or
difference being nonzero . . . a theory tested in this way takes only a
small risk of being refuted if it is false\" (Meehl, 1997, p. 408).

Furthermore, the editors of social science journals routinely favour
reports of significant results over reports of non-significant results
and have done so for more than half a century (Bakan, 1967). One of the
effects of this practice is to suppress the results of experiments which
fail to achieve statistical significance, regardless of whether this
failure is due to a non-existent effect, a weak effect, a poorly
controlled experiment, or a poorly designed measure of learning. In
fact, the results of experiments where the null hypothesis could not be
rejected are often not even submitted for publication because the
authors know in advance that such experiments tend to be rejected by
journal editors. This leads to the file drawer effect which so often
biases attempts to produce a meta-analysis of previous research in a
particular field. The effect of this routine suppression of
non-confirmatory results over a long period of time is difficult to
determine but may well have resulted in the survival of many hypotheses
long past their use-by date. Furthermore, it has almost certainly
removed one of the main incentives which might have operated to produce
improvements in experimental control and experimental method, that is,
the publication of conflicting results.

Thirdly, the interpretation of experimental data is a complex process
which requires the application of good judgement. The experimenter must
consider all rival hypotheses including the possibility that the
dependent variable measures may not have been up to standard, the groups
may have been incomparable from the outset, the experiment may have been
too short, the treatments may have been inadequately controlled, and so
on. It is also possible that a non-significant result may simply
indicate that we have not yet discovered the variables which need to be
controlled (Sidman, 1960). An over reliance on statistical significance
testing too often results in a failure to take into account \"the many
details of experimental method or extraneous factors that might bear on
the conclusions\" (Johnston & Pennypacker, 1993, p. 186). \"Despite the
awesome pre-eminence this method has attained in our experimental
journals and textbooks . . . it is based upon a fundamental
misunderstanding of the nature of rational inference, and is seldom if
ever appropriate to the aims of scientific research\" (Rozeboom, 1960, p.
417).

Proponents of statistical significance testing would do well to abandon
it, at least to the extent of abandoning the corrupt scientific method.
If they must do statistical significance testing, they should do it
after the results have been interpreted with respect to the research
hypothesis as the scientific method requires. There are always rival
hypotheses to consider and the null hypothesis should rightfully take
its place among these secondarily important hypotheses (Carver, 1978, p.
394).

By substituting statistics for replication, and a statistical criterion
for the reasoned interpretation of empirical data, an edifice has been
erected which could be collapsed *simply by changing the criterion*.
This is because \"there is absolutely no reason (at least provided by the
method) why the point of statistical \'significance\' should be set at
the 95% level, rather than, say the 94% or 96% level\" (Rozeboom, 1960,
p. 417). Research findings which have been accepted could be rejected,
not as a result of subsequent experiments failing to replicate the
original experiment, but *simply as a result of a change* in the rule
which is being applied in interpreting the results. The adoption of the
95% confidence interval *as a convention* means that

The body of knowledge constituting much of contemporary psychology could
be overturned not by the introduction of *new* evidence, but by a simple
change in procedure. By shifting the usual and convenient level of
significance from 5 per cent to 3 per cent or 1 per cent, much of what
currently constitutes the body of knowledge of experimental psychology .
. . would change according to the new level of significance. . . .
Furthermore, reliance on the results of significance tests as a form of
evidence for or against scientific assertions brings into question the
meaning of the term \'evidence\' when that evidence may be reversed from
one level of confidence to another. At one level of confidence, a result
may favor a scientific assertion, while at another level the same result
may go against the same assertion (Chiesa, 1994, p. 79).

Generally speaking, the journals which publish the results of social
science and cognitive science experiments do not require any
demonstration by the experimenters that their results are reproducible,
that is, replication is not a requirement for publication. As a
consequence, the great majority of social science experiments in
teaching and learning have never been replicated and the reliability
(reproducibility) of their results remains completely unknown.
:::

::: referencesList
#### References

-   Bakan, D. (1967). On method: Toward a reconstruction of
    psychological investigation. San Francisco: Jossey-Bass.
-   Carver, R. P. (1978). The case against statistical significance
    testing. Harvard Educational Review, 48, 378-399.
-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Meehl, P. E. (1997). The problem is epistemology, not statistics:
    Replace significance tests by confidence intervals and quantify
    accuracy of risky numerical predictions. In L. L. Harlow, S. A.
    Mulaik, & J. H. Steiger (Eds.), What if there were no significance
    tests? (pp. 394-425). Mahwah, N.J.: Lawrence Erlbaum Associates.
-   Popper, K. (1963). Conjectures and refutations: The growth of
    scientific knowledge. London: Routledge and Kegan Paul.
-   Rozeboom, W. W. (1960). The fallacy of the null-hypothesis
    significance test. Psychological Bulletin, 57, 416-428.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howaccuratearewithin-subjectandbetween-groupmeasuresofexperimentaleffects/Howaccuratearethecognitivescientistsattemptstomeasureexperimentaleffects/index.md","# How accurate are the cognitive scientists' attempts to measure experimental effects? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8fd78e35f5c646479716d8badaec94bd}
In a between-groups experiment the researcher determines whether or not
a correlation exists between the independent and dependent variables
selected for study by examining the size of the difference between the
mean performance of control group subjects and the mean performance of
experimental group subjects at the end of the experiment.

Social science methods texts almost always contain a discussion of the
internal validity of between-groups experiments, that is, the kinds of
extraneous variables which need to be controlled if the experimenter is
to be able to draw a valid conclusion from the results of such an
experiment. Discussions of the extraneous variables which pose the
greatest threat to the internal validity of a between-groups experiment
are usually adaptations of a discussion first published by Campbell and
Stanley in 1963. In their original article, Campbell and Stanley listed
the following threats to the internal validity of a between-groups
experiment: *history* (the operation of extraneous variables during the
course of the experiment), *maturation* (incidental learning by and
other uncontrolled changes in the subjects during the course of
experiment), *testing* (the effects of earlier tests on the scores on
later tests), *instrumentation* (the effects of unreliable testing or
observation procedures), *regression towards the mean* (changes which
occur when experimental groups are constituted on the basis of extreme
scores on a classificatory measure prior to the experiment), *selection*
(confounds caused by the selection of groups which are incomparable at
the outset), and *experimental mortality* (confounds caused by the
unequal loss of subjects from experimental and control groups).

Other factors which can make it difficult to interpret the results of a
between-groups experiment include failure of the random assignment
procedure to generate equivalent groups, failure to implement the
experimental treatments in the manner intended by the experimenter,
experimental treatments which operate for too short a period for their
effects to be revealed, failure to control relevant learning experiences
outside of the treatment periods, failure to control for teacher or
therapist commitment to one of the experimental treatments, failure to
avoid ceiling or floor effects on measures of learning outcomes, failure
to take into account the biasing effects of one or two greatly superior
(or greatly inferior) scores on the outcome measure, and so on
(Krathwohl, 1985; Lawson, 1997; Lysynchuk, Pressley, d\'Ailly, Smith &
Cake, 1989).

In order to achieve a level of experimental control sufficient to allow
conclusions to be drawn from the experimental results, investigators who
use the between-groups methodology are counselled to select outcome
measures which are demonstrably valid and reliable, to assign at least
30 subjects to each treatment group, to randomly assign subjects to
treatments, to operate treatments for a reasonable length of time, to
ensure that treatments are administered in the manner intended, to
provide adequate controls over extraneous variables, to use an
appropriate experimental design, and so on (see, for example, Campbell &
Stanley, 1963; Cook & Campbell, 1979; Krathwohl, 1985).

Most methods texts recognise that non-equivalent experimental groups
constitute one of the most serious threats to internal validity and
include a series of suggestions as to how this problem can be avoided.
These suggestions include: the random assignment of subjects to
experimental and control groups, matching cases (selecting pairs of
individuals with closely similar characteristics) and assigning one of
them to the experimental and the other to the control group, matching
groups (ensuring that the pre-experimental means and standard deviations
of the experimental and control groups on selected variables are closely
similar), or the use of analysis of covariance procedures as the
analytic technique (see, for example, Sax, 1968). Sometimes attempts are
made to control for the effects of variability in a particular
organismic variable by building that variable into the experiment as one
of the experimental factors.

Some social science methods texts also discuss the issue of experimental
sensitivity, the factors on which it depends, and the steps which can be
taken in order to ensure that between-groups experiments are
sufficiently sensitive to detect treatment effects (see, for example,
Lawson, 1997; Lipsey, 1990). Social scientists usually refer to
experimental sensitivity as the *power* of the experiment. Some of the
factors identified by Lawson (1997) as factors affecting power
(experimental sensitivity) include: the degree of variability between
subjects with respect to performance on the outcome measure, ambiguity
in the instructions to subjects, variability in the administration of
treatments across teachers or sites, the use of outcome measures which
lack sensitivity, the use of unreliable outcome measures, variability in
the administration of outcome measures, sample size, and the type of
inferential statistic selected.

One of the difficulties faced by the authors of between-groups
experiments is that the difference between the mean score of the
experimental group and the mean score of the control group at the end of
the experiment is often quite small relative to the spread of scores
within each group - making it difficult to ascertain whether the
experimental treatment has had an effect or not.

The most commonly used solution to this problem is the one first
suggested by R.A. Fisher (1935). Once the group means have been
calculated, social scientists usually apply a statistical significance
testing procedure to their data in order to decide whether or not any
conclusions should be drawn from that data. To decide whether any
conclusions should be drawn from a set of group means, between-groups
researchers ask the question \"Is this difference greater than might be
expected on the basis of \'chance\', that is, on the basis of errors of
measurement alone?\" The chance expectation is referred to as the *null
hypothesis*. The null hypothesis is a statement to the effect that
\"these groups have all been drawn from the same population\" or, more
specifically, that the differences between these means are no greater
than the differences which tend to occur when samples are drawn from a
single population. \"Statistical hypotheses must be tested against
something. . . . The alternative usually selected is the null
hypothesis, which was invented by Sir Ronald Fisher. The *null
hypothesis* is a statistical proposition which states, essentially, that
there is no relation between the variables\" (Kerlinger, 1964, p. 173-4).
If the experimental results fit the chance model, then they are said to
be *not significant*. If they depart sufficiently from the chance model,
then they are said to be statistically *significant*.

Differences between two or more mean scores are said to be statistically
significant if there is a less than 1 in 20 probability of them fitting
the chance (the random differences) model. The selection of the .05
confidence level for rejecting the null hypothesis is largely a matter
of custom although not entirely so. \"A level of statistical significance
is to some extent chosen arbitrarily. But it is certainly not completely
arbitrary. . . . The .05 and .01 levels correspond fairly well to two
and three standard deviations from the mean of a normal probability
distribution. . . . The .05 level was originally chosen - and has
persisted with researchers - because it is considered a reasonably good
gamble. It is neither too high nor too low for most social scientific
research\" (Kerlinger, 1964, p. 154).

The calculation of descriptive, inferential and probability statistics
has been greatly simplified during recent years with the appearance of
computer programmes designed specifically to compute such statistics.
However, the researcher who uses such programmes must still have a
knowledge of statistics sufficient to determine which statistical tests
can appropriately be applied to the data collected, sufficient to
determine whether or not the data meet the assumptions of that
statistical test, and sufficient to interpret the results of the
computer generated statistical analysis in the light of the experimental
procedures used.
:::

::: referencesList
#### References

-   Campbell, D. T., & Stanley, J. C. (1963). Experimental and
    quasi-experimental designs for research on teaching. In N. Gage
    (Ed.), Handbook of research on teaching (pp. 171-246). Chicago: Rand
    McNally.
-   Cook, T. D., & Campbell, D. T. (1979). Quasi-experimentation: Design
    & analysis issues for field settings. Chicago: Rand McNally
    Publishing Co.
-   Fisher, R. A. (1935). The design of experiments. Edinburgh,
    Scotland: Oliver and Boyd.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Krathwohl, D. R. (1985). Social and behavioral science research: A
    new framework for conceptualizing, implementing and evaluating
    research studies. San Francisco: Jossey-Bass Publishers.
-   Lawson, M. J. (1997). Experimental studies. In J. P. Keeves (Ed.),
    Educational research, methodology, and measurement: An international
    handbook (2nd ed., pp 126-134). Oxford, England: Pergamon/Elsevier
    Science Inc.
-   Lipsey, M. (1990). Design sensitivity: Statistical power for
    experimental research. Newbury Park: Sage.
-   Lysynchuk, L., Pressley, M., d\'Ailly, H., Smith, M, & Cake, H.
    (1989). A methodological analysis of experimental studies of
    comprehension strategy instruction. Reading Research Quarterly, 24,
    458-470.
-   Sax, G. (1968). Empirical foundations of educational research.
    Englewood Cliffs, NJ: Prentice-Hall Inc.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howaccuratearewithin-subjectandbetween-groupmeasuresofexperimentaleffects/index.md","# How accurate are within-subject and between-group measures of experimental effects? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5f08270e91454570858eba5c2c638611}
Different approaches to research conceptualise the experimental design
task in different ways and hence take different positions on such
matters as establishing procedural reliability, making provision for
replications, and taking care to ensure sufficient experimental control
to guarantee the internal validity of the analysis.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howaccuratearewithin-subjectandbetween-groupmeasuresofexperimentaleffects/Howaccuratearethebehaviouranalystsattemptstomeasureexperimentaleffects/index.md","# How accurate are the behaviour analysts' attempts to measure experimental effects? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0d645eaaa51443c0bd39c583ced1833a}
Behaviour analytic reports of within-subject experiments generally show
a high degree of awareness of the conditions which must be met before an
experiment is likely to yield an interpretable result. Behaviour
analysis methods texts (e.g. Cooper, Heron & Heward, 1987) routinely
make reference to the need for experimental designs in which only one
variable is manipulated at a time, in which treatment fidelity is
demonstrated, in which baseline and treatment phases operate for a
sufficient length of time, and in which direct replication is used to
assess the reliability of measures of treatment effects.

Behaviour analysis researchers assess whether or not there is a
correlation between their independent and dependent variables by
examining the changes in performance which occur from one phase to the
next (as the independent variable is introduced, or withdrawn, or its
value changed). When a change in the independent variable is followed by
substantial changes in performance, that is, changes which can be seen
by visual inspection, this is taken as evidence of a correlation between
the independent and dependent variables.

For behaviour analysts, the achievement and demonstration of
experimental control is an essential component of the research
enterprise and the task of achieving experimental control is greatly
simplified by virtue of the fact that a within-subject methodology is
employed. Because each subject serves as his or her own control,
inter-subject differences in pre-experimental learning history, ability,
achievement, motivation, and so on cannot function as extraneous
variables in this kind of experiment.

With the effects of differences in prior history removed by the use of a
within-subject methodology, the remaining extraneous variables which
need to be controlled are (a) intra-subject variables (such as illness,
fatigue or self-directed learning between sessions), (b) variations in
the administration of the experimental treatment and (c) variations in
the conditions experienced during the control or baseline condition. In
general terms, behaviour analysts attempt to control the effects of each
of these classes of extraneous variables simply by taking a reasonable
degree of care in the design and implementation of their experiments.

Because multiple observations are being made under each experimental and
control condition, the failure to achieve adequate levels of
experimental control is often revealed by a pattern of within-phase
variability in the data. \"The fact that each subject\'s behavior is
repeatedly measured under each supposedly constant condition permits
behavioral variability to serve as a metric of the degree of control
attained\" (Johnston & Pennypacker, 1993, p. 184). When behaviour, or
rate of learning, fluctuates from day to day within a phase, this often
signals that unintended changes are occurring with respect to at least
one of the non-experimental conditions which affect the learning outcome
which is of interest. One of the strengths of the within-subject
methodology is that, where such fluctuations occur, the experimenter may
take action to identify the factor which is causing the unexpected
variability and either redesign the experiment to measure its effects,
or else redesign the experimental procedures to provide better control
over the extraneous variable and its effects.

Behaviour analysts interpret unexpected variability in their data as a
state of affairs which should be responded to by an attempt to improve
the experimental procedures *not* by recruiting more subjects, or by
aggregating data, or by resorting to a statistical analysis of the data.
\"Eliminating the effects of a variable statistically is not equivalent
to eliminating its effects on behavior by controlling the variable
directly\" (Johnston & Pennypacker, 1993, p. 243). The effects of
uncontrolled variables \"are not cancelled statistically. They are simply
buried so that their effects cannot be seen\" (Sidman, 1960, p. 162).

Behaviour analysts argue that a measure of experimental effect must be
shown to be reliable in the same way that a measure of behaviour change
must be shown to be reliable. They argue that a measure of treatment
effect may be judged to be reliable if it can be *reproduced.* \"There is
no way actually to know whether experimental findings are reliable
except through conducting *direct replications*, which are studies that
essentially duplicate conditions of the original investigation\" (Poling,
Methot & LeSage, 1995, p. 28).

Direct replication involves repeating the experiment. Most of the
experimental designs used by behaviour analysts are, in fact,
replication designs. These replication designs take a variety of forms
including alternating conditions designs, reversal designs, multiple
baseline designs, changing criterion designs, and so on. All of these
experimental designs have one characteristic in common and that is that
the experimenter attempts to obtain more than a single measure of the
effect of a particular experimental treatment on the learning outcome
which is of interest. A detailed discussion of the replication designs
most commonly used in behaviour analysis research will be found in
Cooper, Heron & Heward (1987).

Generally speaking, the journals which publish behaviour analysis
experiments require a demonstration by the experimenter that his or her
experimental effects can be and have been replicated. As a result, the
great majority of the environment-behaviour relationships described in
behaviour analysis reports have been replicated many times. The fact
that behaviour analysts employ measurement procedures and experimental
procedures which are likely to generate accurate measurement results,
institute regular reliability and replicability checks, and must report
the results of these data quality evaluations as a condition of
publication represents a very considerable advance over the data quality
assurance procedures employed by both ethnographers and cognitive
scientists.
:::

::: referencesList
#### References

-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Poling, A., Methot, L. L., & LeSage, M. G. (1995). Fundamentals of
    behavior analytic research. New York: Plenum Press.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Howaccuratearewithin-subjectandbetween-groupmeasuresofexperimentaleffects/Problemsarisingfromtheinappropriateuseofsignificancetestingprocedures/index.md","# Problems arising from the inappropriate use of significance testing procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f2f1b5c594e94ec594aeb23b4c8b71d6}
Social science research strategies such as the between-groups
experiment, and the statistical procedures used to interpret the data
from such experiments, have been the subject of critical scrutiny for
more than 40 years. This critical scrutiny has identified a number of
fatal shortcomings in these research strategies as they are
conventionally employed. These include problems arising from the
inappropriate use of significance testing procedures and problems
inherent in the hypothetico-deductive method used by social scientists.

Null hypothesis significance testing (NHST) has been referred to as a
\"tyranny\" (Loftus, 1991), as \"the most misused and misconceived
hypothesis testing model employed in psychology\" (Nunnally, 1960, p.
642), as \"the most boneheadedly misguided procedure ever
institutionalised in the rote training of science students\" (Rozeboom,
1997, p. 336), as \"one of the worst things that ever happened in the
history of psychology\" (Meehl, 1978, p. 817) and as a procedure which
\"has not only failed to support the advance of psychology as a science
but also has seriously impeded it\" (Cohen, 1997, p. 22).

All of the NHST procedures are procedures which seek an answer to the
following question: \"What is the probability that these two (or more)
groups were drawn from the same population?\" By convention, if this
probability is more than 1 in 20, the null hypothesis (that the groups
are from the same population) is accepted and, if this probability is
less than 1 in 20, the null hypothesis is rejected and the results are
labelled *statistically significant*.

Critics of the NHST procedure have pointed out that this procedure says
nothing about the effects of the experimental treatments, it says
nothing about the probable cause of differences between the mean
post-test scores of the experimental groups, and it says nothing about
whether the same result would be obtained if the experiment was
replicated.

The inferential errors which are most commonly made when applying the
NHST procedure are as follows.

The first mistake which researchers make is to argue that the complement
of the p value (e.g. 1 - .05 = .95) indicates the likelihood that the
research hypothesis is true (e.g. that a given teaching method did, in
fact, have an effect on retention). This inference cannot be made from
the results of a significance test (Carver, 1978; Cohen, 1997).

Too many people in education do not seem to realize that a statistically
significant result at the .05 level has nothing directly to do with
inferences about the research hypothesis. Even if the null hypothesis
can be rejected, several other alternative or rival hypotheses still
must be ruled out before the validity of the research hypothesis is
confirmed. Only after rigorous theorizing, careful design of
experiments, and multiple replications of the findings in varied
situations should one contend that the probability is high that the
research hypothesis is true (Carver, 1978, p. 386).

A second mistake which social science researchers routinely make is to
argue that the complement of a p value indicates the probability that a
given result will be replicated by future investigators. This inference
cannot be made from the results of a significance test.

Whether or not the results are replicable or reliable actually depends
upon whether the important variables can be controlled and manipulated
in exactly the same way to give the same results. . . . there is no
magic in the numbers collected and analyzed using the assumptions of the
null hypothesis that allows us to infer anything about the probability
that another researcher will be able to get a similar mean difference. .
. . Too often statistical significance is substituted for actual
replicative evidence; too often statistical significance covers up an
inferior research design (Carver, 1978, p. 385-386).

A number of social scientists (e.g. Robinson & Levin, 1997; Steiger,
1990; Thompson, 1999) have argued (as do behaviour analysts) that
demonstrating an effect to be reproducible is far more important than
demonstrating an effect to be statistically significant. \"The only
conclusive evidence for result replicability is to actually replicate
the study. And replication studies are important, and are too
undervalued in the contemporary social sciences\" (Thompson, 1999, p.
71).

To summarise, \"the test of significance does not provide the information
regarding psychological phenomena characteristically attributed to it\"
(Bakan, 1967, p. 1-2). \"The mere rejection of a null hypothesis provides
only meager information\" (Nunnally, 1960, p. 643). It is \"singularly
unsuited to the task of advancing the development of cumulative
scientific knowledge\" (Schmidt & Hunter, 1997, p. 56) and may well be
one of the main reasons why psychology has failed to develop as a
scientific endeavour (Meehl, 1978). What learning researchers and
teachers want to know is *how much of an effect* a particular type of
experience has on learning. \"Physical scientists have learned much by
storing up amounts, not just directions\" (Tukey, 1969). But randomised
groups experiments which rely on the NHST procedure provide us with no
information about this important question.

Critics of the NHST procedure argue that the valid interpretation of
research results is more dependent upon sound reasoning than it is upon
the calculation of any inferential statistic, that the *p* value
produced by a significance test is uninterpretable unless accompanied by
estimates of power and of effect size, that experimental hypotheses
should be quite specific about the size of the effect to be observed so
that if the risky hypothesis is confirmed it provides strong
corroboration for the theory, and that all studies should be replicated
several times with only the reproducible results being published (see,
for example, Harlow, 1997).
:::

::: referencesList
#### References

-   Bakan, D. (1967). On method: Toward a reconstruction of
    psychological investigation. San Francisco: Jossey-Bass.
-   Carver, R. P. (1978). The case against statistical significance
    testing. Harvard Educational Review, 48, 378-399.
-   Cohen J. (1997). The earth is round (p\<.05). In L. L. Harlow, S. A.
    Mulaik, & J. H. Steiger (Eds.), What if there were no significance
    tests? (pp. 21-35). Mahwah, N.J.: Lawrence Erlbaum Associates.
-   Harlow, L. L. (1997). Significance testing introduction and
    overview. In L.L. Harlow, S. A. Mulaik, & J.H. Steiger (Eds.), What
    if there were no significance tests? (pp. 1-17). Mahwah, N. J.:
    Lawrence Erlbaum Associates.
-   Loftus, G. R. (1991). On the tyranny of hypothesis testing in the
    social sciences. Contemporary Psychology, 36, 102-105.
-   Meehl, P. E. (1978). Theoretical risks and tabular asterisks: Sir
    Karl, Sir Ronald, and the slow progress of soft psychology. Journal
    of Consulting and Clinical Psychology, 46, 808-834
-   Nunnally, J. (1960). The place of statistics in psychology.
    Educational and Psychological Measurement, 20, 641-650.
-   Robinson, D., & Levin, J. (1997). Reflections on statistical and
    substantive significance, with a slice of replication. Educational
    Researcher, 26(5), 21-26.
-   Rozeboom, W. W. (1997). Good science is abductive, not
    hypothetico-deductive. In L. L. Harlow, S. A. Mulaik, & J. H.
    Steiger (Eds.), What if there were no significance tests? (pp.
    335-339). Mahwah, NJ: Lawrence Erlbaum Associates.
-   Schmidt, F. L. & Hunter, J. E. (1997). Eight common but false
    objections to the discontinuation of significance testing in the
    analysis of research data. In L. L. Harlow, S. A. Mulaik, & J. H.
    Steiger (Eds.), What if there were no significance tests? (pp.
    38-64). Mahwah, NJ: Lawrence Erlbaum Associates.
-   Steiger, J. H. (1990). Structural model evaluation and modification:
    An interval estimation approach. Multivariate Behavioral Research,
    25, 173-180.
-   Thompson, B. (1999). Five methodological errors in educational
    research: A pantheon of statistical significance and other faux pas.
    In B. Thompson (Ed.), Advances in social science methodology Vol. 5,
    (pp. 23-86). Stamford, CT: JAI Press Inc.
-   Tukey, J. W. (1969). Analyzing data: Sanctification or detective
    work? American Psychologist, 24, 83-91.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Whatstandardsareusedtoevaluatetheresultsofanexperimentalanalysis/Thereliabilityreproducibilityoftheexperimentalprocedure/index.md","# The reliability (reproducibility) of the experimental procedure \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7656bac6e0fe4a4ca4876e65e73ae713}
The first question which may be asked of a set of experimental
procedures is the question \"Did each experimental treatment operate in a
consistent fashion from one occasion to the next?\" In other words, if
these procedures were replicated (repeated) would they produce much the
same result? This question is analogous to asking whether or not a
measurement procedure has been operated in a reliable fashion.

When we talk about the reliability of an experimental procedure we are,
in essence, talking about the reproducibility of that experimental
procedure. We are asking, \"If I have to replicate this experiment, will
I be able to reproduce the experimental procedures?\" In order to produce
a reliable measure of treatment effects, the experimenter must devise a
way of holding the value of the independent variable constant from one
session to the next within each experimental treatment, and devise a way
of ensuring that the value of the independent variable experienced
during the administration of experimental sessions differs consistently
from the value experienced during control sessions. This facet of
experimental design is most commonly referred to as experimental
control. The reliability of a set of experimental results is closely
related to the degree of experimental control achieved during the course
of the experiment.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Whatstandardsareusedtoevaluatetheresultsofanexperimentalanalysis/Thevalidityoftheconclusionsdrawnfromtheexperimentalresults/index.md","# The validity of the conclusions drawn from the experimental results \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-da76939063444d01a244c29f54fedd73}
The third question which may be asked of an experiment is the question
\"Are the conclusions which have been drawn by the researcher valid
conclusions given the way in which the experiment was designed and the
nature of the conditions under which it was undertaken?\" In particular,
is it possible to conclude that the learning which was observed was a
function of the experimental manipulation and not a function of any
other variable which was operating during the course of the experiment?
This question is most commonly referred to as the *internal validity*
question and its answer requires a complex chain of reasoning which
considers the accuracy of the observation or measurement procedures
used, the way in which the experimental treatments were administered and
controlled, the identification of any extraneous variables which may
have been operating, the length of time over which the experimental
treatments operated, the size of the difference between the rates of
learning observed while each experimental condition was operating, and
the number of replications which the investigator obtained for each
experimental effect (Campbell & Stanley, 1963; Johnston & Pennypacker,
1993; Krathwohl, 1985).

An experimenter may devise a set of experimental procedures which
operate reliably and for a sufficient length of time to produce a
reasonably accurate measure of treatment effects but still draw invalid
conclusions from the results obtained.

The greatest threat to the internal validity of an experiment is the
operation of confounding or extraneous variables which also have an
effect on learning -- an effect which is unrecognised by the
experimenter. Beginning with the seminal work of Campbell and Stanley
(1963), most educational research methods texts attempt to list at least
some of the extraneous variables which can threaten the internal
validity of experiments into teaching and learning. Some of the more
common threats to the internal validity of an experiment are as follows.

-   *Unnoticed extra-experimental instruction, teaching, practice, or
    experience.* Social scientists refer to this threat to the internal
    validity of an experiment as the *history* threat. For example, an
    experimenter who attempts to measure the effects of training
    children to use a particular metacognitive skill during an
    experimental learning task, but who fails to notice that the
    children are also using this new metacognitive skill on the control
    task may well arrive at an invalid conclusion regarding the effects
    of training in the metacognitive skill.
-   *Unnoticed differences in learning tasks.* An experimenter who
    attempts to measure the effects of two teaching conditions using two
    different tasks but who fails to notice that one task is easier than
    the other may well arrive at an invalid conclusion regarding the
    effects of the two training procedures.
-   *Unnoticed differences between the previously acquired skills of
    experimental group and control group learners.* Social scientists
    refer to this threat to the internal validity of an experiment as
    the *selection* threat. For example, an experimenter who uses
    separate experimental and control groups but who fails to recognise
    that, prior to the experiment, the children in the experimental
    group were more knowledgeable, or more skilled, than the children in
    the control group may well arrive at an invalid conclusion regarding
    the effects of the experimental treatment.
-   *Unnoticed differences in the administration of experimental
    treatments*. When experimental treatments are administered by
    teachers or research assistants (as is often the case) there are
    plenty of opportunities for both control group teachers and
    experimental group teachers to depart from instructions regarding
    what is to be taught and how it is to be taught. In experiments
    which last for many weeks or months, such departures become
    increasingly likely. If treatment administration is poorly
    monitored, the experimenter may end up attributing differences in
    student learning to a set of instructional conditions which were
    not, in fact, provided by the teachers who were involved in the
    experiment.
-   *Unnoticed effects on the motivation of control group subjects.* In
    experiments where the control group subjects and the experimental
    subjects attend the same class or school, there is a high likelihood
    that the control group subjects will notice that the experimental
    subjects are receiving lessons or practice activities or incentives
    which they are not receiving. This knowledge can have unpredictable
    effects. Sometimes it may motivate the control group subjects to
    find out what the experimental subjects are learning so that they
    can learn it too. It may even motivate control group subjects to
    study harder than would otherwise be the case so that they can keep
    up with and do as well as their experimental group peers on any
    post-tests. This effect, which is sometimes referred to as the *John
    Henry effect*, may completely mask the effect of the experimental
    treatment. Sometimes the subjects in the control group become
    demoralised because they have been declined access to the new
    materials which the experimental subjects have access to and, as a
    consequence, perform less well on post-tests than would otherwise be
    the case.

It can be seen that designing an experiment in which differences in rate
of learning can be unambiguously attributed to particular experimental
treatments (and not to any other variable which operated during the
course of the experiment) is not a simple matter. It requires
considerable attention to detail not only during the design and
execution of the experiment but also when trying to interpret the data
generated by the experiment.
:::

::: referencesList
#### References

-   Campbell, D. T., & Stanley, J. C. (1963). Experimental and
    quasi-experimental designs for research on teaching. In N. Gage
    (Ed.), Handbook of research on teaching (pp. 171-246). Chicago: Rand
    McNally.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Krathwohl, D. R. (1985). Social and behavioral science research: A
    new framework for conceptualising, implementing and evaluating
    research studies. San Francisco: Jossey-Bass Publishers.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Whatstandardsareusedtoevaluatetheresultsofanexperimentalanalysis/Thechainofinferencewhichisinvolvedininterpretingexperimentaleffects/index.md","# The chain of inference which is involved in interpreting experimental effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-01c483a47cf7460bbc58e048b004bb06}
As stated above, a relatively complex chain of reasoning is involved in
arriving at a valid interpretation of the results of an experiment.

First, the experimenter must be able to demonstrate that the various
treatments operated in the manner described in the report. This aspect
of experimental design is usually referred to as *treatment fidelity* or
*treatment integrity*. In the case of a within-subject experiment,
treatment fidelity can be assessed by observing and recording the
implementation of the experimental treatments as the experiment moves
from one experimental phase to the next. In the case of a between-groups
experiment, treatment fidelity can be assessed by carefully observing
and recording the learning opportunities experienced by each of the
experimental and control group subjects. The results of such
observations are commonly referred to as measures of *procedural
reliability* (Cooper, Heron & Heward, 1987). Only if the description of
the independent variable manipulation is believable, will attempts to
argue that learning was affected by that manipulation also be considered
believable.

Secondly, the experimenter must be able to demonstrate that measurably
different rates of learning occurred under each of the experimental
conditions. In a within-subject experiment this involves presenting data
which show, fairly unambiguously, that the introduction of the
experimental treatment was accompanied by a detectable change in
performance, competence, or rate of learning. In a between-groups
experiment this involves presenting data which show, fairly
unambiguously, that there was a detectable difference between the mean
post-test score of the experimental group and that of the control group.
With this kind of experiment it is often necessary to apply a
statistical test to the mean scores of the several experimental groups
in order to demonstrate that the differences between these means was
greater than might be expected on the basis of random performance
fluctuations attributable to differences in prior learning. The drawing
of valid inferences from such tests is sometimes referred to as
*statistical conclusion validity* (Krathwohl, 1985).

Thirdly, the experimenter must be able to argue, successfully, that \"the
independent variable is the only thing that could possibly explain the
changes in the dependent variable measures that were observed when the
experimental condition was implemented and terminated\" (Johnston &
Pennypacker, 1993, p. 241). This is variously referred to as
demonstrating *experimental control*, demonstrating *internal validity*,
or demonstrating *conclusion validity*. \"Experiments that show
convincingly that changes in behavior are a function of the independent
variable and are not the result of uncontrolled or unknown variables are
said to have a high degree of *internal validity\"* (Cooper, Heron &
Heward, 1987, p. 147).

Of course demonstrations of treatment fidelity, statistical conclusion
validity and internal validity, by themselves, do not guarantee that the
experimenter has obtained an accurate measure of treatment effects. In
order to determine whether a particular experimental procedure has
produced an accurate measure of treatment effects, the experimental
procedure must be administered on more than one occasion so that the
degree of similarity between the results of the two separate experiments
can be observed. (This is analogous to the test of *measurement*
reliability. In order to demonstrate that a particular *measurement* has
produced an accurate measure of learning one must administer that
measurement procedure on more than one occasion and observe a high
degree of similarity between the results of the two separate measurement
attempts.)

The repeated administration of a particular experiment, under closely
similar conditions, is referred to as *direct replication* (Sidman,
1960). The results of two or more direct replications of the same
experiment may be directly compared by the reader. When a set of direct
replications produces a set of experimental effects of closely similar
size, this provides evidence that the experimental procedures are ones
which produce an accurate measure of treatment effects.

The question of whether or not a particular experiment has been
replicated and, if so, whether the replication has produced a closely
similar effect, is absolutely critical when it comes to interpreting the
results of research into teaching and learning. Replication is far more
important than statistical conclusion validity because a successful
replication tells the reader that a particular effect is reproducible.
Knowing that there is a statistically significant difference between the
means of two sets of scores does not tell the reader than a given
experimental treatment has a reproducible effect. Social science
researchers have tended to argue that between-groups experiments do not
need to be replicated because they involve a large number of subjects.
However, the critical datum on which conclusions are based typically
consists of but a single mean score for the experimental group and a
single mean score for the control group and the reproducibility of a
mean score (just like the reproducibility of an individual score) can
only be determined by direct replication.
:::

::: referencesList
#### References

-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Krathwohl, D. R. (1985). Social and behavioral science research: A
    new framework for conceptualizing, implementing and evaluating
    research studies. San Francisco: Jossey-Bass Publishers.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Whatstandardsareusedtoevaluatetheresultsofanexperimentalanalysis/index.md","# What standards are used to evaluate the results of an experimental analysis? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2e0761d69cdd4069a1c9b0dbafb6b637}
In order to measure the effects of an independent variable (such as a
change in teaching procedure) on some kind of learning, not only must
the investigator develop an accurate measure of behaviour change
(learning), they must also design an experiment which will produce an
accurate measure of the effects of the experimental treatment on
learning. Like attempts to measure learning, attempts to measure the
effects of educational interventions on learning may be more or less
reproducible (reliable), the data from an experiment may be a more or
less accurate representation of the actual treatment effect, and the
conclusion drawn by the experimenter may be a more or less valid
inference from the data generated by the experiment given the
experimental procedures which were used.
:::"
".//Typesofresearchevidence/Howaretheeffectsofteachingonlearningtobemeasured/Whatstandardsareusedtoevaluatetheresultsofanexperimentalanalysis/Theaccuracyofthemeasureofexperimentaleffects/index.md","# The accuracy of the measure of experimental effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ff218ab2890c44d7a01b8a2bd93f2cdb}
The second question which may be asked of an experimental result is the
question \"Does the data from this experiment accurately represent the
degree or rate of change (learning) which resulted from the intervention
which was implemented during the experiment?\" This is analogous to
asking whether or not a measurement procedure has generated an accurate
representation of the events which were observed.

The greatest threat to the accuracy of an experimental result is poor
experimental control, that is, the inconsistent administration of
experimental and control treatments from one session to the next. But
there are other factors which can also produce an inaccurate
experimental result. One of these is the failure to run experimental
treatments for a sufficient length of time. In order to produce an
accurate measure of treatment effects, the learner must experience each
experimental treatment for a period of time sufficient to produce an
accurate measure of the rate of learning which occurs under each
treatment condition. This facet of experimental design is seldom
discussed and may be referred to as the *sensitivity* of the
experimental procedure (Church, 1996). Where two treatment conditions
have greatly different effects, this difference in treatment effect may
be accurately measured using a relatively small number of experimental
sessions. Where two treatment conditions have only slightly different
effects, a great many treatment sessions may be required in order to
detect and measure the size of the small treatment effect.

When an experiment consists of groups of subjects, the experimental and
control groups must contain sufficient subjects to enable the detection
of treatment effects over and above the variability in performance which
results from pre-experimental differences in the learning histories of
the subjects. This facet of experimental design is referred to as the
*statistical power* of the experiment (Cohen, 1988). Where the
experimental treatment has a relatively strong effect, the power to
detect treatment effects may be achieved with relatively small
experimental groups of 20 to 30 subjects. Where the experimental
treatment has only a weak effect, the power to detect treatment effects
may require experimental groups of several hundreds of subjects.
:::

::: referencesList
#### References

-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North, New Zealand: New
    Zealand Association for Research in Education.
-   Cohen, J, (1988). Statistical power analysis for the behavioral
    sciences (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum Associates.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Howislearningmeasuredinthethreemainapproachestoresearch/index.md","# How is learning measured in the three main approaches to research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2bf5897fd30f4607a70680e3f0b1a2e3}
In this section we describe the observational and measurement procedures
most commonly used in behaviour analysis research, social science
research and ethnographic research in terms of the focus of individual
investigations, the sampling procedures used, the types of observation
procedures used, and the duration of individual investigations.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Howislearningmeasuredinthethreemainapproachestoresearch/Howdoethnographersobserveandmeasurelearning/index.md","# How do ethnographers observe and measure learning? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4bf2667be9534ee69115dfeb5d70742e}
Ethnographic recording procedures are procedures which have been
developed to provide a holistic picture or portrayal of the social life
or culture of a particular social setting or site. However,
ethnographers do not have an agreed list of the elements of social life
which should be observed and reported on during the course of each
investigation.

**The focus of individual investigations.** Ethnographers do not enter a
particular site \"empty-headed\". Like all researchers, ethnographers
always have a focus. Lincoln and Guba (1985) suggest that most
ethnographic research is either problem focused, evaluation focused or
policy focused. However, while what is to be observed during the course
of an investigation may be framed up in terms of a general research
question, the ethnographer does not usually enter the setting of
interest with a set of predefined categories of actions, meanings, roles
and so on to be observed. Ethnographers enter the setting of interest in
the expectation that the important categories of actions and meanings
which are relevant to their research focus will \"emerge\" during the
course of data collection.

**Sampling procedures.** Ethnographers usually select research
participants using purposive (rather than random) sampling procedures.
Purposive sampling procedures include: the selection of typical cases,
the selection of extreme or deviant cases, the selection of cases which
illustrate maximum variation, the selection of critical cases (on the
grounds that what is true of critical cases will be true of other
cases), or the selection of politically important or politically
sensitive cases (Patton, 1990). Increasingly, ethnographers, like their
social science counterparts, are turning to the study of samples of
subjects who possess certain defined characteristics. \"For example,
studies proposing to study adolescent alienation must define what
behaviors characterize alienated people, determine what kinds of
adolescents exhibit such behavior, and then locate individuals who
possess those characteristics, who are accessible and who are willing to
be studied\" (LeCompte & Preissle, 1993, p. 60-61)

**Data collection procedures.** In order to collect data on
participants\' actions and perspectives, ethnographers employ a range of
data gathering procedures. These include participant surveys,
participant and key informant interviews, life history interviews,
participant observation, non-participant observation, stream of
behaviour records, the examination of written documents, and artefact
collection. The way in which these procedures are to be used is not
governed by any fixed procedural rules. \"I know of no \'method\' for the
conduct of qualitative inquiry . . . There is no codified body of
procedures that will tell someone how to produce a perceptive,
insightful, or illuminating study of the educational world\" (Eisner,
1991, p. 169).

Observations are typically recorded as detailed long-hand descriptions
which researchers refer to as *field notes*. As part of such notes, \"the
researcher will record ideas, strategies, reflections, and hunches, as
well as note patterns that emerge\" (Bogdan & Biklen, 1992, p. 107). The
descriptions contained in field notes are usually supplemented by
interviews with key informants. Interviews tend to be in-depth,
open-ended interviews. Ethnographers do not consider their field notes,
interview transcripts, photocopied documents and so on as *data* but
rather as *resources containing data*. \"Field notes . . . are not data.
Even interview transcripts are not data. All these are documentary
materials from which data must be constructed through some formal means
of analysis\" (Erickson, 1986, p. 149).

**Duration of the investigation.** Many published qualitative studies
have involved a year or more of fieldwork, and \"several months\" is often
referred to as the minimum time required to complete the field work for
an adequate study (Borg & Gall, 1989). \"Qualitative researchers gauge
when they are finished by what they term *data saturation*, the point of
data collection where the information you get becomes redundant\" (Bogdan
& Biklen, 1992, p. 68). Because the ethnographer typically spends many
months observing in the setting of interest, he or she is well placed to
study *changes* in the behaviour and understandings of participants.
Some ethnographers do, in fact, study change and others do not and
procedures for the systematic study of change are described in some
qualitative methods texts (e.g. LeCompte and Preissle, 1993) but not in
others. Eisner (1991, p. 33), for example, argues that change is not the
primary focus of ethnographic research.

**Conclusions.** Qualitative researchers have yet to develop a set of
standard procedures for measuring and describing those changes in
competence, motivation, and so on which are included under the heading
of learning. Qualitative researchers do not distinguish between direct
and indirect measures of actions and perspectives, they do not
distinguish between interval scale and nominal scale measures of
behaviour, and they do not distinguish between idemnotic and vaganotic
measures of change. Textbooks on qualitative research methods simply
ignore all of these matters.
:::

::: referencesList
#### References

-   Bogdan, R. C., & Biklen, S. K. (1992). Qualitative research for
    education: An introduction to theory and methods. (2nd ed.). Boston:
    Allyn and Bacon.
-   Borg, W. R., & Gall, M. D. (1989). Educational research: An
    introduction (5th ed.). New York: Longman.
-   Eisner, E. W. (1991). The enlightened eye: Qualitative inquiry and
    the enhancement of educational practice. New York: Macmillan
    Publishing Co.
-   Erickson, F. (1986). Qualitative methods in research on teaching.
    In M. C. Wittrock (Ed.), Handbook of research on teaching (3rd ed.,
    pp. 119-161). New York: Macmillan.
-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego, CA: Academic
    Press.
-   Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly
    Hills, CA: Sage Publications.
-   Patton, M. Q. (1990). Qualitative evaluation and research methods
    (2nd ed.). Newbury Park, CA: Sage.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Howislearningmeasuredinthethreemainapproachestoresearch/Howdocognitivescientistsobserveandmeasurelearning/index.md","# How do cognitive scientists observe and measure learning? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7a70ac4fc3c94f2788ff2cba6c01667b}
**The focus of individual investigations***.* Decisions regarding the
particular variables which are to be observed are almost always made by
cognitive scientists before the investigation begins. Typically the
researcher specifies not only the particular variable or variables which
are to be observed, but also an hypothesis regarding the relationship
which is presumed to exist between each of these variables. Commonly
this hypothesis is expressed in null form, that is, in the form of a
prediction that there is no detectable relationship between the two
variables.

**Sampling procedures.** The social science methodology requires the
cognitive scientist to draw samples of subjects or participants from the
population of interest. Because the performance of the sample of
subjects will be analysed statistically, the composition of these groups
is a matter of some importance.

First, the samples must of sufficient size. It is widely agreed
(although not universally agreed) amongst social scientists that each
group should contain at least 30 individuals because it is at about this
sample size that \"the magnitude of student\'s *t* critical values for
small samples approach the *z* critical values of the normal probability
table for large samples\" (Best & Kahn, 1993, p. 19).

Secondly, the samples must be representative of the larger population to
which the researcher will be seeking to generalise any relationships
which are observed in the research sample. Methods textbooks argue that
the most satisfactory way of achieving this requirement is by drawing a
random sample of subjects from the population which is of interest.

Thirdly, where the performance of two or more groups is going to be
compared, the researcher must create groups which are equivalent or
comparable at the outset of the investigation. The creation of
equivalent groups is most commonly achieved by assigning individual
subjects at random to each of the comparison groups or treatment groups
taking part in the investigation. Random assignment is used so that the
researcher can \"assume that the groups are approximately equal in all
possible independent variables. The larger the groups, the safer the
assumption\" (Kerlinger, 1964, p. 56).

**Observation procedures.** To measure subjects\' relative positions on
the variables selected for study, the cognitive scientist constructs
tests, rating scales, questionnaires, interviews and observation
schedules. Level of reading comprehension, for example, might be
measured using a reading comprehension test. Teaching style might be
measured using a rating scale or an observational schedule. Attitude
towards mathematics might be measured using a questionnaire or interview
containing items about the respondent\'s liking for various mathematics
activities.

Because cognitive scientists have been attempting to devise measures of
their constructs for almost a century, they have devised a very large
number of tests, rating scales and self report instruments of various
kinds. Many of these instruments have been standardised using large
samples of learners and their reliability evaluated. Lists of published
tests and self-report instruments will be found in publications such as
*Tests in Print* (Murphy, Conoley & Impara, 1994).

Social scientists use both direct and indirect measures of performance.
However, the cognitive scientist\'s desire to measure the performance of
groups of subjects frequently results in the use of indirect measures of
performance. Rather than observing directly the metacognitive skills,
the study skills, or the level of persistence of participants (for
example), the cognitive scientist commonly substitutes participant
self-reports on metacognitive awareness scales, study inventories,
achievement motivation scales, and so on. Direct observation procedures
are used, but they are used much less often than self-reports.

The tests and rating scales of the cognitive scientist typically
generate measurement scales (sets of scores) which have no true zero.
They are ordinal scales which simply rank the performances of
individuals on a scale from \"low\" to \"high\".

Intelligence, aptitude, and personality test scores are . . . ordinal.
They indicate with more or less accuracy not the *amounts* of
intelligence, aptitude, and personality traits of individuals, but
rather the *rank-order positions* of the individuals. . . . ordinal
scales do not possess the desirable characteristics of equal intervals
or absolute zeros. Intelligence test scores are examples. It is not
possible to say that an individual has zero intelligence. . . . there is
no absolute zero on an intelligence scale (Kerlinger, 1964, p. 425).

Cognitive scientists do not draw a clear distinction between idemnotic
and vaganotic measures. The use of vaganotic measures is so entrenched
that almost all standardised social science instruments are vaganotic
measures of performance.

**Duration of the investigation***.* Much cognitive science research
involves a single administration of a battery of tests or measures
(typically two to six) to each of the subjects in the investigation
sample. These investigations last only as long as it takes to administer
the several tests. The purpose of these investigations is to calculate
the correlation (within the sample) between the variables measured by
each of the tests.

Repeated measures of performance are occasionally collected by cognitive
scientists and researchers working within this tradition have devised a
set of experimental designs (the repeated measures designs) which are
capable of handling multiple observations of the performance of the
individuals within an experimental group. By far the most commonly used
practice, however, is that of observing or testing the experimental
subjects just once (or twice) during the course of a particular
investigation. This means that the cognitive and social science research
has tended to focus on educational achievements, outcomes, and products
rather than teaching and learning processes which involve change over
time. \"Traditional experimental designs . . . tend to focus more on the
behavioral result or product of the treatment being studied. Fewer
measurements are usually taken in investigations using traditional
experimental approaches. The method . . . involves formulation of the
sample, administration of a treatment, and assessment of treatment
effects\" (Drew, 1976, p. 36).

**Conclusions.** There are a number of features of the measurement
procedures used by cognitive scientists which make them less than
completely satisfactory measures of learning.

First, cognitive scientists routinely employ indirect measures (such as
self-reports) when measuring behaviours and performances which could be
observed directly. Like the qualitative researcher, social scientists
have developed no agreed procedure for evaluating the veracity or
accuracy of self-report responses on questionnaires and other kinds of
scales, in spite of their widespread use.

Secondly, cognitive scientists routinely employ ordinal, rather than
interval, scale measures of human performance. Cognitive scientists like
to argue that their approach is scientific. This requires measurement
scales which generate scores which can be manipulated mathematically.
Cognitive science decision making often involves the use of inferential
statistics. This also requires scores which can be manipulated
mathematically. But the ordinal measures typically used by the cognitive
scientist do not meet this requirement. Rather than solving this
problem, educational researchers typically *ignore* it. \"The best
procedure would seem to be to treat ordinal measurements as though they
were interval measurements but to be constantly alert to the possibility
of gross inequality of intervals. .. It is unlikely that the educational
researcher will be seriously led astray by heeding this advice, if he is
knowledgeable and careful in applying it\" (Kerlinger, 1964, p. 427-428).

Thirdly, most cognitive science measures are vaganotic, which means that
the measurement results obtained from one investigation to the next
cannot be directly compared (unless the standard deviations of the score
distributions are identical). \"Many people who have become accustomed to
measuring their own weight in pounds and their consumption of
electricity in kilowatt hours have difficulty comprehending a measure of
their child\'s academic achievement given in terms of other children\'s
academic achievement \" (Johnston & Pennypacker, 1993b, p. 38). We can
find no precedent in the natural sciences for this method of defining
phenomena and their units of measurement. The use of procedures wherein
the phenomena being measured or the units of measurement are defined in
terms of (the) variability characterizing a set of otherwise direct
observations seems peculiar to the social sciences. This is one of the
most fundamental differences between the natural and social sciences
(Johnston & Pennypacker, 1993, p. 29).
:::

::: referencesList
#### References

-   Best, J. W., & Kahn, J. V. (1993). Research in education (7th ed.).
    Boston: Allyn and Bacon.
-   Drew, C. J. (1976). Introduction to designing research and
    evaluation. Saint Louis, MO: The C.V. Mosby Company.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Murphy, L. L., Conoley, J. C., & Impara, J. C. (Eds.). (1994). Tests
    in print IV: an index to tests, test reviews, and the literature on
    specific tests Volumes 1 & 2. Lincoln: Buros Institute of Mental
    Measurements of the University of Nebraska, Lincoln.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Howislearningmeasuredinthethreemainapproachestoresearch/Howdobehaviouranalystsobserveandmeasurelearning/index.md","# How do behaviour analysts observe and measure learning? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8c8a4543bfcd443b9899062b1d1fe528}
Behaviour analysis recording procedures are procedures which have been
developed to track the behaviour of individual learners over time. The
observation procedures tend to be direct observation procedures,
observations are usually limited to one or two predefined operant
response classes and observations usually continue over time until a
satisfactory measure of the degree of change has been obtained.
Behaviour analysts routinely distinguish between procedures designed to
*collect* accurate data and procedures designed to *evaluate* the
accuracy of the data which is being collected. (This is one of the major
differences between behaviour analysis research and ethnographic
research.) Behaviour analysts also distinguish between the reliability
of a measurement procedure and the accuracy of a measurement result.

**The focus of individual investigations.** Behaviour analytic
investigations usually focus on a single response class (or a small
number of related response classes). Investigations are usually set up
in such a way as to make possible the recording of individual instances
of the behaviour of interest (such as the oral reading performance of a
particular child) as that behaviour is engaged in with the passage of
time. The aim of individual investigations is usually either (a) to
identify environmental variables (aspects of the learner\'s experience)
which function to produce a certain kind of change in the behaviour of
interest or else (b) to measure the effects of a particular kind of
intervention on the behaviour of interest.

**Sampling procedures.** A behaviour analytic investigation involves
only a small number of learners. Sometimes only a single learner is
studied - although a trend is emerging to include at least two or three
learners in each investigation. These learners are selected purposively.
Once the investigator has decided upon the kind of behaviour change
which is going to be studied, he or she then identifies learners who are
(a) likely to be capable of achieving the learning goal which is of
interest but who (b) have not yet achieved that learning goal. The
behaviour analyst is less concerned with sampling *people* and more
concerned with obtaining an adequate sample of observational sessions or
*occasions* across time.

**Observation procedures**. In order to study changes in behaviour and
ability with the passage of time, behaviour analysts make repeated
observations of the antecedent-action-consequence unit which is of
particular interest. Repeated observations are made because these yield
a more detailed picture of behaviour change than that provided when only
one or two observations are made.

Learning is a continuous process; it can be compared to a motion picture
. . . Assessing a student\'s performance is like taking a single frame
from the motion picture . . . The more instances of measurement we have
to inspect, the more accurate and representative will be our
interpretation of learning. If we can study many frames from the motion
picture, we will have a much better idea of the continuous process the
motion picture represents (West, Young & Spooner, 1990, p. 6).

To measure the effects of environmental variables (such as a change in
teaching procedure) on learning, the behaviour analyst makes repeated
observations, over time, of the behaviour of interest under each
experimental condition. \"This practice accommodates the observed fact
that the effects of environmental variables on behavior occur over time.
Obtaining a clear picture of behavior change therefore requires sampling
thoroughly over time\" (Johnston & Pennypacker, 1993b, p. 12). The need
to track behaviour changes over time is beginning to be recognised by
researchers who are not behaviour analysts. \"Single-subject research
methods enable one to describe the variability predicted by current
theory more precisely than is often possible with either group
experiments or thick descriptions\" (Neuman & McCormick, 1995, p. vii).

Behaviour analysts draw a clear distinction between *direct* and
*indirect* measures of human behaviour. Wherever possible, the behaviour
analyst studies the behaviour of interest by observing it directly,
rather than by probing and recording the recollections of participants.
The data of interest are the records of what the participant *actually*
did in a given situation, not what the participant *said* that they did
or what other people *said* that the participant did.

Behaviour analysts tend to limit their use of indirect measures to those
situations where the behaviour of interest cannot be observed directly.
For example, a behaviour analyst would find it acceptable to substitute
a measure of performance outcome (e.g. number of words written) for
direct observations of the performance itself (e.g. writing a story) in
cases where there is likely to be a close correspondence between the
two. A behaviour analyst would also find it acceptable to substitute
verbal reports in cases where the behaviour of interest was previous
attempts to find a job (because the behaviour has already occurred), or
changes in frequency of sexual intercourse (because the behaviour is
extremely personal), or changes in attitude to reading (where the
researcher\'s interest in attitude change is secondary to their interest
in improvements in reading skill).

Where direct observation is not possible because the behaviour of
interest is occurring very infrequently, the behaviour analyst typically
selects a closely related but more frequently occurring behaviour as the
behaviour of interest. For example, if a behaviour analyst was
interested in studying a child\'s antisocial behaviour at school and
hitting was occurring relatively infrequently, antisocial behaviour
might be defined to include a number of other more frequently occurring
antisocial behaviours in addition to hitting. Where direct observation
is not possible because the behaviour is a private behaviour (e.g.
thinking), the behaviour analyst usually substitutes a behaviour which
*is* observable (e.g. thinking out loud).

Behaviour analysts draw a clear distinction between *idemnotic* and
*vaganotic* measures of performance and have a strong preference for
idemnotic measures. A variety of idemnotic measures are used: measures
of latency and duration (time taken), measures of frequency (e.g. number
of requests for help per day), measures of accuracy (e.g. proportion of
words read correctly), measures of fluency (e.g. words correct per
minute), measures of change (e.g. words correct per minute per daily
test), and so on. Idemnotic measures are preferred because the results
of these measures are directly comparable from one occasion to another
within an investigation and from one investigation to the next.

Behaviour analysts also distinguish between different *dimensions* of
behaviour change and select the kind of direct observational procedure
which is best suited to measuring change in the behavioural dimension
which is of interest. For example, a researcher who was interested only
in recording improvements in the ability to solve a particular class of
problems might record this progress in terms of changes in accuracy,
e.g. by counting the number of steps completed correctly on
representative samples of those problems. A researcher who was
interested fluency (automaticity), however, would select a timed test so
that they could record changes in fluency by counting the number of
steps completed correctly per minute.

The recording devices used by behaviour analysts fall into three general
classes: mechanical recording, recording by trained observers, and
participant recording (self-recording). Examples of mechanical recording
include the use of voice operated tape recorders to record the verbal
interactions which are occurring in a particular setting, the use of
video recorders, the use of computers to record the learner\'s responses
to particular classes of problems or exercises, the use of mechanically
operated counters of various kinds, and so on. More commonly, records of
behaviour are made by trained observers. Self-recording tends to be used
only where mechanical recording or recording by trained observers is
impractical.

The recording procedures employed by observers include counting (event
recording), timing (duration recording and latency recording), interval
recording, momentary time-sampling, accuracy testing, fluency testing,
the analysis of behavioural products, measures of response magnitude,
the classification of response topographies, and so on (Church, 1996;
Cooper, Heron & Heward, 1987; Johnston & Pennypacker, 1993a, 1993b).

**Duration of the investigation**. Behaviour analytic investigations
invariably continue for some time. \"The dynamic and continuous nature of
behavior must be acknowledged by scheduling periods of observation that
are as long as possible and that occur as frequently as possible\"
(Johnston & Pennypacker, 1993b, p. 102).

In an experimental investigation, observations of the behaviour of
interest continue within each phase of the investigation until the
experimenter can determine whether or not performance is changing and,
if it is, the direction and rate of change. \"The dynamic nature of
organism-environment interactions through time dictates that measurement
must be scheduled to occur repeatedly over some period of time under
each different set of experimental conditions\" (Johnston & Pennypacker,
1993b, p. 103. A minimum of four separate observations or tests is
normally required for this purpose. Experimental investigations
typically contain two to four experimental phases.

The length of the investigation depends upon the way in which the
observations have been scheduled. If observations have been scheduled on
a daily basis, the typical behaviour analysis experiment tends to last
for between two to six weeks. However, investigations spanning a whole
school term, or even an entire school year, have been reported.
:::

::: referencesList
#### References

-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North, NZ: New Zealand
    Association for Research in Education.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Johnston, J. M., & Pennypacker, H. S. (1993a). Strategies and
    tactics of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence
    Erlbaum Associates.
-   Johnston, J. M., & Pennypacker, H. S. (1993b). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Neuman, S. B. & McCormick, S. (Eds.). (1995). Single subject
    experimental research: Applications for literacy. Newark, NJ:
    International Reading Association.
-   West, R. P., Young, K. R., & Spooner, F. (1990). Precision teaching:
    An introduction. Teaching Exceptional Children, 22, 4-9.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatexactlyisobservedbythethreemainapproachestoresearch/Doethnographersstudyeventswhichcanbeobservedinpractice/index.md","# Do ethnographers study events which can be observed in practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9be2403694a8445e8c7be9b772cb6ff3}
Qualitative researchers tend to disagree amongst themselves with respect
to the epistemological assumptions which underpin their research. Some
qualitative researchers adopt a realist or critical realist position.
\"We believe something is \'out there\' (however many \'out theres\'
there are) and that the obdurate nature of what is out there does not
always cooperate with our dearly cherished constructions. Sometimes
reality comes and bashes us on the head. Anyone who has been fired from
a job or rejected by a lover, let alone confronted with data that do not
fit expectations, has faced an \'out there\' that resists internal
constructions\" (LeCompte & Preissle, 1993, p. 317). \"There is a world of
empirical reality out there. The way we perceive and understand that
world is largely up to us, but the world does not tolerate all
understandings of it equally (so that the individual who believes he or
she can halt a speeding train with his or her bare hands may be punished
by the world for acting on that understanding)\" (Kirk & Miller, 1986, p.
11).

Some qualitative researchers adopt a pragmatic position. \"The most
important test of any qualitative study is its usefulness\" (Eisner,
1991, p. 58). This is closely similar to the radical behaviourist
position of the behaviour analyst.

And some (perhaps the majority) of qualitative researchers are
relativists who believe that each individual constructs their own
interpretation of what they have seen or heard. \"I suggest an . . .
ontology that is relativist in nature. It begins with the premise that
all social realities are constructed and shared through well-understood
socialization processes. It is this socialized sharing that gives these
constructions their apparent reality\" (Guba, 1990, p. 89). \"Those who
see reality as a construction in the minds of individuals assert that it
is dubious whether there is a reality. If there is, we can never know
it. Furthermore, no amount of inquiry can produce convergence on it.
There is . . . always an infinite number of constructions that might be
made and hence there are multiple realities\" (Lincoln & Guba, 1985, p.
83-84).

Individual qualitative researchers use few constructs in their research
reports, preferring to describe the events which they have observed as
directly as possible and, where feasible, to report their participant\'s
perspectives in the participant\'s own words. While the justifications
which participants provide for behaving in particular ways sometimes
refer to events which are in principle unobservable (e.g. \"I simply did
what God would have wanted me to do\"), these unobservable entities are
creations of the participants rather than being creations of the
researcher.

A considerable amount of qualitative research in education is based upon
the relativist presumption that an objective account is impossible
because different social groups construct different social realities.
The contradictions inherent in the relativist position have been
identified by a number of writers.

First, the observation that several observers can witness a particular
instance of learning, and come to several different conclusions about
what they have seen, does not mean that those observers have witnessed
several different things.

From the fact that we might not be able to reach agreement (an
epistemological matter), it does not follow that there is more than one
\"reality\" (an ontological matter). . . . We can inquire into the beliefs
of a society . . . and we can get these matters right or wrong - we can
get our descriptions of these beliefs right or wrong, or we can be right
or make mistakes about their origins or their effects. It simply does
not follow from the fact of the social construction of reality that
scientific inquiry becomes impossible, or that we have to be relativists
(Phillips, 1992, p. 56).

Secondly, the relativist\'s claim that no generalisations are possible -
that the best the researcher can do is to offer an evocative account of
what has been seen for the reader\'s consideration - involves a category
error. It confuses the accurate reporting of a set of systematic
observations with the writing of a novel, play or film script. Unlike
poets,

qualitative researchers generally do intend for their findings to be
taken as veridical. To say that a description of a classroom . . . is
evocative but is not meant to be true or false is merely another
category mistake (it is to identify qualitative research as being
poetry, or something similar). Moreover, it is a mistake that is fatal
for qualitative research; if a qualitative description or analysis is
not true or false (i.e. these terms are not applicable to it), then the
issue of whether that description or analysis is to be believed or acted
upon cannot arise - it is not sensible to say that one believes the
lines by Keats, just as it is not sensible to say that one believes
Mozart\'s clarinet concerto and is prepared to base policy or social
intervention on it (Phillips, 1987, p. 9-10).

Thirdly, if the members of each social group (and this includes groups
of researchers) construct their own realities, then it cannot be claimed
(by relativist researchers), that relativism is the only appropriate
epistemological position (for all researchers). \"If all statements are
true relative to a social group as opposed to being objectively true for
all people, then the interpretivist claim that \'all knowledge is
relative to a social group\' is itself relative to the social group to
which the interpretivist belongs. This being so, it need not be taken
seriously by those researchers who do not subscribe to the claim\"
(Clark, 1997, p. 41). However, relativists frequently argue, somewhat
illogically, that \"their viewpoint is true, that is, true for everyone
and not just for them. . . . no relativist would accept the argument
from a colleague who had presented an incorrect or faulty piece of work
that \'It is only faulty or incorrect for you, but from my perspective
it is sound\'\" (Phillips, 1987, p. 24).

In short, the relativist position is fatal for research. If observers
from different social groups, or observers with different
epistemological beliefs, cannot, in principle, reach agreement about
what they have seen (when observing particular instances of learning and
teaching) then it follows that the systematic observation of instances
of learning and teaching is pointless. If, as a result of systematic
observation, no generalisations about learning and/or teaching are
possible, then the research endeavour itself is pointless.
:::

::: referencesList
#### References

-   Clark, J. (1997). Educational research: Philosophy, politics,
    ethics. Massey University, Palmerston North, NZ: ERDC Press.
-   Eisner, E. W. (1991). The enlightened eye: Qualitative inquiry and
    the enhancement of educational practice. New York: Macmillan
    Publishing Co.
-   Guba, E. G. (1990). Subjectivity and objectivity. In E. W. Eisner
    & A. Peshkin (Eds.), Qualitative inquiry in education: The
    continuing debate (pp. 74-91). New York: Teachers College Press.
-   Kirk, J., & Miller, M. L. (1986). Reliability and validity in
    qualitative research. Beverly Hills, CA: Sage Publications.
-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego, CA: Academic
    Press.
-   Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly
    Hills: Sage Publications.
-   Phillips, D. C. (1987). Philosophy, science and social inquiry:
    Contemporary methodological controversies in social science and
    related applied fields of research. Oxford, England: Pergamon Press.
-   Phillips, D. C. (1992). The social scientist\'s bestiary: A guide to
    fabled threats to, and defences of, naturalistic social science.
    Oxford, england: Pergamon Press.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatexactlyisobservedbythethreemainapproachestoresearch/Dobehaviouranalystsstudyeventswhichcanbeobservedinpractice/index.md","# Do behaviour analysts study events which can be observed in practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-37da29be49a44964a9e157d277bd75a2}
Behaviour analysts consider epistemological questions to be important
questions and have written at length about the philosophy of science
which underlies behaviour analysis research (e.g. Skinner, 1974; Baum,
1994; Chiesa, 1994). The assumptions which behaviour analysts bring to
their research differ in many important respects from the assumptions
made by both interpretivist researchers and cognitive scientists.

Behaviour analysts refer to their philosophy of science as *radical
behaviourism*. This label is, perhaps, unfortunate since radical
behaviourism has little in common with the Watsonian behaviourism about
which so much has been written or the methodological behaviourism of the
cognitive scientist. (The stimulus--\>cognitive structure--\>response
theories of the cognitive scientist are much closer to Watsonian
behaviourism than the historical explanations of the behaviour analyst
which, in turn, are much more like the selectionist explanations of the
evolutionary biologist than they are like the explanations of Watsonian
behaviourism). As one writer has observed, the fact that radical
behaviourism \"comes under the behaviorist heading at all will eventually
be shown to be an accident of history\" (Chiesa, 1994, p. 10).

The behaviour analyst makes no distinction between the subjective and
the objective worlds and takes no position on the idealist-realist
debate regarding the nature of truth. The radical behaviourist
philosophy of science is a pragmatic philosophy of science. Its origins
can be traced from the American philosophers Charles Pierce and William
James, the physicist Ernst Mach (who was a friend of James), B.F.
Skinner (who was greatly influenced by Mach) down to modern behaviour
analysts and modern philosophers of science such as Thomas Kuhn.

The behaviour analyst asks \"What difference would it practically make to
anyone if this notion rather than that notion were true?\" The behaviour
analyst argues that if a particular way of categorising transactions
with the environment works in the sense that it helps to identify
regularities in these transactions, or to identify factors which
regularly lead to a given kind of behaviour change, then this is a
sufficient justification for the use of these conceptual categories. The
behaviour analyst is agnostic about whether these conceptual categories
represent the \"truth\" about the world in which we live and learn.

The empiricism practised by Skinner and other radical behaviorists . . .
has always been characterized by pragmatism more than by any other
philosophical position (e.g. positivism, operationism). The ultimate
criterion for the validity of a concept or finding is not whether two
people can be brought into agreement but whether the scientist who uses
the concept can successfully predict and control the subject matter
(Heward & Cooper, 1992, p. 353).

Most behaviour analysts are acutely aware that the way in which the
researcher approaches the study of behaviour is profoundly influenced by
the learning history of the researcher, the language of the researcher,
and the conceptual structure of that language. In fact, radical
behaviourists have written at length about the way in which the concepts
and the grammar of everyday language hinder the discovery of scientific,
that is more useful, conceptions of the individual\'s transactions with
the environment and the effects of these transactions on future
behaviour. \"The behavior of the scientist is not exempt from controlling
influences embedded within the larger culture. Scientists do not come to
the study of behavior free from the assumptions and presuppositions of
the surrounding culture but are in part guided by its conceptual
classifications, some of which are to be found in the words we
ordinarily use to describe behavior and in the grammatical patterns of
ordinary language\" (Chiesa, 1994, p. 24).

Chiesa goes on to note that the concepts embedded in everyday language
terms encourage us to look at behaviour in culturally determined ways,
to ask certain questions rather than others, and to accept certain kinds
of explanations while rejecting others. She further notes that the
explanations of the behaviour analyst, couched as they are in terms of
past experiences rather than in terms of either immediate causes or the
actor\'s intentions, are at variance with common cultural practice and
therefore look strange to those who have had no training in behaviour
analysis. Some of the many ways in which everyday language constrains
and even hinders our attempts to develop a science of learning and
teaching have been described by Chiesa (1994), Hineline (1980, 1990,
1992) and Valsiner (1986).

In a similar vein, Johnston and Pennypacker (1993, p. 10-11) observe
that \"In the case of human behavior as a subject matter, investigators
unavoidably approach it with many preconceptions that are learned from
living in this culture. Without realizing it, we are taught a great deal
about the nature of human behavior and how it supposedly works merely by
growing up in this (or any) culture. For example, our language suggests
that (a) behavior is generally motivated and controlled by events going
on in the mind, (b) emotions control subsequent actions, and (c) we can
make choices that are free of outside influence.\"

Because the concepts and grammatical structure of everyday language
influence the way in which we conceptualise changes in behaviour,
behaviour analysts tend to argue that a science of behaviour must
develop its own, carefully defined terms - that it cannot simply use
everyday terms. While the words which people use in describing what they
are doing and why they are doing it \"can be used without embarrassment
by cognitive psychologists and behavior analysts alike in their daily
lives . . . these words cannot be used in their science\" (Skinner, 1989,
p. 18).

Behaviour analysts exclude from their subject matter all events which
are in principle unobservable. For example, they exclude all mental
events or *mentalisms*, most hypothetical constructs, and all
*explanatory fictions.* \"Fictional things and events are unobservable,
even in principle. No one has observed a mind, urge, impulse, or
personality; they are all inferred from behavior\" (Baum, 1994, p. 32).
\"Private events are observable, even if only by an audience of one . . .
Mental events, in contrast are unobservable because they are
nonphysical; no one can ever observe belief itself or intelligence
itself\" (Baum & Heath, 1992, p. 1313).

The subject matter of behaviour analysis includes all events which are
in principle observable including events which are only observable by an
audience of one (the so-called private events). \"Radical behaviorists
allow all natural events, including both the public and the private, and
rule out only the fictional\" (Baum, 1994, p. 31-32). A behaviour analyst
would argue that if we are interested in memory, for example, then we
should talk about the act of remembering rather than \"memory\". This is
because the occurrence of remembering - the behaviour - is a naturally
occurring event which can be observed and recorded. However, we cannot
see or detect a memory (even with the aid of instrumentation) which
raises the question as to whether \"memory\" is anything more than a
metaphor.

As far as observation is concerned, behaviour analysts distinguish
between two general classes of events: public events, and private
events. The behaviour analyst argues that, with care, it is possible for
different observers to observe the same public event (e.g. a change in
behaviour) and to come to an agreement about what they have seen. This
position is taken on empirical, rather than logical or theoretical
grounds. It is an agreed requirement of behaviour analysis research that
the researcher collect some data regarding the reliability of the
observational procedures used. The most common data checking procedure
is a measure of the degree of agreement between two independently
operating observers or coders. The reliability checking data from many
thousands of separate experiments indicate that high levels of agreement
between observers can be achieved and, in fact, is achieved more often
than not. (See, for example, Kelly (1977)).

As far as private events are concerned, the behaviour analyst argues
that accuracy can never be demonstrated. This is because private events
(e.g. an individual\'s thoughts and feelings) can only ever be observed
and reported by the person who is experiencing them. Sometimes this
problem can be handled by making the private events public. For example,
a learner might be asked to \"think out loud.\" In the case of private
events which cannot be made public, the behaviour analyst simply argues
that reports of these events should always be handled with caution since
no evidence of the veracity of the self-report of a private event is
possible. In this respect, behaviour analysts are no different from
qualitative researchers and cognitive scientists who have also found it
impossible to demonstrate the truthfulness of individuals\' self-reports
of their thought processes, attitudes, opinions and beliefs.
:::

::: referencesList
#### References

-   Baum, W. M. (1994). Understanding behaviorism: Science, behavior and
    culture. New York: HarperCollins College Publishers.
-   Baum, W. M., & Heath, J. L. (1992). Behavioral explanations and
    intentional explanations in psychology. American Psychologist, 47,
    1312-1317.
-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 345-365.
-   Hineline, P.N. (1980). The language of behavior analysis: Its
    community, its functions, and its limitations. Behaviorism, 8,
    67-86.
-   Hineline, P.N. (1990). The origins of environment-based
    psychological theory. Journal of the Experimental Analysis of
    Behavior, 53, 305-320.
-   Hineline, P. N. (1992). A self-interpretive behavior analysis.
    American Psychologist, 47, 1274-1286.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Kelley, M. B. (1977). A review of the observational data-collection
    and reliability procedures reported in the Journal of Applied
    Behavior Analysis. Journal of Applied Behavior Analysis, 10, 97-101.
-   Skinner, B. F. (1974). About behaviorism. London: Jonathan Cape Ltd.
-   Skinner, B. F. (1989). The origins of cognitive thought. American
    Psychologist, 44, 13-18.
-   Valsiner, J. (1986). Between groups and individuals: Psychologists\'
    and laypersons\' interpretations of correlational findings. In J.
    Valsiner (Ed.), The individual subject and scientific methodology
    (pp 134-151). New York: Plenum Press.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatexactlyisobservedbythethreemainapproachestoresearch/index.md","# What, exactly, is observed by the three main approaches to research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6c438a1f2e814dd5a52f2b50e282556b}
The history of science tells us that scientific developments begin to
occur when we begin to make the transition from religious, philosophical
and theoretical discussion to systematic and direct observation of the
events which go to make up the subject matter of interest. This suggests
that advances in our understanding of the conditions necessary for
learning are most likely to occur when we begin to observe learning
directly and systematically. This raises two questions. What kinds of
learning and teaching events can, in fact, be observed given current
levels of technological development in observational techniques? And
secondly, what is likely to be the most scientifically productive way of
observing learning and teaching events?
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatexactlyisobservedbythethreemainapproachestoresearch/Docognitivescientistsstudyeventswhichcanbeobservedinpractice/index.md","# Do cognitive scientists study events which can be observed in practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-95a83deafbb64f89aacb51822ec718b9}
Most cognitive scientists presume that the behaviour of others exists
independently of our perception of it (the realist presumption) and that
the changes which we refer to as learning can be objectively observed
and recorded. \"Scientists emphasise objectivity - that is, they attempt
to define and deal with the matters they investigate in ways that can,
at least in principle, be agreed on by everyone\" (Vasta, Haith & Miller,
1992, p. 61). \"Subjective belief . . . must be checked against objective
reality. The scientist must always subject his notions to the court of
empirical inquiry and test\" (Kerlinger, 1964, p. 134).

Further evidence that this is the case is provided by the fact that most
social science methods texts emphasise the importance of employing only
those instruments which provide an accurate measure of the construct
which is of interest. \"The precise measurement of behaviors and their
causes is of utmost importance because scientific research determines
causality by focusing on change. . . . Unless these factors and
behaviors have been measured very accurately, it may be difficult to
determine whether any changes have, in fact, taken place\" (Vasta et al.,
1992, p. 61).

While recognising that the researcher\'s theoretical position, values,
and opinions may distort or bias the questions selected for study and
the way in which they are studied, cognitive scientists in general tend
to assume that the behaviour of others can nevertheless be observed and
recorded with reasonable accuracy. \"Quantitative researchers attempt to
keep themselves from influencing the collection of data. Instruments
with established psychometric properties, such as achievement tests and
standardized observation schedules are used to collect data\" (Borg &
Gall, 1989, p. 23).

The question of whether or not observers can reach agreement on what
they have seen is not simply an assumption which social scientists make.
It is a question which they have studied. Rosenthal (1978), for example,
found a very high level of agreement between observers and checkers in a
sample of 21 studies involving some 140,000 observations.

Most cognitive scientists tend to be critical realists rather than naive
realists. Cook and Campbell, the authors of an influential book on
experimentation, state their position as follows:

Such a . . . perspective . . . enables us to recognize causal
perceptions as \"subjective\" or \"constructed by the mind\"; but at the
same time it stresses that many causal perceptions constitute assertions
about the nature of the world which go beyond the immediate experience
of perceivers and so have objective contents which can be right or wrong
(albeit not always testable). This perspective is realist because it
assumes that causal relationships exist outside of the human mind, and
it is critical-realist because it assumes that these valid causal
relationships cannot be perceived with total accuracy by our imperfect
sensory and intellective capacities (Cook & Campbell, 1979, p. 29).

In spite of the cognitive scientist's strong empirical stance, the great
majority of the constructs created by cognitive scientists are
hypothetical constructs, that is, mechanisms or processes whose
existence is inferred from observable behaviours rather than being
directly observable. Examples include constructs such as intelligence,
locus of control, the various types of memory, metacognitive awareness,
the various types of motivation, self-efficacy, self-esteem, and so on.
The presumed mental structures and mental processes of the cognitive
scientist provide very clear examples of constructs which refer to
entities which are in principle unobservable. Examples include the short
term store, the long term store, a rich network of connections,
distributed processing, and so on.

The great majority of cognitive scientists believe that these
hypothetical constructs refer to events which, while they can only be
inferred from observable behaviours, do, in fact, exist. \"Such traits as
intelligence, learning, hostility, anxiety, or motivation are not
directly observable and are generally referred to as \"constructs,\"
implying that they are constructions of the scientist\'s imagination.
Constructs cannot be seen, heard, or felt. They can only be inferred by
phenomena such as test scores or by observed hostile or aggressive acts,
skin responses, pulse rates, or persistence at a task\" (Best & Kahn,
1993, p. 8).

Cognitive scientists justify the use of hypothetical constructs by
arguing that \"hypothetical constructs are used in all sciences . . . We
postulate mechanical aptitude to account for differences in performance
on certain tests . . . Hypothetical constructs are really products of
the scientist\'s imagination. They are imaginary concepts which produce
a structure around which he can order his thinking\" (Mouly, 1970, p.
60).

Cognitive scientists claim that the methods which they have developed
are methods which enable objective study of the behaviours, mental
processes, feelings, and the other constructs which comprise the subject
matter of social and cognitive science. Most social science methods
texts contain lengthy chapters describing the procedures which must be
followed in order to obtain accurate (that is, objective) measures of
social science constructs.

At the same time, social scientists continually defend the use of
constructs which are mentalisms, that is, entities and processes which
cannot be observed. These two positions are clearly contradictory. How
does one establish the structure, function, or even existence, of
something which can never be observed? The use by avowed empiricists of
constructs which refer to events which can only be inferred but not
observed is one of the great contradictions of cognitive science. The
use of non-physical constructs is unique to cognitive science. No other
science routinely employs such constructs. The use of non-physical
constructs leaves the researcher free to generate whatever constructs he
or she desires and to attribute to these whatever properties he or she
desires. The use of constructs which cannot be observed leaves the
cognitive scientist open to the charge that cognitive science is not a
science at all.
:::

::: referencesList
#### References

-   Best, J. W., & Kahn, J. V. (1993). Research in education (7th ed.).
    Boston: Allyn and Bacon.
-   Borg, W. R. & Gall, M. D. (1989). Educational research: An
    introduction (5th ed.). New York: Longman.
-   Cook, T. D., & Campbell, D. T. (1979). Quasi-experimentation: Design
    & analysis issues for field settings. Chicago: Rand McNally
    Publishing Co.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Mouly, G. J. (1970). The science of educational research (2nd ed.).
    New York: Van Nostrand Reinhold Company.
-   Rosenthal, R. (1978). How often are our numbers wrong? American
    Psychologist, 33, 1005-1008.
-   Vasta, R., Haith, M. M., & Miller, S. A. (1992). Child psychology:
    The modern science. New York: John Wiley & Sons, Inc.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Beliefsaboutthenatureofrealityandwhatcanbeobserved/Assumptionsaboutthenatureofreality/index.md","# Assumptions about the nature of reality \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-440ce8b3af164e6ebf28a2dc6506bc9e}
**Idealism**

Some researchers work on the assumption that there is no external
reality (or at least none that different observers can agree upon) only
the individual realities of individual observers. For example, Lincoln
and Guba, the authors of an influential qualitative methods text, argue
that reality is only what the individual person perceives to be real.
They argue that reality is a construction in the mind of the individual.
Because an infinite number of personal constructions are possible there
are always multiple realities (Lincoln & Guba, 1985). This position is
most commonly referred to as the *idealist position*. (The term
\"idealism\" is a corruption of the term \"idea-ism\".) It refers to the
belief that the only things that can be known for certain are our ideas
and the perceptions which produce them. Some writers (e.g. Lincoln &
Guba, 1985) refer to this position as *social constructivism.*

**Realism and critical realism**

Some researchers work on the assumption that there is an external
reality and that it is possible to observe and describe many of the
events which occur in this world. This position is most commonly
referred to as the *realist position*.

Most realists are *critical realists* who recognise that attempts to
observe and describe events such as learning and teaching are strongly
influenced by the concepts and theories of the observer, and that, in
our attempts to observe and describe, we often make mistakes. For
example, Cook and Campbell, the authors of an influential social science
methods text, describe their position as a critical realist position
because they assume that cause and effect relationships exist outside of
the minds of individuals while recognising that these causal
relationships cannot always be perceived with complete accuracy (Cook &
Campbell, 1979). The philosopher of science Karl Popper describes the
critical realist position using the following analogy.

The status of truth in the objective sense, as correspondence to the
facts, and its role as a regulative principle, may be compared to that
of a mountain peak which is permanently, or almost permanently, wrapped
in clouds. The climber may not merely have difficulties in getting
there - he may not know when he gets there, because he may be unable to
distinguish, in the clouds, between the main summit and some subsidiary
peak. Yet this does not affect the objective existence of the summit
(Popper, 1963, p. 226).

Most learning researchers adopt the critical realist assumption because
attempts to observe only make sense if we assume that there is something
out there to be observed.

**Pragmatism**

Some researchers argue that the question of whether or not there is an
external reality which can be observed is a question of no practical
importance. What is important is that when we assume that the world is
real and act on the world as if the world existed, these actions work
for us. This position is most commonly referred to as the *pragmatist
position*. The pragmatist asks: What difference would it practically
make to any one if this notion rather than that notion were true? \"What
matters about a bicycle is that I see it, call it by its name, may lend
it to a friend, may ride it myself. Pragmatism remains agnostic about
whether there is a real bicycle behind these effects\" (Baum, 1994, p.
20).
:::

::: referencesList
#### References

-   Baum, W. M. (1994). Understanding behaviorism: Science, behavior and
    culture. New York: HarperCollins College Publishers.
-   Cook, T. D., & Campbell, D. T. (1979). Quasi-experimentation: Design
    & analysis issues for field settings. Chicago: Rand McNally
    Publishing Co.
-   Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly
    Hills, CA: Sage Publications.
-   Popper, K. (1963). Conjectures and refutations: The growth of
    scientific knowledge. London: Routledge and Kegan Paul.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Beliefsaboutthenatureofrealityandwhatcanbeobserved/Assumptionsaboutwhatcanbeaccomplishedbyobservation/index.md","# Assumptions about what can be accomplished by observation \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-60cbc3b6a4d748f8a31a083ba9e2c138}
Researchers bring to the research task different assumptions regarding
what can be achieved by systematic observation. Assumptions which we
make about our ability to observe the events which are occurring in the
world in which we live, and the accuracy and reliability of the
knowledge generated by such observations, are usually referred to as
epistemological assumptions. Is it possible, for example, for several
different researchers to observe a particular behaviour change and to
come to some agreement about what they have seen? The assumptions which
the researcher makes about questions such as these also influence what
is looked for and what is seen as a result of that looking.

**Relativism**

Researchers who believe that individual observers construct their own
realities tend also to argue that there can be no such thing as an
objective (that is, an accurate or unbiased) observation of learning or
teaching. They argue that what an observer sees when observing is
affected by the previously acquired beliefs, concepts and theories of
the observer and that, as a consequence, different observers of the same
set of social events are unlikely to agree about what they have seen.
The belief that what is seen is dependent upon, or relative to, the
beliefs of the observer is usually referred to as *relativism*.

**Empiricism**

Other researchers believe that things like learning and teaching can be
observed (however imperfectly) and that there is some point in doing so
(even if only to find out what works). This position has been referred
to using a number of terms: empiricism, objectivism, positivism,
naturalism, and so on. We will refer to this position as *empiricism*.

Most learning researchers tend to take an empiricist position, that is,
to assume that one can learn from looking, because the research activity
(looking) only makes sense if one assumes that events such as learning
can be observed and that the results of such observations can be
described with reasonable accuracy. Most empirical researchers recognise
that accurate observation and reporting is often difficult and may, in
fact, become possible only once suitable observational instruments have
been invented. Most empirical researchers also recognise that what one
looks for and sees is affected by the concepts and theories of the
researcher and that, no matter how much care is taken, mistakes are
often made. The empiricist simply argues that, while observing and
reporting may be difficult, it is not impossible; that it is often
possible for different people to observe the same event and to come to
an agreement about what they have seen.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Beliefsaboutthenatureofrealityandwhatcanbeobserved/index.md","# Beliefs about the nature of reality and what can be observed \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9cc59649ccfe420fb27670c334f52074}
Researchers bring to the research task different assumptions regarding
the nature of the external world and the extent to which it can be
observed. These assumptions are most commonly referred to as ontological
assumptions and they influence what is looked for (and hence what is
seen as a result of that looking).
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whichapproachestoresearcharecollectingthemostbelievabledataonlearning/index.md","# Which approaches to research are collecting the most believable data on learning? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4bb208c78c434be7a9272e31ec16a29b}
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whichapproachestoresearcharecollectingthemostbelievabledataonlearning/Believabilityofthedatacollectedbyethnographers/index.md","# Believability of the data collected by ethnographers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8efbec0172c04234ac7b003f52cfd7cd}
Qualitative researchers are concerned with data quality issues and these
are addressed in most qualitative methods texts. However, qualitative
researchers have yet to develop a common vocabulary for discussing data
quality issues and have yet to develop an agreed set of procedures for
ensuring the accuracy of the data contained in their reports or the
validity of the conclusions drawn from this data.

**Accuracy of the data collected**

The accuracy of the data contained in an ethnographic report is
variously referred to by ethnographers as its *confirmability* or
*credibility* (Guba & Lincoln, 1997; Mertens, 1998), its *reliability*
(Bogdan & Biklen, 1998), its *internal reliability* (LeCompte &
Preissle, 1993), its *descriptive validity* and *interpretive validity*
(Maxwell, 1992), its *trustworthiness* (Lincoln & Guba, 1985), and so
on. \"The credibility test asks if there is a correspondence between the
way the respondents actually perceive social constructs and the way the
researcher portrays their viewpoints\" (Mertens, 1998, p. 181).

Ethnographers usually seek to produce an account or portrayal which is
as accurate (as credible) as possible. \"The ethnographer\'s primary
commitment is to a faithful and accurate rendition of the participant\'s
life ways\" (LeCompte & Preissle, 1993, p. 354). Most recognise that the
accuracy of an account cannot be taken for granted. \"Informants may lie,
omit relevant data, or misrepresent their claims\" (LeCompte & Preissle,
1993, p. 345). Some also recognise that the investigator may not always
operate consistently and that, as a result, his or her records may not
always be reliable. \"The naturalist is willing to concede what might be
called \'instrumental\' unreliability. . . . Humans do become careless;
there is \'instrumental decay\' such as fatigue; the human mind is
tentative and groping and makes mistakes\" (Lincoln & Guba, 1985, p.
294).

The authors of qualitative methods texts suggest a variety of procedures
which should be used either singly or in combination in an attempt to
guard against inaccuracy. These include the following.

1\. *Prolonged engagement*. This involves spending sufficient time in
the setting of interest. This, it is claimed, gives the researcher time
to overcome his or her selective perceptions, to distinguish between the
typical and the atypical, and to develop a degree of trust sufficient to
ensure that repondents are responding honestly (Guba & Lincoln, 1997).
Prolonged engagement of course does nothing to guarantee that the
observer is making an accurate record of events.

2\. *The use of low inference descriptors*. This involves the reporting
of what the participants actually said and \"descriptions phrased as
concretely and precisely as possible\" (Le Compte & Preissle, 1993, p.
338).

3\. *The use of multiple researchers*. This is sometimes referred to as
multiplicative replication. \"The optimum guard against threats to
internal reliability in ethnographic studies is the presence of multiple
researchers\" (Le Compte & Preissle, 1993, p. 339). That fact that
several people produce much the same report certainly increases the
believability of data but it does not necessarily establish that the
report is accurate. A community of liars may produce closely similar
accounts. Kirk & Miller (1986, p. 47) give the example of a qualitative
study of workers in a massage parlour who, without exception, reported
that they did not provide \"extras\".

4\. *Structural corroboration*. This involves \"gathering data or
information and using it to establish links that eventually create a
whole that is supported by the bits of evidence that constitute it\"
(Eisner, 1979, p. 215). This procedure may produce a *coherent* account
but, as Phillips (1992) has noted, a coherent account is not necessarily
an accurate account. A liar may produce a coherent account.

5*. Referential adequacy*. This involves the production of a description
which enables the reader to see what the writer wants them to see. \"The
problem here, of course, is that seeing what the critic or the
qualitative researcher is talking about, does not mean that the account
is *true*\" (Phillips, 1992, p. 115). A liar may produce a convincing
account.

6\. *Participant corroboration.* Participant corroboration (also
referred to as member checking) involves taking the data and the
researcher\'s interpretations back to the informants and asking them
directly whether they find the researcher\'s account accurate. If the
account is an account of the attitudes, understandings or beliefs of the
participants, then the believability of that account will obviously be
enhanced if the participants confirm that their beliefs have been
accurately reported. If, however, the account is an account of events,
then the endorsement by participants of the account will not necessarily
provide confirmation of the accuracy of the account. \"An account of a
classroom might be true even though the teacher (or the pupils) disagree
with it\" (Phillips, 1992, p. 116).

7\. *Triangulation*. The main procedure which ethnographers are
counselled to use to ensure the accuracy of their accounts is the
procedure which they refer to as *triangulation*. \"The anthropologist\'s
trade secret . . . is that he or she would never for a minute rely
solely on a single observation, a single instrument, a single approach.
The strength of fieldwork lies in its \'triangulation\', obtaining
information in many ways rather than relying solely on one\" (Wolcott,
1988, p. 192). The ethnographer\'s concept of triangulation is similar
to the social scientist\'s concept of test-retest reliability and the
behaviour analyst\'s concept of inter-observer agreement. All require
two or more independent observations of the same phenomenon.

The central, unresolved problem with ethnographic accounts of
triangulation is that they fail to distinguish between different data
types (e.g. investigator observations, informant reports, investigator
recollections, informant recollections, investigator interpretations,
informant interpretations, and so on) and hence fail to consider the
question of what would count as adequate triangulation for data of each
of these different types. This is an extremely critical omission. It has
been repeatedly demonstrated by researchers working in a number of
different research traditions that there are many circumstances where
people do not or cannot accurately describe their beliefs, their
actions, or even what happened (Lloyd 1980/1994, 1994; Nisbett & Wilson,
1977; Schnelle, 1974; Steele, House & Kerins, 1971). Because qualitative
researchers have yet to consider what would be required to verify the
accuracy of each of these different data types, qualitative methods
texts provide no guidelines regarding either the actions which
researchers should take to guard against inaccuracy when collecting data
of each type or the procedures which researchers should use to assess
and report the accuracy of the verbal reports which they have collected.
One of the few exceptions is Guba & Lincoln (1989) who argue that
triangulation can only be used to check the accuracy of factual data.
Because each participant experiences their own reality, it cannot be
used to check the accuracy of reports of participant\'s perspectives.
For this, participant corroboration is required.

8*. Following the correct procedures*. A number of qualitative
researchers have argued that if certain data collection *procedures* are
used then this will guarantee an accurate data collection *result*. This
claim ignores the fact that, regardless of the observation procedure
which is used, there is always the possibility that the use of that
observation *procedure* may, under certain circumstances, produce an
inaccurate observation *result*. \"It must be recognised that there are
*no* procedures that will regularly (or always) yield either sound data
or true conclusions\" (Phillips, 1992, p. 117). \"Doing something
correctly does not guarantee the outcome, as all good cooks, poets, and
golfers can attest\" (LeCompte & Preissle, 1993, p. 329). Using the
correct interview procedure to interview a liar (e.g. interviewing the
liar twice) will not necessarily result in an accurate account of the
events described by the liar.

All of these procedures are procedures which researchers are counselled
to employ in their attempts to ensure that the data which is being
collected is accurate data. Qualitative researchers have yet to develop
any procedures for *evaluating* the reliability of their observation
procedures or the accuracy of the data which is being or has been
collected.

It is possible to get the report of a qualitative investigation
published even although that report contains no data quality
information. In fact, the great majority of qualitative reports contain
no information at all about the reliability or accuracy of the data
contained in the report.

**Validity of conclusions which are being drawn from the data**

Most qualitative researchers realise that the validity of their
conclusions (their believability) is a matter of some importance.
Erickson (1986), for example, identifies the following threats to
validity: (a) insufficient evidence to justify the key assertions, (b)
insufficient variety in the different types of evidence, (c) an
insufficient understanding of the actors perspectives to accurately
interpret their actions, (d) an inadequate search for disconfirming
evidence, and (e) an inadequate analysis of discrepant cases. Although
ignored by Erickson, most serious threat to the validity of an
ethnographic account is selection bias. This is because an ethnographic
account is always a selective account. Even the most highly skilled
observer can only record some of what is happening. The rest must be
left out. \"Qualitative observation involves knowing what to leave out\"
(Eisner, 1991, p. 34). Because ethnographic *recording* is selective,
two different observers may provide quite different descriptions of the
events occurring in a particular setting simply because they have
elected to include different events in their data. Furthermore, most
qualitative researchers \"collect . . . more data than they can ever
analyze\" (Bogdan & Biklen, 1992, p. 68). Because ethnographic
*reporting* is always selective, two researchers could easily produce
two quite different analyses of the same data set and two quite
different research reports simply because they elected to include
different parts of the data set in their reports.

Textbooks on qualitative research tend to argue that selection bias can
be minimised by the inclusion of all of the data which has been
collected, by negative case analysis, and by the use of peer review.

1.*The inclusion of all data.* With rare exceptions (e.g. Nuthall,
1999), ethnographers do not normally record everything which happens
during the fieldwork period. Observations are a sample of the
observations which might have been made and interviews are a sample of
the interviews which might have been conducted. However, simply
providing a detailed description of the sampling procedures employed (as
is counselled in most qualitative methods texts) provides no safeguard
against selection bias. The only real safeguard against selection bias
is to record everything. This is because, where the subject matter is
learning, every single learning interaction has the potential to affect
learning. Valid conclusions regarding relationships between experience
and learning become possible only if the ethnographer records every
single learning interaction.

2.*Negative case analysis* involves revisiting and revising emerging
hypotheses until they account for most, or all cases. Guba & Lincoln
(1989) argue that assertions should be revised until they account for \"a
reasonable number\" of cases. Erickson (1986) argues that assertions
should be revised until they account for all cases.

3.*Peer review* involves exposing one\'s emerging hypotheses to the
scrutiny of an informed peer. This process \"helps keep the inquirer
\'honest\', exposing him or her to searching questions by an experienced
protagonist doing his or her best to play the devil\'s advocate\"
(Lincoln & Guba, 1985, p. 308). Mertens refers to this as the
*confirmability audit* where the researcher\'s peers \"review field
notes, interview transcripts, and so on and determine if the conclusions
are supported by the data\" (Mertens, 1998, p. 184).

**Evaluation of the quality assurance procedures used by qualitative
researchers**

Evaluating the data quality assurance procedures of the qualitative
researcher is a particularly difficult task for a number of reasons.
First, qualitative researchers do not use a common language in their
discussions of data quality issues. Secondly, qualitative researchers
take a variety of positions with respect to data quality issues with
some (e.g. Smith, 1984) arguing that the interpretivist assumption
precludes the development of common standards for evaluating qualitative
studies and others (e.g. Kirk & Miller, 1986) arguing that data quality
is just as important in qualitative research as it is in any other kind
of research. Thirdly, qualitative researchers disagree amongst
themselves with respect to the procedures which should be used to ensure
data quality and routinely ignore the procedures which should be
employed to *evaluate* the quality of the data collected. Fourthly,
qualitative researchers such as Eisner, and Lincoln and Guba, who have
written on data quality issues, do not recommend a single set of
procedures - their recommendations have tended to evolve and change with
the passage of time.

Qualitative researchers do not routinely assess the reliability of their
observational procedures or the credibility (accuracy) of the data which
these procedures generate and, in fact, disagree amongst themselves as
to how either of these goals might be achieved. Individual studies are
almost never replicated so the qualitative literature includes no data
which could be used to evaluate the reliability of the procedures which
are being used and no information regarding the generality of the
conclusions which are being drawn from each study.

It can be seen, therefore, that the data quality assurance procedures of
the qualitative researcher are particularly weak - much weaker than the
procedures used by either behaviour analysts or cognitive scientists.
Qualitative researchers collect weak data (e.g. data which includes
recollections and retrospective accounts) - the very kinds of data for
which quality assurance procedures are most needed. They tend to work
holistically which means that the risk of bias (unrepresentativeness) is
greater in a qualitative study than in any other kind of study.
Qualitative researchers tend to work alone which precludes the use of
any kind of inter-observer agreement procedure which might be used to
assess or to demonstrate observer reliability. And they have developed
no agreed procedures *either* for ensuring *or* for assessing the
accuracy of the data which they are collecting and reporting.
Qualitative researchers tend to work in single sites thus ruling out the
possibility of any kind of replication across sites - the one procedure
which might be used to assess the reliability of any assertions,
generalisations, or conclusions which are being drawn.

The suggestion by some qualitative researchers (e.g. Eisner, 1991;
Smith, 1984) that conventional notions of reliability, accuracy, and
representativeness should not be applied to qualitative research reports
is particularly worrisome because, should this view become widespread,
it would remove qualitative investigations from the class of activities
which we commonly refer to as research. If there are no agreed criteria
for evaluating the accuracy of the ethnographer\'s report then, of
course, the ethnographer\'s report can never be said to be either
accurate (true) or inaccurate (false) and it can make no contribution to
our evolving understanding of how learning and teaching processes
operate. If there is no way of demonstrating the accuracy of the data in
a research report, then no implications for policy or practice can
follow from that data. The report is more like a novel, a poem, or a
piece of music - enjoyable, insightful and stimulating but not something
from which any kind of new knowledge, prediction, or practical
implication can be derived.
:::

::: referencesList
#### References

-   Bogdan, R. C., & Biklen, S. K. (1992). Qualitative research for
    education: An introduction to theory and methods (2nd ed.). Boston:
    Allyn and Bacon.
-   Eisner, E. W. (1979). The educational imagination. New York:
    Macmillan.
-   Eisner, E. W. (1991). The enlightened eye: Qualitative inquiry and
    the enhancement of educational practice. New York: Macmillan
    Publishing Co.
-   Erickson, F. (1986). Qualitative methods in research on teaching.
    In M. C. Wittrock (Ed.), Handbook of research on teaching (3rd ed.,
    pp. 119-161). New York: Macmillan.
-   Guba, E. G., & Lincoln, Y. S. (1997). Naturalistic and rationalistic
    enquiry. In J.P. Keeves (Ed.), Educational research, methodology,
    and measurement: An international handbook (2nd ed., pp. 86-90).
    Oxford, England: Pergamon/Elsevier Science Inc.
-   Guba, E. G., & Lincoln, Y. S. (1989). Fourth generation evaluation.
    Newbury Park, CA: Sage.
-   Kirk, J., & Miller, M. L. (1986). Reliability and validity in
    qualitative research. Beverly Hills, CA: Sage Publications.
-   LeCompte, M. D., & Preissle, J. (1993). Ethnography and qualitative
    design in educational research (2nd ed.). San Diego, CA: Academic
    Press.
-   Lincoln, Y. S., & Guba, E. G. (1985). Naturalistic inquiry. Beverly
    Hills, CA: Sage Publications.
-   Lloyd, K. E. (1980/1994). Do as I say, not as I do. The Behavior
    Analyst, 17, 131-139.
-   Lloyd, K. E. (1994). Addenda. The Behavior Analyst, 17, 141-144.
-   Maxwell, J. A. (1992). Understanding validity in qualitative
    research. Harvard Educational Review, 62, 279-300.
-   Mertens, D. M. (1998). Research methods in education and psychology:
    Integrating diversity with quantitative and qualitative approaches.
    Thousand Oaks, CA: Sage Publications.
-   Nisbett, R. E., & Wilson, T. D. (1977). Telling more than we can
    know: Verbal reports of mental processes. Psychological Review, 84,
    231-259.
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Phillips, D. C. (1992). The social scientist\'s bestiary: A guide to
    fabled threats to, and defences of, naturalistic social science.
    Oxford, England: Pergamon Press.
-   Schnelle, J. F. (1974). A brief report on invalidity of parent
    evaluations of behavior change. Journal of Applied Behavior
    Analysis, 7, 341-343.
-   Smith, J. K. (1984). The problem of criteria for judging
    interpretive inquiry. Educational Evaluation and Policy Analysis, 6,
    379-391
-   Steele, J. M., House, E. R., & Kerins, T. (1971). An instrument for
    assessing instructional climate through low-inference student
    judgements. American Educational Research Journal, 9, 197-207.
-   Wolcott, H. F. (1988). Ethnographic research in education. In R. M.
    Jaeger (Ed.), Complementary methods for research in education (pp.
    185-206). Washington, DC: American Educational Research Association.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whichapproachestoresearcharecollectingthemostbelievabledataonlearning/Believabilityofthedatacollectedbycognitivescientists/index.md","# Believability of the data collected by cognitive scientists \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f0381468d2cd481d94c54e27858c860d}
Researchers who work in the social science tradition consider data
quality issues to be matters of some importance. \"Research findings
requiring the use of tests can be no more accurate than the measures
themselves\" (Sax, 1968, p. 154). Hence most social science methods texts
devote at least a chapter to discussions of the reliability and validity
of tests and other measurement procedures. In cases where the researcher
has to devise their own test (rather than making use of an existing
test) the researcher is usually counselled that \"much care should be
devoted to the objective evaluation of the instrument, and the findings
of the evaluation should be included in the research report\" (Sax, 1968,
p. 156).

**Accuracy of the data collected**

Social science methods texts usually use the term reliability to refer
to consistency in the measurement result. \"The problem of reliability is
essentially one of determining the degree of consistency present in any
set of observations or measurements (Sax, 1968, p. 157). Some methods
texts consider test reliability as an aspect of generalizability.
Thorndike and Thorndike (1997, p. 775), for example, argue that the
reliability question asks \"how accurately the observed sample \[of
responses\] represents the broader universe of responses from which it
is drawn.\"

In classical test theory a person\'s score on a test is considered to
consist of two components the *true* score and a random *error*. \"The
true score is defined as the value that the average of repeated
measurements with the identical measure approaches as the number of
measurements . . . is increased . . . The term \'identical\' implies
that it is possible to measure an individual repeatedly without changing
that individual - a condition which obviously cannot be achieved in the
real world\" (Thorndike & Thorndike, 1997, p. 776). Allen & Yen (1979, p.
72) argue that \"a test is reliable if its observed scores are highly
correlated with its true scores\" but note that \"in most cases true
scores cannot be obtained.\"

Most methods texts describe three general procedures for assessing the
reliability of a test. These are (a) the test-retest method (in which
the same test is administered to the same sample of subjects on two
separate occasions), (b) the parallel forms method (in which two
parallel forms of the same test are administered to the same sample of
subjects) and (c) the split half method in which two scores are obtained
for each subject (for example, the score on odd items and the score on
even numbered items). In all three cases, reliability is measured by
computing the correlation between the two sets of scores - as first
suggested by Spearman in 1904 (Allen & Yen, 1979; Thorndike & Thorndike,
1997).

The value of the test-retest and parallel forms reliability coefficients
depends not only on test reliability but also upon the range of ability
(range of scores) in the reliability sample (Thorndike & Thorndike,
1997). Hence these reliability coefficients can only be interpreted if
the standard deviation of the scores of the reliability sample is known.
With the split half method, the correlation coefficient is usually
adjusted to take into account the fact that reliability is being
calculated for a test which is only half as long as the actual test. The
split half-method is, perhaps, the most commonly used (Thorndike &
Thorndike, 1997). As already noted, however, the split-half method does
not actually provide a measure of reliability because the test is
administered only once.

For investigations which use previously standardised tests (such as
standardised achievement tests), test-retest reliabilities will usually
be known and can be used to judge the reliability of the data collected
by the investigator.

Social science methods texts tend to argue that inaccurate measurement
results (which social scientists refer to as errors of measurement) can
arise in any of three ways: (a) as a result of variability in the making
of the observation or judgement by the observer, (b) as a result of
variability in the results produced by the instrument being employed,
and (c) as a result of variability between learners with respect to the
characteristic (the construct) being measured, and further argue that
measurement errors are best managed by making multiple observations
(Keeves, 1997). Less common are discussions of the unreliability which
can arise as a result of inadequate sampling of potential test items, as
a result of variability in the way in which teachers and research
assistants follow the test administration and test scoring instructions,
and as a result of using a test which has been designed for ranking and
selection purposes as a measure of learning or achievement following
instruction.

**Validity of the conclusions which are being drawn from the data**

The instruments used by social science researchers almost always involve
a *sample* of the items or questions which might have been asked. Where
an instrument involves only a small sample of all possible items,
questions can always be asked as to whether or not the instrument
constitutes a valid measure of the construct under investigation. This
question, which is usually referred to as the validity question, asks
whether an instrument actually measures what it was supposed to measure.

Three types of test validity are described in most methods texts:
construct validity, criterion validity (often considered under the
headings of concurrent validity and predictive validity) and content
validity. Construct validity is usually assessed by computing the
correlation between the scores of a sample of subjects on the test which
is of interest and the scores of those same subjects on another test
which has been designed to measure the same construct. Criterion
validity is assessed by computing the correlation between the test
scores of a sample of subjects and some future criterion such as
examination success. Although content validity is extremely important in
any experiment designed to measure the effects of teaching on learning,
procedures for evaluating content validity have yet to be developed
(Zeller, 1997).

**Evaluation of the quality assurance procedures used by cognitive
scientists**

Learning involves a *transition* - from a state of not being able to do
something to a state of being able to do it. But researchers who have
applied the social science methodology to the study of learning have
devoted almost no effort to solving the problem of how such transitions
might best be observed and measured. \"Psychologists are busy studying
the transition state called learning without being able to identify,
with any reasonable degree of precision, either the beginning or the end
of the process\" (Sidman, 1960, p. 289).

Not only have cognitive scientists failed to develop an adequate
technology for studying the transitions which we refer to as learning,
they have not even developed adequate procedures for measuring the
achievement which results from a sequence of instruction. All too often
cognitive scientists simply make use of some kind of standardised
achievement test as the measure of learning outcomes. But standardised
achievement tests are designed to distinguish between pupils (e.g. for
selection purposes), they are not designed to measure the effects of
instruction. \"We have a very bad, but deeply ingrained, habit of using
tests designed for the purpose of *discriminating among individuals*
when the evaluation of instruction should actually be the real concern\"
(Skager & Weinberg, 1971, p. 35).

With standardised tests, item selection is rigged to produce a normal
distribution of scores. They are \"quite insensitive to the effects of
short term educational experience\" (Skager & Weinberg, 1971, p. 36).
This item selection procedure precludes the possibility that all the
test takers might obtain scores in the region of, say, 90-100%. When
measuring the achievement which results from a sequence of instruction,
however, items need to be selected to measure student learning of just
those understandings and skills which were the aim of instruction and
all items should be of similar difficulty. Under these circumstances a
\"test on which a majority of students have near-perfect scores is not a
bad test at all; it in fact reflects the success of our efforts at
teaching\" (Skager & Weinberg, 1971, p. 35). This problem too, has been
largely ignored. Teaching researchers who use the social science
methodology have developed no agreed procedures for checking the content
validity of tests which are being used to measure the effects of a
particular sequence of instruction.

Of course not all investigations used standardised tests of known
reliability. Many use tests, rating scales, observation schedules or
self-report instruments which have been specifically designed for that
investigation. In most investigations, these instruments are
administered only once. This means that the cognitive scientist cannot
demonstrate the reliability of that instrument during the course of the
investigation. In theory, the reliability of the instruments could be
established prior to the investigation using a test-retest procedure -
but this is only rarely done. In most investigations, the scores of
individual learners on each of the instruments is not reported and the
accuracy of those individual scores is neither assessed nor reported.
This routine failure to consider data quality issues (in spite of the
fact that procedures have been developed for assessing data quality) is
a major weakness of much of the published cognitive science research.
:::

::: referencesList
#### References

-   Allen, M. J., & Yen, W. M. (1979). Introduction to measurement
    theory. Belmont, CA: Wadsworth.
-   Keeves, J. P. (1997). Introduction: Advances in measurement in
    education. In J. P. Keeves (Ed.), Educational research, methodology,
    and measurement: An international handbook (2nd ed., pp. 705-712).
    Oxford, England: Pergamon/Elsevier Science Inc.
-   Sax, G. (1968). Empirical foundations of educational research.
    Englewood Cliffs, NJ: Prentice-Hall Inc.
-   Sidman, M. (1960). Tactics of scientific research: Evaluating
    experimental data in psychology. New York: Basic Books.
-   Skager, R. W. & Weinberg, C. (1971). Fundamentals of educational
    research: An introductory approach. Glenview, IL: Scott, Foresman &
    Co.
-   Thorndike, R. L., & Thorndike, R. M. (1997). Reliability. In J. P.
    Keeves (Ed.), Educational research, methodology, and measurement: An
    international handbook (2nd ed., pp. 775-798). Oxford, England:
    Pergamon/Elsevier Science Inc.
-   Zeller, R. A. (1997). Validity. In J. P. Keeves (Ed.), Educational
    research, methodology, and measurement: An international handbook
    (2nd ed., pp. 822-829). Oxford, England: Pergamon/Elsevier Science
    Inc.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whichapproachestoresearcharecollectingthemostbelievabledataonlearning/Believabilityofthedatacollectedbybehaviouranalysts/index.md","# Believability of the data collected by behaviour analysts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b197ce3469bb47199abdc233a89af1b5}
Behaviour analysts have developed a well defined set of terms which they
use when considering data quality issues. Behaviour analysts routinely
distinguish between (i) the adequacy of a measurement *procedure* and
(ii) the adequacy of a measurement *result* (that is, the data resulting
from the application of that procedure) and they routinely distinguish
between (i) the steps taken to ensure that a recording procedure is
producing accurate data and (ii) the steps taken to *evaluate* or assess
the adequacy of the recording procedure which is being used.

**Accuracy of the data collected**

Behaviour analysts treat issues of reliability and accuracy very
seriously, and routinely take a number of steps to ensure that their
recording procedures are reliable procedures which will produce accurate
measures of behaviour and behaviour change. These steps include:
providing a careful definition of the behaviour of interest before
beginning an investigation, using direct (rather than indirect)
observation procedures, ensuring that observers are adequately trained,
making repeated observations of the behaviour of interest, and building
in procedures for assessing the reliability of the recordings which are
being made as they are being made.

Behaviour analysts argue that the reliability and accuracy of measures
of behaviour should never be taken for granted and must always be
demonstrated. The great majority of reports of behaviour analysis
experiments include data evaluation information so that the reader can
make a judgement about the believability of the data which is being
presented. The most commonly used data quality assessment procedure
involves (a) the employment of a second independent observer, marker or
coder during a sample of the observational sessions, (b) calculation of
the percentage of agreement between the records of the two observers,
and (c) reporting of the levels of agreement which were obtained. The
results of these assessments are referred to as measures of
*interobserver agreement* (Cooper, Heron & Heward, 1987).

Behaviour analysts consider the collection of measurement evaluation
data mandatory for reports which are intended for publication and would
have difficulty in getting a report accepted for publication if it did
not contain data evaluation information.

**Validity of the conclusions which are being drawn from the data**

The behaviour analyst is not normally concerned with issues of
measurement validity. Behaviour analysts tend to argue that validity is
achieved by the use of direct observation procedures to study relatively
specifically defined classes of performance. \"If the behavior under
study is directly measured, no question about validity exists. Direct
measurement is automatically valid\" (Johnston & Pennypacker, 1993, p.
142). Behaviour analysts do, however, sample observational *occasions*
so questions can always be asked about the validity (the
representativeness) of the sample of occasions selected for observation.

**Evaluation of the quality assurance procedures used by behaviour
analysts**

Behaviour analysts routinely distinguish between procedures designed to
*collect* accurate data and procedures designed to *evaluate* the
accuracy of the data which is being collected. (This is one of the major
differences between behaviour analysis research and ethnographic
research.) Behaviour analysts also distinguish between the reliability
of a measurement procedure and the accuracy of a measurement result.

Behaviour analysts routinely assess the reliability of their measurement
procedures and report the results of their data quality assessments.
Furthermore, the results of these assessments are expected to
demonstrate that adequate standards of accuracy and/or reliability were
achieved. In addition to this, the reliability of the observation
procedure selected for use is routinely evaluated *during the course* of
most behaviour analysis experiments so that corrective action can be
taken if the accuracy of the data being collected falls below
conventional standards. (This requirement is not one which ethnographers
and social scientists have to meet.)

The procedure most commonly used by behaviour analysts to assess the
reliability of observation and coding procedures is the
two-independent-observers procedure. The main weakness of the use of
inter-observer agreement as the data evaluation measure is that, while a
high level of interobserver agreement enhances the believability of data
by providing evidence of consensual validity, it does not, strictly
speaking, provide a measure of either observer reliability or the
accuracy of the data which have been collected (Johnston & Pennypacker,
1993).

Behaviour analysts do not attempt to generalise from single cases to
populations so subject sampling errors cannot function as a threat to
the validity of the behaviour analyst\'s conclusions. Behaviour analysts
avoid problems of content validity by studying changes in small,
functionally delineated and carefully defined response classes (such as
reading accuracy, or reading fluency) so item sampling bias cannot
function as a threat to content validity.

However, behaviour analysts do select samples of observation occasions,
or tests, over time and bias in the sampling of occasions can be a
threat to the validity of the behaviour analyst\'s conclusions. This is
recognised by behaviour analysts who have conducted a number of
investigations of the accuracy of the estimates provided by different
occasion sampling procedures (see, for example, Powell, Martindale &
Kulp, 1975). Behaviour analysts attempt to avoid occasion sampling
errors by making sufficient observations of the behaviour of interest
within each experimental phase to provide a reliable estimate of the
level of change or the rate of change occurring within each experimental
phase.

Behaviour analysis journals routinely require the authors of reports of
behaviour analysis experiments to include data which assess the level of
reliability achieved during the operation of the observation and/or
testing and/or coding procedures used to measure behaviour change during
the course of the experiment. The fact that behaviour analysts employ
measurement procedures and experimental procedures which are likely to
generate accurate measurement results, institute regular reliability
checks, and must report the results of these data quality evaluations as
a condition of publication represents a very considerable advance over
the data quality assurance procedures employed by both qualitative
researchers and social science researchers.
:::

::: referencesList
#### References

-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Powell, J., Martindale, A., & Kulp, S. (1975). An evaluation of
    time-sample measures of behavior. Journal of Applied Behavior
    Analysis, 8, 463-469.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/index.md","# How is learning to be observed and recorded? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c942a5f6dd184243a8b2f7a03199d471}
In order to study the conditions necessary for learning, or the effects
of teaching on learning, the very first problem to be solved is the
problem of how to observe learning and how to measure the rate at which
learning is occurring. Solving this problem requires the student of
learning to make important decisions about what is to be observed, how
it is to be observed, and the level of accuracy which will be aimed for.

The sections which follow address a number of interrelated questions.

In Section 1 we observe that different people have different views
regarding the nature of learning and what can be accomplished by
observation and that this affects what they select for observation.

In Section 2 we address the question of whether the constructs of
behaviour analysts, cognitive scientists and ethnographers can actually
be observed in practice.

Section 3 identifies five important issues which have complicated
attempts to develop accurate measures of rate of learning and suggest
how each of these issues might most appropriately be resolved.

Section 4 compares and contrasts the types of observation and recording
procedures used by behaviour analysts, cognitive researchers and
ethnographers.

Section 5 identifies and defines three important characteristics of
sound measures of learning: accuracy, reliability and validity and
describes ways in which each may be assessed.

In Section 6 we evaluate the believability of the data commonly
collected by behaviour analysts, cognitive scientists and ethnographers.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatarethemainissuesinobservingandrecordinglearning/Vaganoticoridemnoticmeasuresofchange/index.md","# Vaganotic or idemnotic measures of change? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2e79defac6344d2ebb7d7359f12ddcb7}
Measurement is one of the cornerstones of the research activity.
Measurement involves the \"quantification of observations with respect to
a reference scale defined by units that are both absolute and standard\"
(Johnston & Pennypacker, 1993b, p. 21). The great majority of the
measurement scales in common use are absolute and standard scales.
Following Stevens (1951), such scales are usually referred to as *ratio
scales.* Following Johnston and Pennypacker (1993a), they are also
referred to as *idemnotic measures.* Idemnotic measures have the
following characteristics:

-   The scale exists independently of the things which are being
    measured (as a measure of length, a tape measure exists
    independently of the particular lengths being measured and, as a
    measure of time, a clock exists independently of the particular time
    which is being measured).
-   The scale is divided into units which have a name (e.g. centimetre
    as a unit of length, or minute as a unit of time).
-   The scales are equal interval scales (the distance between each cm
    mark on a tape measure is the same, and the length of time between
    each minute mark on a clock is the same).
-   The scales have a true zero point (a length of zero cm is, in
    principle, possible, as is an elapsed time of zero minutes).
-   The scales have been standardised so that a length of, say, 10 cm is
    always the same length, and an interval of 10 minutes is always the
    same interval, regardless of what is being measured, who is doing
    the measurement, and the particular clock or timer which is being
    used.

\"In the social sciences measurement scales very seldom have either zero
points or equal units\" (Maddox, 1993, p. 74-75). The numbers \"1\" to \"5\"
on an attitude scale have no meaning as absolute units. There is no
answer the question \"One what?\" The zero value (no preference) on a five
point scale is usually \"3\", not \"0\". And the value of \"1\" changes each
time the question changes. Intelligence tests, achievement tests, and so
on, are not standard and absolute scales. If a child has an IQ of 100,
there is no answer to the question \"100 what?\" An improvement from 100
to 110 on an intelligence test is an improvement of quite a different
magnitude to an improvement from 170 to 180. And the scores on an
intelligence test do not refer to any absolute measure of ability. IQ
scales are developed by the repeated application of the measuring
instrument (the IQ test) to a sample of subjects and simply reflect the
variability in that sample. If the population average or the population
variability changes, the scores take on entirely new meanings. A score
of 100 on the XYZ intelligence test normed in 1960 (when 100 was the
average) is not the same as a score of 100 on the XYZ test in 1990 (when
the average had become 110).

In the social sciences, persons and events are most commonly ranked on
ordinal scales in which a person\'s score represents their position
relative to the average score obtained by some sample of persons.
Johnston and Pennypacker (1993a) have coined the term *vaganotic* to
refer to measurement scales where the scale units are defined in terms
of the distribution of scores on the measuring instrument itself (rather
than by reference to an independently defined unit). Some examples of
vaganotic and idemnotic measures of performance are shown in Table 3234.

![Figure 3234. Examples of various vaganotic and idemnotic data
types](../../../../../../assets/images/Figure3234.png \"Figure 3234. Examples of various vaganotic and idemnotic data types\"){.image-inline}

*Figure 3234. Examples of various vaganotic and idemnotic data types*

One of the questions which has yet to be resolved by educational
researchers is the question of when it is appropriate to use vaganotic
measures and when it is appropriate to use idemnotic measures of human
performance and learning. All of the early learning researchers
including Ebbinghaus, E.L. Thorndike and Pavlov used standard and
absolute scales (idemnotic scales) to measure the phenomena they were
studying and behaviour analysts continue to use idemnotic measures such
as counts, measures of time, and counts per unit of time. \"The use of
procedures wherein the phenomena being measured or the units of
measurement are defined in terms of \[the\] variability characterizing a
set of otherwise direct observations seem peculiar to the social
sciences\" (Johnston & Pennypacker, 1993b, p. 29).

Idemnotic measures have a characteristic which vaganotic measures do not
possess. The results of an idemnotic measure are directly comparable
from one phase to the next within an investigation and from one
investigation to another. This allows the community of researchers who
are using that measure to share their data, compare their findings, and
develop a common theory. In addition, the results of idemnotic
measurement are much more believable than the results of vaganotic
measurement.

The question of when to use vaganotic and when to use idemnotic
measuring procedures is a particularly important question for
educational researchers. Although vaganotic measures are much more
widely used in the study of learning and teaching than are idemnotic
measures, the view has been expressed that the scientific study of
learning was seriously subverted by the move to vaganotic measurement
and that the scientific study of learning will again become possible
only when learning researchers return to the use of idemnotic measures
of change (Chiesa, 1994; Johnston & Pennypacker, 1993b).
:::

::: referencesList
#### References

-   Chiesa, M. (1994). Radical behaviorism: The philosophy and the
    science. Boston: Authors Cooperative, Inc.
-   Johnston, J. M., & Pennypacker, H. S. (1993a). Strategies and
    tactics of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence
    Erlbaum Associates.
-   Johnston, J. M., & Pennypacker, H. S. (1993b). Readings for
    strategies and tactics of behavioral research (2nd ed.). Hillsdale,
    NJ: Lawrence Erlbaum Associates.
-   Maddox, H. (1993). Theory of knowledge and its dissemination.
    Castlemaine, Australia: Freshet Press.
-   Stevens, S. S. (1951). Mathematics, measurement and psychophysics.
    In S. S. Stevens (Ed.), Handbook of experimental psychology (pp.
    1-49). New York: Wiley.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatarethemainissuesinobservingandrecordinglearning/Howmanyobservationsshouldbemadeduringthecourseofachange/index.md","# How many observations should be made during the course of a change? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f8912b91d6c14cf394dacb51876df681}
Observation of those behaviour changes which we commonly refer to as
learning may be made just once during the course of an investigation (as
when an investigator administers an achievement test at the end of a
unit of work) or they may be made many times (as when an investigator
administers 2-minute tests each day throughout a unit of work). This
distinction is illustrated in Table 3232

![Figure 3232. Examples of various observation procedures located on the
few to many observations
continuum](../../../../../../assets/images/Figure3232.png \"Figure 3232. Examples of various observation procedures located on the few to many observations continuum\"){.image-inline}

*Figure 3232. Examples of various observation procedures located on the
few to many observations continuum*

One of the issues which educational researchers have yet to resolve is
the question of how many observations of a particular event should be
made during the course of an investigation. This question is of
particular importance in research into learning and teaching because
teachers and teaching researchers are primarily interested in change --
the changes in pupil ability, competence, understanding, motivation,
attitude, and so on which result from various teaching activities and
practices.

It is well understood that *change cannot be described using a single
observation*. One cannot describe changes in the speed of a vehicle by
observing that vehicle on a single occasion. One cannot describe the
rate at which a plant is growing by measuring the height of the plant on
a single occasion. And one cannot describe any of the changes which we
refer to as learning by observing the learner\'s performance on a single
occasion. \"Changes . . . of all kinds can only be understood after
successive observations on different occasions\" (Maddox, 1993, p. 5).
For the researcher who is interested in studying learning or teaching,
one of the critical questions to be asked of any research procedure is;
\"Will this procedure provide me with an adequate picture of the changes
which occur during my investigation?\"
:::

::: referencesList
#### References

-   Maddox, H. (1993). Theory of knowledge and its dissemination.
    Castlemaine, Australia: Freshet Press.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatarethemainissuesinobservingandrecordinglearning/Shouldconclusionsbebasedontheperformanceofindividualsorofgroups/index.md","# Should conclusions be based on the performance of individuals or of groups? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6b52d7ad1310462d93e67ffb93a34393}
Often the observations of the educational researcher are observations of
the performance of individuals in a particular setting or of individuals
operating under particular conditions (such as a test). The data which
results from these observations may be reported on a case by case basis
or it may be aggregated and reported as an average (e.g. an average
score) for each group. The practice of reporting data on a case by case
basis is also referred to as the *idiographic approach* and that of
aggregating data across individuals as the *nomothetic approach*.

One of the issues which has yet to be resolved by educational
researchers is the question of when it is appropriate to report data on
a case by case basis and when it is appropriate to report only the mean
scores of groups of subjects. (In fact, the practice of calculating and
reporting mean scores is so common in educational and psychological
research that some research students have difficulty envisaging any
other kind of research data.)

While nomothetic data (such as mean scores) provide appropriate measures
of population characteristics (such as the reading achievement of New
Zealand 6-year olds), teaching (like medical practice, legal practice,
and raising children) involves providing assistance to individuals and
nomothetic data can tell us nothing about the learning of individuals.
Furthermore, any generalisations or theories which are developed with
respect to learning and teaching will need to be applicable at the level
of the individual learner otherwise they will be of no practical use to
teachers. This cannot be achieved with a nomothetic approach to
measurement.

*![Figure 3235. Examples of various data types which do and do not
involve aggregation across
individuals](../../../../../../assets/images/Figure3235.png \"Figure 3235. Examples of various data types which do and do not involve aggregation across individuals\"){.image-inline}*

*Figure 3235. Examples of various data types which do and do not involve
aggregation across individuals*
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatarethemainissuesinobservingandrecordinglearning/Indirectvsdirectmeasuresofbehaviourchange/index.md","# Indirect vs. direct measures of behaviour change \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-653b1e8760f0443b892f71f5fe4d8c02}
Some observation procedures (such as asking people to describe events
which have already occurred) do not bring the researcher into direct
contact with the behaviour or behaviour change which is of interest.
Other observation procedures bring the observer into direct contact with
the behaviour or the behaviour change which is of interest. In other
words, the data which researchers collect may be arranged on a continuum
from data collected by *indirect* through to those collected by *direct
contact* with the events which are of interest. \"Measurement is said to
be *direct* when the phenomenon that is the focus of the experiment is
exactly the same as the phenomenon being measured\" (Johnston &
Pennypacker, 1993, p. 113). Social science researchers often use the
terms *high inference* vs. *low inference* *variables* to refer to the
indirect/direct distinction.

Table 3231 lists some of the types of data commonly collected by
educational researchers and indicates whereabouts on the indirect/direct
continuum each of these kinds of data are located.

![Figure 3231. Examples of various data types located on the indirect to
direct observation
continuum](../../../../../../assets/images/Figure3231.png \"Figure 3231. Examples of various data types located on the indirect to direct observation continuum\"){.image-inline}

*Figure 3231. Examples of various data types located on the indirect to
direct observation continuum*

One of the problems which has never been satisfactorily solved by
educational researchers is the question of when it is appropriate to
substitute a verbal description of what someone did for a record
collected by direct observation. For example, an investigator might be
interested in a child\'s level of interest in reading. This could be
observed indirectly by asking the child\'s teacher to describe the
child\'s level of interest (as he or she perceives it), or it could be
observed directly by observing the child, recording the choices which
the child makes when given a free choice of activity in the classroom
and counting the occasions when the child chooses to read. Because the
former procedure is easier, less time consuming, and less expensive than
the latter, educational researchers often substitute verbal reports of
performance for direct observations of performance. The problem with
verbal reports of behaviour is that they tend to be less accurate (and
hence less believable) than records made by direct observation. Take for
example, a researcher\'s report of a description by a research
participant of something which the participant has seen. Such reports
are common in qualitative studies. But they would not be acceptable in a
court of law where they would be labelled as *hearsay* and ruled
inadmissible as evidence.

Why do verbal reports tend to generate data which is less accurate than
data collected by direct observation? This is because the accuracy of a
verbal report or recollection is influenced by a number of variables
which do not operate when the event of interest is observed directly.
The accuracy of a description of, say, a video record of an event is
primarily dependent upon the observation, analysis, and reporting skills
of the investigator. The accuracy of a verbal report of the same event
is affected not only by the reporting skills of the investigator but by
at least six other variables as well. These variables are as follows.

1.The extent to which the respondent actually noticed the events which
the investigator is interested in. If the participant has never counted
how often a particular child hits other children they will be unable to
answer, with any degree of accuracy, the question: \"How often does this
child hit others?\"

2.The degree to which the respondent is able to remember and recall what
happened. The details of most events are progressively forgotten with
the passage of time. If the participant is asked to describe events
which occurred more than 24 hours previously, there will be details
which the respondent will be unable to remember.

3.The respondent\'s level of motivation to provide the kind of detail
which the researcher seeks. If the respondent does not share the
researcher\'s commitment to a particular project, or the interview has
been going on for some time, the participant\'s responses will tend to
become shorter and less detailed.

4.The respondent\'s attitude towards or commitment to telling the truth.
If the researcher is inquiring about matters which the respondent does
not wish to disclose, then the respondent may provide an inaccurate or
even an untruthful response to the investigator\'s question.

5.The level of skill of the respondent in describing what they have done
or seen. Young children, for example, tend to provide much less accurate
reports because their level of oral language development is much more
limited. People who have had little practice in distinguishing between
and describing their feelings have difficulty in responding to questions
about feelings.

6.The level of skill of the respondent in making the distinctions which
the investigator wants them to make. An investigator who seeks to group
participant responses into the categories \"evidence of coercive power
relations\" and \"evidence of non-coercive power relations\", for example,
will have difficulty doing so if the participant does not make this
distinction and hence does not include (in their verbal report) the
details needed in order for the investigator to do so.

The distinction between data collected by indirect and by direct
observation procedures is an important one for all researchers. This is
because data collected by direct observation tends to be more believable
than data collected by indirect observation.
:::

::: referencesList
#### References

-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatarethemainissuesinobservingandrecordinglearning/index.md","# What are the main issues in observing and recording learning? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ed918e9119764367851b06d61e8525a1}
Research involves the systematic, controlled observation of the subject
matter which is of interest. In the case of research into learning and
teaching, this is systematic observation of examples of teaching and/or
learning. \"Measurement is the hallmark of any science. It is the
activity that permits scientists to quantify their observations in a
systematic manner and, in so doing, distinguish their endeavour from
philosophy\" (Mace & Kratochwill, 1986, p. 154).

The results of a set of systematic observations are most commonly
referred to as *data*. Different ways of looking generate different
kinds of data. That is, different kinds of observation procedures
generate different kinds of observational results. Watching the learner
produces *direct observation data*. Testing the learner produces data in
the form of a test *score*. Rating the learner produces data in the form
of a *numerical rating* (e.g. from 1 to 5). Interviewing the learner
produces data in the form of *interview responses*.

The particular kind of observation procedure which is selected for use
is a matter of some importance. All researchers seek to collect data
which will be accepted as *believable* by the readers of the research
report. But some kinds of data are more believable than others. In this
section we distinguish between indirect and direct observations,
repeated and one-shot measures, qualitative and quantitative data,
idemnotic and vaganotic measures of change, and non-aggregated and
aggregated data.
:::

::: referencesList
#### References

-   Mace, F. C., & Kratochwill, T. R. (1986). The individual subject in
    behavior analysis research. In J. Valsiner (Ed.), The individual
    subject and scientific psychology (pp. 153-179). New York: Plenum
    Press.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatarethemainissuesinobservingandrecordinglearning/Qualitativeorquantitativedescriptionsofchange/index.md","# Qualitative or quantitative descriptions of change? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a9ede536db6846bd87a14e63c1da4241}
Some kinds of data can be presented only in words. Examples include
respondent self-reports of the situations in which they feel anxious, or
the social rules which operate in a given setting, and so on. Other
kinds of data can be presented numerically. Examples include
participant\'s scores on daily tests, measures of the time taken to
complete a particular task, and behaviour counts of various kinds. Until
the terms were redefined by qualitative researchers, data which could
only be described in words was referred to as *qualitative data* and
data which could be presented numerically was referred to as
*quantitative data* (Krathwohl, 1993). Some examples of qualitative and
quantitative data are shown in Table 3233.

![Figure 3233. Examples of various data types located on the qualitative
to quantitative
continuum](../../../../../../assets/images/Figure3233.png \"Figure 3233. Examples of various data types located on the qualitative to quantitative continuum\"){.image-inline}

*Figure 3233. Examples of various data types located on the qualitative
to quantitative continuum*

Because numerical data have traditionally been considered to be more
scientifically respectable, early educational researchers often fell
into the habit of describing qualitative data using numerical indexes.
For example, the researcher\'s classification of a particular family on
a 5-point scale of *socio-economic status* might be given as \"1\" rather
than \"the highest status category\". However, as Stevens (1951) observed,
the use of a numerical index hides the fact that socio-economic status
is a nominal classification. No numerical operations are possible on the
entries in a nominal classification. Although category membership is
often treated as quantitative data, it is, in fact, qualitative data.
The classification of respondents according to gender, years of service,
income group, ethnicity, developmental stage, grade level, and so on is
still qualitative data because no numerical operations (apart from
counting) can be performed on such classifications.

Educational researchers have yet to resolve the question of when it is
appropriate to collect and report qualitative data and when it is
appropriate to collect and report quantitative data. At the present
time, the collection and reporting of qualitative data is on the
increase - largely as a result of an increase in the use of ethnographic
methods. One of the advantages of qualitative description is that it
allows the researcher to proceed without having to first invent a way of
measuring the kinds of changes which are of interest. The main advantage
of quantitative measures is that they are usually more directly
comparable from one investigation to another thus making it possible for
more than one investigator to work on the same research question.

The qualitative vs. quantitative question is a particularly important
question because one of the developments which defines the transition of
a field of inquiry from natural philosophy to natural science is the
transition from qualitative data and modes of description to
quantitative data and modes of description. Goldstein and Goldstein
(1978) illustrate this transition using as an example the development of
a standard measure to replace subjective judgements of hot, hotter and
hottest, that is, the development of the Fahrenheit scale to measure
temperature.
:::

::: referencesList
#### References

-   Goldstein, M., & Goldstein I. F. (1980). How we know: An exploration
    of the scientific process. New York: Plenum Press.
-   Krathwohl, D. R. (1993). Methods of educational and social science
    research: An integrated approach. New York: Longman.
-   Stevens, S. S. (1951). Mathematics, measurement and psychophysics.
    In S. S. Stevens (Ed.), Handbook of experimental psychology (pp.
    1-49). New York: Wiley.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatstandardsareusedwhenassessingthebelievabilityofreportsoflearning/Reliabilitythreatstoreliabilityandtheassessmentofreliability/index.md","# Reliability, threats to reliability and the assessment of reliability \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-61c6cf172aae40bf96b8a7a4f0fb19c2}
\"If the information produced by observing is to be of any long-term or
general use, it has to be repeatable information; in other words, it has
to be information that would be obtained by any one else attempting to
make the same observations\" (Saslow, 1982, p. 10). The first question
which may be asked of the data collected during the course of a research
investigation is the question \"Did the observation procedure operate in
a consistent fashion from one occasion to the next?\"

**Definition.** In educational research, the extent to which an
observation or measurement procedure has been operated in a consistent
fashion is referred to as its *reliability.* (Some qualitative
researchers use the term *dependability*.) A test which generates the
same score when it is completed by the same individual on several
occasions (without any intervening learning) is referred to as a
reliable test and a coding procedure which generates the same count of
behaviour when it is applied to the same videotape of learner
performance on several separate occasions is said to be a reliable
coding procedure (Johnston & Pennypacker, 1993; Kerlinger, 1964).

**Threats to measurement reliability.** There are many factors which can
operate (during the course of a series of observations) to compromise
the reliability of a measurement procedure. Observer reliability may be
compromised by coding schemes which are too complex, by coding
categories which are inadequately defined, by failing to provide
adequate training for observers, by failing to provide observer
reliability checks at regular intervals, by fatigue or loss of
motivation on the part of observers, and so on.

Generally speaking, recording by highly trained observers is more
reliable than recording by poorly trained or untrained observers,
observers operate more consistently if they know that their accuracy is
going to be regularly checked than if no accuracy checks are
implemented, recording by outside observers is more reliable than
recording by the participants themselves, simple coding schemes with
well defined categories can be applied more reliably than complex coding
schemes or coding schemes with poorly defined categories, and so on
(Cooper, Heron & Heward, 1987; Johnson & Bolstad, 1973; Kazdin, 1977;
Reid, 1970).

Test reliability may also be compromised in many ways: by tests which
are too difficult, by ambiguously worded test questions, by test items
which allow guessing, by tests which are too long, by inadequate test
administration instructions, by changes in the testing conditions, by
changes in motivation on the part of those completing the test, by
inadequate marking guides, by failure to provide adequate training for
test markers, and so on.

Generally speaking, tests are more likely to function reliably if they
consist of items which test a single skill or a small collection of well
defined skills, use a number of items to assess each specific skill or
understanding, consist of well written questions and items which
discourage guessing, and are administered and marked by well trained
personnel who have been provided with clear test administration
guidelines and clear marking instructions (Allen & Yen, 1979; Popham,
1981).

**Assessing and reporting measurement reliability.** In order to assess
the reliability of a data collection procedure, that procedure must be
applied *to the same events* on more than one occasion and the degree of
identity between the two separate records assessed. This means that the
reliability of an observational (or coding) procedure using human
observers (or coders) can only be assessed if a sample of the behaviours
of interest can be preserved in some way - as a written product, audio
recording, or video recording, for example. Assessing the reliability of
a test is a relatively simply matter. The test is simply administered
twice to the same subjects taking care to ensure that no learning or
practice of the tested skills and understandings occurs during the two
administrations. (This is most commonly referred to as the *test-retest*
procedure for assessing test reliability.)

The basic measure of recorder reliability, coder reliability, and
test-retest reliability is the degree of correspondence or identity
between independently obtained records (or codes) of the same behaviour,
test performance, or self-report. The measures of correspondence which
are most commonly calculated and reported are either the percentage of
inter-occasion agreement or else the degree of inter-occasion
correlation. Both of these measures are measures of the extent to which
the two records of the same performance match each other.

The reader\'s reaction to differing levels of reported inter-occasion
agreement depends to some extent on the complexity of the coding scheme
which is being applied. If inter-marker agreement was being calculated
for the marking and check marking of written answers to a set of
mathematics exercises then anything less than 100% agreement between the
two markers would probably be regarded as unreliable. If the reliability
of a direct observation procedure was being assessed by getting two
observers each to independently code a videotaped sample of classroom
interactions using a complex 15 category code, then something better
than 80 per cent agreement between the observers might be accepted by
readers as demonstrating an adequate degree of coder reliability (Barlow
& Hersen, 1984).

*A note on percentage of agreement.* One common procedure which is used
to assess the \"reliability\" of the observations made by an observer (or
the classifications made by a coder) is to arrange for two separate
observers (or coders) to make parallel and independent records of the
same events. The researcher then calculates the degree of inter-observer
agreement (or inter-coder agreement) between the two independently
obtained records. Strictly speaking this procedure does not provide a
measure of the reliability of either of the observers (because only one
record of the same events is obtained from each observer) and it does
not provide a measure of the accuracy of the data obtained by the
primary observer (because the accuracy of the second observer is also
unknown). As a measure of data quality, measures of interobserver
agreement are simply that - measures of interobserver agreement. They
provide some information regarding data quality because it is unlikely
that high degrees of agreement could be obtained unless both observers
were operating in a reliable (consistent) fashion. Interobserver
agreement data provide important information regarding data quality in
situations where neither reliability nor accuracy can be assessed but a
measure of interobserver agreement is not a measure of either
reliability or accuracy (Johnston & Pennypacker, 1993).

*A note on the split-half method of calculating test \"reliability\".* In
order to calculate the reliability of a test, it is necessary to
administer the same test to the same learner(s) on more than one
occasion and to compare the scores obtained by each learner on each of
the several administrations of the test. Often however, a less onerous
procedure is used. The test is administered to a sample of learners, the
items in the test are divided into two halves (e.g. odd numbered items
and even numbered items), and the degree of correlation between the
scores on the two sets of items is calculated. Strictly speaking this
procedure does not provide a measure of test reliability because each
learner completes each item only once.
:::

::: referencesList
#### References

-   Allen, M. J., & Yen, W. M. (1979). Introduction to measurement
    theory. Belmont, CA: Wadsworth.
-   Barlow, D. H., & Hersen, M. (1984). Single case experimental
    designs: Strategies for studying behavior change (2nd ed.). New
    York: Pergamon.
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Johnson, S. M., & Bolstad, O. D. (1973). Methodological issues in
    naturalistic observation: Some problems and solutions for field
    research. In L. A. Hamerlynck, L. C. Handy, & E. J. Mash (Eds.),
    Behavior change: Methodology, concepts and practice (pp. 7-67).
    Champaign, IL: Research Press.
-   Kazdin, A. E. (1977). Artefact, bias, and complexity of assessment:
    the ABCs of reliability. Journal of Applied Behavior Analysis, 10,
    141-150.
-   Kerlinger, F. N. (1964). Foundations of behavioral research:
    Educational and psychological inquiry. New York: Holt, Rinehart and
    Winston Inc.
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Popham, W. J. (1981). Modern educational measurement. Englewood
    Cliffs, NJ: Prentice Hall.
-   Reid, J. B. (1970). Reliability assessment of observation data: A
    possible methodological problem. Child Development, 41, 1143-1150.
-   Saslow, C. A. (1982). Basic research methods. New York: Random
    House.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatstandardsareusedwhenassessingthebelievabilityofreportsoflearning/Measurementvaliditythreatstovalidityandtheassessmentofvalidity/index.md","# Measurement validity, threats to validity and the assessment of validity \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d73ed7ec19db412cb7d561af7e18f4e3}
A third question which may be asked of research data is the question \"Is
the conclusion which the researcher has drawn from his or her data a
valid conclusion given the nature of the data and the conditions under
which it was collected?\" Note that the validity question is not so much
a question about the adequacy of the observation procedure employed or
the data which it has produced as it is a question about the conclusions
which are being drawn from the data collected (Martella, Nelson, &
Marchand-Martella, 1999; Popham, 1981).

The validity question recognises that all data sets are but tiny samples
of the events which might have been observed. Imagine a study of the
language interactions and vocabulary development of a sample of 20
6-year olds. Ten hours observation of the language interactions of each
child represents but a tiny fraction of time in the life of a 6-year
old; a 30 item vocabulary test samples but a tiny fraction of the
thousands of words which 6-year olds know and can use, and a sample of
20 children is but a tiny fraction of all possible English speaking
6-year olds. Any conclusions which are drawn from small data sets, no
matter how accurate the data in the set, must be framed in such a way as
to recognise that the conclusion is based on a very small sample of the
observations which might have been made and that a different sample
might well lead to a different conclusion.

Note that a researcher can collect highly accurate data but still draw
an invalid conclusion from that data. I may observe a child during
mathematics lessons and accurately record the number of aggressive
responses during mathematics as 0. However, if I were to conclude on the
basis of this observation, that the child never engaged in aggressive
responses (when in fact the child hits other children in settings which
I did not observe) then my conclusion would be not be a valid
conclusion.

**Threats to the validity of data-based conclusions.** There are many
factors which can lead investigators into drawing invalid
(unjustifiable) conclusions from the data which they have collected.

The main threat to the validity of the conclusions being drawn by the
researcher is inaccurate data. If the data do not accurately represent
what happened or what was learned, the chances are high that the
researcher will draw an invalid (that is, an unjustified) conclusion
from that data. Because educational researchers have developed no agreed
procedures for routinely assessing the accuracy of their data, invalid
data-based conclusions are extremely difficult to detect and may well be
quite common.

Investigator expectations constitute a second common threat to
measurement validity. The investigator may have developed a belief
(prior to the investigation) regarding how the results should turn out
and, as a result of that belief, analyse or interpret the data which
have been collected in a way which is consistent with that belief. This
source of invalidity may also be difficult to detect - especially if the
investigator\'s expectations have not been disclosed.

A third common threat to validity is sampling bias, that is, the
collection of a non-representative set of observations. For example, the
sample of occasions which are selected for observation may not be
representative of occasions in general thus leading to conclusions
(based on the sample) which differ from those which would have been
drawn if a more representative sample had been drawn. Or the sample of
students or participants may not be representative of the larger group
of students which are of interest to the investigator. Or the sample of
test items included in a test of learning may not be representative of
the skills which were taught and practised during a period of teaching
thus leading to erroneous conclusions about the effects of that teaching
on student learning. (The adequacy of the content covered by a test is
usually referred to as the *content validity* of the test.)

The simplest way to avoid drawing invalid conclusions from a set of
observations or test results is simply to report the conclusions which
are directly indicated (and only the conclusions which are directly
indicated) by the data. The researcher can also minimise the likelihood
of unjustified conclusions by providing an adequate description of the
sampling procedures which were employed. If a sample of learners has
been drawn from a population of learners, then the defining
characteristics of the class of learners should be listed and the
selection procedure described. If a sample of competencies has been
drawn from a class of competencies (as is the case with most achievement
tests) then the class of competencies should be adequately defined and
the procedure which was used to select particular competencies from this
class of competencies should be described. If a sample of observation
sessions has been drawn from all of the occasions when observations
might have been made (as is often the case in ethnographic and behaviour
analytic investigations) then the way in which these observation
sessions were selected should be described. Only if this information is
provided will be reader be able to make a judgement regarding the
representativeness of any samples which have been drawn and, hence, the
validity of the conclusions which the investigator has drawn from the
data collected.

**Assessing the validity of the conclusions which have been drawn.**
There are no established procedures which investigators can follow in
order to prevent themselves from drawing biased, overgeneralised or
invalid conclusions from the data which they have collected. \"It is
immensely difficult to provide compelling evidence of validity\" (Zeller,
1997, p. 823). Generally speaking, evaluating validity is something
which is done by the readers of a research report. Readers evaluate
conclusions in the light of the information which has been provided
regarding the selection procedures used, and the characteristics of any
sample of occasions, participants, or test items selected by the
researcher.
:::

::: referencesList
#### References

-   Martella, R. C., Nelson, R. & Marchand-Martella, N. E. (1999).
    Research methods: Learning to become a critical research consumer.
    Boston: Allyn and Bacon.
-   Popham, W. J. (1981). Modern educational measurement. Englewood
    Cliffs, NJ: Prentice Hall.
-   Zeller, R. A. (1997). Validity. In J. P. Keeves (Ed.), Educational
    research, methodology, and measurement: An international handbook
    (2nd ed., pp. 822-829). Oxford, England: Pergamon/Elsevier Science
    Inc.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatstandardsareusedwhenassessingthebelievabilityofreportsoflearning/index.md","# What standards are used when assessing the believability of reports of learning \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-870a91b8b4ab4079a6b1734fa746d8eb}
\"Whenever we observe something, we make errors; period, no exceptions,
ever\" (Dane, 1990, p. 28). Given that all measurement procedures are
prone to error, it follows that the believability of a set of
observations in going to depend upon the extent to which measurement
errors were avoided. The believability of a set of observations of
learning (or teaching) depend in part upon the reliability of the
observation or testing procedures used, in part upon the accuracy of the
data obtained, and in part upon the validity of the conclusions which
the researcher has drawn from the data which was collected.

Without believable data, the researcher will be unable to draw
believable conclusions. Unfortunately, the collection of believable data
is no simple matter because educational researchers have yet to agree
upon a common set of standards which can be applied in assessing the
quality of research data - with ethnographers, social scientists and
behaviour analysts all applying different standards.

In this section we describe the data quality standards which are widely
applied during research into learning and teaching, some of the ways in
which data quality can be compromised, the steps which educational
researchers often take in order to enhance the believability of their
data, and the main procedures which are used when evaluating data
quality and believability.
:::

::: referencesList
#### References

-   Dane, F. C. (1990). Research methods. Pacific Grove, CA:
    Brooks/Cole.
:::"
".//Typesofresearchevidence/Howislearningtobeobservedandrecorded/Whatstandardsareusedwhenassessingthebelievabilityofreportsoflearning/Accuracythreatstoaccuracyandtheassessmentofaccuracy/index.md","# Accuracy, threats to accuracy and the assessment of accuracy \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4382621ecf1d4029998a5bdcc1886bbf}
The second question which may be asked of research data is the question
\"Does this data accurately represent the events which actually occurred
during the course of each observation?\" The match between the data which
was collected and the events which actually occurred is referred to as
data *accuracy*. \"Accuracy is the term which is used to describe the
extent to which observed values approximate the \'true\' state of
nature\" (Johnston & Pennypacker, 1993, p. 138), that is, the behaviour
actually engaged in, or the events which actually happened. If a child
actually spelled 19 out of a sample of 20 spelling words correctly and
the investigator reported this as a score of 19/20, the investigator\'s
report would be said to be an accurate report. Some qualitative
researchers use the term *confirmability* for accuracy, some (e.g.
Mertens, 1998) use the term *credibility*, and some (e.g. Maxwell, 1992)
use the term *validity.*

In order to obtain accurate results, the observation procedure must be
one which can be operated in a reliable fashion. Note, however, that an
observation procedure can be reliable without being accurate. My
bathroom scales may produce a highly consistent result (always giving my
weight as 70 kg) but be consistently inaccurate (if my actual weight is
80 kg).

**Threats to measurement accuracy.** There are many factors which can
operate (during the course of a series of observations) to compromise
the accuracy of the data which is being collected. The main threat to
data accuracy is an unreliable observation or testing procedure.
However, it is possible for even a reliable observation procedure to
produce inaccurate data. For example, observation periods which are too
short may produce inaccurate estimates of how often a particular
behaviour is engaged in, tests which are too short may produce
inaccurate estimates of a learner\'s current level of achievement, and
infrequent tests (or observations) may produce less accurate estimates
of rate of progress than more frequent tests (or observations).

Generally speaking, mechanical recording (e.g. video recording) produces
more accurate data than recording by human observers, idemnotic
measurement procedures produce more accurate measures of human skill and
ability than vaganotic measurement procedures, direct observation
produces more accurate data than indirect observation (e.g. rating
scales and verbal reports), records which are made at the time when the
behaviour change occurred tend to be more accurate than records which
are made later (i.e. from memory), and observers who are blind to
experimental conditions tend to produce more accurate records than
observers who are aware of experimental conditions (Johnston &
Pennypacker, 1993; Kazdin, 1977). Longer observation sessions produce
more accurate estimates of behavioural frequency than shorter
observation sessions, tests which contain a number of questions testing
the same competency produce more accurate estimates of level of
competency than tests which contain only one or two questions on that
competency and repeated observations or tests, spaced over time, provide
a more accurate picture of behaviour change (learning) than just one or
two observations or tests.

**Assessing and reporting data accuracy.** In order to assess the
accuracy of the data which are being generated by a particular
observation or testing procedure, it is necessary to obtain performance
measures using not only the procedure being used for the research but
also using a second procedure, the accuracy of which is already known
(Johnston & Pennypacker, 1993). For example, the accuracy of the timings
provided by the particular stopwatch used by the researcher might be
evaluated by comparing them against the timings provided by a clock
which is already known to be accurate, or the accuracy of a teacher\'s
marking of a spelling test might be assessed by comparing the teacher\'s
judgements against the dictionary spellings of the same words.

The assessment of measurement accuracy also requires that a record of
the learner\'s behaviour or performance be preserved in semi-permanent
form. For example, the accuracy of the decisions which are being made by
a referee, the judge at a championship competition, or an observer might
be checked by comparing these decisions against the results of multiple
viewings of a videotape of the same performance.

It is often difficult in educational and psychological research to
evaluate the accuracy of the data which is being collected. In those
cases where data accuracy has been assessed, however, it is not
necessary to assess reliability because any procedure which produces
accurate data must have been a reliable procedure.
:::

::: referencesList
#### References

-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Kazdin, A. E. (1977). Artefact, bias, and complexity of assessment:
    the ABCs of reliability. Journal of Applied Behavior Analysis, 10,
    141-150. Martella, R. C., Nelson, R. & Marchand-Martella, N. E.
    (1999). Research methods: Learning to become a critical research
    consumer. Boston: Allyn and Bacon.
-   Maxwell, J. A. (1992). Understanding validity in qualitative
    research. Harvard Educational Review, 62, 279-300.
-   Mertens, D. M. (1998). Research methods in education and psychology:
    Integrating diversity with quantitative and qualitative approaches.
    Thousand Oaks, CA: Sage Publications.
:::"
".//Typesofresearchevidence/index.md","# Types of research evidence \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-998135bde47d4fb2a3366e1a2644fa97}
It is increasingly being argued that teaching practice should be
evidence based. But there are many different kinds of research into
learning and teaching and this claim (that teaching should be evidence
based) only becomes meaningful if we say what kind of research evidence
we are talking about.

In addition, people outside education are beginning to notice that much
educational research doesn't look anything like the scientific research
which usually precedes technological advances and that it doesn't seem
to be resulting in any kind of cumulative development in our
understanding of learning or any kind of visible improvement in our
ability to design effective teaching programmes.

These observations raise a number of questions. How should learning and
teaching be studied? Are there particular research methods which provide
more compelling evidence than others about how best to bring about
different kinds of learning outcomes in different kinds of learners? Or
have education researchers yet to reach agreement on how the effects of
teaching on learning might best be measured? What is to count as
research evidence? Is there any agreed research evidence on which
teaching practices might be based? In this book we will consider these
questions in some detail as we explore the different assumptions which
are being made and the different research methods which are being
employed by those who are engaged in research into learning and
teaching.

This book consists of four major chapters.

Chapter 1 considers various widely used research methodologies
(approaches to research) and asks which of these methodologies have
learning and/or teaching as their subject matter in the sense that they
attempt to identify functional relationships between possible teaching
variables and possible learning outcomes.

Chapter 2 addresses the question of how learning is to be observed and
measured and what is to count as an accurate and reliable record of
learning.

Chapter 3 asks how the effects of teaching variables on learning are to
be identified and measured.

Chapter 4 considers the types of evidence which might be used in a move
to evidence-based teaching practice and asks whether we have yet
discovered enough about the relationships between teaching variables and
learning outcomes to justify a move towards evidence-based practice in
the classroom.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Increasingthesizeoftheresearchestablishment/index.md","# Increasing the size of the research establishment \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4c32169e4f714291905c3943fcf93436}
University of Canterbury, Christchurch, New Zealand. © University of
Canterbury 2008.

During the past 30 years, a small band of researchers have made a strong
start on the development of a science of learning and teaching and this
augers well for the transition to evidence-based practice. However the
research completed to date is only the very beginning of the work which
needs to done. Much more research will be required to complete the
analysis of learning processes and the conditions which they require, to
develop a comprehensive technology of instructional design, and to
develop a complete set of evidence-based teaching materials and
practices for 13 years of compulsory schooling.

However, the number of researchers available to pursue this goal is
tiny. According to the Tertiary Education Commission (2004a), New
Zealand has approximately 280 people actively engaged in educational
research. Given that there are more than 48,000 primary and secondary
teachers alone, it can be seen that well under half a per cent of the
teaching workforce is engaged in research.

Funding for educational research is also miniscule. Working from OECD
figures, Alton Lee (2004, p. 6) reported that the level of R & D funding
in education is probably somewhere between 0.17% and 0.2% of the total
education budget. This is well below the amount spent in other OECD
countries for which data is available. The under-funding of research in
education is a problem of long standing (Whitcombe, 1985).

Note that the very low percentage of the sector involved in research and
the very low level of investment in research (compared to say the health
sector) is not just a New Zealand phenomenon. It exists across the
Western World (Burkhardt & Schoenfeld, 2003; Keeves & McKenzie, 1999).

Not only is the research establishment very small given the size of the
sector, it is not particularly productive. The first assessment, in
2003, by the Tertiary Education Commission for the Performance-Based
Research Fund provided a reasonably detailed picture of the number of
research active staff in each of New Zealand's teacher education
programmes. The PBRF exercise revealed that the majority of New
Zealand's teacher educators were not active educational researchers
(Tertiary Education Commission, 2004a, 2004b). Altogether only 27% of
New Zealand's tertiary education teachers submitted research portfolios
containing sufficient research to qualify them for an A, B, or C rating
(Alcorn et al., 2004). The comparable figures for some of the individual
universities and colleges were as follows: University of Auckland School
of Education: 77%, University of Canterbury School of Education: 62%,
University of Waikato School of Education: 43%, Auckland College of
Education 14% and Christchurch College of Education 9.4% (Tertiary
Education Commission, 2004a). (The recent amalgamation of the Colleges
of Education and the Universities at Auckland, Christchurch and Dunedin
will change these figures.).

Not only are educational researchers small in number but they have to
cover a range of disciplines. Faculties of Education traditionally
include specialists in educational philosophy, educational history,
educational sociology, educational psychology, assessment, human
development, human learning, curriculum studies, methods of teaching,
professional studies, and so on. This further reduces the number of
researchers working on questions relating to learning, teaching, and
teacher education.

How, then, is the research capacity which will be needed for the
transition to evidence-based practice to be created? There are three
main avenues of recruitment into educational research, recruitment from
teacher educators, recruitment from research students, and recruitment
from the teaching profession. To make the transition we will need to
recruit from all three of these sources.

**Increasing the number of teacher educators who are engaged in
research**

Teacher educators have shown a keen interest in becoming involved in
research. As the various New Zealand colleges of education have merged
with their local universities, the membership of the New Zealand
Association for Research in Education has climbed steadily and
membership has more than doubled. However, at we will see below, it is
not easy for a teacher educator who has been recruited from the teaching
profession to become involved in research. This is because they have not
been trained as researchers and because their primary interest is not in
research but in the practice of teaching (Labaree, 2004).

In order to increase the numbers of teacher educators engaged in
research it will be necessary to pursue a number of policies. These
include increased funding for research within the new university based
colleges and faculties of education, increased funding for professional
development leave for those who have been appointed with masters degrees
so that they can upgrade to PhD degrees, and policies which ensure that,
when retirements occur, these retirees are replaced by lecturers with
PhD level qualifications in research as well as professional
qualifications in teaching.

**Increasing the number of education students who are engaged in
research**

Up until very recently, the majority of New Zealand education students
who completed a masters level qualification did so without completing a
research thesis and even those who did complete a thesis tended to study
questions which could be addressed using a relatively unsophisticated
descriptive methodology. Unfortunately these descriptive research
projects add nothing to the scientific knowledge base. Nor do they
prepare students for further research which might generate new
scientific knowledge regarding learning or teaching processes. As we
shall see below, there are good reasons for this, one of which is the
lack of research methods training at the undergraduate level in our
current teacher education programmes.

In order to recruit postgraduate education students into research it
will be necessary to pursue policies which differ from those which are
currently being pursued. For example, we will need to upgrade research
methods training at the undergraduate level so that advanced research
methods training can be undertaken at the postgraduate level and we will
need to upgrade research methods training at the postgraduate level so
that masters students and PhD students who wish to engage in scientific
research into learning and/or teaching have the knowledge and skills
which they will need for this kind of research. We will also need to
encourage masters levels students to complete research theses and to
make it clear to masters students that, if they are hoping eventually to
become teacher educators, they will need to have completed a masters
thesis in order to gain entry to the PhD programme which will qualify
them for university positions in teacher education.

**Increasing the number of teachers who are engaged in research**

Increasing the numbers of teacher educators and post-graduate students
who are working on scientifically oriented research and development
activities will increase the research establishment to a limited extent
but certainly not to the extent required for the transition to
evidence-based practice. The only way of greatly increasing the number
of people engaged in research on teaching relative to the number of
people engaged in the practice of teaching is by making it possible for
teachers themselves to contribute to the research enterprise. This is
what happened during the move to evidence-based practice in medicine 80
years ago and there are no practical impediments to the same thing
happening in education.

What is being suggested here is a greatly accelerated development in
what has come to be known as \"practitioner research\". Unfortunately
practitioner research has all too often been conceptualised as \"action
research\" and other types of relatively simple-minded descriptive and
narrative accounts of elements of classroom culture and practice (e.g.,
Anderson, 2002; Hollingsworth, 1999). This is not what is being
suggested. What is being suggested is practitioner research which takes
the form of scientifically oriented research on teaching, that is,
experimental analyses of learning and teaching processes of individual
children in the classroom.

Is this possible? It certainly is. At the University of Canterbury,
teachers and allied professionals have completed several hundred
experimental analyses of learning processes, management procedures,
motivational procedures, instructional procedures, and remedial teaching
procedures. As a result of this work we have discovered that most
teachers, when given the necessary teaching or mentoring, are quite
capable of scientifically oriented practitioner research where they
measure the effectiveness of what they are doing or seek to discover new
and more effective classroom practices (Church, 1974, 1975, 1976, 1986,
1990, 1996).

As this website develops we will post, in Book 8 of this website,
examples of scientifically oriented practitioner studies of learning and
teaching which have been completed by classroom teachers at both the
undergraduate and postgraduate levels so that practising teachers and
teachers in training can see the contribution which they could be making
to the scientific development of improvements in classroom practice.
:::

::: referencesList
#### References

-   Alcorn, N., Bishop, R., Cardno, C., Crooks, T., Fairbairn-Dunlop, P,
    Hattie, J., et al. (2004). Enhancing education research in New
    Zealand: Experiences and recommendations from the PBRF Education
    peer review panel. New Zealand Journal of Educational Studies, 39,
    275-302.
-   Alton-Lee, A. (2004) Iterative best evidence synthesis:
    Strengthening research, policy and practice. Links to improve
    outcomes. Paper presented to the 4th Annual Policy Evolution
    Conference. Retrieved 17 July, 2006, from
    htttp://www.conferenz.co.nz/2004/library/a/adrienne_altonlee.html
-   Anderson, G. L. (2002). Reflecting on research for doctoral students
    in education. Educational Researcher, 31(7) 22-25.
-   Burkhardt, H., & Schoenfeld, A. H. (2003). Improving educational
    research: Toward a more useful, more influential, and better-funded
    enterprise. Educational Researcher, 32(9), 3-14.
-   Church, R. J. (1974). Some observations on the research
    potentialities of Teachers Colleges. Paper presented to Lopdell
    House Course on Practical Training for Student Teachers, Auckland,
    August, 1974.
-   Church, R. J. (1975). Could teachers be doing worthwhile research?
    set, Number 1, Item 5.
-   Church, R. J. (1976). On designing a classroom experiment.
    Educational Research Newsletter, 9, 1-2.
-   Church, R. J. (1986). Teaching behaviour analysis research skills to
    undergraduate students. Paper presented to the Annual Conference of
    the Australian Association for Research in Education, Melbourne,
    Australia.
-   Church, R. J. (1990). The use of within-subject designs to measure
    the effects of teaching on learning. Paper presented to the Annual
    Conference of the N.Z. Association for Research in Education,
    Auckland, New Zealand.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. \\"State of the Art\\" Monograph Number 5.
    Palmerston North, N.Z: New Zealand Association for Research in
    Education.
-   Hollingsworth, S. (1999). Teachers as researchers. In J. P. Keeves
    & G. Lakomski (Eds.), Issues in educational research (pp. 57-63).
    Amsterdam: Pergamon.
-   Keeves, J., & McKenzie, P. A. (1999). Research in education: Nature,
    needs and priorities. In J. P. Keeves & G. Lakomski (Eds.), Issues
    in educational research (pp. 201-214). Amsterdam: Pergamon.
-   Labaree, D. F. (2004). The trouble with ed schools. New Haven: Yale
    University Press.
-   Tertiary Education Commission. (2004a). Performance-based research
    fund: Evaluating research excellence. The 2003 assessment.
    Wellington, N.Z.: Tertiary Education Commission.
-   Tertiary Education Commission. (2004b). Overview and key findings.
    Performance-based research fund: Evaluating research excellence. The
    2003 assessment. Wellington, N.Z.: Tertiary Education Commission.
-   Whitcombe, J. (1985). Who gets the research money? Input, 7(4), 1-4
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Improvingthequalityofresearchintolearningandteaching/Productiveresearchusesresearchmethodswhicharefitforpurpose/index.md","# Productive research uses research methods which are fit for purpose \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-910c1c365bf54de996506141cdab4c58}
Education consists of a number of disparate disciplines (educational
philosophy, history, sociology, psychology, assessment, human
development, learning, curriculum studies, methods of teaching, and so
on) (de Landsheere, 1997). \"The AERA . . . is subdivided into 12
sections and 128 special interest groups by both discipline and
differing subjects of study\" (Lagemann, 2000, p. 240). Specialists in
each of these fields tend to study different kinds of questions and, to
a considerable degree, study these questions using rather different
kinds of research methods (Keeves, 1997). This means that there is no
common training which can be provided for education researchers, only
training which is appropriate to research in educational history,
educational sociology, human development, human learning, and so on. The
teachers and postgraduate students in university schools of education do
not become researchers by becoming competent in some generic set of
educational research methods but by becoming competent in the research
methods which are required in order to make significant advances in
their chosen field of research.

In some disciplines such as biochemistry, only scientific modes of
inquiry are judged to be appropriate. In some disciplines (e.g. history)
only descriptive modes of inquiry are possible. In many educational
disciplines (e.g. human learning) both pre-scientific and scientific
modes of inquiry are possible and both have their advocates, so the
novice researcher must make an informed choice with respect to which
kind of inquiry their research career will be based upon. This in turn
requires a research methods preparation which will enable an informed
choice to be made.

The pre-scientific modes of inquiry (such as ethnographic and other
types of descriptive inquiry) can be mastered fairly quickly and it is
this feature which seduces many novice researchers into so called
\"qualitative\" research. The inclusion of low level descriptive accounts
of existing activities within the definition of \"research\" has increased
considerably as increasing numbers of teacher educators have become
involved in research. In 1987, 28 per cent of papers presented by New
Zealand researchers at their annual NZARE conference used a descriptive
research method, and 23 per cent employed a correlational or
experimental method (Church, 1988). By 2005, 70 per cent of papers
presented at the annual NZARE conference used a descriptive method and
only 12 per cent used a correlational or experimental method. This
increase in the relative proportion of descriptive research (often
erroneously referred to as \"qualitative research\") is apparent in a
number of educational research journals (Church 1998) and it is apparent
across a number of English speaking countries (Department of Education,
Science and Training, nd).

Senior students who wish to pursue questions about learning or teaching
which require correlational, experimental or statistical methods of
analysis are now finding that the necessary training is often
unavailable. Until very recently, the main research methods course at
Canterbury provided no training in epidemiological, correlational, or
experimental research and no training in the different kinds of
knowledge generated by different research methodologies.

The scientific modes of inquiry take much longer to master and this is
one of the major reasons why the move by teacher educators into research
during the past 20 years has tended to be a move into descriptive modes
of inquiry rather than a move into scientific modes of inquiry. One of
the disadvantages of descriptive modes of inquiry is that the return for
research effort tends to be very small (Church, 1998). That this is so
can been seen from the fact that there are no textbooks summarising the
results of more than 30 years of qualitative research into learning and
teaching.

One of the advantages of scientific modes of inquiry is that results
tend to accumulate and to result in the development of theories which
can be used to make predictions about what does and does not result in
learning for children at the various age levels. A clear demonstration
of this kind of development can been seen in this website. It can also
be seen in the textbooks summarising the results of the learning (and
teaching) research undertaken by behaviour analysts during the past 30
years (e.g. Alberto & Troutman, 1999; Catania, 1992; Gardner et al.
1994; Grant & Evans, 1994; Malott, Whaley & Malott, 1993; Sulzer-Azaroff
& Mayer, 1991; Wolery, Bailey & Sugai, 1988).

Because educational researchers have developed a variety of different
kinds of research methods with which to study learning and teaching,
students, teachers and teacher educators who are coming to research for
the first time face critical choices with respect to both the content of
their research and the methods which they will employ to study this
content. In most fields, the content (the research question) is usually
selected first and a research method then devised which might possibly
provide an answer to the question. In other words researchers in the
fields which employ a scientific approach try to select research methods
which are fit for purpose and which, as a consequence, could possibly
supply an answer to the research question (Ercikan & Roth, 2006;
Raudenbush, 2005). Until educational researchers begin to do the same,
much research time, effort and money will continue to be wasted.

We will know that the transition to evidence-based practice has begun
when the great majority of researchers, whether they be students or
teachers, are not only selecting research questions which could result
in an advance in our understanding but are also choosing to study this
question using a research method which is fit for the purpose.

The critical choices which are involved in selecting a research method
which is fit for purpose are described in Book 3 of this website.
:::

::: referencesList
#### References

-   Alberto, P. A., & Troutman, A. C. (1999). Applied behavior analysis
    for teachers (5th ed.). Upper Saddle River, NJ: Prentice-Hall.
-   Catania, A. C. (1992). Learning (3rd ed.). New York: Prentice Hall.
-   Church, R. J. (1988). Educational research in Australia and New
    Zealand: Priorities and practices. Paper presented to the annual
    conference of the N. Z. Association for Research in Education,
    Palmerston North, New Zealand.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N. Z. Association for
    Research in Education, Dunedin, New Zealand.
-   de Landsheere, G. (1997). History of educational research. In J. P.
    Keeves (Ed.), Educational research, methodology, and measurement: An
    international handbook (2nd ed., pp. 8-16). Oxford:
    Pergamon/Elsevier Science Inc.
-   Department of Education, Science and Training. (nd). The impact of
    educational research. Australian Government: Department of
    Education, Science & Training. Retrieved 5 July, 2005 from
    http://www.dest.gov.au/archive/highered/respubs/impact/overview.htm
-   Ercikan, K., & Roth, W. (2006). Constructing data. In C. F. Conrad
    & R. C. Serlin (Eds.), The Sage handbook for research in education:
    Engaging ideas and enriching inquiry (pp. 451-475). Thousand Oaks,
    CA: Sage Publications.
-   Gardner, R., Sainato, D. M., Cooper, J. O., Heron, T. E., Heward, W.
    L., Eshleman, J., & Grossi, T. A. (Eds.). (1994). Behavior analysis
    in education: Focus on measurably superior instruction. Pacific
    Grove, CA: Brooks/Cole Publishing Co.
-   Grant, L., & Evans, A. (1994). Principles of behavior analysis. New
    York: HarperCollins College Publishers.
-   Keeves, J. P. (Ed.) (1997). Educational research, methodology, and
    measurement: An international handbook (2nd ed.). Oxford:
    Pergamon/Elsevier Science Inc.
-   Lagemann, E. C. (2000). An elusive science: The troubling history of
    education research. Chicago, IL: University of Chicago Press.
-   Malott, R. W., Whaley, D. L., & Malott, M. E. (1993). Elementary
    principles of behavior (2nd ed.). Englewood Cliffs, NJ: Prentice
    Hall.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
-   Sulzer-Azaroff, B., & Mayer, G. R. (1991). Behavior analysis for
    lasting change. Fort Worth: Holt, Rinehart and Winston.
-   Wolery, M., Bailey, D. B., & Sugai, G. M. (1988). Effective
    teaching: Principles and procedures of applied behavior analysis
    with exceptional students. Boston: Allyn and Bacon.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Improvingthequalityofresearchintolearningandteaching/Thewayforward/index.md","# The way forward \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-94e60bf6e1b9469db4ecb8802a0c581c}
In this introduction to the TECKS website we have reviewed the current
state of classroom practice and have concluded that it remains a craft
largely untouched by the scientific research into learning and teaching.
When teachers need to solve an instructional problem, they \"consult the
teacher down the hall\". They do not consult the scientific research into
solutions for that particular problem (Landrum & Tankersley, 2004).

We have also reviewed the current state of research in education and
have concluded (a) that it is grossly understaffed and underfunded
(given the amount which is spent on education), and (b) that teaching
and learning researchers are spending far too much of their precious
time engaged in tediously uninformative, small scale, descriptive
studies of \"what is\" rather than exploring, experimentally, \"what might
be\". It is also clear that the scientific research which could possibly
be used to inform practice, is largely invisible because it is buried
under a mountain of pre-scientific research.

However, we remain optimistic. We believe that progressive improvements
in teaching practice, fuelled by scientific research into learning,
teaching and instructional design are possible during the 21st century
in the same way that progressive improvements in medical practice proved
to be possible during the 20th century. \"Educational research has
reached the point, unimaginable a mere 25 years ago, where it is now
possible to conduct fundamental research amidst principled attempts to
affect practice for the better\" (Burkhardt & Shoenfeld, 2003, p. 7).

This optimism is based on a number of recent developments.

The first is the emergence of a small group of educational researchers
(the behaviour analysts) who have made the transition from
pre-scientific to scientific modes of inquiry and are already hard at
work identifying the conditions which govern behaviour change, learning
and teaching effectiveness (e.g., Greer, 1983; Heward & Cooper, 1992).

The second is the development over the last two decades of an increasing
number of evidence-based and demonstrably effective teaching programmes
for children with unrealistic fears and phobias, children with attention
problems, children with antisocial behaviour problems, children with
language delays, children with reading delays and learning disabilities,
children with autism and intellectual disabilities, and so on (e.g.,
Mash & Barkley, 2006). If we can design teaching procedures which
accelerate the development of our most difficult-to-teach children, then
we can certainly do the same for the rest of the school population.

Thirdly, we have learned how to record those changes which we refer to
as learning and how to measure the effects of teaching variables on
learning (Church, 1996; Cooper, Heron & Heward, 2007), we have learned
how to distinguish between research procedures which do and do not
produce reproducible results and we have learned how to use this
knowledge to produce literature reviews from which reliable conclusions
can be drawn (e.g., Church, 2003; Timperley, Wilson, Barrar & Fung,
2007).

Fourthly, Departments and Ministries of Education across the Western
world are beginning to insist that those researchers who work in the
areas of learning, teaching and teacher education begin to concentrate
their efforts on the development and dissemination of evidence-based
materials and procedures, that is, on those teaching practices and
programmes which are known (from well designed empirical evaluations) to
have desired effects on learning and achievement -- especially the
learning and achievement of low achieving children (Alton-Lee, 2004;
U.S. Department of Education, 2002). Researchers are now beginning to
recognise also that teacher educators \"are at the nexus of research and
practice in education\" (Landrum & Tankersley, 204, pp. 210) and will
therefore play a critical role in determining what is important as well
as what is effective.

Fifthly, increasing numbers of leading researchers are beginning to
recognise that some questions about learning and teaching are more
important than others, that different kinds of questions require
different kinds of research methods if they are to be answered, that
when it comes to evaluating the effects of different teaching practices
we need a set of research methods which \"rule things in and rule things
out\" and that, while not perfect, the scientific methods are the best
procedures that we have for this purpose at this time (e.g. Berninger,
Dunn, Lin & Shimada, 2004; Carnine, 2000; Chall, 2002; Eisenhart &
DeHaan, 2005; Feuer, Towne & Shavelson 2002; Greenwood, 2001; Grossen,
1996; Landrum & Tankersley, 2004; Raudenbush, 2005; Ravitch, 2000;
Reyna, 2004; Slavin, 2002; Wheldall, 2005).

The sixth and most encouraging sign of all is the appearance of attempts
to sketch out the kinds of educational policies which will be needed in
order to begin the transition from craft-based to evidence-based
practice (e.g., Burkhardt & Schoenfeld, 2003; Carnine, 2000; Greenwood,
2001; Raudenbush, 2005; Slavin, 2005).

Stephen Raudenbush argues that the number one question which is being
asked by policy makers is the question of how we can improve classroom
teaching and learning. This includes questions about the interventions
which show the most promise, and the procedures to be used in
identifying these. \"It follows that identifying, testing, and warranting
the effectiveness of strategies for instruction is currently the central
task of applied research in education\" (Raudenbush, 2005, p. 27).
Raudenbush also reminds us that, in order to accomplish this goal,
researchers will also need to undertake descriptive studies designed to
identify the best ways of measuring different types of learning,
epidemiological (correlational) studies designed to find out which
students are having difficulties with which learning outcomes in which
contexts, large numbers of single case experiments designed to identify
promising interventions, to identify which children these work for, and
to identify the conditions under which these interventions do and do not
work, and descriptive studies of what happens when teachers try to
implement these more effective practices in different contexts.

Burkhardt & Schoenfeld (2003) identify some of the key policy changes
which will be required for the transition to evidence-based practice.
These include the development of standard measures of learning (so that
results can be compared across studies), the development of a standard
terminology (so that researchers can communicate with instructional
designers and other research teams), the development of research
programmes (so that research evidence begins to build cumulatively with
time), funding policies which result in the development of larger teams
(so that it becomes possible to upscale effective procedures from
demonstration experiments to widespread implementation trials),
increased funding of \"design experiments\" which contribute both to our
knowledge of the conditions necessary for learning and the development
of more effective teaching materials and procedures, and greatly
improved training of educational researchers in the full range of
research skills which are required for successful R & D work. Burkhardt
and Schoenfeld point to the negligible funding for medical research at
the turn of the 20th century and the way successive research-led
developments in medical practice led to successive increases in research
funding to remind educational researchers of the advantages of
investment in research programmes which result in the development of
more effective teaching materials and procedures.

Robert Slavin who directed the development of \"Success for All\" (the
highly effective junior school programme) argues that we need to greatly
increase expenditure on the development, evaluation and dissemination of
effective instructional programmes and materials (Slavin, 2005). This,
he argues, should include the funding of \"design competitions\" in which
developers are challenged to create more effective programmes to teach
reading, maths, science, social studies, and so on across each grade
level as well as the funding of independent third-party randomised
groups evaluations of current and new educational programs and
practices. Schools should receive financial incentives for participating
in programme evaluations and other types of research and for adopting
teaching programmes which have already been shown to be effective.
Slavin, too, is confident that \"when policymakers perceive that
educational research and development is actually producing programs that
are shown in rigorous experiments to improve student outcomes, they will
fund research at far higher levels\" (Slavin, 2002, p. 15).

Only if we can overcome our obsession with endlessly describing what is,
and begin to divert a major part of our research funding towards
studying what might be, and to do this in a scientific manner, can we
begin the journey towards classroom practices which will enable every
child to develop to the fullest extent possible. The aim of this website
is to show that this journey has already begun. Thirty years ago, Robert
Glaser (1967) predicted that we were about to witness the emergence of a
science of instruction and a technology of instructional design. This
didn't happen in his lifetime. Perhaps it will in yours.
:::

::: referencesList
#### References

-   Alton-Lee, A. (2004). A collaborative knowledge building strategy to
    improve educational policy and practice: Work-in-progress in the
    Ministry of Education's Iterative Best Evidence Synthesis programme.
    Wellington, N.Z.: Ministry of Education.
-   Berninger V. W., Dunn, A., Lin, S. C., & Shimada, S. (2004). School
    evolution: Scientist-practitioner educators creating optimal
    learning environments for all students. Journal of Learning
    Disabilities, 37, 500-508.
-   Burkhardt, H., & Schoenfeld, A. H. (2003). Improving educational
    research: Toward a more useful, more influential, and better-funded
    enterprise. Educational Researcher, 32(9), 3-14.
-   Carnine, D. (2000). Why education experts resist effective practices
    (And what it would take to make education more like medicine).
    Retrieved 10 December, 2000, from
    http://www.edexcellence.net/library/carnine.html
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. \\"State of the Art\\" Monograph Number 5.
    Palmerston North: N.Z. Association for Research in Education.
-   Church, R. J. (2003). The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Report prepared for the Ministry of Education.
    Christchurch, N.Z.: University of Canterbury, Education Department.
-   Chall, J. S. (2002). The academic achievement challenge: What really
    works in the classroom? New York: Guilford Press.
-   Cooper, J. O., Heron, T. E., & Heward, W. I. (2007). Applied
    behavior analysis (2nd ed.). Upper Saddle River, NJ: Pearson
    Educational.
-   Eisenhart, M., & DeHaan, R. L. (2005). Doctoral preparation of
    scientifically based education researchers. Educational Researcher,
    34, 3-13.
-   Feuer, M. J., Towne, L., & Shavelson, R. J. (2002). Scientific
    culture and educational research. Educational Researcher, 31(8),
    4-14.
-   Glaser, R. (1967). The new pedagogy. Pittsburgh, PA: University of
    Pittsburgh Learning Research and Development Centre.
-   Greenwood, C.R. (2001). Science and students with learning and
    behavioral problems. Behavioral Disorders, 27, 37-52.
-   Greer, R. D. (1983). Contingencies of the science and technology of
    teaching and pre-behavioristic research practices in education.
    Educational Researcher, 12(1), 3-9.
-   Grossen, B. (1996) What does it mean to be a research-based
    profession? Retrieved 10 April, 2005, from
    http://darkwing.uoregon.edu/\~bgrossen/pubs/resprf.htm#Science
-   Heward, W. L., & Cooper, J. O. (1992). Radical behaviorism: A
    productive and needed philosophy for education. Journal of
    Behavioral Education, 2, 245-365.
-   Landrum, T. J. & Tankersley, M. (2004). Science in the schoolhouse:
    An uninvited guest. Journal of Learning Disabilities, 37, 207-212.
-   Mash, E. J., & Barkley, R. A. (Eds.). (2006). Treatment of childhood
    disorders (3rd ed.). New York: Guilford.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
-   Ravitch, D. (2000). Left back: A century of failed school reforms.
    New York: Simon & Schuster.
-   Reyna, V. F. (2004). Why scientific research? The importance of
    evidence in changing educational practice. In P. McCardle, & V.
    Chhabra (Eds), The voice of evidence in reading research (pp.
    47-58). Baltimore:Paul H Brooks.
-   Slavin, R. E. (2002). Evidence-based education policies:
    Transforming educational practice and research. Educational
    Researcher, 31, 15-21.
-   Slavin, R. E. (2005). Evidence-based reform: Advancing the education
    of students at risk. Report prepared for Renewing our Schools,
    Securing our Future: A National Task Force on Public Education.
    Retrieved 15 July 2007 from
    http://www.schoolinfosystem.org/archives/Slavin-Evidence-Based-Reform.pdf
-   Timperley, H., Wilson, A., Barrar, H., & Fung, I. (2007). Teacher
    professional learning and development. Best evidence synthesis
    iteration (BES). Wellington, New Zealand: New Zealand Ministry of
    Education.
-   U.S. Department of Education. (2002). No Child Left Behind: A
    Desktop Reference. Washington, D.C.: U.S. Department of Education,
    Office of Elementary and Secondary Education.
-   Wheldall, K. (2005). When will we ever learn? Educational
    Psychology, 25, 573-584.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Improvingthequalityofresearchintolearningandteaching/UpgradingthequalityofresearchfundedbytheMinistryofEducation/index.md","# Upgrading the quality of research funded by the Ministry of Education \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a75a2a8bc42f4af486b1226ffd718562}
In New Zealand, the Ministry of Education is a the major source of funds
for research into all aspects of learning, teaching, materials
development and school functioning. During 2005 and 2006 more than 50
research reports were published by or for the Ministry of Education.
This suggests that the Ministry funds more than 25 new research projects
per year. Some of these projects are simply reports of statistics
collected by the Ministry. Included here are annual reports on the
enrolments in Reading Recovery, enrolments with Resource Teachers:
Literacy, attendance and absence statistics, and workforce statistics.
Some are reports of national and international studies of student
achievement. Included here are reports from the National Education
Monitoring Project and the Progress in International Reading Literacy
Study (PIRLS).

However, much Ministry funded research is research undertaken, under
contract, by non-Ministry researchers working on questions selected by
the Ministry. The way in which these research contracts are designed,
put out to tender, funded, and reported on provide very strong
incentives to the rest of the educational research community. It is
important, therefore, that these projects not only meet Ministry
objectives but also provide models of worthwhile research undertaken
using appropriate research methods.

Some of the research projects which are being commissioned by the
Ministry are conceptually and technically sophisticated and serve as
excellent models of the kind of research required for the transition to
evidence-based practice. Recent examples include the research reviews
which meet conventional quality standards (e.g. Church, 2003; Timperley,
Wilson, Barrar & Fung, 2007), the longitudinal Competent Learners Study
(Wylie, Ferral, Hodgen & Thompson, 2006), the International Reading
Studies (Comparative Education Research Unit, 2005), the National
Education Monitoring Project, and the Te Kötahitanga project (Bishop,
Berryman, Cavanagh & Teddy, 2007).

Other aspects of Ministry sponsored research leave much to be desired.
Ministry research contracts have been criticised for seeking answers to
questions which a brief commissioned project cannot provide, for
commissioning projects which are too small to answer the questions of
interest, and for setting RFP deadlines which are far too short to
permit organisation of the release time and substitute teaching
arrangements necessary in order for suitably qualified staff to mount
the requested project (Alcorn, 2005).

In order to gain some idea of the overall quality of Ministry of
Education research we examined many of the reports of contract research
funded by the Ministry over the period 2005-2006 together with Teaching
and Learning Research Initiative (TLRI) reports published over the
period 2004-2005 to get an idea of their quality. We looked at three
aspects of quality: the value and importance of the research question(s)
addressed, the adequacy of the research designs employed to answer these
questions, and the conceptual sophistication of the research (especially
the potential for the research to generate new knowledge).

**Importance of the questions asked**

An examination of Ministry of Education research reports over this
period quickly reveals that many of the questions which are being
studied are not research questions at all. Some of the questions are so
trivial as not to qualify as research questions, some of the questions
addressed are questions to which the answer is already known, and some
questions are so general that there is no research method which could
ever answer them. The twelve 2004-2005 TLRI reports tended to address
the most trivial questions. In all but one case, these studies are
descriptive studies which addressed trivial questions regarding existing
practices. The following examples illustrate the relatively
unsophisticated nature of the research questions addressed by both TLRI
funded and contract funded Ministry research.

Peterson and Irving (2004), using funds from the \$5m Teaching and
Learning Research Initiative, reported on their attempts to answer
several research questions relating to secondary school assessment
practices. One of these questions was \"What is the impact of students'
conceptions of assessment and feedback on students' learning outcomes?\"
This question is, of course, non-sensical because it is assessment
*practices* which affect student learning not students' *conceptions* of
those practices. A second question addressed by this study was \"What
factors contribute to the success of the TLRI programme? This question
is also unanswerable because the answer depends upon the technical
sophistication of researchers and the authors of the study had no
intention of studying a sample of researchers who varied with respect to
technical sophistication.

Ellis, Loewen and Hacker (2005), under contract to the Ministry of
Education, attempted to evaluate the impact of additional funding under
the Second Language Learning Funding Pool. One of the main indictors was
\"enrolments in second language classes\". This is the kind of information
which can be collected by a short telephone survey and hardly warrants
an expensive research contract.

Waiti (2005), under contract to the Ministry of Education, undertook an
evaluation of the effects of Kaupapa Ara Whakawhiti Mätauranga, a set of
school-based ICT initiatives. One of the aims of the evaluation was to
examine relationships between the uses being made of the three ICT
tools, school curriculum organisation, school curriculum content, within
school teaching approaches, student learning, student interest, teacher
interest, teacher motivation, student retention, degree of professional
development, degree of inter-school collaboration, school management,
and community involvement. Even if a reliable measure could have been
generated for each of these variables (which wasn't the case), this
question is so complex that it almost certainly could never have been
answered in any meaningful manner and, of course, it wasn't.

Winter (2005), reported the results of a Ministry contract to evaluate
the effects of four computer enhanced after school study centres. One of
the aims of this project was to describe lessons learned from the pilot
that could usefully inform any roll out of the scheme to other schools
and other school districts. While this is an interesting question, it is
clearly too broad to function as a research question since there are
literally hundreds of possible answers to the question.

**The adequacy of the research designs used**

Of the external research projects under review, a dozen purport to be
evaluation studies in that they have the words *an evaluation of* in
their title. However, closer examination of the research method employed
in these studies indicates that none of them actually qualify as
evaluation studies because none of them employed an evaluation design.
In order to evaluate the effects of introducing a new programme, several
design criteria must be met. Where the aim is to see whether the new
programme has resulted in enhanced student learning there must be a
reliable measure or measures of student learning or achievement. Where
the aim is to measure the effects of introducing some kind of programme
or initiative, the sample of classrooms (or schools) must be of
sufficient size to generate generalizable conclusions. Where the aim is
to measure effects, then either (a) the outcomes must be measured both
prior to, as well as after, the introduction of the new programme or
else (b) half of the sample must be randomly assigned to a control or
placebo condition. These are the only ways of evaluating the effects of
introducing something new. *None of the 2005-2006 Ministry funded
\"evaluations\" meet these criteria.* The following examples illustrate
this observation.

In evaluating the effects of funding under the Second Language Learning
Funding Pool (Ellis et al., 2005) referred to above, two of the stated
aims of the project were to measure benefits with respect to student
learning and benefits with respect to teacher capability. However, no
attempt was made to measure either of these educational outcomes, so no
conclusions could be drawn about the effects of the extra funding on
either of these outcomes.

Mitchell, Tangaere, Mara, and Wylie (2006), completed an \"evaluation\" of
the effects of equity funding on levels of participation and service
quality in a sample of 47 early childhood education centres. However,
there was no control group nor were measures of any of the indicators
obtained before and after receipt of the equity funding, so no
conclusions could be drawn about the effects of the equity funding.

One of the aims of study by Winter (2005) of the effects of four
computer enhanced after school study centres was to identify the stated
learning objectives and the observed learning outcomes of these study
centres. However, the learning outcomes were never measured, there was
no control group, and no before and after observations were made. These
shortcomings meant that no conclusions whatsoever could be drawn
regarding the effects of this initiative on student learning outcomes.

Not only are completely inappropriate procedures being employed in
Ministry \"evaluations\", they are also being employed in a number of the
literature reviews commissioned by the Ministry. A considerable amount
of money has now been spent on a set of literature reviews within the
Best Evidence Synthesis programme of the Medium Term Strategy Division.
One of the essential elements of a review of research is a clearly
stated set of inclusion criteria. A clear description of the inclusion
criteria is absolutely essential to the success of the review activity
because (a) only if the inclusion criteria are clearly stated can the
reviewer determine when the literature search has been completed and (b)
clearly stated inclusion criteria are necessary in order for the reader
to determine whether the standards set for inclusion were sufficient to
allow conclusions to be drawn from the set of reports included in the
review. So far, only one of the five published BES reviews (Timperley,
Wilson, Barrar & Fung, 2007) meets these requirements.

One of the consequences of the failure to specify a set of inclusion
criteria is that each of the first three BES reviews has failed to
include large numbers of relevant research reports. For example, the BES
review of mathematics teaching (Anthony & Walshaw, 2007) failed to
review more than 250 controlled experimental analyses of mathematics
learning in school aged children and, on these grounds alone, is
virtually worthless as a review.

A second consequence of the failure to operate clearly specified
inclusion criteria is that many of the studies which have been included
in these reviews are quite irrelevant to the questions addressed by the
review. For example, the Alton-Lee (2003) review purports to address
questions relating to the effect of classroom variables and teaching
variables on children's learning outcomes. However, the review includes
many descriptive studies which are quite irrelevant to the questions
asked and these descriptive studies have been summarised and have been
used to generate conclusions *as if they were relevant* to the questions
being addressed. This practice is inexcusable in a Ministry funded
literature review.

**Conclusion**

Our analysis of Ministry procedures and projects indicates a strong
focus on descriptive studies of \"what is\" with large sums of scarce
research funding being spent on evaluations which are not evaluations,
literature reviews which are not literature reviews, and other research
projects which fail to meet even minimal quality standards.

The educational research budget in New Zealand simply is not large
enough to justify this kind of wastage. Worse still, this work sends
completely inappropriate signals to educational researchers. The
Ministry of Education commands a very significant proportion of the
research funding available for educational research in New Zealand. The
projects which it supports therefore function as models and standards
for educational researchers to emulate. These standards are currently
being set so low that Ministry research is currently subverting the
Ministry's stated aim of encouraging the move to evidence-based practice
in this country.
:::

::: referencesList
#### References

-   Alcorn, N. (2005). Will scholarship trump teachers in New Zealand
    teacher education? Waikato Journal of Education, 11, 3-16.
-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, New Zealand: New
    Zealand Ministry of Education.
-   Anthony, G., & Walshaw, M. (2007). Effective pedagogy in
    mathematics/pängarau. Palmerston North, N.Z.: Massey University,
    School of Curriculum and Pedagogy.
-   Bishop, R., Berryman, M., Cavanagh, T., & Teddy, L. (2007). Te
    Kötahitanga phase 3 whänaungatanga: Establishing a culturally
    responsive pedagogy of relations in mainstream secondary school
    classrooms. Report to the Ministry of Education. Hamilton, N.Z.:
    University of Waikato, School of Education in association with
    Poutama Pounamu Research and Development Centre.
-   Church, R. J. (2003). The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Report prepared for the Ministry of Education.
    Christchurch, N.Z.: University of Canterbury, Education Department.
-   Comparative Educational Research Unit. (2005). Processes of reading
    comprehension: A summary of the results from the Progress in
    International Reading Literacy Study 2001. Wellington, N.Z. Ministry
    of Education.
-   Ellis, R., Loewen, S., & Hacker, P. (2005). Evaluation of the Second
    Language Learning Funding Pool (1999-2003). Auckland, N.Z.: The
    University of Auckland, Department of Applied Language Studies and
    Linguistics.
-   Mitchell, L., Tangaere, A. R., Mara, D., & Wylie, C. (2006). An
    evaluation of initial uses and impact of Equity Funding. Final
    report for Ministry of Education. Wellington, N.Z.: New Zealand
    Council for Educational Research.
-   Peterson, E., & Irving, E. (2004). Conceptions of assessment and
    feedback. Auckland, N.Z.: The University of Auckland, Department of
    Psychology.
-   Timperley, H., Wilson, A., Barrar, H., & Fung, I. (2007). Teacher
    professional learning and development. Best evidence synthesis
    iteration (BES). Wellington, New Zealand: New Zealand Ministry of
    Education.
-   Waiti, P. (2005). Evaluation of Kapapa Ara Whakawhiti Mätauranga.
    Wellington, N.Z.: New Zealand Council for Educational Research.
-   Winter, M. (2005). Digital Opportunities Pilot Project (2001-2003):
    Evaluation of digitally boosted study support centres. Report to the
    Ministry of Education. Christchurch, N.Z.: Ultralab South.
-   Wylie, C., Ferral, H., Hodgen, E., & Thompson, J. (2006).
    Competencies at age 14 and competency development for the Competent
    Children: Competent Learners study sample. Wellington, N. Z.: New
    Zealand Council for Educational Research.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Improvingthequalityofresearchintolearningandteaching/Correctingtheimbalanceandupgradingeducationalresearchmethodstraining/index.md","# Correcting the imbalance and upgrading educational research methods training \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f9a291e936734fdc9e1aa9bc648fb489}
Investigators who call themselves \"scientists\" use a wide range of
different investigative procedures (Phillips, 2006). For example,
questions about \"what works\" are essentially causal questions and, in
general, an experimental analysis is regarded as the best way to
discover the effects of alternative procedures and innovations (Church,
1996; Raudenbush, 2005). In our attempts to determine the effects of
particular teaching strategies we also need to discover which children
are affected, which learning outcomes are affected and in which
situations these effects occur. Thirdly we need to discover why
particular procedures work, why they work for some children and not
others, and when they are likely to fail. Expertise in a range of
experimental, correlational and descriptive methods is required to
successfully address these different kinds of questions

At the present time, many educational researchers have been trained only
in descriptive methods (the so called \"qualitative\" methods) and there
is a shortage of researchers who have been trained in the methods which
are required for epidemiological research, scientific programme design,
programme evaluation, time series analyses of children's learning, and
experimental practitioner research. A researcher who is competent in
only ethnographic and narrative methods, is quite severely limited with
respect to the kinds of research questions which they can study.

If we are to begin the move to evidence-based practice this imbalance
will need to be corrected. We will need to upgrade our research methods
training to the point where we can train greater numbers of research
students (at all levels) in the scientific methods needed for sound
epidemiological studies, instructional design work, programme evaluation
and experimental practitioner research.

**1. Undergraduate research training**

In order to produce a new generation of teachers and teacher educators
who see research as an integral part of their career, research
experience at the undergraduate level will need to be very considerably
upgraded for all education students. At the undergraduate level it is
appropriate that this upgrading occur within the context of taught
courses. This goal is most likely to be accomplished if most of the
undergraduate courses contain a research element (as is customary in
university courses). In some courses this element will involve content
which has been derived from scientific research in education, in some
courses this element will involve a study of half a dozen relevant
scientific experiments, in some courses this element may involve
completing a small review of a set of experiments relevant to one of the
issues raised in the course, and in some courses this element may
involve a small closely supervised research exercise in measuring
learning or in measuring the effects of some kind of teaching on
learning (Church 1992, 1996.)

**2. Masters level research training**

In order to produce teachers who can undertake experimental practitioner
studies, who can design and carry out programme evaluations, who can
participate in larger research programmes, and who can eventually move
into positions as university teacher educators, research training at the
masters level will need to be very considerably upgraded for all
post-graduate education students regardless of speciality. At the
postgraduate level it is appropriate that this upgrading occur within
research methods courses followed by supervised thesis research. While
it is likely that the masters degree which consists solely of taught
courses is likely to survive for some time to come it is important that
students enrolling in taught masters degrees clearly understand that
such degrees will no longer provide a route to a university position
should the practitioner later seek a university career.

As a very first step in this upgrading it is essential that research
methods training be reviewed so that students with little or no research
methods background can be provided with the introductory level training
which they missed out on during their undergraduate degree studies and
which they will need in order to gain entry into the main masters level
research methods courses.

The main masters level research methods courses, in turn, will need to
be reviewed to ensure that essential questioning, observation,
measurement and design skills are being mastered and to ensure that
students are learning how to conduct developmental studies,
epidemiological studies, single case experimental research and
randomised groups research at an advanced level. In order to ensure that
adequate levels of competence are achieved, entry to masters level
research courses will need to be limited to those students who meet
specified entry requirements and some specialisation with respect to
particular methods should probably be allowed. Once the student has
reached an adequate level of competence in selected research methods,
they should proceed to a supervised thesis project which examines a
worthwhile question using a method which meets conventional standards of
internal validity (measurement reliability) and external validity
(generalisability).

In the case of newly established faculties of education, it will be
necessary for faculty staff to join post-graduate students in the newly
upgraded masters level research methods courses -- at least until the
faculty contains adequate numbers of staff with advanced qualifications
in the epidemiological methods, developmental methods, single case
experimental methods, randomised groups experiments, and statistical
methods necessary for scientific research into learning and teaching.

**3. Doctoral level research training**

The kinds of preparation required for productive PhD level research in
the 21st century have been well described by Eisenhart and DeHaan (2005)
who argue that educational researchers need training in the principles
of scientific inquiry, training in the diverse research methods required
to answer different kinds of questions, and an interdisciplinary
research orientation.

In order to produce teacher educators with PhD level qualifications in
research, the level of work which is currently required for a PhD will
need to be carefully reviewed, as should the policies governing entry to
the degree. Prior to admission to the degree, candidates should be
required to demonstrate that they meet at least the following
requirements:

\(a\) In all cases that they have an extensive content knowledge
including an extensive knowledge of the results of previous research in
their area of interest (Boote & Beille, 2005)

(b)In all cases that the question which they propose to study is
worthwhile in the sense that it could conceivably generate new knowledge
and not just recycle existing knowledge

(c)In all cases that they have acquired the skills necessary to design
and carry out a series of investigations which have a high probability
of answering the question(s) under examination

(d)In the case of studies of teaching or learning that they will be
collecting accurate data about learning (not just achievement), that
they will employ direct observation procedures to gather this data, and
that they will preserve the records of behaviour change in each
individual learner.

(e)In the case of studies of teaching that they will not only collect
accurate measures of learning or achievement, but also to make an
accurate record (e.g. a video record or equivalent) of all of the
teaching under examination so that the relationships between teaching
and learning can be reliably identified during data analysis.

We will know that the move to evidence-based practice is becoming more
likely as increasing numbers of PhD candidates begin to engage in
research projects which meet these requirements.
:::

::: referencesList
#### References

-   Boote, D. N. & Beille, P. (2005). Scholars before researchers: On
    the centrality of the dissertation literature review in research
    preparation. Educational Researcher, 34(6), 3-15.
-   Church, R. J. (1992). Teaching behaviour analysis research skills to
    undergraduates. Paper presented to 4th World Congress on Behaviour
    Therapy, Gold Coast, Australia, July 1992.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. \\"State of the Art\\" Monograph Number 5.
    Palmerston North: N.Z. Association for Research in Education.
-   Eisenhart, M., & DeHaan, R. L. (2005). Doctoral preparation of
    scientifically based education researchers. Educational Researcher,
    34, 3-13.
-   Phillips, D. C. (2006). Muddying the waters: The many purposes of
    educational inquiry. In C. F. Conrad & R. C. Serlin (Eds.), The Sage
    handbook for research in education: Engaging ideas and enriching
    inquiry (pp. 7-21). Thousand Oaks, CA: Sage Publications.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Improvingthequalityofresearchintolearningandteaching/index.md","# Improving the quality of research into learning and teaching \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-acde269bf291446f907c15af578d72f4}
For far too long educational research has had an \"awful\" reputation
(Kaestle, 1993). In part, this reputation is justified. Large swathes of
educational research are, in fact, awful -- or at least of little value.
Consider, for example, the thousands of studies which have used
between-group designs to study learning -- a phenomenon which actually
occurs in individuals, or the hundreds of studies which have used
ethnographic and other kinds of descriptive methods to study the
relationship between teaching and learning -- even although
relationships cannot be identified using a descriptive method (Reyna,
2004; Robinson et al., 2007).

The move to evidence-based teaching practice will require a very great
increase in the amount of research completed. But this cannot be
achieved simply by increasing the number of researchers. An increase in
the number of educational researchers might simply increase the amount
of \"awful\" research being undertaken.

What we have to achieve is not only to increase the number of education
lecturers, teacher education lecturers and teachers who are engaged in
research into learning and teaching but also to greatly increase the
proportion of these who are engaged in high quality, scientifically
oriented research which could, conceivably, produce improvements in our
understanding of learning and teaching processes. In order to accomplish
this we must first understand why so much of the research into learning
and teaching is of so little value and then identify policies and
practices which are likely to result in substantial improvements in
research quality.
:::

::: referencesList
#### References

-   Kaestle, C. (1993) The awful reputation of educational research.
    Educational Researcher, 22(1), 23-31.
-   Reyna, V. F. (2004). Why scientific research? The importance of
    evidence in changing educational practice. In P. McCardle, & V.
    Chhabra (Eds), The voice of evidence in reading research (pp.
    47-58). Baltimore: Paul H Brooks.
-   Robinson, D. H., Levin, J. R., Thomas, G. D., Pituch, K. A., &
    Vaughn S. (2007). The incidence of \\"causal\\" statements in
    teaching-and-learning research journals. American Educational
    Research Journal, 44, 400-413.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Improvingthequalityofresearchintolearningandteaching/Scientificadvancesdependuponaskingtherightquestions/index.md","# Scientific advances depend upon asking the right questions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7145f4445954462182b7bcc45e16b3d7}
In order for a field to advance, the researchers in that field must be
in a position to ask worthwhile questions and to distinguish between
questions which are worth studying and those which are not. A huge
amount of educational research addresses trivial questions, questions
which practitioners already know the answer to, questions which could
easily be answered by a journalist following a few well placed phone
calls, and questions which can be answered simply by reviewing the
results of previous research. For example, educational researchers had
demonstrated by the 1960s that effective teaching procedures cannot be
identified by interviewing the students or supervisors of teachers who
have been judged by their peers to be effective teachers (Medley, 1972).
Yet investigations of this type continue to be funded even to the
present day (e.g. Hill & Hawk, 2000).

Why do teacher educators continue to study trivial questions? Labaree
(2004) identifies several reasons: the fact that research into learning
and teaching is a difficult field to work in, the fact that teacher
educators are mostly recruited from the teaching profession, and the
fact that teacher educators typically come to research mid career. In
addition, we are not requiring novice researchers to study and master
the understandings which have already been acquired as a result of
previous research.

**The field of learning and teaching is a difficult field to work in**

The field of educational research, with its many different disciplines,
is a field of very considerable epistemological and social complexity
(Labaree, 2004). Berliner (2002) refers to it as \"the hardest science of
all.\" This means that \"doing good research is difficult, expensive, and
time consuming\" (Landrum & Tankersley, 2004, p. 210).

There are many differences between the research undertaken in faculties
of education and the research undertaken in faculties of science,
medicine, engineering and so on. One of the characteristics of the
established sciences is that, at any particular stage in the development
of the science everyone is focused on solving problems at the same level
(Becher, 1989). This is not the case in education where research is
forever starting again at ground level. \"Researchers cannot build ... on
the foundations laid by others because these foundations are always
being reconstructed. As a result, research work is spread thinly over a
wide area, as individuals and groups continually work at rethinking the
most basic issues in the field and as they each pursue their own
interpretive approaches\" (Labaree, 2004, p. 71).

One of the characteristics of the established sciences is that they have
developed a set of established research procedures of known reliability
and there is a consensus across the discipline that these are the
methods which should be used (Kuhn, 1970). This is not the case in
education where the methods used by teacher educators are almost
universally pre-scientific and there is no agreement regarding how even
key elements of the subject matter (learning and teaching) should be
categorised, quantified, measured or analysed (Church, 1997, 1998).

One of the characteristics of the established sciences is that the
results of research are cumulative. This is not the case in education
where researchers are forever reinventing the wheel and then critiquing
it until it is no longer fashionable. Nowhere is this more obvious than
in the so called \"qualitative\" inquiry of the past 30 years -- a huge
research effort which has produced not a single textbook of new
understandings with respect to how children learn or how they might best
be taught.

One of the characteristics of the established sciences, is that it takes
a long time to train and induct new researchers because there is so much
to learn not only about the methods of research but also about what has
been discovered already. This is not the case in education where, in
general, novices are inducted quickly because the field is wide open,
all issues are open for investigation and almost any method of inquiry
has its devotees. Researchers feel free to charge off in all directions
without worrying about the stage of development reached by previous
investigators. \"They constantly re-examine old questions and reconstruct
existing theories\" (Labaree, 2004, p. 71).

**Teacher educators are recruited from the ranks of the teaching
profession**

In New Zealand, as in other Western countries, the great majority of
teacher educators are recruited from schools and not from graduate
schools (Labaree, 2004). However, pre-service teacher education
programmes typically involve little contact with research. In addition,
most classroom teachers view research as a matter of only peripheral
importance as far as teaching is concerned (Floden, 2006). This view is
reinforced in many ways: not only by the absence of scientific research
in our teacher education programmes, by also by the pretentiousness and
poor quality of much educational research and by the fact that much, if
not most, educational research fails to address the questions about
learning, teaching, and behaviour management which are central to the
role of the classroom teacher. What this means is that teachers who take
up positions as teacher educators are often ill-equipped for the
research which is expected of them in a university environment and even
less well equipped to teach others the question asking and
methodological skills necessary for worthwhile research.

An examination of the careers of educational researchers who have chosen
a scientific approach to the study of learning and teaching indicates
that preparing for such a career requires 5 to 6 years of carefully
chosen preparation. This is because it takes several years to master
essential research skills such as the ability to design reliable
measures of learning and achievement, the ability to design experimental
measures of the effects of teaching variables on learning in individual
children, the ability to design epidemiological studies and the ability
to design randomised groups evaluations of teaching programmes. It also
takes more than a year to master the basic statistical techniques which
are involved in interpreting the results of epidemiological studies and
randomised groups evaluations. In addition it takes several years to
acquire an understanding of the knowledge base (e.g. of the research on
learning, or the research on teaching) sufficient to enable one to
distinguish between research questions which are and are not worthwhile.
And it takes at least three years to complete practical requirements,
that is, the masters and doctoral level research projects which provide
access to university level teaching positions.

*However, most teacher educators come to research mid-career.* Because
there is little or no training in or exposure to research during the
teacher's first degree studies, the teacher educator's first exposure to
research typically occurs at the masters level. Unlike first degree
studies, masters level studies are typically undertaken part time while
continuing to work. This means that there is little time for lengthy
reflection, for following up on interesting ideas and research leads, or
for catching up on the academic study which was impossible during the
first degree studies.

All too often the masters level study is seen simply as a means to
promotion and not as the programme of study in which research skills
will be acquired and practised, methodological debates dissected and
analysed, and a field of research selected for one's research career.
\"The vast majority of postgraduate students are part-time and full-time
in their professional commitments. This means that their undertaking
research courses as part of their obtaining a higher degree provides
them with a modicum of research capability and the ability to critique
research rather than a substantive research competency\" (Findsen, 2001,
p. 7). In fact the majority of masters degrees undertaken by New Zealand
teachers until very recently contained no supervised research component
at all. A majority of the students who have completed the UC MEd and the
CCE MTchLn degrees during the past decade have done so without
completing a research thesis.

The PhD studies completed by teacher educators are often completed under
similar conditions (Labaree, 2004; Middleton, 2001). Teacher educators
who elect to study for a PhD tend to do so mid career and part time
while continuing to work. \"The reason for education as a subject doing
poorly in the PBRF rankings was that most staff were in their second or
third careers. People often started their academic careers at 34, or 40,
and sometimes later\" (Nixon, 2004). Many teacher educators come to PhD
studies with little or no undergraduate preparation in research and, in
many cases, minimal masters level preparation in research. Because PhD
study is being undertaken while continuing to work there simply is not
time to do the background reading necessary to bring oneself up to date
with respect to previous research in the field. At the same time, the
new academic's lack of prior research training and experience severely
limits their ability to distinguish between worthwhile and trivial lines
of inquiry or to catch up on missing methods skills and methodological
knowledge (Eisenhart & DeHaan, 2005; Labaree, 2004).

This means that the new teacher education lecturer is almost always
ill-prepared for a research career -- especially when compared to
recently graduated PhDs in engineering, medicine, law, clinical
psychology, and so on. While members of the science departments start
their research careers as soon as they are qualified, members of
education departments, by and large, start their research careers only
after a number of years in the classroom.

Teacher educators who are moving from the classroom to a career which
includes research face significant sources of cognitive conflict.
Several of these sources of conflict have been described by Labaree
(2003, 2004). One of the features of advanced research training is
instruction in learning how to be critical, how to identify and question
underlying assumptions and cultural beliefs, and how to examine the
effectiveness of even well established practices. Teachers who enter
doctoral programmes often misinterpret the critical approach to teaching
as an attack on their role, their practice, and their core beliefs. Some
try to handle this cognitive conflict by avoiding engagement with this
part of their training with the result that they fail to acquire the
critical attitude which is an essential prerequisite for a successful
research career. Others attempt to handle this cognitive conflict by
redefining research to include low level descriptive and interpretive
accounts of the teaching and professional development activities in
which they are already engaged. This kind of activity is easy to spot.
It is variously referred to as \"teacher research\", \"action research\", or
\"practitioner research\" (Darling-Hammond, Hammerness, Grossman, Rust &
Shulman, 2005).

**Is the awful reputation of educational research justified?**

While educational researchers cherish the freedom to study anything they
want using whatever methods they feel like, this has a very serious
downside. It means that much educational research has studied trivial
questions and has, has a result, generated trivial knowledge; much
educational research has used weak research designs and has, as a
result, generated ungeneralisable knowledge, and much research has been
driven by sloppy thinking and has, as a result, generated knowledge with
no explanatory power and hence no enduring qualities.

Because teacher educators have frequently pursued trivial questions
using pre-scientific research methods they have largely failed to
advance our understanding of the conditions under which different kinds
of learning occur. This knowledge has been collected by researchers
working in schools of psychology and in the academic sections (not the
teacher education sections) of schools of education. Teacher educators
have also failed to collect reliable data on the relative effectiveness
and efficiency of different ways of teaching different kinds of skills
and understandings, or to discover effective ways of teaching children
with different kinds of special teaching needs, or to identify those
practices which will ensure that all children master the skills and
understandings specified in the national curriculum.

Given the central role which teacher educators have to play in these
areas, this avoidance behaviour amounts to a very serious waste of time
and effort. This has not gone unnoticed by those both inside and outside
the profession (e.g. Carnine, 2000; Chall, 2002; Greenwood, 2001;
Grossen, 1996; Nuthall, 2001; Meyer, 2002; Ravitch, 1998; Walsh, 2006).
\"Until we do longitudinal research on which approaches do in fact result
in raising student achievement and reducing disparities, we are simply
engaging in superstitious behaviour\" (Meyer, 2002).
:::

::: referencesList
#### References

-   Becher, T. (1989). Academic tribes and territories: Intellectual
    inquiry and the cultures of the disciplines. Bristol: Open
    University Press.
-   Berliner, D. C. (2002). Educational research: The hardest science of
    all. Educational Researcher, 31(8), 18-21.
-   Carnine, D. (2000). Why education experts resist effective practices
    (And what it would take to make education more like medicine).
    Retrieved 10 December, 2000, from
    http://www.edexcellence.net/library/carnine.html
-   Chall, J. S. (2002). The academic achievement challenge: What really
    works in the classroom? New York, NY: Guilford Press.
-   Church, R. J. (1997). Qualitative vs. quantitative: How useful is
    the distinction? Paper presented to the Annual Conference of
    the N. Z. Association for Research in Education, Auckland.
-   Church, R. J. (1998). The utility of qualitative, social science,
    and behaviour analysis research into learning and teaching. Paper
    presented to the annual conference of the N. Z. Association for
    Research in Education, Dunedin, New Zealand.
-   Darling-Hammond, L., Hammerness, K., Grossman, P., Rust F., &
    Shulman, L. (2005). The design of teacher education programmes.
    In L. Darling-Hammond & J. Bransford (Eds.), Preparing teachers for
    a changing world: What teachers should learn and be able to do. (pp.
    390-441). San Francisco, CA: Jossey-Bass.
-   Eisenhart, M., & DeHaan, R. L. (2005). Doctoral preparation of
    scientifically based education researchers. Educational Researcher,
    34, 3-13.
-   Findsen, B. (2001). Mapping the building of capacity and capability
    within the educational research community. Report to the Ministry of
    Education. Wellington, N.Z.: Ministry of Education.
-   Floden, R. E. (2006). What knowledge users want. In C. F. Conrad
    & R. C. Serlin (Eds.), The Sage handbook for research in education:
    Engaging ideas and enriching inquiry (pp. 23-35). Thousand Oaks, CA:
    Sage Publications.
-   Greenwood, C. R. (2001). Science and students with learning and
    behavioral problems. Behavioral Disorders, 27, 37-52.
-   Grossen, B. (1996). What does it mean to be a research-based
    profession? University of Oregon. Retrieved 15 January, 2001 from
    http://www.uoregon.edu/\~bgrossen/ resprf.htm
-   Hill, J., & Hawk, K. (2000). Making a difference in the classroom:
    Effective teaching practice in low decile, multicultural schools.
    Report prepared for the Ministry of Education and the AIMHI Forum.
    Massey University: Institute for Professional Development and
    Educational Research.
-   Kuhn, T. S. (1970). The structure of scientific revolutions. (2nd
    ed.). Chicago: University of Chicago press.
-   Labaree, D. F. (2003). The peculiar problems of preparing
    educational researchers. Educational Researcher, 32(4), 13-22.
-   Labaree, D. F. (2004). The trouble with ed schools. New Haven: Yale
    University Press.
-   Landrum, T. J. & Tankersley, M. (2004). Science in the schoolhouse:
    An uninvited guest. Journal of Learning Disabilities, 37, 207-212.
-   Medley, D. M. (1972). Early history of research on teacher behavior.
    International Review of Education, 18, 430-439.
-   Meyer, L. (2002). Achieving a knowledge society by walking the talk.
    Education Review, February 27-March 5, 2002, p. 12.
-   Middleton, S. (2001). Educating Researchers: New Zealand Education
    PhDs 1948-1998. State-of-the-Art Monograph No. 7. New Zealand
    Association for Research in Education.
-   Nixon, M. (2004). Highs and lows for education research. Education
    Review, April 28-May 4, p. 13.
-   Nuthall, G. A. (2001, December). Cultural myths and the realities of
    teaching. Paper presented to the annual conference of the N.Z.
    Association for Research in Education, Christchurch.
-   Ravitch, D. (1998). What if research really mattered? Retrieved 17
    December, 2001 from
    http://www.edexcellence.net/library/research.html.
-   Walsh, K. (2006). Teacher education: Coming up empty. Fwd:, 3(1),
    Retrieved 17 July 2006 from
    http://www.edexcellence.net/institute/publication/publication.cfm?id=353
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Recognisingtheconstraininginfluenceofteachersbeliefs/index.md","# Recognising the constraining influence of teachers' beliefs \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-49833d4ee78e4bc59d54d3f188bfe42e}
In order to introduce elements of evidence-based practice into the
classroom, the classroom teacher must first come to believe that
research has something to offer. Outside those teaching in special
education, it would be true to say that few classroom teachers believe
that the scientific research into learning and teaching has anything
much to say about the way in which children might be most effectively
taught. Some teachers simply have no contact with the scientific
research into learning and teaching so they have no knowledge of more
effective ways of teaching the children in their classrooms. Some
teachers and teaching researchers believe that scientific research into
learning and teaching is simply not possible. Some believe that the
research to date is largely irrelevant to classroom teaching. Even when
teachers discover interesting research findings, these findings may be
rejected because they are contrary to a belief which is widely shared
within the teaching profession.

*Lack of contact with the scientific research on learning and teaching*

Teachers read few if any books or journals on research and developments
in education (Wheldall, 2005) and surveys of school teachers' and school
principals' knowledge of research findings indicate that their knowledge
of advances in research-based knowledge is relatively limited (Biddle &
Saha, 2002). This is hardly surprising given that pre-service education
to date has been primarily craft based rather than research based.
However it does pose a very substantial impediment to any transition to
evidence-based practice. While it is conceivable that evidence-based
practices could be introduced into the classroom by including them in
pre-service programmes, this is unlikely to happen as long as teacher
educators are recruited from the ranks of practising teachers who
themselves have had almost no contact with the empirical research into
learning and teaching.

*The belief that scientific research into learning and teaching is
impossible*

A significant number of teaching researchers continue to argue that
scientific research into learning and teaching is simply not possible.
\"The interpretive-idealist approach to research rejects the possibility
that laws will ever be found\" (Smith, 1983, p. 12). This position is
often justified by arguing that teaching is too complex to study in a
scientific manner. \"Human relationships are caught up in such an
interacting web of factors, events, and processes that the hope that
'the' cause-effect chain can be sorted out is vain\" (Guba & Lincoln,
1997, p. 87). If cause and effect relations cannot be identified then it
follows that prediction is not possible. In other words it follows that
it will not ever be possible to design any kind of instructional
programme which will have a predictable effect.

The interpretive research methodology is fairly widely taught in schools
of education so a significant minority of teachers have come to believe
that scientific research into classroom practice is not possible.
Teachers who believe that scientific research is not possible are not
likely to go looking for such research and, hence, are unlikely to
discover the existence of the considerable body of scientific research
which is directly relevant to classroom practice and unlikely to
discover that there are teaching procedures and programmes which have
highly predictable effects across particular populations of children.

Interestingly, this belief cannot account for the fact that classroom
practice has remained largely unchanged for the better part of a
century. Interpretive research did not become popular amongst teacher
educators until the mid 1970s and did not begin to be incorporated into
teacher education programmes until the 1990s so this development cannot
be used to explain why teacher educators have shown little or no
interest in scientific research into learning and teaching for most of
the preceding century.

What the existence of this belief does do is to remind us that it will
not be possible to improve classroom practice simply by disseminating
the results of scientific research to teachers and teacher educators.
The beliefs and the teaching practice of a teacher who believes that the
scientific study of teaching is not possible are not going to be changed
by drawing that teacher's attention to the results of scientific studies
of teaching (Sykes, 1999).

*The belief that research into learning and teaching is largely
irrelevant to classroom practice*

A significant proportion of teachers and teacher educators believe that
educational research is largely irrelevant to classroom teaching. Many
teachers \"view research knowledge as irrelevant, contradictory,
inaccurate, and too far removed from the classroom\" (Malouf & Schiller,
1995, p. 417). It is not difficult to work out the reason for this
scepticism. An unselected reading of the research into teaching appears
to most people (including teachers) as a disorganised mess of
pseudo-scientific writing about investigations in which almost
everything is contested -- how learning should be measured, what counts
as an appropriate research method, the methodological assumptions which
should be made, how results should be interpreted, and even the results
themselves (Richardson, 2002).

Should teachers take into account children's learning styles, for
example, or is \"learning styles\" a useless construct which is unrelated
to anything? Can learning and teaching be studied using self-reports
(rather than direct observation) or are such efforts doomed to failure
because human beings are unable to accurately recall the hundreds of
separate learning interactions that are involved in the acquisition of
even a single new competency? Is it appropriate to average test scores
over a number of learners or is this kind of research doomed to failure
because learning involves a transition and a single test catches some
learners prior to this transition, some learners during the transition,
and some learners after they have already made the transition? If
professional researchers cannot sort out these disagreements then
teachers certainly should not be expected to (Landrum & Tankersley,
2004).

To illustrate the current situation in educational research, Diane
Ravitch (1998) imagines what would have happened if the doctors who
attended to her following her admission for a pulmonary embolism had
been replaced by educators.

The physicians who hovered over me dissolved, replaced in my mind's eye
by an equal number of education experts. ... my new specialists began to
argue over whether anything was actually wrong with me. A few thought
that I had a problem, but others scoffed and said that such an analysis
was tantamount to \"blaming the victim.\" Some challenged the concept of
\"illness\" claiming that it was a social construction ... Others rejected
the evidence of the tests used to diagnose my ailment ... Among the
raucous crowd of education experts, there was no agreement, no common
set of standards for diagnosing my problem. They could not agree on what
was wrong with me, perhaps because they did not agree on standards for
good health.

Education researchers have been arguing amongst themselves with respect
to how learning should be measured and how the effects of teaching
should be evaluated for more than 80 years. Given that teaching
researchers (across the various disciplines) have developed no agreed
procedure for measuring the effects of teaching on learning it is hardly
surprising that huge tracts of the research on teaching are
uninterpretable, ungeneralisable, and even incomprehensible. And it is
hardly surprising that teachers who come into contact with this
amorphous, disorganised and unsorted research literature are left with
the impression that it has nothing useful to say about the conduct of
their work as teachers.

Until the research on teaching is stripped back to reveal the empirical
studies which have used valid and reliable measures of student learning
and valid and reliable measures of the effects of teaching on learning
(Church, 1992a, 1992b), the knowledge contained in this research will
remain hidden beneath the mountain of pre-scientific research.

One of the purposes of this website is to reveal to teachers, teacher
educators, and teaching researchers that there is far more scientific
research into the conditions necessary for learning and far more
controlled research into the relative effectiveness of different
teaching practices and procedures than they are aware of. Not only is
this research developing rapidly but it also speaks directly to many of
the problems which teachers face from day to day -- problems which could
be solved by a move towards evidence-based practice.
:::

::: referencesList
#### References

-   Biddle, B. J., & Saha, L. J. (2002). The untested accusation:
    Principals, research knowledge, and policy making in schools.
    Westport, CT: Ablex Publishing.
-   Church, R.J. (November, 1992a). Measuring learning. Paper presented
    to the Second Joint AARE/NZARE Conference, Geelong, Australia.
-   Church, R.J. (November, 1992b). Measuring the effects of teaching on
    learning. Paper presented to the Second Joint AARE/NZARE Conference,
    Geelong, Australia.
-   Guba, E. G., & Lincoln, Y. S. (1997). Naturalistic and rationalistic
    enquiry. In J. P. Keeves (Ed.), Educational research, methodology,
    and measurement: An international handbook (2nd ed., pp. 86-90).
    Oxford: Pergamon/Elsevier Science Inc.
-   Landrum, T. J. & Tankersley, M. (2004). Science in the schoolhouse:
    An uninvited guest. Journal of Learning Disabilities, 37, 207-212.
-   Malouf, D. B., & Schiller, E. P. (1995). Practice and research in
    special education. Exceptional Children, 61, 414-424.
-   Ravitch, D. (1998). What if research really mattered? Education
    Week. Retrieved 3 November, 2000, from
    http://www.edexcellence.net/library/research/html
-   Richardson, V. (2002, April). Finding a center for research on
    teaching. Vice-Presidential address to the American Educational
    Research Association Division K, New Orleans, LA.
-   Smith, J. K. (1983). Quantitative vs. qualitative research: An
    attempt to clarify the issue. Educational Researcher, 15(1), 4-12.
-   Sykes, G. (1999). Teacher and student learning: Strengthening their
    connection. In L. Darling-Hammond & G. Sykes (Eds.), Teaching as the
    learning profession. (pp. 151-179). San Francisco: Jossey Bass.
-   Wheldall, K. (2005). When will we ever learn? Educational
    Psychology, 25, 573-584.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Recognisingtheconstraintsposedbythenatureofclassroomwork/index.md","# Recognising the constraints posed by the nature of classroom work \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4bb28d4fbca342b2bf10cf5966899ba5}
Classroom teaching is a task which looks easy -- because the *content*
of that teaching is something which we have all experienced (Labaree,
2004). It is, however, an enormously complex task. The classroom teacher
spends his or her day trying to keep order and foster learning in 25 to
30 children with a diverse range of background experiences and ability
levels. Learning is likely only if the teacher can keep order and
develop a relationship of trust with each child. This is a task which is
far more complex that that required of a general practitioner who has
only to attend to one patient at a time and who can refer all difficult
problems to a specialist.

Surveys from a number of Western countries have found that teachers on
average work 50 or more hours per week (Alberta Teachers Association,
nd; Livingstone, 1994; Michelson & Harvey, 2000). During term time there
is little or no time for preparation and during the course of the entire
school year half the available time has to be spent in class contact
leaving only one hour per hour of contact for all marking, preparation,
and extra curricular activities. This means that most teaching has to be
done on the run, with little or no preparation. Because there are 25 to
30 children, small group teaching becomes possible only if the teacher
generates enough materials and activities to keep all of the other
children in the class occupied during the small group sessions. Because
classroom teaching has to be carried out continuously with 25 to 30
children simultaneously, the amount of individualisation which is
possible is virtually nil (Brophy, 1983). In other words \"teachers' work
environments are not conducive to the implementation of research
knowledge. Factors such as externally imposed curriculums and materials,
relative isolation, and lack of collegiality, heavy workloads, ambiguity
about goals, and insufficient time and resources combine to limit
teacher incentive and flexibility for learning about or trying
research-based innovations\" (Malouf & Schiller, 1995, p. 417).

Now consider the results of the scientific research on teaching. One of
the things which we have learned from this research is that children
learn more when teachers pay greater attention to detail, when teaching
procedures are changed to match the type of learning outcome which is
being pursued, when the content of instruction is adapted to take into
account individual differences in prior learning, and when progress is
monitored and teaching adapted for the children who are making less than
expected progress (Church, 2004). This is the evidence base.

On the surface this looks as if a move to evidence-based practice would
involve even more work than craft-based practice. So how are teachers to
be motivated to adopt new practices? Many procedures have been
suggested: the introduction of incentive systems, reduced class sizes,
the introduction of accountability systems, the introduction of field
tested teaching materials and so on.

**Motivating change by introducing teaching awards**

One of the suggestions for motivating teachers to engage in more
effective teaching practice is by the introduction of some kind of award
or reward for \"excellence in teaching\". Some of these schemes involve
merit awards, some involve access to professional development leave,
some involve bonus payments and some involve accelerated promotion.

It does not take a great leap of logic to figure out that an award
scheme which rewards only selected teachers cannot result in a general
improvement in teaching practice on the part of all teachers. In order
to motivate change in the classroom teaching practice of all teachers we
would need an award scheme which could be applied to all teachers. Once
the award is one which can be earned by all teachers, it is highly
likely that, over a period of time all teachers would earn it. If the
award scheme involves any kind of financial incentive, we end up
suggesting that all teachers should be eligible for extra pay for doing
what they have been employed to do, that is, to ensure that all of the
children in their care make expected rates of progress in each
curriculum area.

**Motivating change by reducing class sizes**

A second suggestion for improving classroom practice is to reduce class
sizes. The research on class size effects is reasonably extensive and
has been summarised by several research teams (e.g., Hanushek, 1999;
Hattie, 2005; Wößmann & West, 2006). The overall finding from these
studies of class size effects is that the effect of a reduction in class
size on student achievement is very small and that larger effects can be
obtained by providing teachers with well designed professional
development or well designed teaching materials. Hattie argues that the
reason why the effect is so small is because teachers do not change
their behaviour simply because the number of students has been reduced.
\"Teachers teach similarly in classes of 15 as in classes of 30, and the
grammar of schooling does not change (for the teacher or student). We
therefore should not be surprised to find that teachers teach and
students learn similarly regardless of class size\" (Hattie, 2005, p.
407). As might be expected, class size effects tend to be larger in
countries where teachers are poorly trained and in schools with higher
levels of diversity in student ability. Reducing class size is also a
very expensive policy to implement -- much more expensive than improving
the quality of the teaching materials available to teachers.

**Motivating change by introducing accountability systems**

It has been widely argued by certain political groupings that we can
motivate teachers to adopt teaching practices which are more effective
in raising achievement levels by introducing standards which children
are required to meet and by holding teachers accountable for ensuring
that every child meets these standards. A National Standards requirement
for all primary school children was introduced in New Zealand in 2010
with schools being required to report the numbers of children above, at,
or below the national standard at each age level in reading, writing,
and mathematics.

Similar systems were introduced in the UK and in a number of US states
during the 1990s so the likely effect of the New Zealand system can be
predicted from the effects observed in the UK and the US.

In the UK, effects differed from those expected. It is certainly the
case that the introduction of a national testing scheme resulted in
annual increases in test scores across England. However, research
suggests that these increases probably reflect nothing more than
increased time spent preparing for the tests. \"What is most likely to
have led to increases in scores, is practising for the tests. All
international research evidence . . . suggests that this is what happens
when 'high stakes' tests are encountered in educational systems; i.e.
when teachers and students are faced with tests which carry significant
consequences for student life chances and teacher accountability, very
significant time and energy will be devoted to test preparation\"
(Torrance, 2002, p. 8).

Torrance presents further evidence to suggest that the national testing
system in the UK has resulted in a narrowing of the primary school
curriculum with a noticeable increase in the time spent on core subjects
(McNess, Triggs, Broadfoot, Osborn & Pollard, 2001). It has also
resulted in a noticeable increase in primary school exclusions, and an
increased turnover in primary school teachers as a result of \"overwork,
linked to the pressure to meet targets, along with relatively low pay
for an all-graduate profession \[and\] . . . lack of control over
curriculum and teaching methods\" (Torrance, 2002, p. 10).

Similar findings have been reported by American researchers (e.g., Linn,
2000). Conclusions regarding the adverse effects of high stakes testing
have been strengthened by a review of 49 qualitative studies of the
effects of such testing (Au, 2007). The most commonly reported effects
were a narrowing of curricular content to those subjects included in the
tests and the move by teachers to more lecture-based, teacher-centered
teaching procedures. Given the research to date it is clear that the
introduction of so-called accountability systems does not result in the
introduction of evidence-based practice but rather results in extensive
coaching for the tests, a narrowing of the curriculum, and increased
teacher turnover.

**Motivating change with well designed and effective instructional
materials and activities**

Clearly there cannot be a move to evidence-based teaching if that move
involves overworked classroom teachers in even more work than is
currently the case. Rather than trying to design an incentive which
involves additional pay for additional work on the part of large numbers
of teachers, we need to think in terms of an incentive in which the
reward is *less work*, not more work, for most teachers.

The simplest way of making teaching practice *less* difficult and *less*
effortful for those teachers who adopt evidence-based practices is to
develop field-tested and demonstrably effective teaching materials and
lesson activities for a significant proportion of important curriculum
objectives and to make these readily available to classroom teachers.
This is entirely feasible because we are already doing this for a
limited number of curriculum areas such as reading and science. The only
difference is that the materials which are currently being developed for
teachers have never been evaluated and their effectiveness is unknown.

The provision of teaching materials of known effectiveness to large
numbers of teachers has three advantages.

First, teachers tend to adopt with a certain degree of enthusiasm any
kind of instructional materials which simplify the classroom teaching
task. The availability of an instructional programme or instructional
materials of known effectiveness is likely, therefore, to result in its
adoption by large numbers of teachers.

Secondly, with materials development the teaching package can be
trialled and revised until it meets an agreed standard of effectiveness
-- as was done with the Headsprout reading programme (Twyman, Layng,
Stikeleather & Hobbins, 2005). Not only does this kind of scientific
curriculum development result in increased levels of achievement for all
students in the target group, it also greatly reduces the implementation
time and greatly reduces the professional development costs of
introducing the new practice into all schools.

Thirdly, it is possible to develop field tested teaching materials which
not only teach new skills and understanding to students but which also
teach new skills and understandings to teachers. Davis and Krajcik
(2005) refer to teaching resources of this type as *educative curriculum
materials* and have outlined some of the important characteristics of
such materials.

The cost of developing a sets of instructional materials which are
effective in bringing about a particular learning outcome in most
students and making these freely available to all schools is a
relatively inexpensive change management procedure -- far less expensive
than trying to bring about the same level of change through some kind of
nationwide professional development programme. One of the aims in Book 6
of this website will be to identify teaching programmes which have been
developed, field tested, revised and evaluated to a degree which allows
us to predict their effectiveness in bringing about particular learning
outcomes in particular groups of students.

The major impediment to this solution is that there are very few people
world wide who have advanced training in the scientific design and
scientific evaluation of effective teaching programmes and even fewer
with qualifications and experience in designing educative curriculum
materials. Filling this gap will require the Ministry of Education to
buy in the necessary expertise and to invest in the necessary
infrastructure. One of the ways of accomplishing this -- by recruiting
and training teacher educators to engage in materials development
research and evaluation -- is described below.
:::

::: referencesList
#### References

-   Alberta Teachers' Association. (nd). Alberta teachers: A workload
    study. Retrieved 29 May, 2007 from
    http://teachers.ab.ca/Quick+Links/Publications/Other+Publications/Alberta+Teachers+A+Workload+Study
-   Au, W. (2007). High stakes testing and curricular control: A
    qualitative metasynthesis. Educational Researcher, 3, 258-267.
-   Brophy, J. E. (1983). If only it were true: A response to Greer.
    Educational Researcher, 12(1), 10-12.
-   Church, R. J. (2004). Critical teaching variables which govern rate
    of learning. Course reader: Introduction to interventions.
    Christchurch, New Zealand: University of Canterbury, School of
    Education.
-   Davis, E. A., & Krajcik, J. S. (2005). Designing educative
    curriculum materials to promote teacher learning. Educational
    Researcher, 34(3), 3-14.
-   Hanushek, E. A. (1999). Some findings from an independent
    investigation of the Tennessee STAR Experiment and from other
    investigations of class size effects. Educational Evaluation and
    Policy Analysis, 21, 143-163.
-   Hattie, J. (2005), The paradox of reducing class size and improving
    learning outcomes. International Journal of Educational Research,
    43, 387-425.
-   Labaree, D. F. (2004). The trouble with ed schools. New Haven: Yale
    University Press.
-   Linn, R. (2000). Assessments and accountability. Educational
    Researcher, 29, 4-16.
-   Livingstone, I. D. (1994). The workloads of primary school teachers:
    A Wellington region survey. Wellington, N.Z.: Chartwell Consultants.
-   Malouf, D. B., & Schiller, E. P. (1995). Practice and research in
    special education. Exceptional Children, 61, 414-424.
-   McNess, E., Triggs, P., Broadfoot, P., Osborn, M. & Pollard, A.
    (2001). The changing nature of assessment in English primary
    classrooms. Education, 29(3), 9-16
-   Michelson, W. & Harvey, A. S. (2000). Is teachers' work never done?:
    Time-use and subjective outcomes. Radical Pedagogy, 2. Retrieved 10
    April, 2005 from
    http://radicalpedagogy.icaap.org/content/issue2_1/02Michelson.html.
-   Torrance, H. (2002) Can testing really raise educational standards?
    Professorial lecture delivered to the University of Sussex.
    Retrieved 3 July, 2007 from
    www.esri.mmu.ac.uk/respapers/papers-pdf/Professorial%20Lecture.pdf
-   Torrance, H. (1997). Assessment, accountability and standards: Using
    assessment to control the reform of schooling. In A. H. Halsey et
    al. (Eds.), Education: Culture, economy and society. Oxford: Oxford
    University Press.
-   Twyman, J. S., Layng, T. V. J., Stikeleather, G., & Hobbins, K. A.
    (2005). A nonlinear approach to curriculum design: The role of
    behavior analysis in building an effective reading program. In W. L.
    Heward, T. E. Heron, N. A. Neef, S. M. Peterson, D. M. Sainato, G.
    Cartledge et al. (Eds.), Focus on behavior analysis in education:
    Achievements, challenges and opportunities (pp. 55-68). Upper Saddle
    River, NJ: Pearson Education.
-   Wößmann, L. & West, M. (2006). Class-size effects in school systems
    around the world: Evidence from between-grade variation in TIMSS.
    European Economic Review, 50, 695-736.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/index.md","# The transition from craft to science \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-756f5f9193d344e996ef22d136545358}
Discovering that there is a very considerable tradition of scientific
research in child development, in basic learning processes, and in the
relative effectiveness of many commonly used teaching procedures does
not mean that the transition from craft to science in teaching practice
has begun or will now begin. The change from craft to science in medical
practice required the presence of a number of social conditions and took
the better part of 70 years. [A similar transition]{.external-link} in
teaching practice is likely to take a similar amount of time and is
unlikely to occur until certain conditions are met. Some of the
conditions which appear to be necessary for a transition from craft to
scientific practice in classroom teaching include the following.

-   A more detailed knowledge by teachers of the conditions on which
    different types of learning depend.
-   A more detailed understanding by both teachers and researchers of
    the complexities of classroom practice.
-   A greater understanding of teachers' beliefs about teaching and the
    way in which these beliefs constrain the changes which are possible.
-   A more widespread recognition of the nature of teachers' work and
    the way in which this limits the kinds of changes which are
    possible.
-   A greater recognition of the fact that teacher education has the
    potential to improve teaching practice.
-   Recognition of the fact that a move to evidence based practice will
    require a very much greater research effort than is currently
    occurring.
-   Recognition of the fact that progress will depend upon research of a
    much higher quality that that which is currently being undertaken.

In this section we examine each of these conditions and the likelihood
that they will occur in the New Zealand setting.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Recognisingtheresearchpotentialofteachereducation/index.md","# Recognising the research potential of teacher education \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0c5901b134d04089bc37d2b986bdc416}
University of Canterbury, Christchurch, New Zealand. © University of
Canterbury 2008.

The primary function of teacher education at the present time is
cultural transmission, that is, ensuring that the classroom practices of
the current generation of teachers and their beliefs about teaching are
passed on to the next generation of teachers. We know that this is so
when we compare transcripts of classroom lessons which were recorded in
the early 1960s and find that they are identical in format and content
to classroom lessons recorded 40 years later (Nuthall, 2007). We know
that this is so when we compare the teaching and classroom management
skills of teachers who graduated 20 years ago and find that they are
identical to those observed 20 years later (Shearer, 1999).

Nor should we be surprised by this observation. Classroom practice is
initially learned during the 13,000 hours of observational learning
which occur during 12 years of schooling. The teaching behaviours and
beliefs about teaching which are acquired during this initial 13,000
hours of classroom observation are well established prior to entry to
any teacher education programme and, in most cases, are little changed
by that programme (Meier, 1992; Kennedy, 1991; Richardson & Placier,
2002).

Secondly, new teachers quickly develop the decision making skills,
management skills, and teaching skills which are needed for survival as
a classroom teacher. Because these decision making skills, management
skills and teaching skills are used dozens of time every day they
quickly become automatic and, because they are highly automaticised,
they quickly become extremely resistant to change.

Thirdly, classroom teaching occurs in a culture, the culture of the
school. Cultures operate to maintain consistency and continuity. A new
teacher who tries to introduce some radical new classroom practice may
find it hard to continue behaving differently in the face of unconcealed
disapproval from colleagues and supervisors.

For these reasons and others, changes to teaching practice are difficult
to achieve and even when achieved are difficult to maintain (Evertson &
Randolf, 1989). Simply telling teachers about the results of research or
about new and more effective practices does not result in changes in
practice (Henderson, 1982; Sykes, 1999; Timperley, Wilson, Barrar &
Fung, 2007). Teachers are not required to demonstrate their ability to
produce learning in a range of different types of learners in order to
register as a teacher or to remain registered (Stone, 2002). Because no
child ever dies as a result of ineffective teaching, there is no ethical
imperative to change.

Evidence-based practice, in contrast, is not just about cultural
transmission. It is also about improvement. It opens up the possibility
that teacher educators might begin to engage in research which results
in the invention of new kinds of classroom practice -- practices which
result in increasing numbers of children leaving school with the skills
which they require for a productive life in the 21st century.

If such improvement is to occur, teacher educators will have a pivotal
role to play in bringing this about.

At the moment much of the content of teacher education courses is
justified by reference to notions with little or no research base --
notions such learning styles, developmentally appropriate practice,
constructivism, discovery learning, the classroom as a learning
community, and so on. If there is to be a move to evidence based
practice, then teacher educators will need to look more closely at what
they are teaching and begin the task of progressively introducing, into
their courses, those theories and practices which have the strongest
research support (Grosson, 1996; Kozloff, 2003; Stone, 2002). Now that
teacher education programmes in New Zealand have all been moved into
universities this task can proceed quite rapidly. This is because the
intellectual and scientific resources of a university are so much
greater than the resources of a stand-alone college of education.

At the moment much of the research undertaken by teacher educators
involves the seemingly endless description of current practices and
beliefs using small scale, qualitative methodologies (Richardson, 2002).
If there is to be a move to evidence-based practice then significant
numbers of teacher educators will need to begin the move into research
and development activities, instructional design work, and the
development of educative curriculum materials and this movement will
need to continue until we have created a critical mass of teacher
educators who are working on scientifically oriented R & D activities
(Burkhardt & Schoenfeld, 2003; Davis & Krajcik, 2005; Layng,
Stikeleather & Twyman, 2004; Slavin, 2005). Undertaken within the
context of teacher education programmes, the scientific development and
evaluation tasks can proceed quite rapidly. This is because the
evaluation of short units of work can be undertaken by building these
into the professional practice requirements of entire cohorts of several
hundred teacher education students on an annual basis.

In addition to the scientific development of effective teaching
materials, activities and programmes, other types of scientifically
oriented research work will also be required -- scientific
investigations into how best to meet the learning needs of different
groups of learners at each age level, the development of reliable
procedures for monitoring the learning of individual students in the
classroom, the scientific evaluation of current teaching and behaviour
management procedures, and the development of materials and practices
which produce improved rates of progress in children with different
types of special teaching needs (Raudenbush, 2005).

We will know that the move towards evidence-based practice has begun
when we see substantial numbers of teacher educators engaged in these
kinds of research activities, when we see the results of these research
activities integrated into our teacher education courses and when we see
the graduates of those programmes continuing to use these research based
materials and procedures in their classrooms in the years following
their registration as teachers.
:::

::: referencesList
#### References

-   Burkhardt, H., & Schoenfeld, A. H. (2003). Improving educational
    research: Toward a more useful, more influential, and better-funded
    enterprise. Educational Researcher, 32(9), 3-14.
-   Davis, E. A., & Krajcik, J. S. (2005). Designing educative
    curriculum materials to promote teacher learning. Educational
    Researcher, 34(3), 3-14.
-   Evertson, C. M., & Randolf, C. H. (1989). Teaching practices and
    class size: A new look at an old issue. Peabody Journal of
    Education, 67, 85-105.
-   Grossen, B. (1996) What does it mean to be a research-based
    profession? Retrieved 10 April, 2005 from
    http://darkwing.uoregon.edu/\~bgrossen/pubs/resprf.htm#Science.
-   Henderson, A. (1982). Evaluation of an extension studies course in
    classroom management. M.Ed. research project report. Christchurch,
    New Zealand: University of Canterbury Education Department.
-   Kennedy, M. (1991). An agenda for research on teacher learning.
    NCRTL Special Report, Michigan State University: National Center for
    Research on Teaching Learning.
-   Kozloff, M. (2003). Establishment ideas and the anti-establishment
    critique. Retrieved 4 April, 2005 from
    http://people.uncw.edu/kozloffm/edwar.htm.
-   Layng, T. V. J., Stikeleather, G., & Twyman, J. S. (2004).
    Scientific formative evaluation: The role of individual learners in
    generating and predicting successful educational outcomes. Retrieved
    15 July, 2007 from
    http://headsprout.com/home/research_publications.cfm
-   Meier, D. (1992). Reinventing teaching. Teachers College Record. 93,
    56-67.
-   Nuthall, G. (2007). The hidden lives of learners. Wellington, N.Z.:
    NZCER Press.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
-   Richardson, V. (2002, April). Finding a center for research on
    teaching. Vice-Presidential address to the American Educational
    Research Association Division K, New Orleans, LA.
-   Richardson, V., & Placier, P. (2002). Teacher change. In V.
    Richardson (Ed.), Handbook of research on teaching, 4th ed., pp.
    905-947). Washington, DC: American Educational Research Association.
-   Shearer, P. (1999). Learning to teach: First year teacher\'s
    experiences. M.Ed. dissertation. University of Canterbury: Education
    Department.
-   Slavin, R. E. (2005). Evidence based reform: Advancing the education
    of children at risk. Report prepared for: Renewing our schools,
    securing our future. A national task force on public education.
    Institute for America's Future. Retrieved 15 August, 2007, from
    www.schoolinfosystem.org/archives/Slavin-Evidence-Based Reform.pdf.
-   Stone, J. E. (2002). Teacher training and pedagogical methods.
    Hoover Institution/Pacific Research Institute. Retrieved 6 April,
    2005 from
    http://www-hoover.stanford.edu/publications/books/fulltext/teacher/33.pdf
-   Sykes, G. (1999). Teacher and student learning: Strengthening their
    connection. In L. Darling-Hammond & G. Sykes (Eds.), Teaching as the
    learning profession. (pp. 151-179). San Francisco: Jossey Bass.
-   Timperley, H., Wilson, A., Barrar, H., & Fung, I. (2007). Teacher
    professional learning and development. Best evidence synthesis
    iteration (BES). Wellington, New Zealand: New Zealand Ministry of
    Education.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Understandingofthecomplexitiesofclassroompractice/index.md","# Understanding of the complexities of classroom practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-52544cac8a2e406e9c63dfdfbf8875c9}
University of Canterbury, Christchurch, New Zealand. © University of
Canterbury 2008.

Much of the research into teaching demonstrates a relatively shallow
understanding of the complexities of classroom practice. Although the
aim of teaching is to foster learning, educational journals regularly
publish reports of, and PhDs are regularly awarded for, studies which
purport to be studies of teaching even although no data was ever
collected on the learning which occurred in each of the learners who
were exposed to that teaching.

With experience, many teachers come to recognise that classroom teaching
is an extremely complex activity (Alton-Lee, 2003; Church, 1999; Doyle,
1986; Engelmann & Carnine, 1991; Gersten, Baker, Pugatch, Scanlon &
Chard, 2001; Malouf & Schiller, 1995; Nuthall, 1999, 2007; Rosenshine &
Stevens, 1986; Wolery, Bailey & Sugai, 1987). The classroom teacher must
pursue dozens of teaching aims with dozens of learners simultaneously.
This task is infinitely more complex than the task facing, say, a
surgeon -- who has to work with only one patient at a time and who
always has at least a couple of assistants to help out with the work. We
may picture the complex task of classroom teaching in the manner shown
in Figure 1320.

![Figure 1320. Some of the variables which operate to determine the
effects of classroom teaching and their
interrelationships](../../../../../assets/images/TECKSFig1320.png \"Figure 1320. Some of the variables which operate to determine the effects of classroom teaching and their interrelationships\"){.image-inline}

*Figure 1320. Some of the variables which operate to determine the
effects of classroom teaching and their interrelationships*

In order to engage in effective teaching, the classroom teacher requires
a detailed knowledge of the way learning outcomes are affected by:

-   the school and classroom context,
-   the entering skills of the learner,
-   the developmental appropriateness of the learning activities
    provided,
-   the types of learning interactions which go to make up the learning
    activities,
-   the way in which these learning interactions and learning activities
    are sequenced,
-   the expertise of the agent supplying the guidance and feedback
    during these learning activities,
-   the appropriateness of the teaching and practice activities provided
    given the type of learning outcome aimed for,
-   the way in which student improvement is monitored over time and
-   the way in which the results of this monitoring are used to adapt
    teaching and practice activities for each student from day to day

As teachers become more experienced they gradually become aware of the
way in which these factors interact to determine the learning of
individual children within the classroom. The challenge for teacher
educators is how to hasten the development of this understanding in
prospective teachers and prospective teaching researchers. This
knowledge cannot be acquired by observing teachers at work because the
nature of teachers' work prevents most classroom teachers from attending
to many of these variables for much of the time. The notion that this
understanding can be acquired by watching teachers at work is one of the
enduring myths of teacher education.

We will know that teaching is beginning to move in the direction of
evidence-based practice when both teachers and teaching researchers
begin to abandon simplistic two-variable descriptions of teaching aims
and teaching practice (e.g. \"I have found that following learning
activities can be used to teach *x*\") and begin to operate in their
search for knowledge as if they are working in one small part of a
complex six-dimensional puzzle (e.g., \"Which types of examples sequences
lead to the most accurate generalisations about *x* in 6-7 year old
children with little prior knowledge of *x* in classrooms where none of
the children know much about *x*?\").
:::

::: referencesList
#### References

-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Ministry of Education, N.Z.:
    Medium Term Strategy Policy Division.
-   Brophy, J. (2002). Social constructivist teaching: Affordances and
    constraints. New York: Elsevier.
-   Church, R. J. (1999). Instructional processes. Christchurch, New
    Zealand: University of Canterbury, Department of Education.
-   Doyle, W. (1986). Classroom organization and management. In M. C.
    Wittrock (Ed.), Handbook of research on teaching (3rd ed., pp.
    392-431). New York: MacMillan.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications. Eugene, OR: ADI Press.
-   Gersten, R., Baker, S., Pugatch, M., Scanlon, D., & Chard, D.
    (2001). Contemporary research on special education teaching. In V.
    Richardson (Ed.), Handbook of research on teaching (4th ed., pp.
    695-722). Washington, D. C.: American Educational Research
    Association.
-   Malouf, D. B., & Schiller, E. P. (1995). Practice and research in
    special education. Exceptional Children, 61, 414-424.
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Nuthall, G. (2007). The hidden lives of learners. Wellington, N.Z.:
    NZCER Press.
-   Rosenshine, B., & Stevens, R. (1986). Teaching functions. In M. C.
    Wittrock (Ed.), Handbook of research on teaching (3rd ed., pp.
    376-391). New York: MacMillan.
-   Wolery, M., Bailey, D. B., & Sugai, G. M. (1988). Effective
    teaching: Principles and procedures of applied behavior analysis
    with exceptional students. Boston: Allyn and Bacon Inc.
:::"
".//Theproblemtobesolved/Thetransitionfromcrafttoscience/Increasingteachersunderstandingoflearningprocesses/index.md","# Increasing teachers' understanding of learning processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ae24514050504bac9d43be360cec5372}
A number of surveys have found relatively low levels of knowledge about
learning at all levels of the teaching profession. For example, teachers
often leave teacher education programmes with little knowledge of
learning processes apart from that gleaned from a short course on
\"theories of learning\". These courses tend to treat the various
\"theories of learning\" as if they were all of equal status even although
the research base for some (e.g. constructivism) is virtually
non-existent while the research base for others (e.g. the principles of
behaviour) is very extensive. A recent and highly regarded discussion of
what teachers need to know (Darling-Hammond & Bransford, 2005) includes
an extended chapter on research on learning. This chapter makes almost
no reference to any of the scientific studies of the various learning
outcomes which teachers are expected to bring about or the teaching
conditions upon which these learning outcomes depend.

The widespread lack of knowledge of basic learning processes exists at
all levels of the school system. Judith Aiken, previous head of the
Education Review Office, reported at a conference on research that
\"whenever I am in a school, or meeting principals, deputy principals,
and associate principals, I always make a determined (but polite) effort
to ask about the periodicals and journals to which they and they staff
have access--and actually read. This is usually a very short
conversation\" (Aitken, 1997, p. 83). While the school principals
interviewed by Biddle and Saha (2002) were able to point to many
instances of educational research almost none of the examples which they
referred to were examples of scientific research into learning.

In order to move towards an evidence-based profession, one of the first
conditions to be met will be the development of a greatly improved level
of knowledge and understanding of the different types of learning and
the conditions which are necessary for each (Gersten, Chard & Baker,
2000; Grossen, 1996; Walsh, Glaser & Wilcox, 2006; Yates, 2005).
Teachers will need to learn how to distinguish between different types
of learning processes (e.g., attitude change, motivation, acquisition,
and so on), between the various different types of acquisition processes
(e.g., the acquisition of new behaviours, new procedures, new meanings,
new equivalence relations, new conceptual understandings, new knowledge,
and so on), and between the various phases of learning (i.e.
acquisition, independence, mastery, generalisation, application, and so
on). They will need to acquire the ability to recognise the rather
different conditions which are necessary in order for each of these
types of learning to occur (Church, 1999), and they will need to learn
how these conditions can be met in the environment of the classroom.
*Before preservice teachers can acquire these understandings, they will
first need to be acquired by all teacher education lecturers.*

Acquiring these new understandings will not be easy because they will
often conflict with currently held beliefs -- and knowledge which
conflicts with existing beliefs is difficult to acquire (Nuthall &
Alton-Lee, 1993). For example, many teachers and teacher educators
believe in the superior effectiveness of child-centred, enquiry based
and discovery modes of learning which involve only minimal levels of
practice and believe that motivation can be maintained by the use of
interesting activities (Kozloff, 2003). Many teachers and teacher
educators also believe that if children are busy and engaged then they
must be learning (Nuthall, 2007). Large number of teachers still believe
that a failure to learn is a failure on the part of the student and not
a failure on the part of the teacher.

As we shall see in subsequent sections of this website, not only are
these beliefs *not* supported by scientific research, they run directly
*counter* to the results of research -- which consistently reports that
well structured explanations result in the deepest levels of
understanding (e.g., McCleery & Tindal, 2009), that well structured
guidance and scaffolding result in the most rapid learning of new
procedures and processes (e.g., Klahr & Nigam, 2004), that well
structured practice activities with explicit fluency criteria result in
the strongest long term retention (e.g., Ivarie, 1986), that clear goals
and well structured reinforcement (recognition) for goal achievement
result in the highest levels of motivation and liking for learning
(e.g., Sharpe, 1981), and that differences in the prior learning of
specific skills are the major determinant of differences in achievement
(not differences in ability, intelligence, learning style, SES,
ethnicity or culture) (e.g., Nuthall, 2007; Tunmer, Chapman & Prochnow
2006). Discussion of how to distinguish between accurate and erroneous
beliefs about what counts as effective teaching is a discussion which
will be fostered in the final section (Book 9) of this website.

One of the aims of this website is to identify the core knowledge
regarding how and when learning occurs -- the core knowledge that will
be need to be acquired by teacher educators, teachers, and prospective
teachers before we can begin to make the transition from teaching as a
craft to teaching as an evidence-based profession.

Helping teacher education students to understand and distinguish between
the various learning processes and the conditions upon which they depend
will involve a fairly substantial change to teacher education
programmes. No longer will it be possible to leave this aspect of
teacher preparation in the hands of classroom teachers no matter how
expert they may be with respect to classroom teaching. If classroom
teachers are not familiar with the results of scientific research into
the various learning processes, then they will not be qualified to take
teacher education courses in how children learn. \"We cannot pass on to a
new generation that which we do not ourselves possess\" (Meier, 1992, p
59).

We will know that the transition to evidence-based practice has begun
when we see teacher education programmes hiring specialists in
children's learning to teach the next generation of teachers about the
conditions upon which learning depends. The design of these new courses
in learning will require a collaborative effort involving PhD qualified
lecturers who have specialised in child development, in basic learning
processes, in behaviour analysis, in metacognitive processes, and in the
emerging research into how the brain works. These courses will also need
to be sufficiently extensive to allow time for beliefs to change.
Otherwise the cognitive conflict engendered by the new knowledge will
not result in a change in beliefs about how learning occurs. It will
result in a rejection of the hard won scientific knowledge.
:::

::: referencesList
#### References

-   Aitken, J. (1997). Policy makers' expectations: Education Review
    Office. In New Zealand Council for Educational Research (Ed.),
    Priorities for Educational Research in New Zealand: Conference
    Procedings, 81-85.
-   Biddle, B. J., & Saha, L. J. (2002. The untested accusation:
    Principals, research knowledge, and policy making in schools.
    Westport, CT: Ablex Publishing.
-   Church, R. J. (1999). Instructional Processes. Christchurch, New
    Zealand: University of Canterbury, Education Department.
-   Darling-Hammond, L., & Bransford, J. (Eds.) (2005). Preparing
    teachers for a changing world: What teachers should learn and be
    able to do. San Francisco, CA: Jossey-Bass.
-   Gersten, R. , Chard, D., & Baker, S. (2000). Factors enhancing
    sustained use of research-based instructional practices. Journal of
    Learning Disabilities, 33, 445-457.
-   Grossen, B. (1996) What does it mean to be a research-based
    profession? Retrieved 10 April, 2005 from
    http://darkwing.uoregon.edu/\~bgrossen/pubs/resprf.htm#Science.
-   Ivarie, J. J. (1986). Effects of proficiency rates on later
    performance of a recall and writing behavior. Remedial and Special
    Education, 7(5), 25-30.
-   Johnston, J. M., & Pennypacker, H. S. (1993a). Strategies and
    tactics of behavioral research (2nd ed.). Hillsdale: Lawrence
    Erlbaum Associates.
-   Klahr, D., & Nigam, M. (2004). The equivalence of learning paths in
    early science instruction: Effects of direct instruction and
    discovery learning. Psychological Science, 15, 661-667.
-   Kozloff, M. (2003). Establishment ideas and the anti-establishment
    critique. Retrieved 4 April, 2005 from
    http://people.uncw.edu/kozloffm/edwar.htm.
-   Meier, D. (1992). Reinventing teaching. Teachers College Record, 93,
    596-609.
-   McCleery, J. A., & Tindal, G. A. (1999). Teaching the scientific
    method to at-risk students and students with learning disabilities
    through concept anchoring and explicit instruction. Remedial and
    Special Education, 20, 7-18.
-   Nuthall, G. (2007). The hidden lives of learners. Wellington, N.Z.:
    NZCER Press.
-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Sharpe, P. R. (1981). Effects of individualized and group criteria
    for reinforcement on math performance. Educational Psychology, 1,
    359-369.
-   Tunmer, W. E., Chapman, J. W., & Prochnow, J. E. (2006). Literate
    cultural capital at school entry predicts later reading achievement;
    A seven year longitudinal study. New Zealand Journal of Educational
    Studies, 41, 183-
-   Walsh, K., Glaser, D., & Wilcox, D. D. (2006). What education
    schools aren't teaching about reading and what elementary teachers
    aren't learning. Washington D.C.: National Council on Teacher
    Quality.
-   Yates, G. C. R. (2005). \"How obvious\": Personal reflections on the
    database of educational psychology and effective teaching research.
    Educational Psychology, 25, 681-700.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/index.md","# The move from craft to evidence-based practice \n

::: {#parent-fieldname-text .plain}
The basic structure of teacher-student interaction and the teaching
activities which occur in classrooms have changed little during the past
80 years -- a fact which has been documented many times (e.g. Hoetker &
Ahlbrand, 1969; Cuban, 1993; Cuban & Tyack, 1995; Nuthall, 2007).
Compare this with the very considerable scientific and technological
advances which have occurred in almost all other professions during the
20th century. Unlike medical practice, where the traditional craft
philosophy of patient care was gradually replaced by the revolutionary
new clinical science during the first half of the 20th Century (Le Fanu,
1999), teaching practice has remained, to this day, a craft largely
untouched by the scientific research on learning and teaching.

### **A very short history of scientific progress in medicine**

Douglas Carnine, who has spent most of his working life engaged in
scientific research into teaching, has written a provocative article
entitled *Why education experts resist effective practices (And what it
would take to make education more like medicine)* (Carnine, 2000). In
this article Carnine observed that teacher educators have much to learn
from the way in which medicine, pharmacology, and various other
professions have evolved into mature professions. Carnine quotes the
medical historian Lewis Thomas who has written of pre-scientific
medicine that

\"It is hard to conceive of a less scientific enterprise among human
endeavours. Virtually anything that could be thought up for treatment
was tried out at one time or another, and, once tried, lasted decades or
even centuries before being given up. It was, in retrospect, the most
frivolous and irresponsible kind of human experimentation, based on
nothing but trial and error, and usually resulting in precisely that
sequence. Bleeding, cupping, the administration of infusions of every
known plant, solutions of every known metal, most of these based on the
weirdest imaginings about the cause of disease, concocted out of nothing
but thin air -- this was the heritage of medicine up until a little over
a century ago. It is astounding that the profession survived so long,
and got away with so much with so little outcry. Almost everyone seems
to have been taken in (Thomas, 1979, p. 159).

During the 20th century, however, medicine gradually transformed itself
into a mature, evidence-based profession with the result that life
expectancy across the Western world rose from less than 50 years to more
than 75 years.

In part this transformation was fuelled by scientific discoveries which,
following the second world war, began flowing out of medical
laboratories as if medical scientists \"had hit the jackpot (which they
had)\" (Le Fanu, 1999, p xv). Some of the discoveries which had far
reaching effects included the discovery of penicillin and many other
antibiotics, the discovery of cortisone and the various steroid
therapies, the discovery of streptomycin and a cure for tuberculosis,
the development of a vaccination for polio, the treatment of
hypertension and the prevention of strokes, the development of cancer
screening tests, the discovery of heliobacter and the development of a
cure for peptic ulcers, and so on.

In part this transformation was fuelled by technological developments
such as the development of x-ray machines, CT scanners, ultrasound
scanners, the electrocardiogram, the pump, the operating microscope, the
endoscope, the ventilator, the kidney dialysis machine, the pacemaker,
general anaesthesia, hip replacement surgery, kidney transplants, heart
surgery, interoccular lens implants, cochlear implants, intensive care
medicine, and so on.

In part, and most importantly of all, the transformation involved the
gradual replacement of pre-scientific medical practice with the new
clinical science in which medical practitioners not only adopted the
diagnostic and treatment procedures flowing out of the medical
laboratories but also reported the results of their own careful
observations and clinical trials. \"Research of any sort is never easy
but for these doctors to undertake these studies alongside their primary
responsibility of looking after patients suggested a certain zeal and
desire for knowledge. This zeal is the defining characteristic of the
new ideology -- clinical science -- that was to transform medicine\" (Le
Fanu, 1999, p. 198).

Hollman, describing the life of Sir Thomas Lewis describes just how
revolutionary the new clinical science was at the time. \"He had a
passionate belief that clinical science was just as good as any other
science, and it would be established as a University discipline ... one
has to remember that in the 1930s in Britain, the concept of a full-time
life-long career in clinical research was ... regarded rather as a
refuge for those unable to withstand the strains of a consultant's life\"
(Hollman, 1994). Yet in the 10 years following the end of World War 2
\"the situation where research was regarded as a refuge for those unable
to withstand the strains of consultant's life was completely reversed\"
and people began to make their reputations by publishing the results of
clinical investigations (Le Fanu, 1999, p. 203).

Medicine, says Carnine, now qualifies as a mature profession. \"A mature
profession ... is characterised by a shift from judgements of individual
experts to judgements constrained by quantified data that can be
inspected by a broad audience, less emphasis on personal trust and more
on objectivity, and a greater role for standardized measures and
procedures informed by scientific investigations that use control
groups\" (Carnine, 2000, p. 9).

### A very short history of scientific progress in teaching

::: {#parent-fieldname-text .kssattr-macro-rich-field-view .kssattr-templateId-widgets/rich .kssattr-atfieldname-text}
Educational researchers have been studying learning and teaching for
more than 100 years -- since Edgar Rice's 1895 study of the effects of
time spent on spelling practice (Nuthall, 2005). In a century of
unprecedented scientific and technological development, classroom
practice has hardly changed at all. By and large, it remains much the
same as it was 100 years ago (Cuban, 1993).

\"The scientific revolution that utterly transformed medicine,
agriculture, transportation, technology, and other fields in the 20th
century almost completely bypassed the field of education. If Rip Van
Winkle had been a physician, a farmer or an engineer, he would be
unemployable if he awoke today. If he had been a good elementary school
teacher in the 19th century, he would probably be a good elementary
school teacher today\" (Slavin, 2002).

Notwithstanding 100 years of effort, educators have yet to accomplish
the task of teaching every non-brain-damaged child how to read the
newspaper, how to write a simple descriptive essay, how to perform the
main types of arithmetic calculations, and how to behave in ways which
will keep them out of prison. It other words, teaching practice has much
in common with the medical practice of 100 years ago (Carnine, 2000).

Teachers still routinely assign children to each day\'s learning
activities without any diagnostic testing of the child to determine just
exactly what it is that the child needs to learn next (Nuthall, 2007).
Imagine a medical practitioner placing each day's patients on a course
of treatment without any attempt at a diagnosis to determine exactly
what course of treatment those patients required.

Teachers are still required to make most of their own teaching materials
and tests (Twyman, Layng, Stikeleather & Hobbins, 2005). Imagine a
surgeon being required to manufacture all the instruments, drips, pumps,
anaesthetics, scalpels, clamps, needles and so on required for the next
day's procedures at home the night before.

School textbooks and materials which have never been evaluated to see if
they work for anyone are still purchased by schools and routinely used
by teachers (Carnine & Bean, 1994; Engelmann, 1992; Grossen & Romance,
1994). Imagine a medical practitioner prescribing a course of treatment
which had never by subjected to a single clinical trial and never
approved by the Federal Drug Administration or any similar body. \"It is
. . . amazing to realize that publishers, test makers, and reformers of
every color and stripe can \"sell\" their wares without prior piloting or
evaluation\" (Lagemann, 2000, p. 238).

Teachers still get paid for doing what they do, that is, keeping
children engaged and occupied, and not for ensuring that children learn
(Nuthall, 2005, 2007). No teacher is ever likely to be dismissed because
some of her students did not learn very much. When a child fails to
learn this is still routinely assumed to be because of some defect in
the child, not some defect in the teaching provided. Imagine a medical
practitioner arguing in front of the Medical Council that his or her
patient died because the patient lacked the ability to profit from the
treatment provided.

Teacher educators still get paid for turning out graduates who behave
like the teachers who went before them, not for turning out graduates
who have demonstrated that they can produce learning (Kennedy, 1991;
Meier, 1992). In this respect Colleges of Education have more in common
with Theological Colleges than they do with Medical Schools.

Clearly classroom practice is not an evidence-based practice in the same
way that clinical medicine is an evidence-based practice and teaching is
not a mature profession in the way that medicine is a mature profession.
Teaching is still a craft. Unlike medical practice where the traditional
craft philosophy of patient care was gradually replaced by the
revolutionary new clinical science during the first 70 years of the 20th
century, teaching practice has remained, to this day, a craft largely
untouched by the scientific research on learning and teaching. It fact,
one could almost say that teaching practice is a bit like the practice
described in the anonymous observation:

\\"Theory is when you know why it doesn\'t work.

Practice is when it works but you don\'t know why.

We combine theory and practice.

It doesn\'t work and we don\'t know why.\\"
:::
:::

[ ![Section](../../../++resource++section_icon.gif){width=\"16\"
height=\"16\"} [Calls for change](Callsforchange){.contenttype-section
.state-published .url} ]{.summary} [ ]{.documentByLine}

[ ![Section](../../../++resource++section_icon.gif){width=\"16\"
height=\"16\"} [What is to count as evidence-based
practice?](Whatistocountasevidence-basedpractice){.contenttype-section
.state-published .url} ]{.summary} [ ]{.documentByLine}

[ ![Section](../../../++resource++section_icon.gif){width=\"16\"
height=\"16\"} [What is to count as
evidence?](Whatistocountasevidence){.contenttype-section
.state-published .url} ]{.summary} [ ]{.documentByLine}"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Whatistocountasevidence-basedpractice/index.md","# What is to count as evidence-based practice? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c6ea786ffc844d47b7a990340fd252d4}
Teaching, in its successful forms, is an activity which results in
series of transformations. A particular learner arrives with a
particular set of skills, understandings, interests, and beliefs
acquired as a result of prior learning and is transformed into an
individual with one or more additional skills, understandings, interests
and/or beliefs which they did not have before.

These transformations are most commonly referred to as \"learning\" and
activities which are specifically designed with the intention of
inducing such transformations are commonly referred to as \"teaching\".
Some authors refer to teaching as \"pedagogy\" but, in this site, we will
stick with the plain English term *teaching*.

Evidence-based practice is most commonly defined as teaching which
employs procedures practices and materials which are known, on the basis
of controlled evaluation research, to be effective in bringing about
particular learning outcomes in particular groups of learners (Slavin,
2002).
:::

::: referencesList
#### References

-   Slavin, R. E. (2002). Evidence-based education policies:
    Transforming educational practice and research. Educational
    Researcher, 31, 15-21.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Whatistocountasevidence/Evidenceofwhatquality/index.md","# Evidence of what quality? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-34d24f50b7fc4edb82789114f7c699cd}
Research in education tends to be of very variable quality -- ranging
from poorly controlled \"action research\" studies through to tightly
controlled single case experiments and randomised groups experiments.
Because different kinds of research questions can only be answered using
different kinds of research methods, there is no single set of quality
standards which can be applied to all research into learning and
teaching.

**Quality standards in the measurement of learning and behaviour
change**

Teaching researchers employ a wide variety of data collection procedures
ranging from hearsay reports through to video recordings of teacher and
student performance (Keeves, 1997). These data collection procedures
vary widely with respect to reliability and the data collected varies
widely with respect to accuracy. Reliability refers to the extent to
which an observation procedure can be operated in a consistent or
reproducible fashion*.* Accuracy refers to the closeness of the match
between the changes (learning) which actually occurred and the data
describing those changes (Johnston & Pennypacker, 1993).

Some observation and recording procedures are more reliable and produce
more accurate data than others. For example, recording by trained
observers is more reliable than recording by untrained observers,
recording by outside observers is more reliable than recording by the
participants themselves, and simple coding schemes with well defined
categories can be applied more reliably than complex coding schemes
(Cooper, Heron & Heward, 1987; Kazdin, 1977; Reid, 1970). Generally
speaking, low inference recording procedures can be operated more
reliably than high inference recording procedures.

We also know that video recording produces more accurate data than
recording by human observers, direct observation produces more accurate
data than indirect observation (e.g. rating scales and verbal reports),
observers who are blind to experimental conditions tend to produce more
accurate records than observers who are aware of experimental conditions
(Johnston & Pennypacker, 1993; Kazdin, 1977) and tests which measure
performance fluency on specific academic tasks provide a more accurate
measure of learning than most tests of achievement.

Because low inference recording and measurement procedures produce data
which is more trustworthy than high inference recording procedures,
research which uses low inference recording and measurement procedures
is more likely to meet \"scientific\" standards (in the sense of producing
potentially reproducible results) than research which uses high
inference recording and measurement procedures.

Because the data collected by teaching researchers varies widely with
respect to quality, making sense of the research base relevant to
teaching practice requires a fairly sophisticated understanding of the
relative accuracy of the data generated by the various observation,
testing and recording procedures currently in use. A more detailed
exploration of these difficulties will be found in Book 3 of this
website.

**Quality standards in design experiments**

One of the most important activities in research into teaching practice
is the design and formative evaluation of new teaching techniques,
procedures, programmes, and curricula. These activities are often
referred to as *design experiments.* The new programmes may be designed
by practitioners using the best available practitioner knowledge or they
may be developed using an iterative processes of controlled research
(often conducted under laboratory conditions) designed to identify those
conditions which are necessary conditions for mastery of the skills and
understandings being taught. We will refer to this latter process as
*scientific* *development*.

The scientific approach to instructional design was first described by
Markle and Tiemann (Markle & Tiemann, 1967; Tieman & Markle, 1991). It
is an adaptation of the Markle and Tiemann process which was employed by
Layng, Stikeleather and Twyman (2004) to develop the highly effective
Headsprout reading programme. The Headsprout development process
provides us with a model of the scientific approach to programme
development and evaluation against which all attempts at instructional
design can be compared. The process described by Layng at al. (2004) is
a process involving the following sequence of steps.

1\. *Analyse the content.* The content to be taught is examined and
classified according to the type of learning outcome involved (e.g.,
strategy, principle, concept, equivalence relation, operation, or motor
response).

2\. *State objectives.* The aims of the teaching programme are stated by
listing what the student is to be able to do at the end of the
instructional programme or instructional sequence.

3.*Design the criterion tests.* Tests are developed for each teaching
activity or routine within a lesson segment, for each lesson, for blocks
of lessons, and finally for the program. Tests of both accuracy
(understanding and retention) and fluency (automaticity) are employed.

4.*Identify the required entry skills.* Given what is to be learned,
determine the skills needed to progress through the program. Entry
repertoires are the specific prerequisites skills needed for success
(not just a list of prior experiences).

5\. *Build the instructional sequence*. The content analysis and the
criterion tests are used as a guide to the design of instructional
experiences and activities that will result in acquisition of the
desired criterion skills and understandings.

6\. *Formative evaluation.* The individual performance data collected
over successive field tests is used to iteratively refine the teaching
procedures until they meet the objectives listed in (2) as measured by
the criterion tests in (3). In this approach the behaviour of individual
learners shapes the program until nearly all learners meet the specified
criteria. For example, in the Headsprout Early Reading programme, \"a
single learner makes about 200 meaningful responses per 20 minute
lesson, about 10 per minute. That means approximately 16,000 responses
are individually collected and analyzed during the course of the
program. As of this writing, across all learners, well over 100 million
instructional interactions . . . have been collected and regularly
examined in an effort to understand how learners interact with the
program and to continually improve it\" (Layng et al., 2004, p. 6).

7.*Build in the motivating consequences*. Motivational elements usually
include a mixture of intrinsic elements (e.g., a high success rate on
practice responses) and extrinsic elements (e.g., interesting
activities, charts on which to record progress, and/or rewards for
achieving particular goals).

8.*Summative evaluation*. Once the programme has been refined to the
point where almost all individual children are achieving criterion
levels of performance, the programme as a whole is subjected to one or
more randomized control group studies so that its overall effectiveness
when compared against other programmes is known.

With this approach to instructional design, all elements of the program
are tested for effectiveness, and if particular criteria are not met,
alternative elements are designed and tested until they are. Evaluation
during the development phase is based on the performance of individuals
so that teachers who adopt the programme will be able to predict not
only group performance but also the individual performance of children
completing the programme (Twyman, Layng, Stikeleather & Hobbins, 2005).

**Quality standards in evaluation research**

Regardless of whether a teaching variable, practice or programme is
selected intuitively or as a result of scientific development its
effects on learning must still be measured. When the measurement of
instructional effects is undertaken in a controlled fashion it may be
referred to as *scientific evaluation* (to distinguish it from
scientific *development*).

In certain cases, a teaching practice or programme may qualify as
evidence-based when it has been evaluated using several well controlled
clinical trials where its effectiveness has been measured against that
of an existing practice or programme using appropriate samples of
learners who have been randomly assigned to the two teaching programmes.
However, there are many other ways of measuring the effects of teaching
on learning and any quality standards that are developed for evaluation
research must be applicable to the range of experimental designs which
can be used to measure instructional effects (Raudenbush, 2005).

In an attempt to clarify the kinds of evidence which should taken into
account in deciding whether a given practice is evidence-based or not,
Gina Green (1996) has argued that the believability of the research
evidence for a particular effect depends upon the extent to which
learning is observed directly (rather than indirectly), the level of
experimental control achieved, the extent to which the effects of
different ways of producing the same learning outcome can be directly
compared, and the extent to which particular research findings have been
replicated by different research teams.

Green provides the following diagram to summarise the main dimensions of
what we commonly refer to as research \"method\" and to locate various
commonly used research methods along a continuum from those which
provide the most to the least ambiguous evidence.

![Figure 1135 Types of evidence about treatment effects (from Green,
1996, p. 25)
](../../../../../../assets/images/figure-1135-types-of-evidence-about-treatment-effects-from-green-1996-p.-25 \"Figure 1135 Types of evidence about treatment effects (from Green, 1996, p. 25) \"){.image-inline
.captioned}

We have expanded Green's list into a set of *inclusion criteria*.
Inclusion criteria are the criteria which are to be applied when
attempting to decide whether the report of a particular investigation is
to be included for consideration in a research review. The inclusion
criteria which have been applied in the reviews appearing on this site
have been chosen on the grounds that investigations which meet these
inclusion criteria are more likely to produce reliable estimates of the
relative effects of different kinds of pedagogical practices on the rate
of learning of different kinds of skills and understandings in different
kinds of learners than those which do not. The inclusion criteria which
have been used in this site are as follows.

1.The investigation addressed a specific question about the effects of
some defined condition or aspect of teaching or teaching materials or
instructional programme on some type of student learning.

2.The investigation addressed a question the answer to which (or the
generality of the answer to which) was unknown at the time when the
research was undertaken.

3.The investigation employed a research method which, if appropriately
applied, could have answered the question which was asked.

4.The investigation employed a measure of learning which provided a
record of repeated observations of the learning demonstrated by each of
the individual learners who took part in the experiment.

5.The investigation demonstrated that an accurate measure of behaviour
change (learning) was obtained.

6.The investigation employed a research procedure which, when
appropriately applied, is known to produce an accurate measure of the
effect of a change in conditions on rate or degree of behaviour change
(learning).

7.The investigation demonstrated much the same effect across several
direct replications or the result has subsequently been replicated.

8.The generalisability of the results (if any) was clearly indicated or
is now being explored in subsequent investigations.

9.The report of the investigation described the research procedures,
research results, and theoretical explanations using standard terms with
agreed or defined meanings.

There are many aspects of teaching and learning which have yet to be
studied in any detail. This means that a particular aspect of learning
and/or teaching practice may be one for which there are no experimental
analyses which meet all of these criteria. At this point in the
development of evidence-based practice, it is necessary, therefore, to
allow inclusion of the occasional research report which does not meet
all of the above criteria -- simply because there is no research at all
which meets all of the criteria. Where the results of such
investigations are included, reviewers will be required to ensure that
the criteria which are and are not met by the investigation are given so
that the reader can assess the believability of the results of that
investigation.

In the interests of economy, we will refer to individual investigations
which meet these nine criteria as *scientific* and we will refer to
collections of scientific analyses of the effects of a particular
teaching practice as the *scientific research* into that practice.

We recognise that there is an ongoing debate amongst educational
researchers regarding what is to qualify as scientific research in the
study of learning and teaching (e.g., Berliner, 2002; Dixon & Carnine,
1994; Eisenhart, 2005; Erickson, 2005; Feuer, Towne & Shavelson, 2002;
Gee, 2005; Lather, 2004; Mayer, 2000; National Research Council, 2002;
Phillips, 2006; Raudenbush, 2005; Yates, 2005). This debate has been
going on for 80 years and is likely to continue until either the
activities which we have referred to as \"scientific\" are shown to
generate the understandings and the improvements in educational practice
which have been predicted or they do not.

However, there is a bottom line in this debate. Regardless of one's
personal view about the possibility of scientific research into learning
and teaching, the bottom line is that \"we need principles that rule
things in and out of research, and we need principles of quality that
distinguish weak from strong research, depending upon the research
question and the research design\" (Eisenhart, 2005, p. 57). This is why
increasing numbers of researchers are beginning to argue that \"only when
the profession embraces scientific methods for determining efficacy and
accepts accountability for results will education acquire the status --
and the rewards -- of a mature profession (Carnine, 2000, p. 10).
:::

::: referencesList
#### References

-   Berliner, D. C. (2002). Educational research: The hardest science of
    all. Educational Researcher, 31(8), 18-21.
-   Carnine, D. (2000). Why education experts resist effective practices
    (And what it would take to make education more like medicine).
    Retrieved 10 December, 2000, from
    http://www.edexcellence.net/library/carnine.html
-   Cooper, J. O., Heron, T. E., & Heward, W. L. (1987). Applied
    behavior analysis. New York: Macmillan Publishing Co.
-   Dixon, R. & Carnine, D. (1994). Ideologies, practices, and their
    implications for special education. The Journal of Special
    Education, 28, 356-367.
-   Eisenhart, M. (2005). Science plus: A response to the responses to
    Scientific Research in Education. Teachers College Record, 107,
    52-58.
-   Erickson, F. (2005). Arts, humanities, and sciences in educational
    research and social engineering in federal education policy.
    Teachers College Record, 107, 4-9.
-   Feuer, M. J., Towne, L., & Shavelson, R. J. (2002). Scientific
    culture and educational research. Educational Researcher, 31(8),
    4-14.
-   Gee, J. P. (2005). It's theories all the way down: A response to
    Scientific Research in Education. Teachers College Record, 107,
    10-18.
-   Green, G. (1996). Evaluating claims about treatments for autism.
    In C. Maurice, G. Green, & S. L. Luce (Eds.), Behavioral
    intervention for young children with autism: A manual for parents
    and professionals (pp. 15-28). Austin: Pro-ed.
-   Grossen, B. (1996) What does it mean to be a research-based
    profession? Retrieved 10 April, 2005, from
    http://darkwing.uoregon.edu/\~bgrossen/pubs/resprf.htm#Science
-   Johnston, J. M., & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research (2nd ed.). Hillsdale, NJ: Lawrence Erlbaum
    Associates.
-   Kazdin, A. E. (1977). Artefact, bias, and complexity of assessment:
    The ABCs of reliability. Journal of Applied Behavior Analysis, 10,
    141-150.
-   Keeves, J. P. (Ed.) (1997). Educational research, methodology, and
    measurement: An international handbook (2nd ed.). Oxford, England:
    Pergamon/Elsevier Science Inc.
-   Lather, P. (2004). Scientific research in education: A critical
    perspective. British Educational Research Journal, 30, 759-772.
-   Layng, T. V. J., Stikeleather, G., & Twyman, J. S. (2004).
    Scientific formative evaluation: The role of individual learners in
    generating and predicting successful educational outcomes. Retrieved
    15 July 2007 from
    http://headsprout.com/home/research_publications.cfm
-   Markle, S. M., & Tiemann, P. W. (1967). Programming is a process.
    Slide tape programme. Chicago: University of Illinois at Chicago.
-   Mayer, R. E. (2000). What is the place of science in educational
    research? Educational Researcher, 29(6), 38-39.
-   National Research Council. (2002). Scientific research in
    education. R. J. Shavelson & L. Towne (Eds.), Committee on
    Scientific Principles for Educational Research. Washington, DC:
    National Academy Press.
-   Phillips, D. C. (2006). Muddying the waters: The many purposes of
    educational inquiry. In C. F. Conrad & R. C. Serlin (Eds.), The Sage
    handbook for research in education: Engaging ideas and enriching
    inquiry (pp. 7-21). Thousand Oaks, CA: Sage Publications.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
-   Reid, J. B. (1970). Reliability assessment of observation data: A
    possible methodological problem. Child Development, 41, 1143-1150.
-   Tieman, P. W., & Markle, S. M. (1991). Analysing instructional
    content. Champaign, IL: Stipes.
-   Twyman, J. S., Layng, T. V. J., Stikeleather, G., & Hobbins, K. A.
    (2005). A nonlinear approach to curriculum design: The role of
    behavior analysis in building an effective reading program. In W. L.
    Heward, T. E. Heron, N. A. Neef, S. M. Peterson, D. M. Sainato, G.
    Cartledge, et al. (Eds.), Focus on behavior analysis in education:
    Achievements, challenges, and opportunities. Upper Saddle River, NJ:
    Pearson Education.
-   Yates, G. C. R. (2005). \"How obvious\": Personal reflections on the
    database of educational psychology and effective teaching research.
    Educational Psychology, 25, 681-700.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Whatistocountasevidence/Evidencecollectedatwhatlevelofspecificity/index.md","# Evidence collected at what level of specificity? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f1ad33480d104c7386e247a314a978a5}
Claims about what works in the classroom need to specify the particular
teaching practice under consideration, the particular types of learning
outcome which are affected by this practice, the strength of this
effect, and the particular kinds of learners who are affected in this
way. Only if these four elements are specified does it become possible
to examine the truth or otherwise of the claim.

Research into teaching typically contains one or more claims about the
effects of particular classroom practices on student learning. These
claims are almost always over-generalisations in the sense that they
hardly ever specify the practice *and* the particular learning
outcome(s) which were observed *and* the strength of the effect *and*
the developmental level of the learners who were so affected.

Claims about teaching can lie anywhere on a continuum from highly
specific to highly generalized. To simplify discussion of the
specificity-generality continuum we will divide this continuum into
three parts: 1) specific, 2) general, and 3) overgeneralised. Let us
define these three levels as follows.

**Level 1. The specific level**

At Level 1 (the specific level) the great majority of the effectiveness
claims in the report or review are claims where (a) the particular
teaching practice under consideration is specified in concrete terms,
(b) the particular learning outcome or outcomes are specified using an
agreed or defined classification, (c) the size of the effect is given
either in absolute terms or else relative to an alternate practice of
known effect, and (d) the particular population of learners under
discussion are described in terms of their pre-instructional levels with
respect to each of the learning outcomes studied.

**Level 2. The general level**

At Level 2 (the general level) effectiveness claims are claims in which
one of the four necessary parts of a claim about teaching effectiveness
are missing. For example, there may be no reference to the developmental
level of the students -- implying that all students are similarly
affected by the particular teaching practice under discussion. Or the
particular learning outcome which is affected may be left unspecified --
implying that all learning outcomes are affected in the manner
described.

**Level 3. The overgeneralisation**

Level 3 (the overgeneralisation) includes all claims regarding teaching
effectiveness in which only one or two of the four necessary elements
are present while the remaining elements are either missing or else are
given in such general terms that the reader has no way of working out
which particular teaching practice and/or learning outcome and/or
student population the writer is talking about.

The following claims from three different reviews of research on
teaching illustrate Level 3 overgeneralisations.

-   *\"Students learn best within cohesive and caring learning
    communities\"* (Brophy, 2001, p. 6). This conclusion is regularly
    repeated in New Zealand's BES reviews (see for example Alton-Lee,
    2003; Anthony & Walshaw, 2007). It is clearly an overgeneralisation
    for, by failing to specify any categories of students and any
    categories of learning outcomes, it implies that the claim is true
    for all students and all learning outcomes. The absurdity of the
    claim will be quickly recognised by anyone who was a high achieving
    secondary or tertiary student who learned most rapidly when studying
    on their own.
-   *\"Pedagogies that emphasise, embed and enable metacognitive
    strategy-use through curriculum engagement for class groups, are
    associated with much higher achievement and enable marked
    improvements for low achievers\"* (Alton Lee, 2003, p. 84). This
    claim immediately raises a number of questions. How much higher?
    Much higher than what? Only low achievers? At which age levels? For
    which kinds of learning outcomes? Clearly this claim meets our
    definition of an overgeneralisation.
-   *\"The long term use of concrete materials is positively related to
    increases in student mathematics achievement and improved attitudes
    toward mathematics\"* (Grouws, 2004, p. 172). Although this
    conclusion is based on a meta-analysis of 60 between-groups
    experiments by Sowell (1989), the claim by Grouws leaves out all of
    the limiting conditions listed in the original review. For example,
    Sowell found that the effect was very small and that it varied by
    grade level, learning outcome and study length. For example, the
    mean effect size for concrete materials vs. symbolic materials in
    studies of 1 year or longer was 0.29 for rate of acquisition in
    Grades 1-4 and was 0.38 for retention in grades 1 to 8. The
    meta-analysis \"could not answer questions about the nature of the
    situations in which manipulatives might be appropriate. Nor was it
    possible to find out which manipulatives are most appropriate in
    particular situations\" (Sowell, 1989, p. 504).
-   *\"Accomplishing the most significant instructional goals requires
    open-ended questions that call for students to apply, analyze,
    synthesize, or evaluate what they are learning\"* (Brophy, 2001, p.
    13). Here again, Brophy is guilty of overgeneralisation. He has
    failed to specify which kinds of students he is talking about and he
    has failed to define \"significant instructional goals\". It needs to
    be remembered that \"significant instructional goals\" is a very large
    category given that there are very few \"insignificant instructional
    goals\". The overgeneralisation also ignores a very substantial
    corpus of scientific research demonstrating that there are many
    groups of children who learn more rapidly and develop higher levels
    of understanding under conditions of well structured, step-by-step
    questioning (Adams & Engelmann, 1996; Klahr & Nigam, 2004).
-   *\"Peer tutoring (tutoring of slower or younger students by more
    advanced students) appears to work nearly as well as teacher
    tutoring\"* (Walberg & Paik, 2004). In the absence of closer
    examination this appears to be a plausible summary of the peer
    tutoring literature. However, it fails to specify any categories of
    learning outcomes (implying that it applies to all learning
    outcomes), fails to specify any categories of students (implying
    that it applies to all students), and fails to define \"nearly as
    well\". This makes the claim an overgeneralisation.

It can be seen that the kinds of conclusions which research might
generate (regarding the relative effectiveness of different classroom
practices and different instructional materials) may be presented at
various levels of specificity and that a certain degree of expertise is
required in order to evaluate the research base which is being cited in
favour of a particular teaching practice. We will consider in some
detail the level of specificity which is required if the research base
is to be of any practical value in Book 2 of this website.
:::

::: referencesList
#### References

-   Adams, G.L. & Engelmann, S. (1996). Research on Direct Instruction:
    25 years beyond DISTAR. Seattle: Educational Achievement Systems.
-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, New Zealand:
    Ministry of Education.
-   Anthony, G. & Walshaw, M. (2007). Effective pedagogy in
    mathematics/Pängarau. Best evidence synthesis Iteration. Wellington,
    New Zealand: Ministry of Education. Retrieved 16 June 2007 from
    http://educationcounts.edcentere.govt.nz/goto/BES.
-   Brophy, J. (2001). Introduction. Advances in Research on Teaching:
    Subject-Specific Instructional Methods and Activities, 8, 1-23.
-   Grouws, D. A. (2004). Mathematics. In G. Cawelti (Ed.), Handbook of
    research on improving student achievement (3rd ed.). Arlington, VA:
    Educational Research Service.
-   Klahr, D., & Nigam, M. (2004). The equivalence of learning paths in
    early science instruction: Effects of direct instruction and
    discovery learning. Psychological Science, 15, 661-667.
-   Sowell, E. J. (1989). Effects of manipulative materials in
    mathematics instruction. Journal for Research in Mathematics
    Education, 20, 498-505.
-   Walberg, H. J., & Paik, S. J. (2004). Effective general practices.
    In G. Cawelti (Ed.) Handbook of research on improving student
    achievement (3rd ed.). Arlington, VA: Educational Research Service.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Whatistocountasevidence/index.md","# What is to count as evidence? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-be1a3dd946cd4f26b98a59474b14c156}
Suggestions that teaching practice might be based on research evidence
do not always deal with the question \"what kinds of research evidence?\"
This is an important question because educational researchers employ a
variety of different kinds of research procedures and different research
procedures generate different kinds of knowledge.

Secondly educational researchers work at different levels of specificity
and hence their research results vary widely with respect to their level
of applicability in practical settings such as classrooms.

Thirdly, educational researchers vary with respect to the degree of
quality control which they attempt to achieve over the subject matter of
their investigations and this in turn results in variations in the
believability of their findings.

Fourthly, the effects of some teaching procedures on some learning
outcomes have been studied much more frequently than others and this
results in research-derived knowledge with widely differing levels of
research support.

These difference are compounded when educational researchers attempt to
review the research literature, especially when they try to look across
investigations which have used different types of research method, and
this results in review-based conclusions which vary widely with respect
to their validity and believability.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Whatistocountasevidence/Howmuchevidence/index.md","# How much evidence? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e3e948fab4fd42149459674c62d10dfd}
Some generalisations about the effects of a given teaching practice on
learning have no research support, some are supported by the results of
a single scientific investigation and some are supported by the results
of many scientific investigations by different teams of researchers.
Figure 1136 illustrates this continuum using the example of research
into a particular functional relationship, say the arrangement of
positive and negative examples of a new concept during an explanation
and the degree of conceptual understanding which results from the
explanation.

![Figure 1136. Levels of support for the view that a functional
relationship exists between some aspect of teaching and some aspect of
learning (Graphic adapted from Martens & Eckert,
2000.)](../../../../../../assets/images/TECKSFig1136.png \"Figure 1136. Levels of support for the view that a functional relationship exists between some aspect of teaching and some aspect of learning (Graphic adapted from Martens & Eckert, 2000.)\"){.image-inline}

Because a generalisation about pedagogical effects may be supported by
the result of anything from one to a large number of controlled
investigations this raises the question of how many times a research
finding result needs to be replicated before it is admitted to the
research base for a particular teaching practice.

Teaching researchers have engaged in little discussion concerning the
amount of empirical evidence which would be required in order to justify
a claim that a given practice qualified as \"evidence-based\". The
standard adopted by clinical child psychologists is that a particular
intervention may be classified as \"well established\" provided two or
more separate research teams have found the intervention to be more
effective than a placebo treatment using well controlled clinical
trials, *or* if 10 or more well designed single-case experiments have
shown the intervention to be more effective than some other intervention
(Lonigan, Elbert & Johnson, 1998).

Two clinical trials seems a very low standard of proof (Fonagy, Target,
Cottrell, Phillips & Kurtz, 2002) but is certainly an improvement over
the current situation in education where effectiveness claims are often
being made on the basis of a single investigation (e.g., Alton Lee,
2003; Anthony & Walshaw, 2007).
:::

::: referencesList
#### References

-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, New Zealand:
    Ministry of Education.
-   Anthony, G. & Walshaw, M. (2007). Effective pedagogy in
    mathematics/Pängarau. Best evidence synthesis Iteration. Wellington,
    New Zealand: Ministry of Education. Retrieved 16 June 2007 from
    http://educationcounts.edcentere.govt.nz/goto/BES.
-   Fonagy, P., Target, M., Cottrell, D., Phillips, J., & Kurtz, Z.
    (2002). What works for whom? A critical review of treatments for
    children and adolescents. New York: The Guilford Press.
-   Lonigan, C. J., Elbert, J. C., & Johnson, S. B. (1998). Empirically
    supported psychosocial interventions for children: An overview.
    Journal of Clinical Child Psychology, 27, 138-145.
-   Martens, B. K., & Eckert, T. L. (2000). The essential role of data
    in psychological theory. Journal of School Psychology, 38, 369-376.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Whatistocountasevidence/Evidencegatheredusingwhatkindsofresearch/index.md","# Evidence gathered using what kinds of research? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8443f2cad9694e33bf33e603499bf3be}
It is possible to make the case that teaching practice should be based
on the results of research, but only if it is understood that questions
about teaching can take a variety of forms. Sometimes we are interested
in descriptive questions such as \"What is happening here?\" Sometimes we
are interested in questions about whether or not something has an
effect. For example, \"Does this teaching practice have a reproducible
effect on learning?\" And sometimes we are interested in explanation. For
example \"How (or why) does this practice have this effect on children's
motivation?\" (Feuer, Towne & Shavelson, 2002). Attempts to answer these
different kinds of questions require the application of different kinds
of research procedures.

**Different kinds of research methods**

Put in a slightly different way, educational researchers use a variety
of different kinds of research methods and these different methods
produce quite different kinds of information (Keeves, 1997). Some
research procedures collect only descriptive information. Much of the
research into classroom practice, for example, consists of ethnographic
and other kinds of descriptive research. (For an example, see Angier and
Povey (1999)). It is not possible, however, to distinguish between
teaching practices which are more or less effective in bringing about
learning by simply describing what teachers are currently doing or by
describing the way in which teachers justify what they are currently
doing. To identify cause and effect relationships between elements of
teaching practice and student learning, it is necessary to conduct
experimental analyses of those teaching practices. Claims about
particular types of teaching practices and the effect which they have on
particular types of learning cannot be warranted (supported) by
reference to the results of descriptive studies no matter how elegantly
these are carried out.

Some research procedures collect information on the relationship between
one or more teaching variables and one or more learning outcomes in
naturally occurring situations but present only data describing the
correlations between subsets of these variables. (For an example, see
Nuthall and Alton-Lee (1993)). While correlational studies can suggest
that a relationship may exist between teaching practice X and learning
outcome Y, only an experiment can demonstrate that the learning outcome
in question is a direct function of X and not a function of something
else and only a series of experiments can demonstrate that X is a
necessary condition for the development of Y in certain types of
learners.

Different kinds of educational experiments are also possible. Some
experimental evaluations employ randomised groups designs of one kind or
another to measure the average effect of a particular teaching practice
or teaching programme on the mean level of post-instructional
achievement of a group of learners relative to that of a control group
of closely similar learners who did not experience the instruction being
evaluated. (For an example, see Chun and Winter (1999)).

The results of this kind of experiment, while useful for programme
evaluations, cannot be used to measure the effects of a particular
teaching practice on the learning of individual students. That is, this
method cannot answer the question which is of primary interest to
teachers \"What shall I do for this student?\" For this reason it cannot
be considered the \"gold standard\" in experimental research as some
researchers (e.g., Shavelson & Towne, 2002) have argued. In order to
measure the effects of any aspect of teaching on the learning of
individual students, an experimental method which preserves the
observations of the progress of each individual learner (rather than
averaging these) is required. Clinical trials must be preceded by
numerous experimental studies designed to identify which outcomes in
which children are affected by which interventions. \"The randomized
experiment becomes a powerful tool for warranting causal effects after a
rather protracted process has identified the most promising
interventions for changing the most important outcomes for target
children in settings of interest\" (Raudenbush, 2005, p. 29).

The experimental procedure which preserves the record of learning in
individual children and which has proved to be most productive is the
behaviour analysis experiment (the single case experiment). These
experiments follow the progress of individual students in the days
leading up to the experimental treatment, the days while it operated and
the days following. (For an example, see Umbriet, Lane and Dejud
(2004)). Unlike the results of a clinical trial which cannot be
generalised to individual learners, collections of single case
experiments can both identify cause and effect relationships between
teaching and learning and can be generalised to individual learners.

**Different kinds of review methods**

Similar variability exists across the scholarly reviews of research on
teaching. Some research reviews consist largely of anecdotes drawn from
ethnographic and other kinds of descriptive studies of classroom life
(e.g., Anthony & Walshaw, 2007). Because the individual studies say
nothing about the effects of particular teaching practices on particular
learning outcomes, few if any conclusions about teaching effects, or the
conditions necessary for learning, can be drawn from such reviews.

Some reviews of research on teaching take the form of a meta-analytic
review of a set of randomised groups experiments which meet certain
inclusion criteria with respect to the teaching process or procedure
under examination (e.g., National Reading Panel, 2000). While
conclusions regarding the effects of particular teaching strategies on
particular learning outcomes at the group or population level can
sometimes be drawn from such reviews, no conclusions regarding the
effects of a particular teaching strategy on the learning of individual
children can be drawn from this type of review. Furthermore, the results
of this type of review are frequently uninterpretable. This is the case
whenever

-   the children in different experiments varied with respect to age,
    developmental level or symptom severity but these groupings were not
    separately analysed
-   individual experiments used different outcome measures but no
    breakdown by outcome measure was undertaken
-   teaching interventions in the various experiments were of varying
    length but this is ignored in the review
-   the interventions (even although there were given the same name)
    were actually different
-   the review contains experiments with no-treatment controls and
    experiments with business-as-usual controls but these are not
    analysed separately.

Some reviews of research on teaching take the form of \"best evidence
syntheses\". Most of the recent New Zealand reviews of teaching take the
form of BES reviews. These reviews are of variable quality. Some (e.g.,
Timperley, Wilson, Barrar & Fung, 2007) provide a clear description of
the inclusion criteria employed and others (e.g., Alton Lee, 2003) do
not. The latter review includes descriptive studies, correlational
studies and experimental studies and treats them as if they are
producing comparable forms of knowledge which, of course, is not the
case. This kind of review generates few conclusions of any consequence
because the believability of individual conclusions is impossible to
determine.

Some reviews of research on teaching take the form of reviews of sets of
single case experiments. (For an example, see Cates (2005)). Generally
speaking these reviews apply inclusion criteria which are sufficiently
stringent to ensure that only well controlled experimental analyses of a
single teaching variable or a single learning outcome are included in
the review. Unlike most of the narrative reviews, meta-analyses, and
\"best evidence syntheses\", reviews of single case experimental analyses
of the effects of particular instructional variables on particular
learning outcomes often generate reliable and generalisable conclusions.

It can be seen that different kinds of research procedure generate
different kinds of knowledge. In order to make sense of the research
base on particular aspects of teaching practice a fairly sophisticated
understanding of the various types of research method and the kinds of
knowledge which they generate is required. A more detailed account of
these difficulties will be found in Book 3 of this website.
:::

::: referencesList
#### References

-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, New Zealand:
    Ministry of Education.
-   Angier, C. & Povey, H. (1999). One teacher and a class of school
    students: Their perception of the culture of their mathematics
    classroom and its construction. Educational Review, 51, 147-160.
-   Anthony, G. & Walshaw, M. (2007). Effective pedagogy in
    mathematics/Pängarau. Best evidence synthesis Iteration. Wellington,
    New Zealand: Ministry of Education. Retrieved 16 June 2007 from
    http://educationcounts.edcentere.govt.nz/goto/BES.
-   Cates, G. L. (2005). A review of the effects of interspersing
    procedures on the stages of academic skill development. Journal of
    Behavioral Education, 14, 305-325.
-   Chun, C. C., & Winter, S. (1999). Classwide peer tutoring with or
    without reinforcement: Effects on academic responding, content
    coverage, achievement, intrinsic interest and reported project
    experiences. Educational Psychology, 19, 191-205.
-   Feuer, M. J., Towne, L., & Shavelson, R. J. (2002). Scientific
    culture and educational research. Educational Researcher, 31, 4-14.
-   Keeves, J. P. (Ed.) (1997). Educational research, methodology, and
    measurement: An international handbook (2nd ed.). Oxford, England:
    Pergamon/Elsevier Science Inc.
-   National Reading Panel. (2000). Teaching children to read. Retrieved
    June 25, 2000, from
    http://www.nichd.nih.gov/publications/nrp/smallbook.htm
-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
-   Shavelson, R. J., & Towne, L. (Eds.). (2002). Committee on
    scientific principles for educational research. Washington, DC:
    National Research Council, National Academy Press.
-   Timperley, H., Wilson, A., Barrar, H., & Fung, I. (2007). Teacher
    professional learning and development. Best evidence synthesis
    iteration (BES). Wellington, New Zealand: New Zealand Ministry of
    Education.
-   Umbreit, J., Lane, K. L., & Dejud, C. (2004). Improving classroom
    behavior by modifying task difficulty: Effects of increasing the
    difficulty of too-easy tasks. Journal of Positive Behavior
    Interventions, 6, 13-20.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Callsforchange/Callsforincreasedaccountability/index.md","# Calls for increased accountability \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cffb8ded945b41ef935b8728aa008464}
Another source of calls for change is the accountability movement. These
calls are based on the simple idea that those responsible for education
should \"set . . . goals, measure whether or not they have been met, do
something about it if they haven't\" (Torrance, 2002, p. 1).

The implementation of the standards movement in the UK, has been
described by Torrance (1997, 2002). Torrance argues that the movement
was based on four assumptions. These were

-   that agreement can be reached on national educational aims and
    specific curricular objectives
-   that these can be expressed in traditional subject-specific
    programmes of study
-   that tests can be devised which validly assess such objectives and
    accurately represent pupil attainment of them, and
-   that setting targets, publishing results and constantly pressing for
    increases in scores will both raise standards and provide evidence
    of these rising standards.

Similar systems have been introduced in a number of US states
(Darling-Hammond, 2004). In 2010 the New Zealand government decided to
introduce a national standards system into New Zealand primary schools.

The introduction of these standards-based reforms, and the huge
expenditure which these have involved, is further evidence that parents
and politicians are becoming increasingly concerned about the apparent
lack of progress which is being made in developing more effective forms
of classroom practice.
:::

::: referencesList
#### References

-   Darling-Hammond, L., (2004). Standards, accountability and school
    reform. Teachers College Record, 106, 1047-1085.
-   Torrance, H. (1997). Assessment, accountability and standards: Using
    assessment to control the reform of schooling. In A. H. Halsey et
    al. (Eds.), Education: Culture, economy and society. Oxford: Oxford
    University Press.
-   Torrance, H. (2002) Can testing really raise educational standards?
    Professorial lecture delivered to the University of Sussex.
    Retrieved 3 July, 2007 from
    www.esri.mmu.ac.uk/respapers/papers-pdf/Professorial%20Lecture.pdf
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Callsforchange/Callsforamovetoevidence-basedpractice/index.md","# Calls for a move to evidence-based practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-18f362f389bf4157bf87b9279fd7d623}
From researchers themselves, the call has been a call to begin the move
to evidence-based practice. \"To improve the results achieved by schools,
the instructional practices that are shared widely across the profession
should be limited to those that are most likely to produce better
results\" (Grossen, 1996, p. 2). Educational decisions \"should be built
on objective data that can be inspected by a broad audience rather than
wishful thinking\" (Carnine, 2000, p. 10).

Increasing numbers of teaching researchers are making the point that the
scientific study of learning is well advanced, that there are numerous
examples of teaching procedures and programmes which are much more
effective than those currently in use, and that teachers have an ethical
and professional obligation to provide students with the most effective
teaching discovered to date (e.g., Berninger, Dunn, Lin & Shimada, 2004;
Chall, 2002; Engelmann, 1992; Greenwood, 2001; Grossen, 1996; Landrum &
Tankersley, 2004; Raudenbush, 2005; Ravitch, 2000; Slavin, 2002;
Stanovitch, 1993/4; Vaughn & Dammann, 2001; Wheldall, 2005).

In the US this call was taken up by Congress in the form of the No Child
Left Behind legislation of 2001. \"The phrase 'scientifically based
research' occurs more than 100 times in the Bush administration's No
Child Left Behind Act of 2001\" (Traub, 2002, p. 1). Furthermore the
legislation includes funding incentives. For example, funding of some
\$5 billion over six years will be made available to states and
districts where reading is taught using 'scientifically based' methods.

In New Zealand, teaching researchers and teachers are coming under
increasing pressure from the Ministry of Education and the Education
Review Office to introduce teaching programmes and methods which will
reduce the gap in achievement between high achievers and low achievers,
between non-Maori and Maori students, and between non-PI and Pacific
Island students. In a major New Zealand literature review it is argued
that \"this best evidence synthesis is intended to contribute
evidence-based and comprehensive strategies for optimising learning
opportunities for Maori and breaking patterns of system
under-performance for Maori\" (Alton-Lee, 2003, p. 5).

These developments led the editors of the report of the National
Research Council's Committee on Scientific Principles in Educational
Research to conclude that \"The current demand for scientific
understanding of educational phenomena is unmatched in history\" (Feuer,
Towne & Shavelson, 2002, p. 11-12).
:::

::: referencesList
#### References

-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, N.Z.: Ministry of
    Education.
-   Berninger V. W., Dunn, A., Lin, S. C., & Shimada, S. (2004). School
    evolution: Scientist-practitioner educators creating optimal
    learning environments for all students. Journal of Learning
    Disabilities, 37, 500-508.
-   Carnine, D. (2000). Why education experts resist effective practices
    (And what it would take to make education more like medicine).
    Retrieved 10 December, 2000, from
    http://www.edexcellence.net/library/carnine.html
-   Chall, J. S. (2002). The academic achievement challenge: What really
    works in the classroom? New York: Guilford Press.
-   Engelmann, S. (1992). War against the schools' academic child abuse.
    Portland, OR: Halcyon House.
-   Feuer, M. J., Towne, L., & Shavelson, R. J. (2002). Scientific
    culture and educational research. Educational Researcher, 31(8),
    4-14.
-   Greenwood, C.R. (2001). Science and students with learning and
    behavioral problems. Behavioral Disorders, 27, 37-52.
-   Grossen, B. (1996) What does it mean to be a research-based
    profession? Retrieved 10 April, 2005, from
    http://darkwing.uoregon.edu/\~bgrossen/pubs/resprf.htm#Science
-   Landrum, T. J. & Tankersley, M. (2004). Science in the schoolhouse:
    An uninvited guest. Journal of Learning Disabilities, 37, 207-212.
-   Raudenbush, S. R. (2005). Learning from attempts to improve
    schooling: The contribution of methodological diversity. Educational
    Researcher, 35(5), 25-31.
-   Ravitch, D. (2000). Left back: A century of failed school reforms.
    New York: Simon & Schuster.
-   Slavin, R. E. (2002). Evidence-based education policies:
    Transforming educational practice and research. Educational
    Researcher, 31, 15-21.
-   Stanovitch, K. E. (1993/4). Romance and reality. Reading Teacher,
    47, 280-291.
-   Traub, J. (10 November, 2002). Does it work? The New York Times.
    Retrieved 13 November, 2002, from http;//www.nytimes.com/2002/11/10
-   Vaughn, S., & Dammann, J. E., (2001). Science and sanity in special
    education. Behavioral Disorders, 27, 21-29.
-   Wheldall, K. (2005). When will we ever learn? Educational
    Psychology, 25, 573-584.
:::"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Callsforchange/index.md","# Calls for change \n

::: {#parent-fieldname-text .plain}
 

One does not have to look far to find suggestions that we could and
should be developing and implementing more effective teaching practices.
Numerous observers, teaching researchers, and politicians have begun to
call for a radically different approach to the development and
improvement of classroom practice.

Some have called for an end to what they refer to as \"faddism\" in
education. By faddism they mean the continual recycling of teaching
practices (such as \"sensory integration\") which have never been shown to
produce any of the benefits claimed for them.

Some have called for increased accountability on the part of teachers.
By accountability they mean the regular testing of children and the move
to hold teachers accountable for ensuring that every student reaches
certain \"standards\" with respect to selected academic skills.

Some have called for a move to evidence-based practice. By
evidence-based practice they mean the replacement of teaching procedures
of unknown effectiveness with procedures which have been shown, by
controlled research, to be effective for all students.
:::

[ ![Section](../../../../++resource++section_icon.gif){width=\"16\"
height=\"16\"} [Calls for an end to
faddism](Callsforanendtofaddism){.contenttype-section .state-published
.url} ]{.summary} [ ]{.documentByLine}

[ ![Section](../../../../++resource++section_icon.gif){width=\"16\"
height=\"16\"} [Calls for increased
accountability](Callsforincreasedaccountability){.contenttype-section
.state-published .url} ]{.summary} [ ]{.documentByLine}

[ ![Section](../../../../++resource++section_icon.gif){width=\"16\"
height=\"16\"} [Calls for a move to evidence-based
practice](Callsforamovetoevidence-basedpractice){.contenttype-section
.state-published .url} ]{.summary} [ ]{.documentByLine}"
".//Theproblemtobesolved/Themovefromcrafttoevidence-basedpractice/Callsforchange/Callsforanendtofaddism/index.md","# Calls for an end to faddism \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9eb18626d84e4142a385c90955a2ba4a}
A number of writers have described the cyclical pattern of \"innovation\"
in education as \"faddism\".

\"Imagine the outcry if new miracle wonder drugs were released to an
unsuspecting public without extensive, experimental clinical trials
testifying to their efficacy. But in education, this is precisely what
typically happens. And so we see them pass, fad after fad, guru
following guru, educational disaster after educational disaster. The
result is that in education we do not make progress, we merely see
changes of fashion\" (Wheldall, 2005, pp. 579-580).

\"The story of educational innovation over the long run is a depressing
one. Most innovations adopted on a large scale were never adequately
evaluated . . . . Most often, innovations that have been
enthusiastically adopted and even found to be effective in particular
schools are later dropped, sometimes to be replaced by other innovations
and sometimes for a return to the status quo ante. The reasons for this
boom-to-bust cycle in innovation are all too familiar (see Slavin, 1989,
1999). In any area of endeavor ruled by fashion rather than by evidence,
such as art, music, design, and haute couture, novelty is prized and no
fad or trend can last for many years. Unfortunately innovation in
education far more closely resembles faddism in these areas than the
generational progress based on evidence characteristic of such fields as
medicine, applied physics or engineering\" (Slavin, 2004, p. 61).

For Wheldall and for Slavin, the only way to halt the pendulum of
faddish innovation is to change the ground rules for selecting,
implementing and evaluating innovations in teaching. Such innovations
must be limited, they argue, to changes which have been rigorously
evaluated, which have been shown to be more effective than current
practice, which are supported by well developed curriculum materials and
which are supported by a commitment to long term funding, research, and
professional development support (Slavin, 1989).
:::

::: referencesList
#### References

::: {#parent-fieldname-tecks_references-9eb18626d84e4142a385c90955a2ba4a}
Slavin, R. E. (1989).  PET and the pendulum: Faddism in education and
how to stop it. Phi Delta Kappan, 70, 750- 756.
:::
:::

::: referencesList
#### References

-   Slavin, R. E. (1989). PET and the pendulum: Faddism in education and
    how to stop it. Phi Delta Kappan, 70, 750- 756.
-   Slavin, R. E. (1999). The pendulum revisited: Faddism in education
    and its alternatives. In G. J. Cizek (Ed.), Handbook of educational
    policy (pp. 373-386). Burlington, MA: Academic Press.
-   Slavin, R. E. (2004). Built to last: Long-term maintenance of
    Success for All. Remedial and Special Education, 25, 61-66.
-   Wheldall, K. (2005). When will we ever learn? Educational
    Psychology, 25, 573-584.
:::"
".//Theproblemtobesolved/Isamovefromcraft-toevidence-basedpracticepossible/Howextensiveistheresearchintoteachingprocesses/index.md","# How extensive is the research into teaching processes? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-1b71fbcc06644b38ad6d9c3c2b246cc9}
University of Canterbury, Christchurch, New Zealand. © University of
Canterbury 2008.

Given the advances, during the past 40 years, in the scientific study of
learning processes and the rapid development of our understanding of the
conditions necessary for the acquisition of different kinds of
competencies it is hardly surprising to find that there have also been
important developments in our understanding of teaching processes of
various kinds. As previously stated, a move to more effective,
evidence-based classroom teaching practices is only possible if the
evidence base has developed to the point where we can make reasonable
research-based predictions about what works to bring about particular
kinds of learning outcomes in particular groups of students. It is our
view that this is now the case for a number of different learning
outcomes.

**Research into maintaining the motivation of all children in diverse
classrooms**

Following identification of the variables upon which motivation depends,
researchers quickly began to develop a variety of management procedures
which work to motivate even the most poorly motivated learners (e.g.,
Martella, Nelson & Marchand-Martella, 2002; Sulzer-Azaroff & Mayer,
1991) In fact, there has been more scientific research into motivation
and behaviour management, during the past 35 years, than there has been
into any other aspect of classroom practice and we long ago discovered
that the children of teachers who have mastered these procedures learn
more (because they get more done) than the children of teachers who have
not mastered these procedures (e.g., Broughton & Lahey, 1978; Lovitt,
Guppy & Blattner, 1969). Teacher educators who are familiar with this
research continue to express amazement that this knowledge is not part
of the working knowledge of all classroom teachers and is not even part
of the curriculum of many teacher education programmes (e.g., Greenwood,
2001).

Sometimes classroom misbehaviour is symptomatic of development along an
antisocial (rather than a prosocial) trajectory. Here too researchers
have developed and demonstrated the effectiveness of a number of home
and school based interventions for halting antisocial development and
accelerating prosocial development -- at least in children up to the age
of about 9 years (Church, 2003).

**Research into the appropriate level of structure during instruction**

Well controlled studies of teaching processes (e.g. Church, 1976; Klahr
& Nigam, 2004; McCleery & Tindal, 1999) have discovered that loosely
structured teaching arrangements (such as discovery learning and
constructivist learning arrangements) result in lower levels of
understanding and slower rates of mastery for the great majority of
children than do more carefully structured teaching arrangements. (See
also Adams and Engelmann (1996), Chall (2002), Hermann (1969), and Mayer
(2004)). The results of controlled experimental research stand in stark
contrast to the beliefs of many classroom teachers and teacher educators
regarding the efficacy of discovery and \"constructivist\" learning
activities.

We have also discovered that co-operative learning activities can
facilitate learning but only if each child's learning is monitored and
there is some kind of incentive for group members to tutor each other in
an effective manner (Slavin, 1990). This is a major departure from the
way in which these procedures are currently used by the majority of
classroom teachers.

**Research into the conditions necessary for the development of new
understandings and the avoidance of misunderstandings**

We have identified the critical teaching conditions which must be
provided in order for children to master new understandings and have
developed procedures for explaining and teaching new concepts and rules
which are much more effective than the classroom procedures currently in
use (e.g., Church, 1999; Engelmann & Carnine, 1991; Muthukrishna,
Carnine, Grossen & Miller, 1993). Of particular importance is the
research into the relative efficiency of different kinds of explanations
and different kinds of example sequencing operations. This knowledge is
essential knowledge for anyone who is involved in subject matter
teaching or instructional design.

**Research into prompting procedures during the teaching of new skills
and operations**

Research has identified many of the critical teaching conditions which
must be provided in teaching new skills and this has stimulated the
development of prompting and scaffolding procedures (for teaching new
skills, procedures, and metacognitive skills) which are much more
effective than the ad hoc procedures currently used by classroom
teachers (e.g., Church, 1999; Pressley, Harris & Guthrie, 1992; Wolery,
Bailey & Sugai, 1988).

**Research into the teaching conditions necessary for long term
retention**

Following the discovery that level of fluency is the best predictor of
long term retention, researchers have developed procedures for measuring
fluency which are both accurate and simple enough for everyday classroom
use and they are making good progress in identifying the kinds of
practice procedures which are most effective in helping students achieve
a level of fluency sufficient to ensure that essential skills and
understandings are not forgotten (e.g., Binder, Haughton & Bateman,
2002; Church, 1999; Johnson & Layng, 1994). The results of the research
into fluency and fluency building, although essential for planning
effective teaching-practice cycles is almost completely unknown to the
majority of classroom teachers.

**Research into teaching programmes which are effective for all
children**

Following discovery of the key component skills which must be mastered
in order to learn to read we are making good progress in developing
reading teaching procedures which will ensure that all young children
master each of these skills and hence learn to read in a timely fashion
(Church, 2005; National Reading Panel, 2000). The best of the
scientifically developed reading programmes have a Year 2-3 failure rate
of less than 5%. In other words there are a number of reading programmes
which result in 95% of children learning to read in a timely fashion
rather than the 80% which currently occurs in New Zealand classrooms
(Church, 2005). Two of the most extensively evaluated reading programmes
(which have been shown to be effective for *all* children, including low
achieving children and children from impoverished environments) are the
Direct Instruction Reading programmes (Adams & Engelmann, 1996) and the
Success for All reading programme (Slavin & Madden, 2001).

**Research into accelerating progress through the curriculum**

Not only do the best of the scientifically derived teaching programmes
greatly reduce the number of children who fail, they also result in a
very considerable acceleration of the rate of progress of all children.
For example, there have been multiple demonstrations of the introduction
of scientifically designed teaching programmes being introduced to
entire schools with the result that the children in that school achieve,
on average, twice the national average rate of progress through the
early years of the school curriculum (e.g., Adams & Engelmann, 1996;
Johnson & Layng, 1994; Slavin & Madden, 2001).

By combining our emerging scientific knowledge of the various learning
processes in novel ways, scientifically oriented researchers have begun
to develop instructional systems which are considerably more effective
than anything previously reported in the educational research literature
(e.g. Heward, et al., 2004; Gardner et al., 1994; Moran & Malott, 2004).
In addition to the Direct Instruction programmes and the Success for All
programmes, these measurably superior teaching arrangements include
Greenwood's Classwide Peer Tutoring (e.g., Greenwood, Delquadri & Hall,
1989), Precision Teaching (Lindsley, 1991), Generative Instruction
(Johnson & Layng, 1994), the CABAS programme (Greer, 1994), decision
rule systems (e.g., Liberty & Haring, 1990; Fuchs, Fuchs & Hamlet,
1994), and mastery learning systems (e.g., Sherman, Ruskin & Semb,
1982). Each of these programmes has produced large and reproducible
gains in rate of learning across individual learners, across teachers,
and across time.

**Research into adapting instruction to prevent learning failures**

As a result of scientific research we have discovered how to track, from
lesson to lesson, the improvements in new skills and/or understandings
which are occurring during the course of instruction (e.g., Church,
1996; Deno & Fuchs, 1987; Shapiro, 1996) and we have discovered that the
children of teachers who have mastered these skills learn more (because
their teachers make better adaptive teaching decisions) than the
children of teachers who have not mastered these skills (e.g., Stecker &
Fuchs, 2000).

**The development of interventions which are effective in accelerating
the development of children with special teaching needs**

The 1998 issue of the *Journal of Clinical Child Psychology* which
reviewed the then current state of development in remedial treatments
for children with special needs showed that very considerable progress
had been made with respect to the design of effective treatments for
children with various types of disabilities. In that particular issue,
Kaslow and Thompson (1998) identified a number of effective
interventions for children and teenagers with depression, Ollendick and
King (1998) identified a number of effective treatments for children
with anxiety disorders, Brestan and Eyberg (1998) identified several
well-established treatments for children with disruptive and antisocial
behaviour difficulties, and Rogers (1998) reviewed the research into the
effectiveness of various teaching programmes for children with autism.
Not only were effective interventions identified for each of these
groups of children, many qualified as well established, and all had been
derived by behaviour analysts from basic scientific research into the
conditions responsible for the development of these types of
developmental problems.

Other reviewers have identified effective interventions for children
with intellectual disabilities (Snell, 1997), for children with
stuttering and other types of speech disorders (Gillon & Schwartz, 1998)
and have extended the findings of the 1998 reviews to identify effective
interventions for children with antisocial behaviour difficulties at
various age levels (Church, 2003).

**Research which demonstrates the possibility of scientifically oriented
research into classroom practice**

One of the most interesting by-products of all of this scientific
research into learning and teaching has been the repeated demonstration
that *classroom teachers* can function as researchers and can undertake
successful teaching evaluations and teaching experiments with children
in their own classrooms. This has become possible because of the
development of progress monitoring procedures and single case
experimental procedures which bring experimentation within the reach of
the classroom teacher (Church, 1975, 1996; Neuman & McCormick, 1995).
For the first time in the history of research on teaching it is now
possible for classroom teachers to move beyond qualitative \"action
research\" and to develop forms of practitioner research which are more
closely akin to the clinician research and experimentation which
characterises the more mature professions such as medicine.

Unlike previous forms of practitioner research which were largely
narrative and descriptive, the new practitioner research is experimental
and this creates considerable potential to stimulate improvements in
teaching practice. \"Single subject methodology is well suited for
teacher research in schools since it can be situated in ongoing
instruction. . . This methodology provides practice-oriented ways for
field-based personnel to learn more about what is effective - and what
is not - in what they do\" (Neuman & McCormick, 1995, p. 29).

Much the research reviewed in Book 4 and Book 5 of this site is research
which has been undertaken by practitioners. We have also set aside the
final volume (Book 9) to receive reports of practitioner research which
meet the inclusion criteria for this site.
:::

::: referencesList
#### References

-   Adams, G. L., & Engelmann, S. (1996). Research on Direct
    Instruction: 25 years beyond DISTAR. Seattle, WA: Educational
    Achievement Systems.
-   Binder, C., Haughton, E., & Bateman, B. (2002). Fluency: Achieving
    true mastery in the learning process. Retrieved January, 2004, from
    http://www.haughtonlearningcenter.com
-   Brestan, E. V., & Eyberg, S. M. (1998). Effective psychosocial
    treatments of conduct-disordered children and adolescents: 29 years,
    82 studies, and 5,272 kids. Journal of Clinical Child Psychology,
    27, 180-189.
-   Broughton, S. F., & Lahey, B. J. (1978). Direct and collateral
    effects of positive reinforcement, response cost, and mixed
    contingencies for academic performance. Journal of School
    Psychology, 16, 126-136.
-   Chall, J. S. (2002). The academic achievement challenge: What really
    works in the classroom? New York: Guilford Press.
-   Church, R. J. (1975). Could teachers be doing worthwhile research?
    set, Number 1, Item 5.
-   Church, R. J. (1976). A study of the components of an effective
    teaching strategy. Unpublished doctoral dissertation. University of
    Canterbury: Education Department.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North, New Zealand: New
    Zealand Association for Research in Education.
-   Church, R. J. (1999). Instructional Processes. Christchurch, New
    Zealand: University of Canterbury, Education Department.
-   Church, R. J. (2003). The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Christchurch, New Zealand: University of Canterbury,
    Education Department.
-   Church, R. J. (2005, December). The origins and treatment of delayed
    development in learning to read: A review of research. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin, New Zealand.
-   Deno, S. L., & Fuchs, D. (1987). Developing curriculum-based
    measurement systems for data-based special education problem
    solving. Focus on Exceptional Children, 19, 1-16.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications. Eugene, OR: ADI Press.
-   Fuchs, L. S., Fuchs, D., & Hamlett, C. L. (1994). Strengthening the
    connection between assessment and instructional planning with expert
    systems. Exceptional Children, 61, 138-146.
-   Gardner, R., Sainato, D. M., Cooper, J. O., Heron, T. E., Heward, W.
    L., Eshleman, J. et al., (Eds.). (1994). Behavior analysis in
    education: Focus on measurably superior instruction. Pacific Grove,
    CA: Brooks/Cole Publishing Co.
-   Gillon, G., & Schwarz, I. (1998). An international literature review
    of best practices in speech and language therapy August, 1998.
    Christchurch, New Zealand: University of Canterbury, Department of
    Speech and Language Therapy.
-   Greenwood, C. R. (2001). Science and students with learning and
    behavioral problems. Behavioral Disorders, 27, 37-52.
-   Greenwood, C. R., Delquadri, J. C. & Hall, R.V. (1989). Longitudinal
    effects of classwide peer tutoring. Journal of Educational
    Psychology, 81, 371-383.
-   Greer, R .D. (1994). The measure of a teacher. In R. Gardner, D. M.
    Sainato, J. O. Cooper, Y. E. Heron, W. L. Heward, J. W. Eshleman et
    al. (Eds.), Behavior analysis in education: Focus on measurably
    superior instruction (pp. 161-171). Pacific Grove, CA: Brooks Cole.
-   Hermann, G. (1969). Learning by discovery: A critical review of
    studies. Journal of Experimental Education, 38, 58-72.
-   Heward, W. L., Heron, T. E., Neef, N. A., Peterson, S. M.,
    Sainato, D. M., Cartledge, G., et al. (Eds.). (2004). Focus on
    behavior analysis in education: Achievement, challenges and
    opportunities. Englewood Cliffs, NJ: Prentice Hall.
-   Johnson, K. R., & Layng, T. V. J. (1994). The Morningside model of
    generative instruction. In R. Gardner, D. M. Sainato, J. O.
    Cooper, Y. E. Heron, W. L. Heward, J. W. Eshleman et al. (Eds.),
    Behavior analysis in education: Focus on measurably superior
    instruction (pp. 173-197). Pacific Grove, CA: Brooks/Cole Publishing
    Co.
-   Kaslow, N. J., & Thompson, M. P. (1998). Applying the criteria for
    empirically supported treatments to studies of psychosocial
    interventions for child and adolescent depression. Journal of
    Clinical Child Psychology, 27, 146-155.
-   Klahr, D., & Nigam, M. (2004). The equivalence of learning paths in
    early science instruction: Effects of direct instruction and
    discovery learning. Psychological Science, 15, 661-667.
-   Liberty, K. A., & Haring, N. G. (1990). Introduction to decision
    rule systems. Remedial and Special Education, 11(1), 32-41.
-   Lindsley, O. R. (1991). Precision teaching's unique legacy from B.F.
    Skinner. Journal of Behavioral Education, 1, 253-266.
-   Lovitt, T. C., Guppy, T. E. & Blattner, J. E. (1969). The use of a
    free-time contingency with fourth graders to increase spelling
    accuracy. Behavior Research and Therapy, 7, 151-156.
-   Martella, R. C., Nelson, J. R., & Marchand-Martella, N. E. (2002).
    Managing disruptive behaviour in the schools: A school wide,
    classroom, and individualized social learning approach. Boston:
    Allyn & Bacon.
-   Mayer, R. E. (2004). Should there be a three-strikes rule against
    pure discovery learning? American Psychologist. 59, 14-19.
-   McCleery, J. A., & Tindal, G. A. (1999). Teaching the scientific
    method to at-risk students and students with learning disabilities
    through concept anchoring and explicit instruction. Remedial and
    Special Education, 20, 7-18.
-   Moran, D. J., & Malott, R. W. (Eds.). (2004). Evidence-based
    educational methods. San Diego, CA: Elsevier Academic Press.
-   Muthukrishna, N., Carnine, D., Grossen, B., & Miller, S. (1993).
    Children\'s alternative frameworks: Should they be directly
    addressed in science instruction. Journal of Research in Science
    Teaching, 30, 233-248.
-   National Reading Panel. (2000). Teaching children to read: An
    evidence-based assessment of the scientific research literature on
    reading and its implications for reading instruction. Retrieved 17
    December, 2001 from National Institute of Child Health & Human
    Development Website: http://www.nichd.nih.gov/ publications/nrp
-   Neuman, S. B. & McCormick, S. (Eds.). (1995). Single subject
    experimental research: Applications for literacy. Newark, NJ:
    International Reading Association.
-   Ollendick, T. H., & King, N. J. (1998). Empirically supported
    treatments for children with phobic and anxiety disorders: Current
    status. Journal of Clinical Child Psychology, 27, 156-167.
-   Pressley, M., Harris, K. R., & Guthrie, J. T. (Eds.). (1992).
    Promoting academic competence and literacy in school. San Diego, CA:
    Academic Press Inc.
-   Rogers, S. J. (1998). Empirically supported comprehensive treatments
    for young children with autism. Journal of Clinical Child
    Psychology, 27, 168-179.
-   Shapiro, E. S. (1996). Academic skills problems: Direct assessment
    and intervention (2nd ed.). New York: The Guilford Press.
-   Sherman, J. G., Ruskin, G., & Semb, G. B. (Eds.). (1982). The
    Personalised System of Instruction: 48 seminal papers. Lawrence, KS:
    TRI Publications.
-   Slavin, R. E. (1990). Cooperative learning: Theory, research and
    practice. Englewood Cliffs, NJ: Prentice-Hall.
-   Slavin, R. E., & Madden, N. A. (Eds.). (2001). One million children:
    Success for all. Thousand Oaks, CA: Corwin Press.
-   Snell, M. E. (1997). Teaching children and young adults with mental
    retardation in school programs: Current research. Behaviour Change,
    14, 73-105.
-   Stecker, P. M. & Fuchs, L. S. (2000). Effecting superior achievement
    using curriculum-based measurement: The importance of individual
    progress monitoring. Learning Disabilities: Research and Practice,
    15, 128-134.
-   Sulzer-Azaroff, B., & Mayer, G. R. (1991). Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart and Winston.
-   Wolery, M., Bailey, D. B., & Sugai, G. M. (1988). Effective
    teaching: Principles and procedures of applied behavior analysis
    with exceptional students. Boston: Allyn and Bacon Inc.
:::"
".//Theproblemtobesolved/Isamovefromcraft-toevidence-basedpracticepossible/index.md","# Is a move from craft- to evidence-based practice possible? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a2dd96d12c5f446c93c4240ab81a2152}
The suggestion that we should begin the transition from craft-based
teaching practices to evidence-based teaching practices rests on the
central assumption that there exists a tradition of scientific research
into learning and teaching together with a corpus of research findings
which are directly relevant to improving the effectiveness of current
classroom practice. Embedded in this assumption are two important
questions. First, is the scientific research into the conditions
necessary for learning sufficiently advanced to be used in guiding
design experiments aimed at the development of more effective teaching
procedures? Secondly, is the research on teaching sufficiently advanced
to enable the development of evaluation procedures which will enable
teachers to distinguish between effective and ineffective teaching
procedures and programmes?
:::"
".//Theproblemtobesolved/Isamovefromcraft-toevidence-basedpracticepossible/Howextensiveistheresearchinlearningprocesses/index.md","# How extensive is the research in learning processes? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4532417c6c19471e914a0589e9b9b64b}
University of Canterbury, Christchurch, New Zealand. © University of
Canterbury 2008.

The earliest explorations of the conditions necessary for learning were
made by social scientists and cognitive scientists. These contributions
are described in most conventional educational psychology textbooks
(e.g. Gage & Berliner, 1998; Slavin, 1999) and have been summarised in
many meta-analyses and reviews of meta-analyses (e.g. Lipsey & Wilson,
1993). The work of cognitive psychologists has identified a number of
the variables which operate when students are engaged in unstructured
and semi-structured learning activities. Variables which have been found
to have reproducible effects on remembering include such things as the
age of the learner, recency, list length, amount of practice,
meaningfulness of the material to be remembered, the quality of the
explanations provided by the teacher, the provision of learning goals
and study questions, conditions which motivate self-rehearsal of the
material to be learned, corrective feedback following errors, the
teaching of certain types of study skills, and so on (Cawelti, 2004;
Lipsey & Wilson, 1993; Walberg, 1986; Walberg & Wang, 1987; Wang,
Haertel, & Walberg, 1993; Wittrock, 1986).

Following the development of repeated measures, single case procedures
and their application to the experimental analysis of teaching and
learning in the early 1970's, rapid progress has been made in
identifying instructional variables which directly affect rate of
learning -- with over 1,500 such experiments having been reported to
date. This research is beginning to reframe our view of the behaviour
changes which we refer to as learning and the relationships between
teaching variables and learning (e.g. Church, 1999b, 2004).

**Conditions necessary for different kinds of learning**

As a result of this research we have discovered that there are different
kinds of learning outcomes which teachers and teaching researchers need
to distinguish between. This is because different kinds of teaching and
practice conditions need to be provided before the learning and
remembering of different kinds of skills and understandings can occur
(Church, 1999b; Engelmann & Carnine, 1993). For example, we now know
that meanings and attitudes are acquired primarily through respondent
processes while motivation, new skills, new concepts, and so on are
acquired primarily through operant processes. We also know that
motivation requires the presence of conditions which are different to
those which are required for acquisition and that different conditions
are required during the initial, independence and fluency building
phases of acquisition processes. The implications of these distinctions
for the scientific study of learning processes will be considered in
greater detail in Book 4 of this website.

**Research on child development**

In addition, there is a very extensive research base in child
development charting the developmental trajectories which most children
follow with respect to physical development, the development of large
motor skills, language acquisition, learning to read, the acquisition of
writing skills, the development of mathematical concepts and skills,
social development, the acquisition of initial scientific
understandings, and so on (e.g., Brown, 1973; Geary, 1996; Gessell,
1940, 1956; Gessell, Ilg, Ames & Bullis, 1946; Gordon, 1986; Meggitt,
2006; Piaget, 1930).

There is also a very large research base describing the way in which
these typical developmental trajectories can be interrupted in children
with physical disabilities, intellectual disabilities, learning
disabilities, emotional and behavioural disorders, and so on (e.g.,
Church, 2003; Hallahan & Kauffman, 2005; Heward, 2005).

**The determinants of motivation**

Research on learning has identified many of the variables upon which
motivation depends. We have discovered that the consequences of student
effort are the most important variables (rather than the interest level
of instructional activities) and researchers have explored in some
detail the effects of different kinds of consequences, schedules of
consequences, and contingencies on motivation, effort, productivity, and
persistence (e.g., Catania, 1998; Cooper, Heron & Heward, 2007; Malott,
Whaley & Malott, 1993).

**Conditions necessary for the development of meaning**

We have discovered the basic process involved in the acquisition of word
meaning and have found, from research, that new meanings are acquired
almost instantaneously and sometimes without conscious effort
(DeGrandpre, 2000; Staats, 1968). This finding is quite contrary to the
view that the acquisition of new meanings requires a process of
conscious of meaning construction.

**Conditions necessary for acquisition**

Analysis of the conditions necessary in order for different kinds of
acquisition to occur is well advanced. This research includes
experimental analyses of the conditions necessary for language
development (e.g., Hart & Risley, 1995; Sidman, 1994); the conditions
necessary for the development of various kinds of motor skills (e.g.,
Ward, Crouch, & Patrick, 1998), the conditions necessary for the
development of mathematical competencies (e.g., Paine, Carnine, White, &
Walters, 1982) and the conditions necessary for the development of
literacy skills including decoding fluency (e.g., Church, Nixon,
Williams & Zintl, 2005), reading (e.g., Church & Martin, 1992;), reading
comprehension (e.g., Bruce & Chan, 1991), handwriting (e.g., Trap,
Milner-Davis, Joseph & Cooper, 1978), spelling (e.g., Okyere, Heron &
Goddard, 1997), and compositional writing (e.g., Hopman & Glynn, 1988).

**Conditions necessary for learning to read**

We have discovered the key component skills which must be mastered in
order to learn to read (e.g., Church, 2005; National Reading Panel,
2000). We have discovered that complex skills, such as reading, require
mastery of a number of component skills and that, if the component
skills are not mastered at the right time, then the child may never
master the more complex skill during their years at school.

**Identification of a useful unit of analysis**

Learning researchers have identified the basic unit of analysis which
needs to be tracked during the study of acquisition processes -- the
three term contingency (Albers & Greer, 1991; Church, 1999a) and have
made a start in seeking to discover the number of learning interactions
which are necessary during the acquisition of different types of
academic skills (e.g., McLay, 2003; McWilliams, 2005).

**Number of practice responses and their distribution in time**

We have discovered not only that learning interactions must be within
the child's zone of proximal development but also that the number of
times that a child comes into contact with a particular word, fact, or
concept is the most important determinant of whether or not that word,
fact or concept will be remembered (e.g., Church, 1976; Greenwood,
Delquadri & Hall, 1984; Hart & Risley, 1995; Nuthall, 1999, 2007).

We have discovered not only that the number of learning opportunities is
critical but also that their distribution in time is critical as well. A
new item of knowledge is only remembered if the child gets to work with
that idea on at least four occasions with no more than two days between
each learning opportunity (Nuthall, 1999). The work on response
opportunity and the distribution of practice responses in time has
profound implications for teaching research for it means that
experimental analyses of learning and teaching are only likely to
generate interpretable results if the number of learning opportunities
and their scheduling is controlled, or at least recorded, across all
experimental conditions (McWilliams, 2005).

**Conditions necessary for long term retention**

A long tradition of research into the retention process has revealed
that recall speed (also referred to as level of automaticity or level of
fluency) is the best predictor of long term retention and this has led
to the development of practical ways of measuring fluency in academic
subjects and research into the fluency criteria which predict long term
retention (e.g., Church, 1999b; Johnson & Layng, 1994).

**Identification of research procedures which work**

Most importantly we have learned, as a result of more than 1,500
experiments, how to measure motivation, learning, and the development of
mastery in individual learners and we have learned how to accurately
measure the effects of particular social and instructional conditions on
motivation, learning and the development of mastery in individual
learners (e.g. Church, 1996; Fuchs & Fuchs, 2001; Johnston &
Pennypacker, 1993).

A description of the main types of learning which need to be
distinguished and the main events which have been shown to influence
learning will be found in Book 2 of this website and a detailed account
of the scientific research into the conditions necessary in order for
these different kinds of learning to occur will be found in Book 4 of
this site.
:::

::: referencesList
#### References

-   Albers, A. E. & Greer, R. D. (1991). Is the three-term contingency
    trial a predictor of effective instruction? Journal of Behavioral
    Education, 1: 337-345.
-   Brown, R. (1973). A first language: The early stages. Cambridge, MA:
    Harvard University Press.
-   Bruce, M. E., & Chan, L. K. S. (1991). Reciprocal teaching and
    transenvironmental programming: A program to facilitate the reading
    comprehension of students with reading difficulties. Remedial and
    Special Education, 12, 44-54.
-   Catania, A. C. (1998). Learning (4th ed.). New York: Prentice Hall.
-   Cawelti, G. (Ed.). 2004. Handbook of research on improving student
    achievement (3rd ed.). Arlington, VA: Educational Research Service.
-   Church, R. J. (1976). Components of an effective teaching strategy.
    Unpublished PhD thesis. Christchurch, New Zealand: University of
    Canterbury.
-   Church, R. J. (1996). Within-subject experimental analysis: A guide
    for students in education. Palmerston North: New Zealand Association
    for Research in Education.
-   Church, R. J. (1999a). Basic learning processes. Christchurch, New
    Zealand: University of Canterbury, Education Department.
-   Church, R. J. (1999b). Instructional processes. Christchurch, New
    Zealand: University of Canterbury, Education Department.
-   Church, R. J. (2003). The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Report prepared for the Ministry of Education.
    Christchurch, N.Z.: University of Canterbury, Education Department.
-   Church, R. J. (2004). Critical teaching variables which govern rate
    of learning. Course reader: Introduction to interventions.
    Christchurch, New Zealand: University of Canterbury, School of
    Education.
-   Church, R. J. (2005, December). The origins and treatment of delayed
    development in learning to read: A review of research. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin, New Zealand.
-   Church, R. J. & Martin, T. (1992). The Co-operative Reading Resource
    and how it changed the reading skill of 8- and 9-year olds. Set, No
    2, Item 6.
-   Church, R. J., Nixon, J., Williams, D. & Zintl, S. (2005, December)
    Building decoding fluency in 8- to 9-year old poor readers. Paper
    presented to the annual conference of the New Zealand Association
    for Research in Education, Dunedin.
-   Cooper, J. O., Heron, T. E., & Heward, W. I. (2007). Applied
    behavior analysis (2nd ed.). Upper Saddle River, NJ: Pearson
    Educational.
-   DeGrandpre, R. J. (2000). A science of meaning: Can behaviorism
    bring meaning to psychological science? American Psychologist, 55,
    721-739.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications. Eugene, OR: ADI Press.
-   Fuchs, L. S., & Fuchs, D. (2001). Computer applications to
    curriculum-based measurement. Special Services in the Schools,
    17(1-2), 1-14.
-   Gage, N. L. & Berliner, D. C. (1998). Educational psychology (6th
    ed.). Boston: Houghton Mifflin Company.
-   Geary, D. C. (1996). Children's mathematical development: Research
    and practical applications. American Psychological Association.
-   Gessell, A. (1940). The first five years of life. New York: Harper &
    Row.
-   Gessell, A. (1956). Youth: The years from ten to sixteen. New York:
    Harper.
-   Gessell, A., Ilg, F. L., Ames, L. B., & Bullis, G. E. (1946). The
    child from five to ten. New York, Harper & Row.
-   Gordon, W. (1986). The meaning makers: Children learning language
    and using language to learn. Portsmouth, NH: Heinemann Educational
    Books.
-   Greenwood, C. R., Delquadri, J. C., & Hall, R. V. (1984).
    Opportunity to respond and student academic performance. In W. L.
    Heward, T. E. Heron, D. S. Hill, & J. Trap-Porter (Eds.) Focus on
    behavior analysis in education (pp. 58-88). Columbus, OH: Charles E.
    Merrill Publishing Co.
-   Hallahan, D. P., & Kauffman, J. M. (2005). Exceptional learners:
    Introduction to special education (10th ed.). Boston: Allyn & Bacon.
-   Hart, B., & Risley, T. R. (1995). Meaningful differences in the
    everyday experience of young American children. Baltimore: Brookes.
-   Heward, W. L. (2005). Exceptional children: An introduction to
    special education (8th ed.). Upper Saddle River, NJ: Prentice Hall.
-   Hopman, M., & Glynn, T. (1988). Behavioural approaches to improving
    written expression. Educational Psychology, 8, 81-100.
-   Johnson, K. R., & Layng, T. V. J. (1994). The Morningside model of
    generative instruction. In R. Gardner et al. (Eds.), Behavior
    analysis in education: Focus on measurably superior instruction (pp.
    173-197). Pacific Grove: Brooks/Cole Publishing Co.
-   Johnston, J. M. & Pennypacker, H. S. (1993). Strategies and tactics
    of behavioral research. (2nd ed.) Hillsdale, NJ: Lawrence Erlbaum.
-   Lipsey, M. W., & Wilson, D. B. (1993). The efficacy of
    psychological, educational and behavioral treatment. American
    Psychologist, 48, 1181-1209.
-   Malott, R. W., Whaley, D. L., & Malott, M. E. (1993). Elementary
    principles of behavior (2nd ed.). Englewood Cliffs, NJ: Prentice
    Hall.
-   McLay, L. K (2003). Acquisition, retention and generalisation of
    object names in 4 year old children during child initiated and adult
    initiated learning interactions. Unpublished M.Ed. dissertation.
    Christchurch, New Zealand: University of Canterbury, School of
    Education.
-   McWilliams, K. 2005. An analysis of variables affecting
    instructional efficiency. Unpublished PhD thesis. Christchurch, New
    Zealand: University of Canterbury.
-   Meggitt, C. (2006). Child development: An illustrated guide. Oxford,
    England: Harcourt Heinemann.
-   National Reading Panel. (2000). Teaching children to read: An
    evidence-based assessment of the scientific research literature on
    reading and its implications for reading instruction. Retrieved 17
    December, 2001 from National Institute of Child Health & Human
    Development Website: http://www.nichd.nih.gov/ publications/nrp
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Nuthall, G. (2007). The hidden lives of learners. Wellington, N.Z.:
    NZCER Press.
-   Okyere, B. A., Heron, T. E., & Goddard, Y. (1997). Effects of
    self-correction on the acquisition, maintenance, and generalization
    of the written spelling of elementary school children. Journal of
    Behavioral Education, 7, 51-69
-   Paine, S. C., Carnine, D. W., White, W. A. T., & Walters, G. (1982).
    Effects of fading teacher presentation structure (covertization) on
    acquisition and maintenance of arithmetic problem-solving skills.
    Education and Treatment of Children, 5, 93-107.
-   Piaget, J. (1930). The child's conception of physical causality.
    London: Kegan Paul.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
-   Slavin, R. E. (1999). Educational psychology: Theory and practice
    (6th ed.). Needham Heights, MA: Allyn & Bacon.
-   Staats, A. W. (1968). Learning, language, and cognition. New York:
    Holt, Rinehart and Winston, Inc.
-   Trap, J. J., Milner-Davis, P., Joseph, S., & Cooper, J. O. (1978).
    The effects of feedback and consequences on transitional cursive
    letter formation. Journal of Applied Behavior Analysis, 11, 381-393.
-   Walberg, H. J. (1986). Syntheses of research on teaching. In M. C
    Wittrock (Ed.), Handbook of research on teaching (3rd ed., pp.
    214-229). New York: Macmillan Publishing Co.
-   Walberg, H. J., & Wang, M. C. (1987). Effective educational
    practices and provisions for individual differences. In M. C.
    Wang, M. C. Reynolds & H. J. Walberg (Eds.), Handbook of special
    education research and practice, Vol. 1 (pp. 113-128). Oxford,
    England: Pergamon Press.
-   Wang, M. C., Haertel, G. D., & Walberg H. J. (1993). Toward a
    knowledge base for school learning. Review of Educational Research,
    63, 249-294.
-   Ward, P., Crouch, D. W., & Patrick, C. A. (1998). Effects of
    peer-mediated accountability on opportunities to respond and correct
    skill performance by elementary school children in physical
    education. Journal of Behavioral Education, 8, 103-114.
-   Wittrock, M. C. (Ed.). (1986). Handbook of research on teaching (3rd
    ed.). New York: Macmillan Publishing Co.
:::"
".//Theproblemtobesolved/index.md","# The problem to be solved \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-35fea2ac90bf4814af23bb227ef39b65}
The teaching activities which occur in classrooms have changed little
during the past 80 years -- a fact which has been documented many times.
Compare this with the very considerable scientific and technological
advances which have occurred in almost all other professions during the
20th century. Unlike medical practice, where the traditional craft
philosophy of patient care was gradually replaced by the revolutionary
new clinical science during the first half of the 20th century, teaching
practice has remained, to this day, a craft largely untouched by the
scientific research on learning and teaching.

It does not need to be this way. Very considerable advances have been
made in the scientific analysis of both learning and teaching. However,
it is true that the scientific research into learning and teaching is
buried under a mountain of pre-scientific research. This makes the
scientific research difficult to find and difficult to use in the
development of more effective classroom teaching practices and
programmes.

In this book we examine the nature of the problem to be solved, examine
what would count as evidence-based practice, ask whether a move from
craft-based to evidence-based practice is possible at this time, and
identify some of the conditions which will need to be present before a
change from craft-based to evidence-based practice is likely to occur.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Theselectionandspecificationofexitcriteria/index.md","# The selection and specification of exit criteria \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6505752cd3684af1affbd34f63cb1ee2}
Sooner or later, the teacher will decide that a given response, skill or
understanding has received sufficient practice and will move the student
on to the next topic or set of skills specified by the curriculum. Exit
criteria are referred to using a variety of terms \"performance
criteria\", \"mastery criteria\", \"fluency criteria\", \"promotion criteria\"
and so on.

Amount of practice can be described both for classroom purposes and
research purposes in a variety of ways: (a) by specifying the number of
minutes spent in practice, (b) by specifying the number of practice
responses engaged in during practice or (c) by specifying the fluency
criterion which had to be achieved in order to exit from practice. The
first measure (time spent) is never a satisfactory measure because
different learners complete different numbers of practice responses
during a given period of time. The third measure (practice to a given
level of fluency) has the advantage of allowing the teacher and the
teaching researcher to measure both the effectiveness and the efficiency
of the teaching or practice procedure under examination. The advantage,
for teachers, of using a fluency criterion as the criterion for deciding
when to move a child on to the next step in the curriculum is that
fluency criteria can be objectively specified and the level of fluency
which a child has reached can be objectively measured.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Numberofpracticeopportunities/index.md","# Number of practice opportunities \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e0b31ee55d1a4da39ac6f9be96c4c6fa}
Someone who is trying to learn a new idea, or concept, or word or skill
may experience any number of practice opportunities involving that new
idea or skill from none to thousands. Only if practice responses occur
can learning occur. If only one or two practice responses occur it is
extremely unlikely that the new idea or skill will be learned and
remembered. This makes practice responses a necessary condition for
learning and it makes the number of practice opportunities experienced
by the learner the major determinant of learning. Because the number of
practice responses is a major determinant of learning it follows that
this variable is the most important of the variables which needs to be
managed by teachers and the most important of the variables which must
be controlled and recorded during research into learning and teaching.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Thesizeofthepracticeset/index.md","# The size of the practice set \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-97b7f6ed640346b9badd3bed0f51c51f}
When students are acquiring or practising new responses the number of
different responses in the set of practice responses may vary from one
to many dozens. For example, a child might be given the task of learning
or practising a single spelling word, a set of five new spelling words,
or a set of 10 new words. The term \"practice set\" refers to the set of
different responses which the learner is expected to study or practice
during a single lesson or practice session and the term \"size of the
practice set\" refers to the number of different responses which the
learner is expected to practice during a single session.

The size of the practice set is a critical learning variable for two
reasons. First, the practice set needs to be greater than working memory
capacity otherwise the child may be able to respond to practice stimuli
from working memory with little learning occurring as a result. Second,
working memory increases with age which means that the size of the
practice set also needs to increase with age.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Thedistributionofpracticeopportunitiesintime/index.md","# The distribution of practice opportunities in time \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5e30704de8754854b1af830911388daf}
The practice opportunities which are necessary for learning and
remembering may be distributed across time in a wide variety of ways --
clumped together in a single learning activity, spread across several
days, or distributed across many months. It is now known that the
learning of a new response, skill or understanding depends not only on
the number of practice opportunities involving that response but also on
the time which elapses between successive practice opportunities
involving that response. There is evidence that mammalian brains
continue to process new experiences for up to 24 hours (Rose, 1993).
There is also evidence to suggest that, during the acquisition phase,
new responses are likely to be remembered when practice opportunities
are less than 2 days apart but not when practice opportunities are more
than 2 days apart (Nuthall, 1999; Nuthall & Alton-Lee, 1993).

There was some indication that this might be the case in the earlier
research into massed versus spaced practice. The term \"spaced practice\"
refers to the use of regular (e.g. daily) short practice sessions.
\"Massed practice\" refers to the use of less frequent (e.g. weekly) but
longer practice sessions. The research into massed and spaced practice
long ago demonstrated that both children and adults make more rapid
progress in learning a set of new responses or skills when practice time
is distributed across short daily practice sessions than when that same
time is spent in a single longer practice session such as a weekly
practice session (Dempster, 1991). We now know that this is probably
because the brain retains the capacity to remember initial practice
responses for a day or two but not for any longer.

Although the scheduling of practice opportunities has important effects
on learning, there exist no agreed terms for describing the scheduling
of practice opportunities (which involve the same response) across time
and no agreed way of quantifying variations in the scheduling of
response opportunities across time. We cannot use the older terms
\"massed\" and \"spaced\" practice because these terms are too imprecise.
The lack of a procedure for measuring and describing the distribution of
practice responses in time is a major impediment to the scientific study
of learning and teaching.

To summarise, effective teaching involves knowing not only how many
practice opportunities are required in order to learn and remember a new
response, skill, or understanding but also how these must be distributed
in time. This means that research into learning and teaching must
control and describe not only (a) the number of practice opportunities
which occurred with respect to each response, skill or item of
information being taught but also (b) the distribution of each of these
practice opportunities in time for each individual learner.
:::

::: referencesList
#### References

-   Dempster, F. N. (1991). Synthesis of research on reviews and tests.
    Educational Leadership, 48(7), 71-76.
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Rose, S. (1993). The making of memory. Toronto: Bantam Books.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/index.md","# Practice response sequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8b572ae6e1604af99a2221242032c79b}
One of the functions of the learning activities which occur in
classrooms is to provide learners with the opportunity to acquire and
practice curriculum relevant skills and understandings. We are using the
term \"practice opportunity\" to refer to learning interactions involving
the *same* response, behaviour, or skill. (We have had to invent this
term because there is no word in the English language which refers to
\"learning interactions involving the same behaviour\".) Some of the ways
in which practice responses can vary have already been described. For
example, we have already distinguished between overt and covert practice
responses, constructed responses and selection responses, various
response modes, various types of practice opportunities, and variations
in response effort.

The changes that we refer to as learning all require a certain amount of
practice, that is, they are likely to be acquired only if the learner
experiences an adequate number of practice opportunities. When children
are practising a new skill or understanding, this practice can vary in
many ways. It can vary with respect to the length of the practice
session, the number of different responses which are practised in any
one session, the number of times the same response is practised in any
one session, the ratio of yet-to-be learned to previously learned
responses in a session, the total number of practice opportunities
experienced by the learner, the distribution of these practice responses
in time, whether the practice is timed or untimed and the type of
criterion which is used in deciding when the learner should cease
practice on the current skill and progress to the next skill in the
curriculum.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Theinterspersalratio/index.md","# The interspersal ratio \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-27e62d0ea49940a0b27fc7076c509f6e}
A practice set may consist of responses, skills or understandings which
have already been acquired (but which still need further practice). Or
it may consist of responses which have yet to be acquired. Or it may
consist of a mixture of previously acquired and yet to be acquired
responses. The simplest way of defining a practice set which consists of
a mixture of learned and yet to be learned items is in terms of the
interspersal ratio. *The interspersal ratio refers to the ratio of yet
to be learned to previously learned responses in the practice set for a
particular lesson, learning activity or practice session.*

The interspersal ratio is not the same as the accuracy level during
practice. The interspersal ratio refers to the ratio of yet to be
mastered responses compared to previously acquired responses (as
determined during previous practice sessions or tests). The accuracy
level during practice refers to the proportion of practice responses
which are correct compared to the total (correct plus incorrect)
practice responses during the current practice session.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Numberofpracticeopportunitiesperresponsepersession/index.md","# Number of practice opportunities per response per session \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-53679a036815462ba0293f2e9d1d77e5}
Each of a set of to-be-acquired responses may be practised once, twice
or many times during the course of a single lesson, learning activity or
practice session. How often a particular response is practised during a
particular session depends upon the size of the practice set, the time
set aside for practice, and the length of time which the learner
requires in order to complete each practice response. Since learning
depends upon the number of times a new response is practised and the way
in which these practice opportunities are scheduled in time, it can be
seen that the size of the practice set and the number of practice
opportunities per session are important instructional variables.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Practiceresponsesequences/Timedvsuntimedpractice/index.md","# Timed vs. untimed practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-724cf2d1b28747aebe4a1a22b60790fc}
Practice responses may be timed or untimed. During the initial
acquisition phase, teachers tend to be more concerned with improvements
in the learner's ability to respond correctly and untimed practice is
usually appropriate. Later, however, we often require students to
develop a certain level of mastery, that is, to learn to respond both
correctly and with a functional level of speed. In order to develop
speed, practice activities need to be timed so that both the teacher and
the student can determine whether or not increases in speed are being
achieved. It can be seen therefore that timed and untimed practice serve
quite different functions and must therefore be clearly distinguished
both during instructional planning and during the design of learning and
teaching experiments.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Presentationsequences/Examplerange/index.md","# Example range \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f4736207b15346b48b07958e9d6c793b}
During explanations and other types of presentation sequences, the
concept or principle under examination will usually be illustrated or
given meaning by the use of selected examples. The number of examples
may vary from a single example to a set of examples. A set of examples
may be \"typical\" examples or they may be more varied. Some textbooks
argue that concept examples should be selected to illustrate the outer
boundaries of the stimulus class, that is, the set of examples should
consist of a set of examples which are as varied as possible.

The range of examples contained in a sequence of presentations is an
important variable because it is this variable which operates to
determine, in part, the degree of generalised understanding which the
learner will develop. This variable also plays a role in preventing the
development of misconceptions about new concepts. If only a limited set
of examples of a new concept are used the learner may develop an
undergeneralised understanding of the concept.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Presentationsequences/Sequencingofexamplesandnon-examples/index.md","# Sequencing of examples and non-examples \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-94845acfa4eb4c81b4bf0f89235c1dae}
The sequence of concept examples and non-examples used within a set of
presentations or exercises may vary in many ways. The only
example/non-example sequencing procedure which has been studied in any
detail to date is the sequencing procedure which has come to be called
the \"general case procedure\". A general case teaching sequence is one in
which the sequencing of examples and non-examples conforms to the
following rules.

1.The teaching sequence includes a number of positive examples of the
concept and these positive examples illustrate the full range of values
which can be found in the stimulus class.

2.The teaching sequence includes a number of non-examples of the concept
and these non-examples are closely similar to the positive examples
which have been selected - especially with respect to irrelevant
features.

3.Positive examples are sequenced so that adjacent positive examples are
maximally different.

4.Example to non-example pairs (and vice versa) are sequenced so that
minimally different example/non-example pairs occur together.

5.Examples are sequenced in such a way that only one feature changes
from one example (or non-example) to the next.

Many other kinds of sequences are possible but, to date, the general
case sequencing procedure is the only one which has generated any
research and the only one which has been given a name. As can be seen
from the above rules, general case programming involves the selection
and sequencing of teaching examples in such a way as to teach the
desired generalisation without producing any misconceptions.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Presentationsequences/Presentationlength/index.md","# Presentation length \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e97dd122d9c9404eb89ed46d00bed814}
Presentations consist of curriculum relevant statements, propositions,
or claims about some topic. The expectation of the person doing the
presentation is that the learners will attend to the presentation.
Presentations can be of any length from a single proposition to a 50
minute lecture. Presentation length may be defined in terms of the
amount of material presented by the teacher from the end of one practice
response to the beginning of the next practice response. The amount of
material presented can be measured in terms of the number of
propositions contained in the presentation under examination.

Presentation length is an extremely important teaching variable given
that young children can only hold the content of one meaningful
proposition in working memory at a time and even adult learners can only
hold three or four propositions in working memory at any one time. Above
this, propositions which might have been processed or rehearsed (and
possibly remembered) are simply displaced by the incoming content of
subsequent presentations.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Presentationsequences/index.md","# Presentation sequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-29ac19aa95fd458882925a3f4f0e190d}
When teachers provide an explanation, take a lesson, give a lecture, and
so on, you will almost always observe sequences of presentations, that
is sequences of statements about the subject matter or topic which the
teacher is talking about. Presentation sequences also occur during
multi-media presentations such as instructional videos and films,
illustrated lectures, and so on. Some of the ways in which presentations
can vary have been listed already. Just as individual presentations can
vary with respect to presentation mode, content, and meaningfulness so
can sequences of presentations. In addition, sequences of presentations
can vary with respect to their length, the number of and range of
examples referred to, the way in which examples and non-examples are
sequenced, and so on.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Presentationsequences/Non-examplerange/index.md","# Non-example range \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-316aa0e4de3e49ff83e513d45f4a7d0e}
Presentations about concepts and principles also tend to include
non-examples of the concept or principle under examination. Non-examples
are important instructional events because they can teach the learner
what the concept is not. The number of non-examples may vary from a
single non-example to a set of non-examples. A set of non-examples may
consist of instances which are widely different from the examples used
or they may consist of close-in non-examples. Close-in non-examples are
instances which are similar to the positive examples which are being
referred to in the presentation.

The number and type of non-examples used in a sequence of presentations
is a matter of some importance because this variable plays a critical
role in preventing the development of misconceptions about the concept
which is being discussed. If the non-examples selected to show what the
concept is not are widely dissimilar to the examples (rather than being
close-in non-examples), the learner may develop an overgeneralised
understanding of the new concept.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Contingencyerrors/Inadvertentpunishmentofdesiredbehaviour/index.md","# Inadvertent punishment of desired behaviour \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-fc871817e841428a8a82d5d4acd1ef74}
Careless, inappropriate, and antisocial behaviour often has aversive
outcomes. But it is possible for desirable, appropriate, and correct
responses to generate aversive consequences as well. A child may work
hard in class and complete all the set work ahead of time only to
discover that they are given more work to do -- a potentially aversive
consequence for working hard. A child may solve a maths problem using an
unusual procedure and have the solution marked wrong (because they used
the wrong procedure) -- a potentially aversive consequence for both
creativity and for producing the correct answer. A child may work hard
at a task which they find very difficult, only to be reprimanded for
failing to complete the task -- a potentially aversive consequence for
working as well as one is able to on an unreasonably difficult task.

One of the major causes of motivational problems in children of all ages
is the setting of tasks which are too difficult, which require much
effort, and which result in high levels of mistakes and negative
feedback. The effect of being required to work on such tasks is that the
child gradually loses interest and develops a dislike for this type of
task because working on such tasks too often generates aversive outcomes
and too infrequently generates reinforcing outcomes.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Contingencyerrors/Inadvertentpositivereinforcementofmisbehaviour/index.md","# Inadvertent positive reinforcement of misbehaviour \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-27d516312b104bbba28a070f05ce14d7}
Whether a particular behaviour is socially \"appropriate\" or
\"inappropriate\" is quite irrelevant when trying to identify the
contingency which is motivating continued use of that behaviour.
Desirable, appropriate, and correct responses often produce reinforcing
consequences. *But undesirable, inappropriate and incorrect responses
can produce reinforcing consequences too*.

While most parents and teachers try to ensure that only appropriate
responses are followed by reinforcing consequences, this aim is not
always achieved. A child who throws a tantrum may succeed in persuading
the parent to give the child what he or she wants -- with the result
that the parent inadvertently reinforces tantrumming. Inappropriate
attention seeking may succeed in attracting the pre-school teacher's
attention -- with the result that the pre-school teacher inadvertently
reinforces attention seeking. A student may make an error, the teacher
may praise the child (perhaps for effort) -- with the result that a
confusion on the part of the child is inadvertently reinforced. A
help-seeking response may work to produce help, even though the child
has reached the independence phase -- with the result that dependency is
inadvertently reinforced. One of the major causes of behaviour problems
in children of all ages occurs when children discover that inappropriate
behaviour works to get them something which they want.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Contingencyerrors/index.md","# Contingency errors \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8d03ee7c5cdf4315a599ff7f10698a56}
One of the important understandings which has arisen from the research
into contingencies of reinforcement and punishment is that it is
possible not only for appropriate behaviour to generate reinforcement
but also for errors, inappropriate behaviour, and antisocial behaviour
to generate reinforcement as well. Only the teacher who understands the
difference between the main reinforcement and punishment contingencies
and their effects will be in a position to respond effectively to these
commonly occurring causes of misbehaviour and declining motivation in
the classroom.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Contingencyerrors/Inadvertentnegativereinforcementofmisbehaviour/index.md","# Inadvertent negative reinforcement of misbehaviour \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-214fef38720c4c4db02d09fd55a81d22}
It is also possible for inappropriate child behaviour to be negatively
reinforced. A child may throw a tantrum in an attempt to avoid
completing a particular task and this tantrum may work to avoid the task
-- with the result that tantrumming is inadvertently (negatively)
reinforced. A child may lie to avoid punishment. If the lie works, lying
will have been negatively reinforced. A second major cause of behaviour
problems in children of all ages occurs when the child discovers that
inappropriate behaviour works to avoid having to do something which they
do not want to do.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/index.md","# Functional sequences of learning interactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b1f925ab492b4b60a05097f2f80fbbe0}
Chapter 4 described the important components of a single learning
interaction, the various values which these components can take, and the
varied functions which each can perform. Of course, very little is
learned as a result of a single learning interaction. New skills and
understandings develop as a function of experiences which consist of a
number of learning interactions distributed over time. In order to
develop an understanding of what the word \"yellow\" means, the young
child must experience many learning opportunities with yellow objects.
These may be spread out over several months.

We will refer to the occurrence, on a number of occasions, or repeated
opportunities to practise a given behaviour or skill as a *sequence of
learning interactions*. Sequences of learning interactions serve many
important functions: maintaining motivation, developing understanding,
shaping increased levels of skill, ensuring that new skills are
remembered, developing independence, building fluency, and so on.

Chapter 5 describes some of the ways in which sequences of learning
interactions can vary -- especially those variations which are known to
affect motivation, acquisition, remembering, independence and fluency.

Chapter 5 consists of eight sections. Section 1 describes some of the
ways in which presentation sequences can vary, Section 2 describes some
of the different kinds of prompting sequences and prompt fading
sequences which can occur, Section 3 describes a number of commonly
occurring types of practice sequences, Sections 4 and 5 describe a
number of different types of response-consequence contingencies,
Sections 6 describes different types of schedules of reinforcement and
punishment and Section 7 identifies three important types of contingency
errors (contingencies which have effects which differ from those
intended).
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Schedulesofreinforcementandpunishment/Predictableversusunpredictableschedules/index.md","# Predictable versus unpredictable schedules \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6a8339ec54174aae913071c69938ad48}
Particular behaviours and actions may generate reinforcement in a
predictable or unpredictable manner. If the teacher always marks a
pupil\'s maths exercises at the conclusion of every maths lesson, any
reinforcement (or punishment) which is produced as a result will occur
in a highly predictable manner. Schedules of reinforcement in which the
reinforcement is predictable are usually referred to as *fixed
schedules*.

More commonly, however, reinforcement (and punishment) does not occur in
such a predictable manner. The teacher may sometimes mark the maths and
sometimes not. Schedules of reinforcement in which the reinforcement is
unpredictable are referred to as *variable schedules.*
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Schedulesofreinforcementandpunishment/Continuousversusintermittentschedules/index.md","# Continuous versus intermittent schedules \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6ebc6a7c44c24e5a941a4ab5dc0976c8}
Some behaviours have reinforcing (or punishing) outcomes each and every
time that they are engaged in. Eating known food, for example, is a
behaviour which is reinforced every time that it occurs. A behaviour
which produces reinforcement every time that it is engaged in is said to
be on a *continuous* *schedule* of reinforcement. It is also possible to
have a continuous schedule of punishment. Touching live electrical wires
is a behaviour which generates punishment on a continuous schedule.

Other behaviours produce reinforcement only from time to time. In the
classroom, working consistently is sometimes noticed by the teacher and
praised and at other times it goes unnoticed. Behaviours which are
reinforced only some of the time are said to be on an *intermittent
schedule* of reinforcement. The intermittent schedules are also referred
to as *partial schedules* by some authors. It is also possible to have
an intermittent schedule of punishment as when a parent sometimes sends
a child to time out for defying an instruction and sometimes does not.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Schedulesofreinforcementandpunishment/Thematchinglaw/index.md","# The matching law \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0ef41f7c8c444c36af2ce1fb7a44c1d6}
Children and adults often find themselves in a situation where there are
several different responses which can be used to obtain a particular
type of reinforcement, that is, several different actions which can be
taken to achieve a particular goal. Past experience has taught the
individual that each of these actions works at least some of the time
(but not always). In this kind of situation the various actions which
can be taken are said to be on *concurrent intermittent schedules* of
reinforcement. This is one of the situations where we say that the
individual \"has a choice.\" How are choices made in this kind of
situation? According to Richard Herrnstein, responses in this situation
are distributed according to what Herrnstein referred to as the
*Matching Law* (Herrnstein, 1961). \"The matching law states that an
individual will distribute his or her behavior between alternatives in
the same ratio that reinforcements have been obtained for these
alternatives\" (Myerson & Hale, 1984, p. 367).

An understanding of the effects on motivation and behaviour of the
matching law in situations where reinforcement is only intermittent is
essential for teachers and anyone who is involved in behaviour
management or the design of remedial interventions for inappropriate
behaviour. This is because interventions in which desirable behaviour is
reinforced on a richer variable ratio schedule than that produced by the
inappropriate behaviour will have the effect of motivating a complete
cessation of the inappropriate behaviour while interventions which do
not will be completely ineffective (Myerson & Hale, 1984, p. 369).
:::

::: referencesList
#### References

-   Herrnstein, R. J. (1961). Relative and absolute strength of response
    as a function of frequency of reinforcement. Journal of the
    Experimental Analysis of Behavior, 4, 267-272.
-   Meyerson, J., & Hale, S. (1984). Practical implications of the
    matching law. Journal of Applied Behavior Analysis, 17, 367-380.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Schedulesofreinforcementandpunishment/index.md","# Schedules of reinforcement and punishment \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2df28ceea85f49e4a777fd94a68a003e}
Most behaviours are engaged in repeatedly over time. Sometimes a
particular response is successful and generates reinforcement and
sometimes it does not. A student who seeks help in the classroom will
find that help seeking sometimes works and sometimes does not. In other
words, not all instances of a particular response generate
reinforcement. This is particularly true during the childhood years
where much activity involves attempts to acquire and to master new
responses and skills.

When a particular behaviour sometimes generates reinforcement (or
succeeds in avoiding punishment) and sometimes does not, we refer to the
ratio of reinforced to non-reinforced responses as the *schedule of
reinforcement* for that response. The term schedule of reinforcement can
refer to either a schedule of positive reinforcement or a schedule of
negative reinforcement. It is also possible to have schedules of
punishment. In this case the term schedule refers to the ratio of
punished to non-punished responses.

Schedules of reinforcement (and punishment) may vary with respect to
frequency of reinforcement (or punishment), predictability, and type --
whether response based or time based -- as shown in the following table.

![Figure 2570. Five basic schedules of reinforcement and
punishment](../../../../../assets/images/TECKSFig2570.png \"Figure 2570. Five basic schedules of reinforcement and punishment\"){.image-inline}

*Figure 2570. Five basic schedules of reinforcement and punishment*

The distinctions in the preceding table are important because different
schedules of reinforcement have different effects on motivation and
learning.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Schedulesofreinforcementandpunishment/Themovefromcontinuoustointermittentschedulesofconsequences/index.md","# The move from continuous to intermittent schedules of consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-12c62c8a83454bfc829f7fe62669b099}
During the initial phases of instruction it is often considered
desirable to provide some kind of feedback following every attempt to
perform a new response, that is, it is considered desirable to provide
differential reinforcement on a continuous schedule. Later in the
teaching sequence, however, the teacher may check practice responses
only from time to time (perhaps as a check to ensure that the student
has remembered the correct response). The procedure which the teacher
uses to make this transition from continuous reinforcement to
intermittent reinforcement is obviously an instructional variable of
some importance. Currently however, this transition (from continuous to
intermittent reinforcement) has no agreed name.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Schedulesofreinforcementandpunishment/Timebasedschedulesversusresponsebasedschedules/index.md","# Time based schedules versus response based schedules \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c8a3496442344c33b0219c3bbe30daa0}
The third way in which schedules of reinforcement and punishment can
vary is with respect to type: ratio or interval. A ratio schedule is one
in which a certain number of responses are necessary in order to produce
reinforcement. An example might be the poorly motivated child who is
earning reinforcement for the number of lines written or the number of
exercises completed.

An interval schedule is one where reinforcement occurs only after a
certain amount of time has passed. An example might be the poorly
motivated child who is being checked from time to time and who can earn
reinforcement if she is working at the time when the check is made. In
this case any reinforcement which can be earned depends upon the time
interval rather than upon the number of responses which have been made
by the child.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Promptingandpromptfadingsequences/Promptingbeforeandpromptingafterthepracticestimulus/index.md","# Prompting before and prompting after the practice stimulus \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5ecc4c72252f43a1b859c08d2b29591a}
Wherever possible it is considered good practice to first present the
practice stimulus and only then to present the prompt. This is because,
if the prompt is presented *before* the practice stimulus is presented,
the pupil may respond to the prompt (instead of responding to the
practice stimulus) and may fail to learn how to respond to the practice
stimulus when no prompt is provided. Although this procedure (presenting
the practice stimulus and then presenting the prompt) is considered to
be good practice, it has yet to be given an agreed name.

There are, of course, some situations where the prompt has to be
presented prior to presentation of the practice stimulus. When showing a
child how to catch a ball the demonstration (the prompt) must be
provided before throwing the ball to the child (the practice stimulus)
because it cannot be provided after the ball has been thrown.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Promptingandpromptfadingsequences/Thepromptdelayinterval/index.md","# The prompt delay interval \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-371e06adda5545df85a7bd3e005dd3a3}
It is possible to present the practice stimulus and then to immediately
follow this with the prompt. This technique is often referred to as
*simultaneous prompting.* If a practice stimulus is presented, and then
*immediately* followed by a prompt, the learner will be deprived of the
opportunity to respond without prompting (if they are able to do so). In
addition, the teacher will be unable to tell whether or not the learner
has reached the point where they can respond without assistance. For
this reason, teachers normally present the practice stimulus or question
and then wait for a brief interval before providing the prompt. In this
account we will refer to the interval of time which occurs between the
presentation of a practice stimulus and the presentation of a prompt as
*the prompt-delay interval*.

Some writers use the term \"wait time\" but the term \"wait time\" refers to
the period of time which the teacher allows to elapse between the asking
of a question (in a classroom lesson) and the act of indicating who may
respond to that question. So it can be seen that \"wait time\" is not the
same as the prompt-delay interval.

The prompt-delay interval may vary from a fraction of a second to
several seconds. Since one of the aims of instruction is always to bring
the learner to the point where they can respond independently (that is,
respond without prompting), it follows that the prompt-delay interval
should be sufficient to allow the learner to respond without prompting
if they are now able to do so. Given that responding during the early
stages of instruction may be quite slow and hesitant, it follows that
the prompt-delay interval may need to be several seconds long (3 to 5
seconds long) if it is to provide the learner with the opportunity to
respond independently.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Promptingandpromptfadingsequences/Promptfadingprocedures/index.md","# Prompt fading procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cea34b0f34d34c6db92cea1320df1624}
The task of withdrawing any prompts which have been used during the
initial phase of learning is referred to as *fading*. Fading is an
essential teaching process during transition from the initial learning
phase to the independence phase of learning any new skill. There are a
number of different ways of fading prompts during the initial
acquisition phase and there is a body of research regarding the
effectiveness of each of these fading procedures. It follows, therefore,
that the ability to identify different kinds of prompt fading procedures
is an important skill for both teachers and teaching researchers.

**Delayed prompting.** The *delayed prompting procedure* introduces a
prompt delay interval (a pause) between the presentation of the practice
stimulus (the question, exercise, or instruction to perform) and the
presentation of the prompt. This provides an opportunity for the learner
to respond without assistance if they are able to. Only if the student
responds incorrectly (or does not respond at all within the delay
interval) is assistance provided (usually in the form of a strong
prompt). Initially, the learner is unable to respond, so most responses
are prompted. During the later phases of instruction, most responses are
correct so prompts occur only following errors. As the number of errors
declines, so too does the number of prompts until, eventually, no
further prompts are required.

The delayed prompting procedure for fading prompts has several different
names: time-delay, time delayed prompting, progressive delay, and
delayed prompting. This account uses the term *delayed prompting.*

For teachers, waiting before prompting is the easiest of the fading
procedures to use correctly. This is because the student's performance
determines whether or not a prompt should be used.

**Increasing assistance.** With increasing assistance, the teacher
begins each learning interaction with a weak prompt and, if this does
not work to prompt the correct response, the teacher introduces stronger
and stronger prompts until the learner responds correctly. The
increasing assistance procedure can often be observed in the classroom.
Teachers often use it during early reading instruction, for example. If
a novice reader is reading an instructional text and comes to a word
which they cannot read, the teacher may prompt the correct word by
directing the reader\'s attention to the meaning of the sentence (a weak
prompt) and, if this doesn\'t work, by pointing the reader\'s attention
to the shape of the word and, if this doesn\'t work, by telling the word
(a strong prompt).

The increasing assistance procedure is also known as graduated
prompting*.* The rationale for the increasing assistance procedure is
similar to the rationale for delayed prompting. Each practice trial
begins with the opportunity to respond following presentation of the
weakest prompt. (This is the situation most similar to independent
performance.) Only if the student is unable to respond does the teacher
resort to stronger prompts. As the learner becomes more skilled, fewer
and fewer strong prompts are required, that is, the use of strong
prompts is faded as soon as the learner is able to perform without them.

This is a more difficult procedure for teachers to master. This is
because a great deal of experience is required in deciding upon the
strength of the initial prompt. Inexperienced teachers frequently start
with a much weaker prompt than the student actually requires in order to
respond correctly and this error results in many unnecessary errors.

**Decreasing assistance.** With decreasing assistance, the level of
assistance provided by the teacher is gradually reduced over successive
practice attempts. During early practice trials the teacher provides
explicit directions regarding what to do. During subsequent learning
trials, the teacher provides less and less assistance. In other words,
the teacher starts with detailed or strong prompts and moves to fewer or
weaker prompts once the learner begins to respond correctly.

This is the most commonly used of all fading procedures. For example,
the teacher might introduce a new procedure (such as the long
multiplication procedure) with an explicit show and tell demonstration
(detailed prompting), review the procedure in a more abbreviated form
the next day (reduced prompting) and, during subsequent practice of the
procedure, cease to provide any reminders regarding how to perform the
procedure (no prompting).
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Promptingandpromptfadingsequences/index.md","# Prompting and prompt fading sequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d6648e1c40fb4d93a72763a3da94f7aa}
Most new skills are acquired only after a certain amount of practice.
This means that a sequence of prompted practice responses will normally
be required in order to teach a new skill. One of the characteristics of
skilled performance, however, is the ability to respond independently,
that is, without prompting. So, if prompts are used during the initial
phases of instruction then, eventually, they must be removed from the
practice situation so that the learner receives the opportunity to
engage in unprompted practice. The task of withdrawing prompts during
practice is most commonly referred to as *fading* and this is the term
which will be used in this account.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Promptingandpromptfadingsequences/Thenumberofresponsespromptedatonetime/index.md","# The number of responses prompted at one time \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-390972b624794e73bf8dd53c5613fe36}
When someone is learning how to perform a new operation or procedure,
the teacher may demonstrate, describe or otherwise prompt one step at a
time, or several steps at a time, or all of the steps in the procedure.
There is little agreement as to what the \"number of steps prompted at
one time\" should be called. Margolius and Sheffield (1961) referred to
this variable as the learner\'s *demonstration-assimilation span* but
this term has not caught on. Although there is no agreed term for this
variable, it is nevertheless an important teaching variable for two
reasons. Because young children can only hold one or two steps in mind
at a time, the number of steps which are prompted at once is an
important determinant of how quickly the new procedure will be acquired.
The size of the demonstration-assimilation span also needs to vary as
practice progresses. During the initial stages of instruction in a new
procedure, the demonstration-assimilation span may need to be limited to
two or three steps at a time. As the learner begins to master some of
the steps in the sequence of responses, the demonstration-assimilation
span can be, and usually is, increased.
:::

::: referencesList
#### References

-   Margolius, G. J. & Sheffield, F. D. (1961). Optimum methods of
    combining practice with filmed demonstration in teaching complex
    response sequences: Serial learning of a mechanical-assembly task.
    In R. C. Anderson, G. W. Faust, R. C. Roderick, D. J. Cunningham,
    & T. Andre (Eds.), Current research on instruction. Englewood
    Cliffs, NJ: Prentice Hall.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Promptingandpromptfadingsequences/Theaccuracylevelduringpractice/index.md","# The accuracy level during practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-589be38ebfe848a9baea58a79650ca2f}
The proportion of learner responses which are correct during practice
may vary from 0 to 100 per cent. This variable is often referred to as
the \"error rate\" but in this account we will refer to it as the accuracy
level since it is improvements in accuracy which we are primarily
interested in. The main way in which teachers manage the accuracy level
during instruction is by the use of prompting procedures of various
kinds.

The accuracy level during acquisition and practice is a very important
variable because variations in accuracy level have profound effects both
on rate of acquisition and on motivation. Compare for example, the
differences in rate of learning and in motivation which you would expect
to find after periods of practice in which the proportion of correct
responses was, say, 20%, 80% and 100%. Another reason why accuracy level
is important is because teachers disagree with respect to optimal
accuracy levels. Some writers counsel teachers to aim for high accuracy
levels during practice while other writers counsel teachers to use
discovery learning activities in which the accuracy level is inevitably
quite low. Barak Rosenshine (1983), for example, counsels teachers to
aim for an accuracy level of 80 to 85 per cent and teachers are
routinely counselled to select instructional reading materials which the
child can read with at least 85% accuracy to maintain motivation. These
accuracy levels are impossible to achieve using discovery learning
activities.
:::

::: referencesList
#### References

-   Rosenshine, B. (1983). Teaching functions in instructional programs.
    The Elementary School Journal, 83, 335-351.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Negativereinforcementcontingencies/index.md","# Negative reinforcement contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8efa0e94c54a4c89aee58248934ac112}
A particular behaviour can also function to *put a stop* to things, or
enable us *to escape* from things or *to avoid* things. For example, a
child might be being reprimanded by a parent, the child might apologise
and the parent might cease her reprimanding. In this case the child's
behaviour (apologising) has put a stop to something which was happening
(the parent's reprimands). Or a child might be being teased by another
child and the child who is being teased might run away. In this case the
child's behaviour (running away) has enabled the child to escape from
something which was happening (the teasing). Or a student might notice
that the teacher has glanced his way and get back to work in order to
avoid a reminder from the teacher. In this case the student's behaviour
(getting back to work) has avoided an outcome which would otherwise
occur (a reminder from the teacher).

When someone continues to engage in a behaviour (or begins to engage in
a behaviour more frequently) because that behaviour works to get rid of,
or to subtract something from that person\'s immediate environment, or
to avoid an aversive (unpleasant) consequence which would otherwise
occur, the recurring relationship between behaviour and consequence is
referred to as a *negative reinforcement contingency*.

The negative reinforcement contingency is defined as follows:

*If* (a) a behaviour begins to *put a stop to,* or to *avoid* an event,

and (b) the behaviour *increases* in frequency

*then*

\(a\) the event is a *punisher* (an aversive event),

and(b) the contingency is a *negative reinforcement* contingency

Negative reinforcement contingencies are extremely common in everyday
life. We navigate our environment with care because careful behaviour
avoids the falls, the bruises and the injuries which we would experience
if we did not act carefully. We behave politely because polite behaviour
avoids the refusals, the rebukes and the anger which we would tend to
elicit in others if we did not behave politely. At the secondary school
level, much class work and much homework is completed, not because of
the reinforcing outcomes which this behaviour produces, but because it
avoids the teacher disapproval and parental disapproval which might well
occur if the work was not completed.

**Escape responses.** Negatively reinforced responses may be of two
general kinds: escape responses and avoidance responses. An *escape
response* is a response which functions to put a stop to an aversive
state of affairs or which allows the learner to escape from an aversive
state of affairs. An example might be the child who turns on a heater
(or who moves to a warmer room) to escape from the cold.

**Avoidance responses.** Not only do we learn to terminate and to escape
from aversive (punishing) situations, we also learn how to avoid
aversive situations altogether. We learn to recognise the signals which
indicate that punishment is imminent and we learn to take evasive
action - to engage in *avoidance responses* - which enable us to avoid
the aversive consequence altogether. The child who is reprimanded for
arriving late to class may be motivated to arrive on time in order to
avoid further reprimands. The child who dawdles and has to complete her
maths instead of reading (which is a preferred activity) may be
motivated to work more quickly next time in order to avoid further
deprivations of this kind.

Note that *both positive and negative reinforcement contingencies
function to motivate the continued use of a particular response.* If a
person is motivated to continue performing a particular behaviour
because of the reinforcing outcomes which it produces, the contingency
is a *positive* reinforcement contingency. If a person is motivated to
continue performing a behaviour because that behaviour works to avoid
certain aversive events, then the contingency is a *negative*
reinforcement contingency.

It is important to distinguish between positive reinforcement and
negative reinforcement contingencies. This is because, although the two
contingencies both function to motivate continued performance of a
behaviour, the emotional effects of the two contingencies are quite
different. The only consequence of failing to perform a positively
reinforced behaviour is that you do not get the reinforcement. The
consequence of failing to perform a negatively reinforced behaviour,
however, is that you fail to avoid punishment. When children are working
under negative reinforcement contingencies, errors, mistakes, and other
kinds of failure result in punishment. Working to avoid punishment
(working under the constant threat of punishment) leaves people feeling
anxious and motivates them to look for ways of avoiding the situation
altogether. Working to earn reinforcement, on the other hand, leaves
people feeling more confident and more positive about the situation in
which they are working and the tasks which they are being asked to
perform. In short, positive reinforcement contingencies produce positive
attitudes and negative reinforcement contingencies produce negative
attitudes.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Reinforcementversuspunishmentcontingencies/index.md","# Reinforcement versus punishment contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e6b432ece5224a1a9685993c29675237}
Some contingencies (response-consequence relationships) have a
strengthening effect. They make it *more likely* that a particular
behaviour will be remembered and used again (under similar
circumstances) in the future. Contingencies which have this
strengthening effect are referred to as *reinforcement contingencies.*

Other contingencies have a weakening effect. They *reduce* the
likelihood of the learner using that particular behaviour again in the
future. They teach us a lesson and the lesson is **not** ** to make that
mistake again next time. ** In the scientific literature on learning,
contingencies which have a weakening or suppressive effect are referred
to as *punishment contingencies*.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Differentialreinforcement/index.md","# Differential reinforcement \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-193144f6cdc04e62b429ef09d9691d99}
Reinforcement and punishment contingencies seldom occur in isolation.
This is because we have choices; a child can choose either to attend or
not to attend to the teacher. It is also the case that when we are
practising some responses are correct or satisfactory while others are
incorrect or less than satisfactory. Correct responses and errors
typically have different consequences as do improvements and
non-improvements in performance. For example, the teacher may mark
correct answers as correct and the incorrect answers as errors to be
corrected. Similarly, the teacher may respond to improvements with
praise but react to responses which show no improvement by asking the
learner to \"try again\".

When certain members of a response class result in reinforcement and
other members of the same response class do not we refer to the two
contingencies which are operating as differential reinforcement.

Differential reinforcement of improvements in performance may be
intentionally managed by the teacher (as when the teacher praises
successful responses and ignores unsuccessful responses) or it may occur
naturally as a result of the learner's performance (as when accurate
shots go through the basketball hoop and inaccurate shots do not).

Differential reinforcement is the third most important teaching
variable. Practice opportunities are necessary for learning as is the
appropriate scheduling of these practice opportunities in time. But
practice only results in the in the appearance of new skills and
abilities if improvements in performance (or correct responses) are
differentially reinforced.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Theintroductionmaintenanceandwithdrawalofcontingencies/index.md","# The introduction, maintenance, and withdrawal of contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f9d69da861da44ff9459c739a84a0cc2}
When an action is being engaged in repeatedly over time, the
consequences of that action may change. The action may initially have no
consequence but, over time may come to have a consistent consequence.
For example, a child who has just been admitted to preschool may attempt
to engage in co-operative play but these attempts may initially meet
with little success. As the days go by, however, these attempts may
increasingly result in opportunities to engage in co-operative play with
other children.

A second possibility is that a new response, behaviour or action, once
mastered may consistently produce much the same consequence or effect.
For example, once a child has learned to read, the reading activity
consistently results in sensory stimulation, usually results in
understanding and very often results in enjoyment.

A third possibility is that, over time, a given action may cease to
produce the consequences which it previously produced. For example, a
child who is trying to master skate boarding may initially experience
many painful falls but, as the child become more competent, fewer and
fewer skate boarding attempts result in painful falls.

These observations remind us that the relationship between behaviour and
its consequences is a reciprocal relationship. Particular behaviours
have outcomes and these outcomes affect the likelihood of the learner
using that behaviour again in the future. Over time, contingencies of
reinforcement and punishment gradually shape the performance of the
learner resulting in a person who habitually behaves in certain ways,
but not others, in particular circumstances.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Positiveversusnegativecontingencies/index.md","# Positive versus negative contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b559239b8805445d866bf2e9cd821848}
Some behaviours make things appear and other behaviours make things go
away. A child can turn the radio on and make music *appear*. A child can
turn the radio off and make the music *go away*.

When a response, behaviour or action works to make something *appear*,
or to get, or to produce something which wasn\'t there before we refer
to the contingency (the response consequence relationship) as a
*positive contingency*. When a behaviour works to make something *go
away*, or to avoid something altogether, we refer to the contingency as
a *negative contingency.*

When we are talking about contingencies, the terms \"positive\" and
\"negative\" are used in the *mathematical* sense of adding something or
subtracting something from our immediate environment. These terms ***do
not*** refer to \"good\" and \"bad\" consequences and they ***do not***
refer to \"nice\" and \"nasty\" consequences.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Themovefromextrinsictonaturallyoccurringcontingencies/index.md","# The move from extrinsic to naturally occurring contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7bef76c9dbb149f0a6f3fab3e9365274}
Sometimes teachers choose to motivate poorly motivated students using
some kind of extrinsic reinforcement such as a star chart, preferred
activity reward, or regular praise. These kinds of reinforcers are often
referred to as \"extrinsic\" reinforcers because they have been introduced
in order to provide the poorly motivated student with an extrinsic
source of motivation. Once the poorly motivated student begins to
experience some success on classroom tasks, and the reinforcement which
results from such success, it will usually be the case that the
extrinsic reinforcement which was initially required will become less
and less necessary. Once this happens the teacher will normally make a
transition from extrinsic sources of reinforcement to naturally
occurring sources of reinforcement to maintain the improvement in
student effort.

Sometimes teachers choose to provide the differential reinforcement
which is necessary for learning using extrinsic sources of reinforcement
such as a star chart, regular praise, public displays of work completed,
and so on. However, once the child has mastered a new skill and can
tell, through self-evaluation, that their performance meets expected
standards, this extrinsic differential reinforcement becomes largely
unnecessary. Here too, the teacher will normally make a transition from
extrinsic sources of reinforcement to the naturally occurring
reinforcement which results from the student's own self-evaluation of
their performance, their success on tests, and so on.

These examples illustrate that fact that the transition from extrinsic
sources of reinforcement to naturally occurring sources of reinforcement
is an important variable and that the way in which the teacher manages
this transition is an important teaching function. Currently however,
this transition (from extrinsic to naturally occurring contingencies of
reinforcement) has no agreed name.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Thedifferentialreinforcementofdifferentperformancedimensions/index.md","# The differential reinforcement of different performance dimensions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c8562a64401d4f098cbadb15306b86a3}
Most behaviours can vary along several different *dimensions*. Kicking a
football has both accuracy and force dimensions. We can reinforce
kicking *accurately* (kicking the ball in the right direction) or we can
reinforce kicking *forcefully* (kicking the ball far enough). Naming an
object has both a meaning dimension and a pronunciation dimension. We
can reinforce the child for using the *correct word* or for *pronouncing
it correctly.* Reading has both an accuracy and a fluency dimension. We
can react positively when the child reads the words *correctly* or when
the child reads *fluently*, that is, with sufficient accuracy and speed
to maintain comprehension.

Practice responses may be judged to be successful on the basis of
whether or not they are correct, whether or not they qualify as
improved, whether or not they are performed with sufficient force,
whether or not they are performed with sufficient creativity, whether or
not they are performed with sufficient beauty and style, and so on.

In order to specify a reinforcement contingency, therefore, it is always
necessary to specify the dimension or dimensions of behaviour which are
going to be differentially reinforced. While there are many dozens of
performance dimensions, three dimensions are of particular importance
during the childhood years. These are *productivity* (working quickly),
*accuracy* (responding correctly) and *fluency* (responding both
correctly and quickly).

Contingencies which result in the differential reinforcement of
productivity are contingencies in which attention to practice stimuli,
engagement with learning tasks, staying on task, and completing assigned
tasks are differentially reinforced.

Contingencies which result in the differential reinforcement of accuracy
are contingencies in which correct responses and correctly performed
procedures are differentially reinforced. For example we may
differentially reinforce improvements in printing accuracy, or in the
number of words correctly spelled or in the number of maths problems in
which an appropriate procedure was used to arrive at the correct answer.

A third dimension of classroom performance is the *fluency dimension*,
that is, accurate and speedy responding. One of the characteristics of
mastery is that correct responses can be recalled very quickly --
without having to spend any time thinking through or working out the
answer. Where the objective of practice is to develop mastery, then it
is improvements in the speedy performance of correct responses which
needs to be differentially reinforced.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Recoverycontingencies/index.md","# Recovery contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cb7701dee6164d4ead5f547a4dff1f8a}
There is a third contingency which may cause a behaviour to *increase in
frequency* (to be used more often). There are some behaviours which we
do not engage in because, to engage in them might produce punishment,
disapproval, or sanctions of some kind. Behaviours which have been
suppressed by punishment, may recover and begin to be used again if the
environment changes in a way which makes it clear that the behaviour in
question is no longer going to be punished.

Take, for example, the behaviour of drawing a pretty border around each
page of work. Let us say that this behaviour was learned in Year 5 and
the following year the child moved into a class where the teacher
prohibited this behaviour. The behaviour (drawing borders) was
suppressed (in Year 6) because, if it was engaged in, it produced a
major reprimand from the teacher. The following year (Year 7) the child
moves into a new class where borders are no longer prohibited (and,
therefore, no longer punished). Under these conditions, the child might
well begin once again to engage in this behaviour (because it no longer
generates an aversive outcome). If this happened, the reappearance of
the behaviour of drawing borders would be an instance of *recovery*.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/index.md","# Response-consequence contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-51cc8bc21e87440083d7bd34cc845fee}
From the very first occasions on which they are attempted, most
behaviours have consequences. The kinds of consequences which can result
from a particular response, behaviour or action have been described in
earlier sections. They include reinforcing consequences (reinforcers)
and aversive consequences (punishers), biologically determined and
learned reinforcers and punishers, consequences which are natural
outcomes of our behaviour, consequences which take the form of
opportunities to engage in other behaviours, consequences which consist
of reactions from other people, and consequences in the form of feedback
regarding the success or otherwise of our behaviour.

In addition, most behaviours (e.g. reading) are engaged in over and over
again. When we begin to track repeated use of the same response over
time we discover that different kinds of relationships can exist between
a particular behaviour and its consequences. In this section we describe
some of the different arrangements which can exist between an action
which is being engaged in repeatedly and the consequences which are
resulting from that action. The relationship between a behaviour which
is being used repeatedly and its consequences or outcomes is referred to
as a *contingency*. *The term contingency refers to a relationship
between a particular behaviour and its consequences.*

While many kinds of contingencies are possible, most are combinations of
the following six basic types of contingencies: positive and negative
reinforcement, positive and negative punishment, recovery and
extinction.

![Figure 2550. The six main contingencies of reinforcement and
punishment.](../../../../../assets/images/TECKSFig2550.png \"Figure 2550. The six main contingencies of reinforcement and punishment.\"){.image-inline}

*Figure 2550. The six main contingencies of reinforcement and
punishment.*

These six contingencies are distinguished because they have differing
effects on learning, on our motivation to engage in particular
behaviours, and on our liking for particular courses of action. The
importance of being able to recognise these six contingencies cannot be
overemphasised. It is essential that all teachers be able to distinguish
between these six contingencies because a failure to recognise the
contingencies which are operating in a particular setting will leave the
teacher unable to identify the causes of many of the behaviour changes,
motivational changes and attitudinal changes which are occurring (or
failing to occur) in the classroom, the playground, and so on.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Positivepunishmentcontingencies/index.md","# Positive punishment contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-32606dd006e74c8a900bafeaafd74f5e}
A behaviour may produce an event (e.g. praise) and continue to be used
as a result. But a behaviour may also produce an event (e.g. reprimands)
and cease to be used as a result. This kind of response-consequence
relationship is called *positive punishment* (or punishment, for short).
The term punishment refers to a state of affairs where a particular
behaviour, when engaged in, produces an outcome or an experience which
has a suppressing effect on the future performance of that behaviour.
The positive punishment contingency is defined as follows.

*If* (a) a behaviour begins to *produce* an event,

and (b) the behaviour *decreases* in frequency (or ceases to be used)

*then*

\(a\) the event is a *punisher* (an aversive consequence),

and (b) the contingency is a *positive punishment* contingency

Note that this technical definition of punishment differs from our
everyday use of the word \"punishment\". In everyday language, we use the
term punishment to include all of those occasions when someone tries to
suppress or eliminate behaviour by responding negatively - regardless of
whether or not the attempt is successful.

Learning scientists, on the other hand, use the term \"punishment\" in its
much more limited, technical sense. A response-consequence relationship
meets the definition of a positive punishment contingency *only* if (a)
the behaviour produces an event (having something taken away does not
count), *and* (b) this relationship occurs on a number of occasions (a
single instance does not count), *and* (c) the behaviour begins to be
used less frequently as a result. (A contingency which does not have a
suppressive effect on behaviour is not a punishment contingency in the
technical sense defined above.)

Punishment contingencies are extremely common in everyday life and much
of the behaviour which we might engage in has been suppressed by the
aversive consequences which that behaviour has produced in the past. As
children grow and mature, most cease to take things without asking, they
cease to ask others to do things which they can do for themselves, they
cease to interrupt others when they are talking, and they cease to
demand, to whine, to yell and to throw tantrums in the way that they did
when they were two or three years of age. Most people also learn not to
engage in behaviours which offend and antagonise others and they learn
not to engage in behaviours which are regarded by the culture as
inappropriate, antisocial or illegal.

It is very important to distinguish between negative reinforcement (the
successful avoidance of an unpleasant event) and punishment (the failure
to avoid an unpleasant event) because these two contingencies have quite
different effects. Negative reinforcement motivates continued use of the
successful avoidance responses. Punishment tends to suppress the
punished response.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Thetimingofconsequencesandthepost-responseinterval/index.md","# The timing of consequences and the post-response interval \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-163fe12fdcb44fb88f0203535c9adf75}
The consequences of successful and unsuccessful responses, behaviours,
and actions may follow the action immediately or they may following the
action after a period of time. For example, when a student attempts a
basketball shot the consequences are immediate because the student can
immediately see whether the shot went through the hoop or not. On the
other hand, the success or otherwise of a student's attempts to prepare
for a test will not be known by the student until the test has been
completed, marked by the teacher, and the marks returned to the student.

In this account we will refer to the delay between the completion of a
response and the occurrence of any consequence such as feedback as the
*post-response interval*. The post-response interval is the time which
elapses between completion of the learner\'s response to the practice
stimulus and the presentation of any consequence by the teacher, the
instructional medium or the environment. The post response interval can
vary from a fraction of a second (as in the goal shooting example) to
several weeks (as in the test preparation example).

The post-response interval is referred to by some writers as \"wait-time\"
or as \"wait-time II\" or as \"teacher wait time\". This usage is normally
limited to the period of time which the teacher waits following a
student answer before reacting to that answer and hence refers to a
particular kind of post-response interval.

The post-response interval is an important instructional variable
because it affects rate of acquisition. In addition, the most
efficacious post-response interval is different for correct responses
and for incorrect responses.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Positivereinforcementcontingencies/index.md","# Positive reinforcement contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cca227f53c1a4a77bd4009ce2086fd82}
A particular response or behaviour can *produce* an outcome. It can make
something happen. It can add something to our environment. The learner
may work carefully, get all their answers correct, and get a merit
certificate from the teacher for \"excellent work\". In this case the
behaviour (responding correctly) has produced a consequence (produced a
certificate). If this contingency continues to operate, and the number
of correct answers produced by the learner is maintained, or increased,
then this response-consequence relationship meets the definition of a
*positive reinforcement contingency.* Positive reinforcement
contingencies are often referred to as reinforcement for short.

Positive reinforcement contingencies are defined as follows.

*If* (a) a behaviour begins to *produce* an event,

and (b) the behaviour *increases* in frequency

*then*

\(a\) the event is a *reinforcer*,

and(b) the contingency is a *positive reinforcement* contingency

Note that positive reinforcement contingencies also motivate continued
use of a behaviour once that behaviour has been acquired.

Positive reinforcement contingencies are extremely common in everyday
life. Large amounts of our behaviour are maintained from day to day by
the reinforcing outcomes which that behaviour has for us. This is true
of all of those activities which we engage in because of the enjoyment
which they generate: listening to particular compact disks, watching
particular TV programmes, reading particular types of books, spending
time in the company of particular friends, and so on. It includes all
those behaviours which we engage in because we get paid for doing so.
And it includes all those behaviours which work to provide intellectual
stimulation, to keep us warm, to satisfy hunger and to satisfy other
bodily needs.
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Twotypesofdifferentialreinforcementcontingencies/index.md","# Two types of differential reinforcement contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3e1967925b83437db70af4a0022d8f60}
Successful responses may generate many different kinds of reinforcing
consequences. They may be naturally reinforced by getting the outcome
which the learner wants, they may be reinforced with positive feedback,
or by a positive reaction from another person or by gaining access to a
preferred activity, and so on.

Unsuccessful responses may generate consequences in the form of negative
feedback, a negative response from others, postponement of access to a
more reinforcing activity, and/or a prompt and a request to try again,
and so on.

Because there are dozens of different ways of reinforcing correct
responses, and many different ways of reacting to errors, the
differential reinforcement of improvements in performance can be
accomplished in hundreds of different ways. However, these differential
reinforcement arrangements can be grouped under two general headings as
shown in the table below.

Notice that in both of these types of differential reinforcement,
correct (or improved) responses are followed by reinforcement. The
reinforcing consequences may be any of the types of reinforcing
consequences previously described.

Where the two types of differential reinforcement differ is with respect
to what happens following incorrect (or unsatisfactory) responses. There
are two main possibilities.

1.The first is that the errors are simply ignored, that is, neither
accepted as correct, nor corrected. This procedure is very frequently
used by teachers. If one student responds with an incomplete or less
than satisfactory answer, the teacher simply calls upon another student
to respond to the original question.

2.The second possibility is that errors result in some kind consequence.
The most commonly observed consequences are: (a) somebody provides some
kind of error feedback (e.g. \"No, that's not right.\"), (b) somebody
provides error feedback and some kind of correction (e.g. tells the
learner the correct response), or (c) somebody provides error feedback,
and a prompt, and a secondary response opportunity.

![Figure 2562. The two main types of differential reinforcement for
corrects and
errors](../../../../../../assets/images/TECKSFig2562.png \"Figure 2562. The two main types of differential reinforcement for corrects and errors\"){.image-inline}

*Figure 2562. The two main types of differential reinforcement for
corrects and errors*

It is important to distinguish between these two types of differential
reinforcement because many teachers prefer to use the first type (in
which errors are ignored) whereas others teachers believe that errors
should be corrected. (The research suggests that we learn more rapidly
when our errors are corrected.)
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Extinctioncontingencies/index.md","# Extinction contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-890ffe0b5243484da94a94b49b86124c}
There is a third contingency which may cause a behaviour to *decrease in
frequency* (to be used less often). Let us say that a behaviour has been
used in the past because, in the past, it has worked to produce
reinforcement. But the environment changes so that, when this behaviour
is used, it longer works to produce reinforcement. When this happens,
the behaviour which previously produced reinforcement (but which now
doesn\'t) may decline in frequency or even cease to be used. When the
reinforcement for a particular behaviour is removed either as a result
of a change in the environment, or as an intentional management
strategy, the behaviour is said to have been placed on an *extinction
contingency*.

Extinction contingencies are sometimes referred to as extinction, for
short. There are two types of extinction contingencies: (a) extinction
following the removal of positive reinforcement and (b) extinction
following the removal of negative reinforcement. For example, a teacher
might use much praise during the initial acquisition phase of learning a
new skill and then cease to provide this encouragement. If performance
of the new skill then declined in frequency this would be an example of
extinction following the withdrawal of positive reinforcement. Or a
teacher might cease to check homework (and to reprimand the learners who
fail to complete the homework) only to find that homework completion
declines in frequency. This is an example of extinction following the
withdrawal of negative reinforcement. The behaviour has declined in
frequency because performance of the behaviour (completing homework) is
no longer necessary in order to avoid punishment (teacher disapproval).
:::"
".//Importantlearningandteachingevents/Functionalsequencesoflearninginteractions/Response-consequencecontingencies/Negativepunishmentcontingencies/index.md","# Negative punishment contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2554da21782d4da0a51c6aea2df0e652}
There is a second kind of penalty which a behaviour may have. A
behaviour may have a cost. When performed, it may result in the
*subtraction* of something from that person\'s environment. It may
function to put a stop to something which the person would prefer to see
continued. It may result in the removal of something which the learner
would rather not have removed. For example, the student who parties
instead of studying may fail to gain a pass in the course which they
have enrolled in. Or the football player who stomps on another player
may be sent off the field and prevented from playing for the rest of the
game. A behaviour which consistently results in a loss or postponement
of reinforcement, and which begins to be used less often as a result, is
said to be on a *negative punishment contingency*. \"Negative\" because
something is being removed and \"punishment\" because the behaviour begins
to be used less often.

Negative punishment is defined as follows.

*If* (a) a behaviour begins to result in the *loss or postponement* of
something,

and (b) the behaviour *decreases* in frequency

*then*

\(a\) the something is a *reinforcer*,

and (b) the contingency is a *negative punishment* contingency

A number of different terms have been used to refer to the negative
punishment contingency. Negative punishment contingencies have been
referred to as Type II punishment contingencies, as response cost, as
punishment by removal, as fining, as reinforcement loss and so on.

Negative punishment contingencies are widely used as instruments of
social control. The sports person who infringes the rules of their sport
may be banned from playing for a certain period of time. The penalty for
certain illegal behaviours is a fine. The penalty for more serious
infringements of the law is imprisonment (the loss of access to most
sources of reinforcement for a given period of time). Some of the
penalties which are used by schools as punishments for misbehaviour have
the potential to function as negative punishment contingencies - being
deprived of access to a favourite activity, being required to sit apart
from the rest of the class, being sent from the classroom, being sent to
detention and so on.

Two negative punishment operations are commonly employed by parents and
teachers. These are *response cost* and *time out from reinforcement.*

**Response cost.** A response cost contingency is one where a behaviour
has a penalty and the penalty is the loss of some portion of a
previously earned or previously granted reinforcement. For example, an
older child breaks a window and the consequence is that he has to pay
for the window out of his pocket money.

**Time out from reinforcement.** With time out, the penalty is a
temporary interruption or postponement of access to currently
reinforcing activities. Examples of contingencies which are often
intended to act as time out contingencies are sending the child to the
side of the classroom for a few minutes following stated misbehaviours
(often referred to as \"sit and wait\"), sending the child to her room
following stated misbehaviours at home (often referred to as \"time
out\"), and sending a player off the field following a rule infringement.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Learninghowtoplancomposeproofreadandreviseinvariousgenres/index.md","# Learning how to plan, compose, proof read and revise in various genres \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-07a4a068b4dc448e833ce813b9da219a}
Initially, the act of transcribing thoughts consumes so much working
memory that there is little left over for planning or revising. One of
the implications of this is that early instruction in writing should
emphasise the development of fluency in writing and spelling so that the
learner can progress to thoughtful compositional writing as soon as
possible (Berninger, 1999). By age 9 or 10 the resource demands imposed
by transcription (handwriting and spelling) decrease to a manageable
level for most children, and no longer interfere with children\'s text
generation (McCutchen, 1996).

Detailed accounts of the processes which are presumed to be involved in
mature compositional writing have been provided by a number of authors
(Gersten & Baker, 2001; Hayes & Flower, 1980; Kameenui, Carnine, Dixon,
Simmons & Coyne, 2002; Scardamalia & Bereiter, 1986). These accounts
suggest that skilled writing is a recursive activity involving four
interacting procedures: planning, composing (or text generation),
editing, and revising. However, there is little agreement amongst
writing researchers as to how these learning outcomes should be defined
or measured and there has been little research into the developmental
progression which occurs with respect to each of these components of
writing competence.
:::

::: referencesList
#### References

-   Berninger, V. (1999). Coordinating transcription and text generation
    in working memory during composing: Automatic and constructive
    processes. Learning Disability Quarterly, 22, 99-112.
-   Gersten, R., & Baker, S. (2001). Teaching expressive writing to
    students with learning disabilities: A meta-analysis. The Elementary
    School Journal, 101, 251-272.
-   Hayes, J. & Flower, L. (1980). Identifying the organization of the
    writing process. In L. W. Gregg & E. R. Steinberg (Eds.), Cognitive
    processes in writing (pp. 3-10). Hillsdale, NJ: Erlbaum.
-   Kameenui, E. J., Carnine, D. W., Dixon, R. C., Simmons, D. C., &
    Coyne, M. D. (2002). Effective teaching strategies that accommodate
    diverse learners (2nd ed.). Columbus, OH: Merrill.
-   McCutchen, D. (1996). A capacity theory of writing: Working memory
    in composition. Educational Psychology Review, 8, 299-325.
-   Scardamalia, M., & Bereiter, C. (1986). Research on written
    composition. In M. C. Wittrock (Ed.), Handbook of research on
    teaching (3rd ed., pp. 778-803). New York: MacMillan.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Learningcommonphoneme-graphemeequivalencerelations/index.md","# Learning common phoneme-grapheme equivalence relations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f45464e0585841b6aaf256cfb29397fb}
The act of spelling involves reproducing the correct sequence of letters
for a particular word. The stimulus may be either the spoken word (as
when taking notes) or it may be the thought of the word (as when
composing). The response may be oral, written, or typed. Competent
spelling involves the ability to translate phonemes into graphemes with
a high degree of accuracy (Hallahan, Kauffman & Lloyd, 1985).

Written English is partly phonetic and partly morphological (Dixon,
1991; Moats, 1995; Simonsen & Gunter, 2001; Templeton & Morris, 2000).
This is one of the reasons why the English language has some 250
different spellings for its 43 phonemes. Of these, some 170 are
reasonably common (Mann, 2003; Moats, 1995). Knowledge of sound-spelling
relationships is variously referred to as knowledge of the alphabetic
principle, graphophonemic knowledge, knowledge of spelling-sound
relationships, knowledge of sound-syllable correspondences, knowledge of
spelling rules, knowledge of phoneme-grapheme conversion rules, and so
on. The technical term is knowledge of *phoneme-grapheme* equivalence
relations.

In a limited number of cases, the reversibility property will ensure
that once a child has learned a particular grapheme--\>phoneme
equivalence during learning to read (e.g. see the letter t --\>say the
sound \|t\| ) then the child will have learned also the phoneme-grapheme
equivalence (i.e. hear the sound \|t\|--\>write the letter t ) (Sidman,
1994). However, this will only be true for the equivalence relations
which involve one-to-one correspondences and this is a relatively small
proportion of the total in reading and an even smaller proportion of the
total in spelling.

According to Moats (1995), at least 20 English language phonemes have
spellings which are predictable over 90% of the time and a further 10
phonemes have spellings which are predictable over 80% of the time. The
spelling of only eight phonemes is predictable less than 78% per cent of
the time and five of these are vowel sounds. This means that the
spelling of the so called \"regular words\" which, according to Moats
(1995), comprise some 50% of all words can be derived from a knowledge
of phoneme--\>grapheme equivalences. Because a mastery of regularly
occurring phoneme--\>grapheme equivalence relations allows students to
engage in self-directed learning of regularly spelled words (and many of
the syllables of irregularly spelled words), it can be seen that pursuit
of this learning outcome is essential if a child is to become a
competent writer. Although not systematically taught at the present
time, these equivalence relations could be systematically taught thereby
greatly accelerating the rate at which young children learn to write.
:::

::: referencesList
#### References

-   Dixon, R. C. (1991).The application of sameness analysis to
    spelling. Journal of Learning Disabilities, 24, 285-291, 310.
-   Hallahan, D. P., Kauffman, J. M., & Lloyd, J. W. (1985).
    Introduction to learning disabilities. Englewood Cliffs, NJ:
    Prentice-Hall.
-   Mann, V. A. (2003). Language processes: Keys to reading disability.
    In H. L. Swanson, K. R. Harris, & S. Graham (Eds.), Handbook of
    learning disabilities (pp. 213-228). New York: Guilford Press.
-   Moats, L. C. (1995). Spelling: development, disability, and
    instruction. Baltimore: York Press.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
-   Simonsen, F., & Gunter, L. (2001). Best practices in spelling
    instruction: A research summary. Journal of Direct Instruction, 1,
    97-105.
-   Templeton, S., & Morris, D. (2000). Spelling. In M. L. Kamil, P. B.
    Mosenthal, P. D. Pearson, & R. Barr (Eds.), Handbook of reading
    research. Vol 3 (pp. 525-543). Mahwah, NJ: Erlbaum.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Acquiringanadequatelevelofmorphographicknowledge/index.md","# Acquiring an adequate level of morphographic knowledge \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-995715ff98834db494059445dbe5df83}
In addition to mastering the phoneme--\>grapheme equivalence relations
which are involved in spelling regularly spelled syllables and words,
the novice writer must also acquire a large amount of morphographic
knowledge. For example, \"write\" and \"written\" contain a common morpheme
(Templeton & Morris, 2000). Unlike phonemes, morphemes tend to be
spelled in the same way whenever they appear (or to change in
predictable ways). Morphemes are the smallest units of words that are
meaningful. Root words, prefixes and suffixes are examples of morphemes.
English tends to preserve the spelling of morphemes, that is, to use the
same morphograph, even when the pronunciation changes - as in the case
of \"magic\" and \"magician\"

A morphographic approach to the teaching of spelling greatly increases
the efficiency of that teaching. This is because there are many fewer
root words than there are words in general. \"We know, for example, that
about 800 morphographs appear in 10 or more words and generate
approximately 16,000 words\" (Dixon, 1991, p. 287). A second advantage is
that the spelling of morphographs is highly consistent across the words
in which they appear. Either they are spelled in exactly the same way or
else they change their spelling in quite predicable ways - as when
\"save\" and \"make\" become \"saving\" and \"making\" (Dixon, 1993; Moats,
1995; Templeton & Morris, 2000).
:::

::: referencesList
#### References

-   Dixon, R. C. (1991).The application of sameness analysis to
    spelling. Journal of Learning Disabilities, 24, 285-291, 310.
-   Moats, L. C. (1995). Spelling: development, disability, and
    instruction. Baltimore: York Press.
-   Templeton, S., & Morris, D. (2000). Spelling. In M. L. Kamil, P. B.
    Mosenthal, P. D. Pearson, & R. Barr (Eds.), Handbook of reading
    research. Vol 3 (pp. 525-543). Mahwah, NJ: Erlbaum.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Learningthemaingrammaticalconceptsandrules/index.md","# Learning the main grammatical concepts and rules \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2e33cdf6f26d48d4b289578ffe18cb5f}
Grammar refers to a collection of skills which includes both a set of
concepts and a set of rule guided procedures. The concepts include such
stimulus classes as sentences, questions, singular and plural, parts of
speech (e.g. nouns and verbs), tense, possessives, direct speech, and so
on. The rules describe the conventions relating to the formation of
sentences, agreement with respect to tense, the formation of plurals,
and the punctuation of sentences, direct speech, questions, and so on.
The main New Zealand curriculum reference for grammatical and
punctuation conventions is *Exploring language: A handbook for teachers*
(Ministry of Education, 1996).

While much has been written about the grammatical structure of English,
there has been little research into the way in which children develop an
understanding and ability to use these grammatical concepts and
conventions and, hence, little is known about how this learning should
be sequenced.
:::

::: referencesList
#### References

-   Ministry of Education (1996). Exploring language: A handbook for
    teachers. Wellington, NZ: Learning Media Ltd.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/index.md","# The skills involved in learning to write \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cb8ba1bf19894b0ea22502ba677ffe3b}
Although there has been less research into the development of writing
skills than there has been into the development of reading skills, the
research into how children learn to write is nevertheless substantial
(e.g. Baker, Gersten & Graham, 2003; Berninger & Amtmann, 2003; Gersten
& Baker, 2001; Moats, 1995; Templeton & Morris, 2000).

Structural analyses of the process of learning to write suggest that the
early development of compositional writing skills depends upon the
acquisition of fluent performance of a number of component skills. The
developmental sequence for these component skills is pictured in Figure
2320.

*![Figure 2320. The early developmental sequence for learning to
write](../../../../../assets/images/TECKSFig2320.png \"Figure 2320. The early developmental sequence for learning to write\"){.image-inline}*

*Figure 2320. The early developmental sequence for learning to write*

1.In order to become a competent writer, the learner must (a) acquire a
knowledge of writing conventions (e.g. grammatical rules, punctuation
rules, etc.), (b) learn how to plan and revise written work, (c) acquire
a large automatised spelling vocabulary, and (d) acquire a high level of
fluency in handwriting and/or typing skills.

2.There are at least three component skills in learning to spell in
English. The first is mastery of the phoneme--\>grapheme equivalence
relations necessary in order to learn the spellings of regularly spelled
syllables and words. The second is mastery of the spelling of all of the
commonly used words with irregular spellings (Dixon & Engelmann, 1999)
and the third is the acquisition of morphographic knowledge, that is a
knowledge of the spelling of commonly occurring morphographs and rules
for combining morphographs. Because some of the grapheme-phoneme
equivalence relations are reversible, some of this knowledge is acquired
during learning to read. However, much of it -- especially the
morphological knowledge and the phoneme-grapheme relationships which are
unique to spelling -- requires explicit teaching if it is to be acquired
in a timely fashion.

3\. Before a child can learn the phoneme-grapheme equivalence relations
they must first be able to discriminate between each of the graphemes
and each of the phonemes.

The reason why each of these skills needs to be distinguished is not
because they involve different kinds of actions but because the mastery
of each depends upon the provision of different types of learning
experiences. Each of these skills is described in greater detail in the
sections which follow.

A knowledge of the component skills which must be acquired during the
process of learning to write is essential knowledge not only for
teachers, but also for teaching researchers. Without this knowledge, the
teacher of writing will be unable to assess the learner's current level
of development in writing, identify component skills weaknesses which
are causing delays in learning to write, plan a teaching programme, or
provide the teaching conditions necessary to ensure that each child
acquires each of the various component skills in a timely fashion.
:::

::: referencesList
#### References

-   Baker, S., Gersten, R., & Graham, S. (2003). Teaching expressive
    writing to students with learning disabilities. Journal of Learning
    Disabilities, 36, 109-123.
-   Berninger, V. W., & Amtmann, D. (2003). Preventing written
    expression disabilities through early and continuing assessment and
    intervention for handwriting and/or spelling problems: Research into
    practice. In H. L. Swanson, K. R. Harris, & S. Graham (Eds.),
    Handbook of learning disabilities (pp. 345-363). New York: Guilford
    Press.
-   Dixon, R. C., & Engelmann, S. (1999). Spelling Mastery. Columbus,
    OH: SRA/McGraw-Hill.
-   Gersten, R., & Baker, S. (2001). Teaching expressive writing to
    students with learning disabilities: A meta-analysis. The Elementary
    School Journal, 101, 251-272.
-   Moats, L. C. (1995). Spelling: development, disability, and
    instruction. Baltimore: York Press.
-   Templeton, S., & Morris, D. (2000). Spelling. In M. L. Kamil, P. B.
    Mosenthal, P. D. Pearson, & R. Barr (Eds.), Handbook of reading
    research. Vol 3 (pp. 525-543). Mahwah, NJ: Erlbaum.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Learningtoprintwriteandtype/index.md","# Learning to print, write, and type \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ce91646174dc4727b849ca6c559d6173}
In order to set down their ideas on paper, students must first learn how
to print, or to write cursively, or to type. Handwriting is a fine motor
skill which can only be shaped through extensive practice in copying
models of well formed letters. The effectiveness of this practice is
greatly dependent upon the accuracy of the differential reinforcement
(the differential feedback) provided following practice attempts
(Church, 1999). More than a year's practice is normally required before
the young child begins to produce legible and neatly formed copies of
sentences. Accurate typing, on the other hand, can be acquired much more
rapidly (in a few months) because the level of hand eye coordination
which is required for keyboarding is considerably less than it is for
handwriting. Given the spread of small computers it is clearly important
than all young children have the opportunity to master not only
handwriting but also keyboarding skills.
:::

::: referencesList
#### References

-   Church, R. J. (1999). Instructional processes. Christchurch, NZ:
    University of Canterbury, Education Department.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Learningtheequivalencerelationsforirregularlyspelledwords/index.md","# Learning the equivalence relations for irregularly spelled words \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d0c13dc624a64f7bbc23de6a6798bb95}
While the spelling of approximately 50% of words can be predicted from a
knowledge of phoneme--\>grapheme equivalences, the other half cannot, at
least not in their entirety. In fact about 60 per cent of the 500 words
used most often in writing have partly irregular spellings (Moats,
1995). There are a number of reasons for this.

-   In some words the same phoneme can be represented by more than one
    spelling pattern. For example, the long \|e\| sound can be
    represented by \"ee\", \"ea\", \"ei\", \"y\", and several other spellings.
-   In some words the spelling of a phoneme is given by the pattern or
    position of letters in a word. An example of this is the case where
    both a vowel and a final \"e\" is used to translate a long vowel
    sound. Compare, for example, \"tap\" and \"tape\".
-   In some words spelling depends upon orthographic conventions, such
    as knowing when to use \"oy\" or \"oi\" and when to use \"dge\" or \"ge\".
-   In some words the spelling is simply unique (e.g. \"people\",
    \"straight\", \"friend\" and \"yacht\").

These features of written English mean that the spelling of significant
numbers of words can be acquired only by means of systematic spelling
practice of those words which the child cannot yet spell correctly.
:::

::: referencesList
#### References

-   Moats, L. C. (1995). Spelling: Development, disability, and
    instruction. Baltimore: York Press.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtowrite/Developingfluencyinprintingwritingortyping/index.md","# Developing fluency in printing, writing, or typing \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-06d479cf5edb43f9b61aae24f26a5abe}
The aim of handwriting instruction is to bring the student to the point
where they can write both legibly and with a functional level of speed.
Children \"need to develop enough fluency so that the mechanics of
producing text do not interfere with the process of composing\" (Graham &
Weintraub, 1996, p. 7). Fluent handwriting is handwriting which is (a)
legible, (b) fast, and (c) writing which occurs with little conscious
attention to the physical act of forming the letters.

The same is true of typing. Typing skills become functional only when
they have been practised to the point where copy typing can be performed
with accuracy and speed, that is, with a functional level of fluency.

The development of fluent writing and typing requires considerable
practice. This practice must be timed practice so that the learner (and
the teacher) can see whether or not improvements in speed are occurring.
In spite of its obvious importance, educational researchers have yet to
identify the handwriting fluency levels and the typing fluency levels
which are characteristic of children at each age level who are making
average rates of progress in learning to write.
:::

::: referencesList
#### References

-   Graham, S., & Weintraub, N. (1996). A review of handwriting
    research: Progress and prospects from 1980 to 1994. Educational
    Psychology Review, 8, 7-87.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Typesofmathematicalskills/Acquiringmathematicalconcepts/index.md","# Acquiring mathematical concepts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-278f36ccadc541b9ba790e0b6bdd5965}
Mathematics curricula are \"conceptually dense\". This means that even
during the early years, the child is faced with the task of mastering
large numbers of mathematical concepts. Concepts in the early
mathematics curriculum include the names and symbols used to represent
whole number quantities from 0 to 100, place value concepts and common
fractions; the ordinal concepts (\"1st\", \"2nd\", \"3rd\" and so on); the
common measurement units such as \"minute\", \"centimetre\" and so on; basic
mathematical relations such as \"equality\", \"greater than\", \"less than\",
and so on; the four basic operations of addition, subtraction,
multiplication and division; the single digit addition and subtraction
facts and the single digit multiplication and division facts.

Some mathematical concepts refer to quantities (e.g. \"five\"), some refer
to values (e.g. \"five centimetres\" etc.), some refer to cardinality
(e.g. \"first\", \"fifth\" etc.), and some refer to relations (e.g.
\"equals\", \"less\", \"least\", \"smaller\", \"shorter\", etc.). In order to
achieve a well developed understanding of any particular mathematical
concept, the child must experience the opportunity to work with a wide
variety of examples (representations) of the concept together with many
opportunities to distinguish between examples and non-examples of the
concept (Church, 1999; Engelmann & Carnine, 1991; Kameenui & Simmons,
1990). This means that the ability to identify mathematical concepts is
an essential skill for anyone involve in the planning of effective maths
lessons.

Conceptual understanding is demonstrated when the child can discriminate
between never-before-seen examples and non-examples of the concept and
can correctly name the new examples (Church, 1999; Engelmann & Carnine,
1991; Tiemann & Markle, 1990). This skill is variously referred to as
\"understanding\", \"generalisation\" or \"transfer\". Many mathematical
concepts such as \"greater than/less than\", \"larger/smaller\" and so on
are relational concepts. Relational concepts are more difficult to teach
than classification concepts because they require the use of teaching
examples which involve comparisons rather than examples which simply
involve classification.
:::

::: referencesList
#### References

-   Church, R. J. (1999). Instructional processes. University of
    Canterbury, Education Department.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications (Rev. ed.). Eugene, OR: ADI Press.
-   Kameenui, E. J., & Simmons, D. C. (1990). Designing instructional
    strategies: The prevention of academic learning problems. Columbus,
    OH: Merrill Publishing Co.
-   Tiemann, P. W., & Markle, S. M. (1990). Analyzing instructional
    content: A guide to instruction and evaluation (4th ed.). Champaign,
    IL: Stipes Publishing.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Typesofmathematicalskills/Learningwhenaparticularprocedureshouldbeused/index.md","# Learning when a particular procedure should be used \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-829c99d8a87348a9a32b3685cff5735e}
Knowing how to perform a particular mathematical procedure is of little
practical value unless the learner also acquires the ability to
recognise those situations in which this procedure can, and cannot, be
used to solve a mathematical or measurement problem. \"Knowing when to
use a procedure is just as indispensable for successful cognitive
activity as knowing how to execute the procedure or understanding the
concepts that underlie it\" (Siegler, 1991, p. 128).

The situation facing the learner here is closely similar to the
situation facing the learner who is learning the meaning of, and how to
use, a new maths concept such as the concept of \"eight\". Understanding,
that is, generalisation of the use of the procedure, occurs as a result
of experiences of two types: opportunities to apply the procedure to the
full range of problems to which it can be applied and, secondly,
opportunities to distinguish between those problems to which the
procedure can be applied and those to which it cannot be applied. It is
probably this fact which has led a number of writers to conclude that
procedural knowledge and conceptual knowledge develop in an interactive
or reciprocal fashion -- with each influencing the other (Gersten &
Chard, 1999; Siegler, 1991).
:::

::: referencesList
#### References

-   Gersten, R., & Chard, D. (1999). Number sense: Rethinking arithmetic
    instruction for students with mathematical disabilities. The Journal
    of Special Education, 44, 18-28.
-   Siegler, R. S. (1991). In young children's counting, procedures
    precede principles. Educational Psychology Review, 3, 127-135.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Typesofmathematicalskills/Thedevelopmentoffluencyinmathematicaloperations/index.md","# The development of fluency in mathematical operations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ad4226c719ec4167900c344d4cf5eff9}
Because mathematics is strongly hierarchical, it is not sufficient for
the child simply to learn how to respond correctly or when to use a
particular procedure. Growth in early arithmetic competence is strongly
correlated with the child\'s level of fluency in naming and writing
letters and numbers (Siders, Siders & Wilson, 1985) and in the fast
recognition of small quantities (Young-Loveridge, 1991). Practice with
the equivalence relationships and the core arithmetical procedures needs
to continue until correct responses have been memorised, that is, until
an adequate level of fluency (automaticity) has been achieved with
respect to each of the performances and understandings which will be
built upon at the next step in the mathematics curriculum.

In well developed teaching programmes in early mathematics the fluency
level which is used to define fluency is usually set somewhere between
70 and 80 correct written digits per minute (Binder, Haughton & Bateman,
2002; Johnson & Layng, 1992). One of the major shortcomings of most
mathematics curricula is that they fail to specify the fluency criteria
which are to be met by children at each age level with respect to such
things as number recognition, single digit maths facts and essential
operations. Without this information it is impossible for the classroom
teacher to determine whether or not children are receiving sufficient
fluency building practice to ensure future success in mathematics, and
it is impossible for researchers either to select or to describe the
participants taking part in research into the learning and/or teaching
of mathematics.
:::

::: referencesList
#### References

-   Binder, C., Haughton, E., & Bateman, B. (2002). Fluency: Achieving
    true mastery in the learning process. Retrieved January 29, 2004,
    from http://www.haughtonlearningcenter.com
-   Johnson, K. R., & Layng, T. V. J. (1992). Breaking the structuralist
    barrier: Literacy and numeracy with fluency. American Psychologist,
    47, 1475-1490.
-   Siders, J. A., Siders, J. Z., & Wilson, R. M. (1985). A screening
    procedure to identify children having difficulties in arithmetic.
    Journal for Research in Mathematics Education, 16, 356-363.
-   Young-Loveridge, J. M. (1991). The development of children's number
    concepts from ages five to nine: Early mathematics learning project:
    Phase II. Hamilton, NZ: University of Waikato, Education Department.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Typesofmathematicalskills/index.md","# Types of mathematical skills \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-024a109cf5ea4e5baa481360c3888298}
Mathematical terms, concepts, operations, and generalisations are
hierarchically interrelated (Resnick, Wang and Kaplan, 1973). Some of
the hierarchical relationships which must be understood in order to plan
sequences of mathematics instruction have been analysed and described by
Evans, Evans and Mercer (1986), Silbert, Carnine and Stein (1990) and
Underhill, Uprichard and Heddens (1980) among others. The Silbert et al.
(1990) analysis is the most detailed of the analyses currently
available.

Early mathematics development involves the acquisition of a number of
component skills: mastering the equivalence relations of mathematics,
developing an adequate understanding of mathematical concepts, learning
how to perform a variety of mathematical procedures (operations), and
learning when it is appropriate to use each of these operations.
:::

::: referencesList
#### References

-   Evans, S. S., Evans, W. H., & Mercer, C. D. (1986). Assessment for
    instruction. Boston: Allyn & Bacon.
-   Resnick, L. B., Wang, M. C., & Kaplan, J. (1973). Task analysis in
    curriculum design: A hierarchically sequenced introductory
    mathematics curriculum. Journal of Applied Behavior Analysis, 6,
    679-710.
-   Silbert, J., Carnine, D., & Stein, M. (1990). Direct instruction
    mathematics (2nd ed.). Columbus, OH: Merrill.
-   Underhill, R. J., Uprichard, A. E. & Heddens, J. W. (1980).
    Diagnosing mathematical difficulties. Columbus, OH: Merrill.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Typesofmathematicalskills/Learningmathematicaloperations/index.md","# Learning mathematical operations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e1e650af804646c8b904fefd5b33d80f}
In addition to mathematical concepts, maths curricula also contain
numerous calculation procedures. These calculation procedures are most
commonly referred to as operations. They are also referred to as
\"algorithms\", \"strategies\", and \"processes\". For consistency we will
refer to these operations as procedures.

Mathematical operations are rule guided procedures (Church, 1999). They
consist of a number of steps which are performed on two or more concepts
such as numerical quantities. The steps can be identified by performing
a task analysis which identifies each of the component operations which
must be undertaken in order to arrive at the correct result.

A task analysis of any particular mathematical procedure produces a
hierarchy of learning objectives \"such that mastery of objectives lower
in the hierarchy (simpler tasks) facilitates learning of higher
objectives (more complex tasks), and ability to perform higher-level
tasks reliably predicts ability to perform lower level tasks\" (Resnick
et al., 1973, p. 679). A detailed analysis of many of the learning
hierarchies which are involved in elementary arithmetic will be found in
Silbert et al. (1990).

An example of a simple hierarchy of learning objectives, the component
steps which must be mastered in order to solve a two-digit addition
problem, are shown in Figure 2333.

![Figure 2333. Sample task analysis for a simple mathematical procedure
(two digit
addition)](../../../../../../assets/images/TECKSFig2333.png \"Figure 2333. Sample task analysis for a simple mathematical procedure (two digit addition)\"){.image-inline}

*Figure 2333. Sample task analysis for a simple mathematical procedure
(two digit addition)*

The hierarchical nature of mathematics curricula has extremely important
implications for teaching practice for it means that progress through
the curriculum will be dependent upon mastery, by the child, of each of
the terms, concepts and procedures from earlier in the curriculum
(Underhill et al., 1980). In order to learn how to perform a new
mathematical procedure the child must be able to (a) associate a symbol
(e.g. =, +, x) with that operation, (b) remember the sequence of steps
involved in the operation and (c) be able to automatically recall the
equivalence relations which are embedded in problems of this type (Smith
& Rivera, 1991).
:::

::: referencesList
#### References

-   Church, R. J. (1999). Instructional processes. Christchurch, NZ:
    University of Canterbury, Education Department.
-   Resnick, L. B., Wang, M. C., & Kaplan, J. (1973). Task analysis in
    curriculum design: A hierarchically sequenced introductory
    mathematics curriculum. Journal of Applied Behavior Analysis, 6,
    679-710.
-   Silbert, J., Carnine, D., & Stein, M. (1990). Direct instruction
    mathematics (2nd ed.). Columbus, OH: Merrill.
-   Smith, D. D., & Rivera, D. P. (1991). Mathematics. In B. Y. L. Wong
    (Ed). Learning about learning disabilities (pp. 345-374). San Diego,
    CA: Academic Press.
-   Underhill, R. J., Uprichard, A. E. & Heddens, J. W. (1980).
    Diagnosing mathematical difficulties. Columbus, OH: Merrill.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Typesofmathematicalskills/Learningmathematicalequivalencerelations/index.md","# Learning mathematical equivalence relations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0e0a63445c324b688cee9061428113b2}
The first step in coming to understand a mathematical concept such as
the quantity \"eight\" is mastery of a set of six equivalence relations
between the name of the concept, its mathematical symbol, and examples
or representations which contain the defining features of the concept.
These equivalence relations have also been referred to as simple facts
(Engelmann & Carnine, 1991), \"interactive units\" (Cawley & Reines,
1996), \"central conceptual structures\" (Griffin & Case, 1997) and so on.
The six basic equivalence relations for the concept of \"eight\", for
example are shown in the following figure

![Figure 2331. The six essential equivalence relations for the concept
of \"eight\" (Adapted from Sidman,
1994).](../../../../../../assets/images/TECKSFig2331.png \"Figure 2331. The six essential equivalence relations for the concept of “eight” (Adapted from Sidman, 1994).\"){.image-inline}

*Figure 2331. The six essential equivalence relations for the concept of
\"eight\" (Adapted from Sidman, 1994).*

As can be seen from Figure 2331, the six basic equivalence relations for
a concept like the quantity \"eight\" consist of three pairs of reversible
stimulus-response relations. Research (e.g. Sidman, 1994) has shown that
once one member of the pair has been learned, the stimulus and response
elements are usually found to be interchangeable. The technical name for
this interchangeability is *reversibility.* The reversibility property
means that, although there are six equivalence relationships to be
learned, only three of these actually need to be taught and practised
(Sidman, 1994). This greatly simplifies the task facing the learner (and
the task facing the teacher as well). In fact, if any two pairs of
equivalence relations have been acquired, the child will almost
certainly be able to perform the responses in the third pair of
relations without additional instruction (Sidman, 1994). This further
simplifies the task of learning (and teaching) mathematical concepts at
each age level -- at least for teachers who have a clear understanding
of the nature of equivalence relations in mathematics.
:::

::: referencesList
#### References

-   Cawley, J. P., & Reines, R. (1996). Mathematics as communication:
    Using the interactive unit. Teaching Exceptional Children, 28(2),
    29-34.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications (Rev. ed.). Eugene, OR: ADI Press.
-   Griffin, S., & Case, R. (1997). Re-thinking the primary school math
    curriculum: An approach based on cognitive science. Issues in
    Education, 3, 1-49.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/index.md","# The learning outcomes hidden inside curriculum goals \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9b2717e1b6124f3e82227ab55ba3e798}
At the present time, the school curriculum groups the competencies which
are to be acquired during the school years into very broad collections
such as \\"English\\", \\"Mathematics\\", \\"Science\\" and so on. English
includes learning to interpret visual and oral presentations, learning
to read, learning to make spoken and visual presentations, and learning
to write. Mathematics includes the development of conceptual
understanding, operational fluency and problem solving skills in number,
algebra, geometry, measurement and statistics.

The achievement objectives listed within each of the learning areas are
very broad and lacking in specificity. Consider, for example, the
following Level 2 English achievement objective: \\"Spells most high
frequency words correctly and shows growing knowledge of common spelling
patterns.\\" Which high frequency words? How much is \\"most\\"? Is the
child expected just to spell these words correctly (no matter how
slowly), or correctly and quickly? Which common spelling patterns? How
is this growing knowledge to be demonstrated? How much knowledge is a
\\"growing knowledge\\"? Does this growing knowledge include an increasing
level of spelling fluency? Note also that the achievement of this
objective requires the prior achievement of a number of prerequisite
skills (such as the mastery of numerous phoneme grapheme equivalence
relations) but that these prerequisites are nowhere listed in the Level
1 curriculum.

The lack of specificity in the New Zealand curriculum generates a
cascade of difficulties which permeate the instructional design task,
lesson planning, the selection of suitable learning activities, the
day-to-day assessment of learner improvement, and the selection and
assessment of \\"national standards\\". It also generates enormous
difficulties for the educational researcher who is provided with almost
no guidance regarding the selection and assessment of valid learning
outcomes during experimental investigations of either school learning or
the relative effectiveness of different teaching strategies.

To illustrate the complexity of the task facing both the classroom
teacher and the teaching researcher this chapter analyses several
curriculum areas into their component skills in order to make clear the
various different types of learning outcomes which each curriculum area
involves. In the sections which follow we present structural analyses of
the interconnected learning outcomes which are involved in learning to
read, learning to write, and learning to find the sum of 2-digit
numbers. These are provided as illustrations of the work which still
needs to be done in identifying the learning outcomes which are implicit
in the \\"achievement objectives\\" listed in the New Zealand curriculum.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Developingreadingfluencyandreadingcomprehension/index.md","# Developing reading fluency and reading comprehension \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-954dd5d50eb9446f9c7f98eba1d21f65}
Reading fluency and reading comprehension are closely linked.
Comprehension remains tenuous until the learner can read grade level
text at 120 correct words per minute -- a level which is reached by the
average child after about four years of schooling (Hasbrouck & Tindal,
2006).

In order to accomplish this level of reading fluency, the learner needs
to complete very large amounts of reading practice. Large amounts of
reading practice are required in order to ensure that the majority of
words in the text are instantly recognised (without having to be decoded
letter by letter).
:::

::: referencesList
#### References

-   Hasbrouck, J. E. & Tindal, G. (2006).) Oral reading fluency norms: A
    valuable assessment tool for reading teachers. The Reading Teacher,
    59, 636-644.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Acquiringanadequatesightwordvocabulary/index.md","# Acquiring an adequate sight word vocabulary \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0d9c32a406b34c94811150e2df41d50a}
After a certain amount of practice, the learner acquires the ability to
instantly recognise particular printed words. In this account we will
refer to those words which the learner instantly recognises as *sight
words* and the number of words which the learner can instantly recognise
as the learner's *sight word vocabulary*. The acquisition of an adequate
sight word vocabulary at each age level is necessary for normal reading
development because an adequate level of reading fluency, and hence
comprehension, is only possible if the child instantly recognises most
of the words in the texts which are being used for reading practice.

It is thought that the acquisition of a functional level of knowledge of
grapheme-phoneme relations is an essential step on the way to reading
competence because this knowledge allows the learner to decode new words
*without having to ask a teacher or peer to pronounce the word for*
them. This metacognitive skill has been referred to as \"self-teaching\"
(Share, 1995; Share & Stanovich, 1995) although it is more appropriately
referred to as *self-decoding*. The development of self-decoding skills
allows the child to *independently* acquire the final equivalence
relation necessary in order for a new printed word to be added to the
child's sight word vocabulary. It is thought that some kind of
self-teaching process is the only kind of process which could
conceivably account for the explosive growth which occurs in the
normally developing child\'s sight word vocabulary during the first four
years of reading instruction (Share & Stanovich, 1995).
:::

::: referencesList
#### References

-   Share, D. L. (1995). Phonological recoding and self-teaching: Sine
    qua non of reading acquisition. Cognition, 55, 151-218.
-   Share, D. L., & Stanovich, K. E. (1995). Cognitive processes in
    early reading development: Accommodating individual differences into
    a model of acquisition. Issues in Education, 1, 1-57.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Acquiringanadequatereceptivevocabulary/index.md","# Acquiring an adequate receptive vocabulary \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5d8afccebdec4e48818deb6f13c710da}
While an adequate level of reading fluency is necessary for
comprehension it is not sufficient for comprehension. Comprehension of a
text requires also that the student knows (has learned) the meanings of
most of the words in the text. Only if the student can instantly
recognise and instantly comprehend the meaning of most of the words
contained in a text will the learner comprehend the text as a whole. It
follows therefore that receptive vocabulary development also plays an
important role in learning to read increasingly advanced texts (Adams,
1990; Jenkins & O\'Connor, 2002).

At each level, learning to read proceeds much more rapidly if the
meanings of the words which are being read are already known to the
child. Where this is the case the child has only to acquire one
equivalence relation (rather than two) in order to recognise a word as a
meaningful word in its printed form (Sidman, 1994). This suggests that
receptive vocabulary size (the number of words which the learner knows
as meaningful words) plays an important role throughout the process of
learning to read.

Finally, the novice reader must acquire a knowledge of the conventions
governing the structure and organisation of the various written genres.
This means that, following the first three years at school, the student
should be exposed not only to narrative texts, but also to descriptive,
expository and explanatory texts on a regular basis.
:::

::: referencesList
#### References

-   Adams, M. J. (1990). Beginning to read: Thinking and learning about
    print. Cambridge, MA: MIT Press.
-   Jenkins, J. R., & O\'Connor (2002). Early identification and
    intervention for young children with reading/learning disabilities.
    In R. Bradley, L. Danielson, & D. P. Hallahan (Eds.), Identification
    of learning disabilities: Research to practice (pp. 99-149). Mahwah,
    NJ: Lawrence Erlbaum.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Learningtodiscriminatebetweenthespokenphonemes/index.md","# Learning to discriminate between the spoken phonemes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9f4c0f408d62448ca8819e3c866a5b94}
In order to begin to learn the letter-sound equivalence relations which
will be necessary in order to make timely progress in learning to read,
the child must also learn to discriminate between the 43 phonemes of
which spoken English is comprised. Standard English uses 25 consonant
phonemes and the 18 vowel and diphthong phonemes. The ability to aurally
discriminate between the 43 English phonemes is variously referred to as
phoneme awareness, phonemic awareness, phonological awareness, and
linguistic awareness. The most appropriate term is phoneme
discrimination skill.

Teaching a child to distinguish between 43 different sounds is a
discrimination training exercise similar to the task of teaching a child
to discriminate, by ear, between 43 notes on a piano. Because many
phonemes can be articulated only as part of a word, phoneme
discrimination exercises always need to point to the position (in the
word) of the target phoneme. The most common kind of response used
during this kind of training is to ask the child whether two spoken
sounds (e.g. at the beginning of a word) are \"the same or different\".
Matching responses (\"Which of these is the same?\") may also be used.

\"A lack of phonological sensitivity makes the learning of
grapheme-to-phoneme correspondences very difficult\" (Stanovich, 1988, p.
601). Actually it probably makes it impossible. It hardly seems likely
that a child could learn to name 43 notes on the piano by ear if they
could not discriminate between some of the notes.
:::

::: referencesList
#### References

-   Stanovich, K. E. (1988). Explaining the differences between the
    dyslexic and the garden-variety poor reader: The phonological-core
    variable-difference model. Journal of Learning Disabilities, 22,
    590-604, 612.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Acquiringdecodingfluency/index.md","# Acquiring decoding fluency \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8cc6367166b94000a2f8a1679402fc20}
Once the child has learned the code (or at least the first 80 or so
items of the code) the ability to read these commonly occurring
graphemes needs to be built to a functional level of fluency
(automaticity) so that a correct response occurs almost instantaneously
and without conscious effort. \"To be useful, any given individual
letter-sound correspondence or phonic generalisation must not merely be
learned; it must be overlearned such that it is instantly and
effortlessly available to the reader\" (Adams, 1990, p. 291).

We will refer to the fast reading of individual graphemes as *decoding
fluency*. Decoding fluency refers to the speed with which the child can
see and correctly say the commonly occurring grapheme--\>phoneme
equivalences of his or her native language. Of course, learning to
instantly recognise the most commonly occurring grapheme--\>phoneme
equivalence relations is not the end of the story. This skill must still
be generalised to include less commonly occurring letter-sound
relationships (e.g. reading the final syllable of plateau as a long
\|o\| sound), to include commonly occurring syllables and morphemes
(e.g. pre- and -less); to encompass context-sensitive regularities (soft
and hard g and c), to include positional regularities (e.g. final versus
initial y), and to include semantic constraints (e.g. their and there)
(Share and Stanovich, 1995).

The level of automaticity which distinguishes good from poor readers
appears to be between 60 and 70 correct responses per minute (Church,
Nixon, Williams & Zintl, 2005). Achievement of this level of decoding
fluency is an important milestone in learning to read because, until
this level of fluency is achieved, the decoding of unknown words is
likely to be too slow for the child to maintain comprehension over
passages containing unknown words and the level of prose reading fluency
is likely to be too slow to be sufficiently interesting to motivate the
large amount of reading practice which is required in order to become a
competent reader.
:::

::: referencesList
#### References

-   Adams, M. J. (1990). Beginning to read: Thinking and learning about
    print. Cambridge, MA: MIT Press.
-   Church, R. J., Nixon, J., Williams, D., & Zintl, S. (2005). Building
    decoding fluency in 8- to 9-year old poor readers. Paper presented
    to the annual NZARE Conference, Dunedin, N.Z.
-   Share, D. L., & Stanovich, K. E. (1995). Cognitive processes in
    early reading development: Accommodating individual differences into
    a model of acquisition. Issues in Education, 1, 1-57.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/index.md","# The skills involved in learning to read \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ce0e9e69aee2474fb1e9223e6bcdcd78}
There have been many hundreds of research based analyses of how children
learn to read and the results of this research have been summarised by
many authors (e.g. Adams, 1990; Jenkins & O\'Connor, 2002; National
Reading Panel, 2000). These analyses suggest that:

-   in order to read with comprehension (at any level), the learner must
    have previously acquired (a) a knowledge of the meanings of most of
    the words in the text and (b) the ability to read that text at a
    functional level of fluency.
-   in order to read with a functional level of fluency, the learner
    must have previously acquired (a) the ability to instantly recognise
    a majority of the words in the text and (b) the ability to decode
    the remaining words with a functional level of decoding fluency.
-   in order to acquire an age appropriate sight word vocabulary
    (vocabulary of words which can be instantly recognised) and a
    functional level of decoding fluency, the learner must have mastered
    the most commonly occurring of the grapheme-phoneme equivalence
    relations which occur in written English.
-   in order to acquire grapheme-phoneme equivalence relations in a
    timely fashion the child must be able (a) to distinguish between
    each of the 52 printed letters and (b) distinguish between each of
    the 43 English language phonemes.

This process is pictured in the following diagram.

![Figure 2310. The early developmental sequence for learning to
read](../../../../../assets/images/TECKSFig2310.png \"Figure 2310. The early developmental sequence for learning to read\"){.image-inline}

*Figure 2310. The early developmental sequence for learning to read*

Each of these skills is distinguished because each involves a different
type of learning outcome and, hence, the provision of different types of
learning experiences if they are to be acquired in a timely fashion.
Each of these skills is described in greater detail in the sections
which follow.

A knowledge of the component skills which must be acquired during the
process of learning to read is essential knowledge for all teachers,
teacher educators, teaching researchers and anyone else who is involved
in teaching children to read. Without this knowledge the teacher of
reading will be unable to assess the learner's current level of reading
development, identify component skills weaknesses which are causing
delays in learning to read, describe research participants, plan a
reading programme, or provide the teaching conditions necessary to
ensure that each child masters each of the various component skills in a
timely fashion.
:::

::: referencesList
#### References

-   Adams, M. J. (1990). Beginning to read: Thinking and learning about
    print. Cambridge, MA: MIT Press.
-   Jenkins, J. R., & O\'Connor (2002). Early identification and
    intervention for young children with reading/learning disabilities.
    In R. Bradley, L. Danielson, & D. P. Hallahan (Eds.), Identification
    of learning disabilities: Research to practice (pp. 99-149). Mahwah,
    NJ: Lawrence Erlbaum.
-   National Reading Panel. (2000). Teaching children to read. Retrieved
    June 25, 2000, from
    http://www.nichd.nih.gov/publications/nrp/smallbook.htm
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Learningcommongrapheme-phonemeequivalencerelations/index.md","# Learning common grapheme-phoneme equivalence relations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-869de9f00ac74af2b6453342ddfbacfe}
Critical to learning to read is the acquisition, in a timely fashion, of
the ability to translate English language graphemes (letters and letter
groups) into phonemes. Being able to translate written graphemes into
spoken phonemes is variously referred to as sounding out, word attack,
phonics, phonological recoding, cipher reading, deciphering, knowledge
of the alphabetic principle, graphophonemic knowledge, knowledge of
spelling-sound relationships, knowledge of letter-sound relationships,
grapheme-phoneme correspondences, grapheme-phoneme conversion rules,
decoding skills, and so on. We will use the term *decoding skills* and
will define decoding skills as the ability, given an English language
grapheme in the context of a word, to say (that is, pronounce) that
grapheme.

Acquisition of grapheme-phoneme equivalence relations involves learning
a set of discriminated oral responses where the stimulus takes the form
of a grapheme (a letter or group of letters) and the response takes the
form of a correctly pronounced sound. In the case of the phoneme \|f\|,
for example, the child needs to learn three common grapheme-phoneme
relations: (a) see f -\> say \|f\|, (b) see ph -\> say \|f\| and (c) see
a terminal gh -\> say \|f\| (sometimes). There are 43 possible oral
responses (because there are 43 English language phonemes).

The English language represents its 43 phonemes with some 250 different
spellings. Of these, about 170 are reasonably common (Moats, 1995). Of
these, it has been suggested that 70 to 80 might be specifically taught
during the process of learning to read (Carnine, Silbert & Kameenui,
1990). There is, however, no agreement on which grapheme-phoneme
relations should be specifically taught during the first three years of
reading instruction (Adams, 1990).
:::

::: referencesList
#### References

-   Adams, M. J. (1990). Beginning to read: Thinking and learning about
    print. Cambridge, MA: MIT Press.
-   Carnine, D. W., Silbert, J., & Kameenui, E. J. (1990). Direct
    instruction reading (2nd ed.). Columbus, OH: Merrill Publishing Co.
-   Moats, L. C. (1995). Spelling: Development, disability, and
    instruction. Baltimore: York Press.
:::"
".//Importantlearningandteachingevents/Thelearningoutcomeshiddeninsidecurriculumgoals/Theskillsinvolvedinlearningtoread/Learningtodiscriminatebetweentheletters/index.md","# Learning to discriminate between the letters \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4538c2d957b245519f74507d543a0901}
In order to begin to learn the letter-sound equivalence relations which
will be necessary in order to make timely progress in learning to read,
the child must first learn to discriminate (tell the difference) between
each of the printed letters. English orthography consists of 26
unaccented lower case letters and 26 upper case letters. Several of the
letters (e.g. a and g) have alternate forms (e.g. *a* and g)*.* Learning
to discriminate between the 52 letter shapes typically occurs within the
context of letter naming activities which take the form:

see the letter--\>say the name of the letter.

The ability to discriminate between the printed English language letters
is most commonly referred to as letter naming or knowledge of letter
names, or orthographic knowledge and is widely recognised as a skill
which needs to be acquired during the first year of school, if not
before.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practicestimuli/Thematchbetweenpracticestimulusandlearningoutcome/index.md","# The match between practice stimulus and learning outcome \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f3aeaf3785ca49b4b591894a1f2096b8}
If I am trying to improve a child's reading (reading is the learning
outcome) and I provide a story for the child to read (the story is the
practice stimulus), there is likely to be a close match between the
child's practice responses and the intended learning outcome. If,
however, I seek to improve the child's reading skills and I read the
child a story while the child listens there is little or no match
between the practice stimulus (listening to a story) and the desired
learning outcome (independent reading).

The phrase \"match between practice stimulus and learning outcome\" refers
to the degree of correspondence between the practice stimuli which are
being used during practice and the test stimuli which will be used in
assessing the child's progress towards the desired learning outcome. In
everyday language we might talk about the \"relevance\" of the practice
activities in relation to the learning outcome which these practice
activities are intended to foster. Although there has been little
research into the matter, it seems self-evident that practice stimuli
which result in practice of the responses listed in the teaching aim are
more likely to move the child towards achievement of that aim than
practice stimuli which result in the practice of responses which are not
included in the teaching aim.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practicestimuli/index.md","# Practice stimuli \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-eba6832624034ba6b19755a2931d2c28}
Students spend much of their school day responding to instructional
questions, exercises, problems, and activities of various kinds and yet
the English language has no word to refer to these things. In this
account we will used the invented term *practice stimulus* to refer to
any kind of stimulus, question, exercise, or problem which the learner
is expected to respond to and we will refer to the responses which
result as *practice responses. A practice stimulus is an antecedent
stimulus event to which a response is expected*. Practice stimuli are
antecedent stimulus events which provide practice opportunities. They
may also result in practice responses. Note, however, that it is
possible for the teacher to present a practice stimulus (such as a
question) and hence to provide a practice opportunity (the opportunity
to construct an answer) but for no practice response to occur (perhaps
because the learner does not yet know the answer to the question which
has been asked.) Technically speaking, a practice stimulus which does
not result in any kind of response should be referred to as a \"potential
practice stimulus\".

Practice stimuli are of critical importance for learning. Without
practice stimuli there can be no practice responses. And without
practice responses (either overt or covert) there will usually be no
learning.

Practice stimuli can take many different forms. They can take the form
of objects to be named, symbols (e.g. words) to be read, questions to be
answered, exercises to be worked, problems to be solved, activities to
be completed, and so on. They may occur in various modes, and they may
be teacher initiated or child initiated.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practicestimuli/Themodeofthepracticestimulus/index.md","# The mode of the practice stimulus \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a9fe9486509b4949a8218205a357ba68}
The practice stimuli which are provided for children to respond to can
occur in various modes: aural, visual, audio-visual, and so on.

Examples of practice stimuli presented in the *aural mode* include such
things as oral instructions to be followed, oral questions to be
answered, orally presented words to be spelled, orally presented
problems to be discussed, music to be analysed, and so on.

Practice stimuli which are presented in the *visual mode* may take a
variety of forms. They may consist of *objects,* as when a pre-school
provides equipment for children to play with, a geology teacher provides
rocks to be classified, a chemistry teacher provides chemicals to mix, a
music teacher provides instruments to be played, and so on. They may
consist of *pictures* as when a teacher presents pictures of objects to
be named, pictures of concept examples to be classified, diagrams to be
labelled, paintings to be analysed, and so on. Or they may take the form
of *symbols* as when a teacher presents letters and words to be copied
(e.g. during handwriting lessons), material to be read, texts to be
studied for their content, written questions to be answered, written
problems and exercises to be worked, music to be read and played, and so
on.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practicestimuli/Childinitiatedandteacherinitiatedlearninginteractions/index.md","# Child initiated and teacher initiated learning interactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0baf8f39399040bb983a0c38c0597962}
Learning interactions may be initiated by the environment (e.g. by other
people) or they may be initiated by the learner. If mum says to the
child, \"What is this letter?\" and the child responds, we have an example
of a learning interaction initiated by the environment. If the child
says to mum, \"What letter is this?\" and mum responds, we have an example
of a learning interaction initiated by the learner.

We distinguish between child initiated and teacher initiated learning
interactions because it is widely argued that child-initiated
interactions are \"better\" than interactions initiated by others. The
research evidence, on the other hand suggests that even young children
learn just as quickly from adult initiated learning interactions as they
do from child initiated learning interactions (McLay, 2003). This debate
makes the distinction doubly important.
:::

::: referencesList
#### References

-   McLay, L. (2003). Acquisition, generalisation and retention of
    object names in 4-year old children: A comparison of child-led and
    adult-led learning interactions. Unpublished M.Ed. dissertation.
    Christchurch, NZ: University of Canterbury, School of Education.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/Thedistinctionbetweenprimaryquestionsandsecondaryquestions/index.md","# The distinction between primary questions and secondary questions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-76c09c3ef7f74f01a70c21d03f9d7eb8}
When the learner is having difficulty in responding, the teacher may
provide several opportunities for the student to make the one response.
In the following case, the student\'s first response was incorrect, so
the teacher pointed to a particular part of the written problem and
repeated the question in a second attempt to get the student to respond
correctly. In this kind of interaction, the initial question or response
opportunity is referred to as the *primary* *question* and subsequent
attempts to elicit the same response are referred to as *secondary
questions*.

![Figure 2413. A learning interaction with a primary question and a
secondary
question](../../../../../../assets/images/TECKSFig2413.png \"Figure 2413. A learning interaction with a primary question and a secondary question\"){.image-inline}

*Figure 2413. A learning interaction with a primary question and a
secondary question*

In this example there is only one learning interaction (although there
are two responses) because both responses are attempts to answer the
same question.

The distinction between antecedents and consequences is an important one
because the two types of stimulus events have very different kinds of
effects on learning. Antecedent events provide practice opportunities
and this is an important function because, without practice responses
there would be no learning. But it is the consequences of practice
responses which operate to determine whether or not a particular
practice response will be remembered and used again in the future.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/Thedistinctionbetweenstimuliandresponses/index.md","# The distinction between stimuli and responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bfaed34a6a8e4499b5894da07d3db9c0}
The description and analysis of a learning interaction requires us to
distinguish between (a) learner responses and (b) the stimuli (the
objects and events) to which the learner is responding.

**Response.** When we want to talk about a particular behaviour, we
usually use the term *response*. In a learning interaction, the response
is the action performed by the learner. One of the characteristics of a
response, as a unit of behaviour, is that most responses are used over
and over again. The response \"following the teacher's instruction\" is a
unit of behaviour which is likely to be engaged in by a particular child
several times today, several times tomorrow, and so on.

Responses can be either overt responses which we can see (e.g. reading
aloud) or covert responses which we cannot see (e.g. reading silently or
thinking about what one has read). For example when the teacher displays
12 counters and says \"How many have I got now?\" and the learner mentally
counts to 12 and puts her hand up, the display of 12 counters plus the
question is the stimulus (because it is the counters and the question
which determine the response) and the responses are (a) mentally
counting to 12 and (b) hand-raising.

**Stimulus.** A *stimulus* (plural *stimuli*) is something which is
seen, heard, or otherwise sensed by the learner and which has an effect
on what the learner does, thinks or feels. If a parent issues an
instruction and the learner follows that instruction, then the parent's
instruction is a stimulus for the response \"following the instruction\".
Teachers spend much of their time providing things for children to
respond to: letters to be copied, stories to be read, maths activities
to be completed, questions to be answered, and so on. Many of these
function as stimuli. Some stimuli are events which are seen (e.g. a
printed word to be read), some are events which are heard (e.g. an oral
question from the teacher), some are events which are smelled or tasted
(e.g. the smell of sulphur dioxide in a chemistry class), and some are
events which are felt (e.g. a prod with a ruler from the child sitting
behind you).

The great majority of stimuli are outside the learner but stimuli may be
internal as when the learner responds to bodily sensations of various
kinds (e.g. the sensation of a full bladder, the pain from a twisted
ankle, a pounding heart, and so on).
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/Interactionswhichcanandcannotresultinlearning/index.md","# Interactions which can and cannot result in learning \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-694b4e5486e44ae1bb005e2d8426178b}
In order for an interaction to result in learning it must involve an
action or set of actions which have not yet been mastered by the
learner. It must involve a response which cannot yet be performed
without prompting, or which cannot yet be performed correctly, or which
cannot yet be performed with sufficient speed. It can be seen therefore,
that not all of the interactions which occur in classrooms are learning
interactions.

A commonly occurring classroom interaction which is not a learning
interaction is the procedural interaction. For example, a teacher might
say to a group of 10-year olds, \"Put your books away\". Clearly the
teacher is not providing an opportunity for the children to practice
putting their books away. Rather the teacher is engaged in an
organisational activity -- perhaps beginning a transition from one
learning activity to the next.

Organisational activities are quite common in classrooms and need to be
clearly distinguished from learning activities. For example, an activity
which involves setting up a series of groups for co-operative group work
in social studies (an organisational activity), needs to be
distinguished from the social studies activity itself (the learning
activity itself).

Organisational activities are often initiated by a series of *procedural
instructions* from the teacher. Procedural instructions may take a
variety of forms. They may describe the learning activities which are
going to occur. They may describe the order in which learning activities
are to be completed. They may indicate what the learner is to do next.
Or they may describe how a learning activity is going to be organised.
Just as procedural interactions (which involve actions which have
already been mastered) need to be distinguished from learning
interactions, so procedural instructions must be distinguished from
practice stimuli and from prompts (which provide opportunities for new
learning to occur).
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/Thedistinctionbetweentwo-termandthree-termlearninginteractions/index.md","# The distinction between two-term and three-term learning interactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5f581db64de0410fa1b97c6fdd8845db}
Once a distinction has been made between antecedents and consequences,
it becomes possible to distinguish between two general types of learning
interactions: three-term interactions, and two-term interactions.

-   A *three-term* *learning interaction* is one which contains an
    antecedent stimulus, a response, and a consequence following that
    response.
-   A *two-term learning interaction* is one which contains only an
    antecedent stimulus and a practice response (but no consequence).

The distinction between two-term and three-term learning interactions is
extremely important because three-term interactions often result in more
rapid learning than is the case with two-term interactions especially
during the initial phase of learning something new.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/hedistinctionbetweenpresentationspracticestimuliandprompts/index.md","# The distinction between presentations, practice stimuli and prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5e619f134bd942cbb0843f8726ba2074}
Teachers use many different kinds of antecedent instructional events.
Three of these serve such different instructional functional that they
must always be distinguished. These are presentations, practice stimuli,
and prompts.

In teaching situations, one of the most commonly observed kinds of
antecedent stimulus events is the presentation of curriculum relevant
information by the teacher. In this account, messages which the learner
receives from the verbal environment will be referred to as
*presentations*.

Parents and teachers also provide practice opportunities by providing
questions, exercises, problems and other kinds of stimuli for the
learner to respond to. We will call these kinds of antecedent events
*practice stimuli.*

A third kind of antecedent event is the stimulus which serves the
function of showing the learner how to perform a new behaviour (or how
to respond correctly to a new stimulus). We will refer to these kinds of
antecedents as *prompts.*

The following exchange illustrates the difference between a
presentation, a practice stimulus and a prompt.

![Figure 2415. A learning interaction with a practice stimulus, a
prompt, and a
presentation](../../../../../../assets/images/TECKSFig2415.png \"Figure 2415. A learning interaction with a practice stimulus, a prompt, and a presentation\"){.image-inline}

*Figure 2415. A learning interaction with a practice stimulus, a prompt,
and a presentation*

In this interaction the teacher points to the word car. The question
indicates that the learner is expected to read the word. This makes the
printed word car a practice stimulus. The learner\'s response indicates
that she cannot yet respond correctly to this stimulus. The teacher then
says \"You came to school in one of these today.\" Since the child now
gives the correct response, it is clear that this antecedent has
functioned as a prompt. Next the teacher makes a statement about \"how
people travel to school\". No response is expected, so this statement is
not a practice stimulus. The statement does not describe how to respond
correctly, so it is not a prompt. But the statement does contain
information and this makes it a presentation.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/Thedistinctionbetweenantecedentstimuliandconsequences/index.md","# The distinction between antecedent stimuli and consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4e442dc9d8d44838aeb291d73f8b35d1}
In the analysis and description of learning interactions, two general
classes of stimuli are always distinguished: stimuli which are sensed
*before* the learner responds and those which the learner senses *after*
the response has been made. Events which occur before the learner
responds are referred to as *antecedent stimuli*. Antecedent stimuli are
stimuli which the learner responds *to*.

Events which are experienced *after* a response has been made are
referred to as *consequences*. Responses often have consequences. I look
for something (response) and I find it (consequence). I write something
(response) and the teacher corrects it (consequence). It is important to
note that *consequences are also stimuli,* that is, they are events
which are seen or heard or otherwise sensed by the learner. If the
learner draws a picture and then hears the teacher say \"That's lovely\"
the teacher's remark is a consequence because (a) it occurs after the
response of drawing the picture and (b) it is a stimulus (an event heard
by the learner). *Consequences are events which the learner sees, or
hears, or otherwise senses immediately following performance of the
response, behaviour or action which is of interest*. Most consequences
are external to the learner. They are changes to the environment --
changes produced by the behaviour which has just been performed. It is
also possible for the consequence of an action to be internal. I start
eating an ice cream and experience a nice taste. I take an aspirin and
cease to experience a headache.

In the following learning interaction, the teacher\'s question is the
antecedent stimulus (A), the learner\'s answer is the response (B), and
the teacher\'s comment is the consequence (C).

![Figure 2412a. A simple 3-term learning
interaction](../../../../../../assets/images/TECKSFig2412a.png \"Figure 2412a. A simple 3-term learning interaction\"){.image-inline}

*Figure 2412a. A simple 3-term learning interaction*

The distinction between antecedents and consequences is simply a
distinction in time. Events which occur *prior* to a response are
antecedents. Events which occur *after*, or following, or as a result of
a response are consequences. Note also that, in order to identify the
antecedents and the consequences for a particular response, we must
first specify the response (the aspect of the learner\'s behaviour)
which we wish to talk about. Until a particular action has been
specified, it is not possible to distinguish between those events which
are antecedents and those which are consequences for that action.

Sometimes the consequence part of a learning interaction is not
immediately visible, or is missing altogether. In the following exchange
there are two interactions (because there are two responses) and there
is a consequence following the second response, but there is no apparent
consequence following the first response (apart from the next teacher
request).

![Figure 2412b. A learning interaction with two learner responses and
one
consequence](../../../../../../assets/images/TECKSFig2412b.png \"Figure 2412b. A learning interaction with two learner responses and one consequence\"){.image-inline}

*Figure 2412b. A learning interaction with two learner responses and one
consequence*

In some interactions, the behaviour of interest consists of several
attempts to respond to a single antecedent stimulus.

![Figure 2412c. A learning interaction with a response which includes a
self-correction](../../../../../../assets/images/TECKSFig2412c.png \"Figure 2412c. A learning interaction with a response which includes a self-correction\"){.image-inline}

*Figure 2412c. A learning interaction with a response which includes a
self-correction*
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Thecomponentsofindividuallearninginteractions/index.md","# The components of individual learning interactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b8cadf99e202458bbb2a1cc909983822}
By definition, the changes which we refer to as learning are changes
which are occurring as a result of experience, that is, as a result of
the learner's *interaction* with his or her environment. Interactions
are the building blocks of the learning process. *A learning interaction
consists of a single learner response together with the event or events
which the learner is responding to plus any immediate consequences which
result from that response*. Individual interactions (e.g. writing a
word) typically occur as part of a sequence of interactions (e.g.
writing a story). However, we must be able to identify and to analyse
individual interactions because it is at the level of the individual
interaction that learning occurs. (Writing a single word may result in
the child learning how to spell that word, for example.)
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practiceresponses/Constructedresponsesvsselectionresponses/index.md","# Constructed responses vs. selection responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d6b0f579bde44fcc95f881b0549c0210}
Sometimes students are set to work on activities where they have to
select the correct spelling from several options, or select the correct
name from the names given, or select the correct answer from examples
given. *A selection response is one where the learner selects a given
option from a limited number of possibilities by pointing, circling,
ticking, underlining or clicking on the option which has been selected*.

Other learning activities require the student to create, construct or
complete a response or action or procedure. For example, the student
might be asked to write (construct) a one paragraph description, or to
generate an answer to a teacher question, or to complete the incomplete
answer of another student.

The distinction between constructed responses and selection responses is
an important one because the two types of responding have different
effects both on acquisition and on remembering.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practiceresponses/Overtvscovertresponses/index.md","# Overt vs. covert responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-45cdf9b0556d49048e96be476a976a58}
*An overt response is one which can be seen or heard by others.* Some
writers refer to these as public responses. *A covert response is one
which cannot be seen by other people.* Covert responding is variously
referred to as cognitive processing, thinking, reflecting, \"working it
out in the head\", and so on. Covert responding includes such activities
as silent reading, thinking about the material which is being read,
constructing an answer to a problem in one's mind, self-rehearsal of
selected facts, and so on.

The distinction between overt and covert responding is extremely
important because, when a teacher addresses a question to an entire
class or group of students the teacher often assumes that all of the
students are mentally constructing an answer to the question and
research has shown that this assumption is seldom correct.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practiceresponses/Responsemode/index.md","# Response mode \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6c295bf2cd3e406e9fd9504ff5c69c6a}
Practice activities can require the learner to respond in a variety of
different modes. Some of the most common response modes observed in the
classroom are

-   *saying* (as in giving an oral answer, reading out loud, reciting,
    giving a talk, and so on),
-   *writing* (as in writing the answers to questions, compositional
    writing, copying notes from the blackboard, completing written
    exercises, and so on) and
-   *doing* (as in cutting and pasting, practising a gymnastic exercise,
    playing a musical instrument, imitating the movements of another
    child, and so on).
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practiceresponses/Typesofpracticeopportunities/index.md","# Types of practice opportunities \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-13e34f2cd37f4709a1d5b6eab6e8aa79}
Different practice stimulus modes may be combined with different
practice response modes to produce a variety of different kinds of
practice stimulus--\>practice response combinations.

There is no ordinary language term for \"stimulus-response combinations\"
and various technical terms (e.g. \"learning channels\") have been
proposed. We will refer to the various practice stimulus--\>practice
response combinations as *types of practice opportunities*. Many of
these types of practice opportunities are so common that they have their
own names. For example, when the practice stimulus takes the form of
printed words and the practice response is \"saying the words\" the
resulting responses are called *reading* responses.

Some of the most common types of practice opportunities together with
their common names are listed below.

![Figure 2454. Some common types of practice opportunities (practice
stimulus--\>practice response
combinations)](../../../../../../assets/images/TECKSFig2454.png \"Figure 2454. Some common types of practice opportunities (practice stimulus–>practice response combinations)\"){.image-inline}

*Figure 2454. Some common types of practice opportunities (practice
stimulus--\>practice response combinations)*

The kind of practice opportunity which is provided may or may not
correspond with the learning outcome which the teacher is aiming for. If
the aim is to help the learner improve their performance of some kind of
skill, for example, then the learner may experience the opportunity to
practice that skill or the learner may be given the experience of
listening to talk about how to perform the skill. Although there has
been little research, it seems reasonable to assume that the achievement
of a given learning outcome is more likely to occur if the practice
opportunity experienced by the learner matches the stimulus--\>response
mode which will be used in assessing the learner's achievement.

There is, as yet, no agreed technical term for the match between
practice opportunity and learning outcome and this hinders discussion
and analysis of this important learning variable. Nor have learning
psychologists developed an agreed procedure for measuring, and hence
describing, the degree of match between particular practice
opportunities and particular learning outcomes. This is unfortunate
given the obvious importance of this variable in the selection of
effective learning activities.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practiceresponses/index.md","# Practice responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-dd10d47dfc93471b898f68c8b8e57a6b}
Many different kinds of practice responses are possible; overt responses
and covert responses, constructed responses and selection responses,
verbal responses and performance responses, oral responses and written
responses. These distinctions are quite important because different
types of learning outcomes involve different types of response modes and
these different types of learning outcomes are more likely to be
achieved if the response mode required by the learning activity matches
the response mode involved in the learning outcome.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Practiceresponses/Responseeffort/index.md","# Response effort \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a390e88e712747b48ec08c7dc4b132ab}
Practice responses can vary in size (and effort) from writing a single
word through to writing a complete project report. The effort which is
involved in completing a practice activity is also a function of how
fluent the learner has become in performing the component responses. A
student who writes at 5 words a minute will find completing a 2-page
report a much more effortful activity than the student who is able to
write the same report at 20 words a minute.

Although most teachers can distinguish between more and less effortful
tasks, response effort has yet to be adequately defined. This is
unfortunate because practice activities which involve considerable
response effort are much less likely to be completed than practice
activities which involve the learner in less response effort. Response
effort also has a very powerful effect on student motivation.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Presentations/Presentationmeaningfulness/index.md","# Presentation meaningfulness \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3190cff7c0c44bc495caa814f61276cd}
Presentations may be more or less meaningful to the individual learner.
A meaningful presentation is one which \"makes sense\" to the learner. In
some accounts, meaningful presentations are referred to as
comprehensible presentations. In everyday language we talk about
presentations which the learner \"understands\" or \"comprehends\". In spite
of the importance of the meaningfulness dimension, meaningfulness
remains an extremely slippery concept, one which has yet to be
adequately defined, and one which remains difficult to measure.

The meaningfulness dimension of instructional presentations is of
critical importance because the content of meaningful presentations is
more likely to be remembered than the content of presentations which are
not meaningful to the learner .
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Presentations/Presentationmode/index.md","# Presentation mode \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-616c19f78bc04a408ebe8cac97b18e1b}
New information may be presented to the learner in various ways, that
is, in various presentation modes. The presentation modes most commonly
seen in the classroom are aural presentations, visual presentations, and
audio-visual presentations.

-   *Aural* presentations include such things as teacher talk, student
    talk, audio tapes, radio broadcasts, and so on for the learner to
    listen to.
-   *Visual* presentations include such things as written texts to read,
    maps and diagrams to look at, demonstrations to watch, and so on.
-   *Audio-visual* presentations include such things as DVDs, videos,
    films, plays, and so on to be watched and listened to.

The distinction between different presentation modes is important
because the different modes often serve different functions. For
example, until a child learns to read, new information must be presented
in the aural mode, that is, in the form of talk. Written presentations
become possible only when the learner can read with a reasonable level
of expertise. The different modes are also processed in different areas
of the brain.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Presentations/Presentationcontentfactsconceptsandprinciples/index.md","# Presentation content: facts, concepts and principles \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-34ad8c534ce54e798444261c00dc4e73}
Presentations may be about facts, concepts, or principles and they may
make reference to definitions, examples, non-examples, and so on.

**Presentations about facts.** A fact is a proposition about a unique
object or event. A proposition is a statement which describes a
relationship between two or more objects, events, or qualities, e.g.
\"Beethoven wrote nine symphonies.\" The utterance \"pencil, typewriter,
word processor\" is not a fact because it is not a proposition. The
statement \"There are 26 letters in the English alphabet\" is a fact
because (a) it is a proposition and (b) there is only one English
alphabet. Facts have no generality and it is this feature which
distinguishes them from concepts and principles.

Presentations about a *fact* simply state the fact. For example, \"The
distance between the Earth and the moon is 384,400 km.\" Or \"Chlorine is
a poisonous gas.\" Or \"Cook produced the first map of New Zealand.\"

**Presentations about concepts.** A concept is a class of objects,
qualities or events (rather than a unique object or event). Individual
objects are grouped together because they share a common characteristic
(or set of characteristics). The term \"cat\", for example, can be used to
refer to all members of the stimulus class \"cats\", not just the
household cat, and the term \"red\" can be used to refer to all members of
the stimulus class \"red hued objects\". Terms such as \"cat\", and \"red\"
are referred to as *concept names*.

For any class of objects or events there are *examples* of the class and
*non-examples*. For the concept \"noun\" there are thousands of examples
-- all the nouns in the language. Words which are not nouns are
non-examples of the concept \"noun\".

Presentations about a *concept* may be about the name of the concept
(e.g. \"These things here are called hexagons\"), or they may be about the
definition of the concept (\"A hexagon is a six sided figure\"), or they
may be about an example of the concept (\"Is this one a hexagon? Yes.
Because it has got six sides\"), or they may be about a non-example of
the concept (\"Is this one a hexagon. No. Because it has got five
sides.\")

**Presentations about principles.** A principle is a proposition which
describes the relationship between two or more concepts. In some
accounts, principles are referred to as rules. The principle \"plants
grow faster in the summer than in the winter\" describes a relationship
between plant growth and seasonal climate. The principle \"distance
travelled equals speed over time\" describes the relationship between the
concepts \"distance\", \"speed\" and \"time\".

Learning to use a principle correctly is rather like learning to use a
concept name correctly. In learning to use a principle, the learner must
not only learn to state the principle but must also learn to distinguish
between those situations in which the principle applies and those
situations in which the principle does not apply.

Presentations about a *principle* may be about any of the following: (a)
the principle itself, (b) the name of the principle, (c) an example to
which the principle applies, (d) an instance where the principle does
not apply, (e) or a definition, example, or non-example of one of the
concepts contained within the principle.

Being able to distinguish between facts, concepts, and principles is a
matter of some importance for a teacher. This is because different kinds
of learning experiences are needed in order to master new facts, new
concepts, and new principles. Unless a teacher can look at a curriculum
objective and immediately distinguish between the facts, concepts and
principles contained in that objective, the teacher will be unable to
select the kinds of learning experiences which are needed in order to
produce these various different kinds of learning outcomes.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Presentations/index.md","# Presentations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bb71808a98264a6299cfd79fd8ad8abd}
In teaching situations, one of the most commonly observed kinds of
antecedent stimulus events is the presentation of curriculum relevant
information to the learner. We will refer to messages which the learner
receives from the verbal environment as *presentations*. Presentations
always involve some kind of curriculum relevant content. They are always
about something. (In everyday language, the content of a presentation is
usually referred to as \"information\".) The information is not
information about what to do. It is information about the lesson
content, that is, it is curriculum relevant information which is being
presented in the hope that the learner will remember it.

Unlike practice stimuli and prompts, presentations can occur without any
practice response on the part of the learner. The only response which is
expected to a presentation is that the presentation be attended to by
the learner.

![Figure 2420. A learning interaction where the practice stimulus is
preceded by a
presentation](../../../../../assets/images/TECKSFig2420.png \"Figure 2420. A learning interaction where the practice stimulus is preceded by a presentation\"){.image-inline}

*Figure 2420. A learning interaction where the practice stimulus is
preceded by a presentation*

Presentations come in many forms: teacher or student talk, written
accounts, diagrams, pictures, television programmes, and so on. In
addition, presentations can differ in a number of important ways. They
may differ with respect to mode, content, and meaningfulness, for
example.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/index.md","# Learning interactions and their component events \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8f7aadc8fcab44ada9628384cb6cc669}
In this section we identify some of the main events which learning
depends upon. These events have been the subject of scientific study for
the better part of 100 years and, as a result it is possible to describe
them with some confidence. The main problem which still faces learning
researchers is the problem of deciding upon the level of
specificity/generality which should be used when describing and
analysing different kinds of learning.

Activities which result in learning may be described at various levels
of abstraction. For example, a common level of analysis is the teaching
topic or unit of work. A teaching topic typically consists of several
lessons or class meetings each of which involves a number of
identifiable learning activities. This is the level of analysis which is
commonly employed for programme evaluations and method comparisons -- as
when an investigator compares a radical new method of teaching something
against the boring old \"traditional method\" of teaching the same thing.

At a less general and more specific level is an analysis at the level of
a particular learning activity. For example we might analyse or measure
the effects on learning of a single class lesson, or a single peer
tutoring session or a single instance of a fluency building game.

At the least general and most specific level we can analyse the effects
of single learning interactions. For example, we can describe the events
which go to make up a single learning interaction (such as responding to
a request to spell a particular word and receiving feedback on that
attempt) and we can measure the effects on learning of different forms
of learning interactions (such as learning interaction which include
feedback and those which do not include feedback following the practice
response).

We know from experience (and more than 100 years of research) that
learning can occur as a result of just one or two repetitions of an
experience so it is clear that the description and analysis of learning
must be at the level of individual learning interactions. We also know
that learning can result from interactions which are as small as
hearing, or saying, or seeing, or writing a single word so it is clear
that the description and analysis of individual learning interactions
must be at the level of specific responses that is, at the level of
specific and distinguishable behaviour-and-purpose units.

The ability to analyse learning activities at the level of the learning
interaction is a very important teaching and research skill because it
enables teachers and learning researchers to describe both the
particular types of learning interactions which have been selected for
use and, even more importantly, to describe the number of learning
opportunities received by each child.

In Section 1 of this chapter we define a learning interaction and its
component elements (antecedents, practice responses, and consequences).
Subsequent sections describe and define several types of antecedent
presentations (Sections 2) and antecedent prompts (Section 3). Section 4
describes various ways in which practice responses can vary and Section
5 describes several different kinds of consequences (such as
reinforcing, aversive and neutral consequences).
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Prompts/Copyingandnon-copyingprompts/index.md","# Copying and non-copying prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-918f47681fd74c4797362af02039f24b}
It is important to distinguish between prompts which stay in view while
the learner responds and prompts which are presented (and removed)
before the learner responds. For example a teacher might show a child
how to spell a word by orally spelling the word before the child begins
to write or by writing down the word for the child to copy. The first
case is an example of a non-copying prompt. *A non-copying prompt is a
prompt which is presented and removed before the learner responds.* The
second case is an example of a copying prompt. *A copying prompt is a
prompt (usually a model) which stays in view while the learner
responds.*

Copying and non-copying prompts perform different functions during
acquisition. For example, some responses are so difficult to perform
that a model which the learner can copy is required. Copying and
non-copying prompts also have different effects. During the early stages
of acquisition, for example, a copying prompt may result in the
performance of a completely new response and, hence, learning. During
the later stages of acquisition, copying prompts often result in copying
rather than learning.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Prompts/Stimulusprompts/index.md","# Stimulus prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d1b286e79e2643ada8c0d809db2a2892}
*Stimulus prompts are prompts which point backwards to important
features of a practice stimulus* -- features of the practice stimulus to
which the learner must attend in order to respond correctly. Let\'s say
that a child is learning to tell the time and makes an incorrect
response. If the child got the hour wrong, we might provide a stimulus
prompt by pointing to or touching the position of the hour hand on the
clock. If the child got the minutes wrong, we might provide a stimulus
prompt by pointing to the position of the minute hand on the clock.

There are many ways in which the learner\'s attention can be directed to
critical features of the practice stimulus. Three examples are pointing,
highlighting and the use of instructions.

**Pointing.** Attention may be prompted by pointing to an important part
of the display as in the example above where the teacher pointed to
either the hour hand or the minute hand of the clock following an error
in telling the time.

**Highlighting.** Attention may be prompted by simplifying the stimulus
display so that the important features of the display are more clearly
visible. For example, the distinction between yellow and orange might be
taught to a young child by temporarily ignoring colours other than
yellow and orange so that the child\'s attention was focused on the
single yellow/orange discrimination.

**Instructing.** Attention may be prompted using verbal instructions to
attend to particular features (e.g. \"Notice how these sedimentary rocks
look and feel sandy to the touch\"), or by prompting attention to the
definition which defines membership in a particular category (\"Remember
that a hexagon has six sides\").
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Prompts/Behaviourprompts/index.md","# Behaviour prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-70364cf84ff741f3a40dfe0dbe4e4cc1}
Behaviour prompts are prompts which show or tell the learner how to
perform a new behaviour, skill, or sequence of responses. A teacher who
models a forehand tennis stroke to a novice tennis player is using a
behaviour prompt as is the teacher who shows a learner the steps to be
performed in completing a long multiplication problem*. A behaviour
prompt is a prompt which points forward to the behaviour to be performed
by the learner*. Behaviour prompts can take a variety of forms: physical
guidance, models, instructions, and so on.

Being able to distinguish between the different kinds of behaviour
prompts is a useful skill because some kinds of prompts are more
effective at certain developmental levels than others. For example, the
effectiveness of a verbal instruction depends upon the learner\'s
ability (and motivation) to follow the instruction. Verbal instructions
cannot be used to prompt the performance of new behaviours in pre-verbal
learners, or in learners who have not yet learned to comply with the
instructions of other people, or with learners who do not understand the
instruction.

**Physical guidance.** One way of prompting an improved response from
the learner is to physically guide the learner through the actions which
are involved in performing the target skill. The coach who guides the
novice player\'s arm and racquet through a forehand tennis stroke is
using this kind of prompt.

**Modelling (demonstrating)**. The most common prompting procedure is
demonstrating the response for the learner. Demonstrations are often
referred to as *models*. The act of providing a demonstration is called
*modelling* the desired behaviour. In everyday language we talk about
*showing* the learner what to do. Note that much early language learning
occurs when the child imitates the language modelled by other, older
persons during conversations with the child.

Demonstrations are normally presented \"live\" by the teacher but they can
be presented in other ways. For example, they may take the form of a
*permanent model* -- a diagram of a worked example which the learner can
refer to whenever they need to. Models can be of two general kinds:
process models and product models.

-   A *process model* is one where the teacher demonstrates the process,
    that is, the action which needs to be performed, or the steps which
    need to be performed, in order to produce a particular product or
    outcome. A teacher who shows a learner how to operate, say, a fax
    machine (while the learner watches) is providing a process model.
-   A *product model* is one which shows the final product. The teacher
    who displays each of the printed letters on the wall of the
    classroom for the children to copy is providing a product model as
    is the woodwork teacher who displays an example of the finished
    product for the students to emulate.

**Instructing**. Instructions are verbal descriptions of the behaviour
to be performed. They are statements which describe to the learner when
to perform a particular response or how to perform a particular response
or sequence of responses. In everyday language we talk about *telling*
the learner *how* to perform a particular skill. Instructions may be
presented orally by the teacher, or they may be written down to form a
set of written instructions. The instruction manuals which come with
most modern appliances, and which describe how to operate the appliance,
are good examples of written prompts.

**Mechanical prompts**. Some prompts consist of a mechanical or
electronic device. The training wheels on a young child\'s bicycle
constitute a mechanical balancing prompt. The use of a metronome to
model the correct tempo during practice on a musical instrument is an
example of a mechanical timing prompt. The use of a spelling checker to
prompt the correct spelling of each word during compositional writing
practice on a word processor is an example of a mechanical (electronic)
spelling prompt.

**Combination procedures.** Often the initial performance of a new
procedure is prompted using a mixture of both demonstrations and
instructions. Teaching a student how to perform the procedure for adding
fractions, for example, would usually be achieved by both describing and
demonstrating each of the steps in the procedure.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Prompts/Themodeoftheprompt/index.md","# The mode of the prompt \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-73bf4e78adc34986a6079535541a3620}
There are two general types of prompts: stimulus prompts and behaviour
prompts and these two types of prompts are distinguished because they
serve different functions. Each of these types of prompts may be
delivered in a number of different modes. An awareness of the different
kinds of prompting procedures is very useful for a teacher because, if a
particular type of prompt does not work, the teacher may proceed to
select a more effective prompting procedure.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Prompts/index.md","# Prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b76300c101824e588d5a82b09cb58df2}
An important type of antecedent stimulus event is the stimulus which
serves the function of showing the learner how to perform a new
behaviour (or how to respond correctly to a new stimulus). This kind of
antecedent event is commonly referred to as a prompt. A prompt is an
antecedent stimulus, *additional to the practice stimulus,* which has
been provided with the aim of helping the learner to perform the correct
or appropriate response to a practice stimulus.

Prompts are defined in terms of their effects. *Prompts are antecedents
which have the effect of making performance of the correct response more
likely*. Prompts can also have the effect of helping the learner to
respond more accurately, or more proficiently, or more expertly. An
antecedent only meets the definition of a prompt if it increases the
likelihood of the learner responding correctly (or with greater
expertise) to the practice stimulus. Prompts are identified by first
identifying the practice stimulus and then by asking whether any
additional help has been provided to show the learner how to respond to
that practice stimulus.

Being able to identify prompts is an essential teaching skill because
prompted practice usually results in much more rapid acquisition of new
skills and understandings than trial and error practice. In fact, a
sequence of prompted practice responses is usually an essential teaching
condition during the teaching of new responses.

Prompts are also referred to as \"scaffolds\" and the act of prompting as
\"scaffolding\" by many writers. However, the term \"scaffold\" is used more
as a metaphor than as a technical term, and those who use the term
scaffold have yet to distinguish between the many different kinds of
scaffolding activity which are possible. Because these problems can be
avoided by using the terms *prompt* and *prompting,* it is these terms
which will be used in this account.

Prompts can take many different forms. They can take the form of
demonstrations, oral descriptions of what to do, written instructions,
rules, directions to attend to a particular part of a stimulus display,
hints, clues, and so on.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Prompts/Levelofresponsecontrol/index.md","# Level of response control \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e3f16443c1cf4b468ff710c522a9d852}
Prompts can vary with respect to their effectiveness. In technical terms
we say that prompts vary with respect to the degree of control which
they have over the desired response. I can provide a demonstration of
how to solve a particular type of maths problem and this may function as
an effective prompt for some children and as an ineffective prompt for
other children. An \"ineffective prompt\" is, of course, not a prompt at
all because an \"ineffective prompt\" has no effect on the learner's
performance or learning.

The effectiveness of a particular prompt for a particular child lies
somewhere on a continuum from highly effective through to barely
effective. One way of distinguishing between more and less effective
prompts is to talk in terms of strong prompts and weak prompts.

**Strong prompts***.* Effective prompts are often referred to as strong
prompts (because they provide a high degree of control over the
learner's response and make correct responding highly likely). *A strong
prompt is one which, if presented, makes it highly likely that the
learner will respond with the prompted response*. If a child comes to a
reading word which they do not recognise and the teacher says the word
and the child then imitates the word, \"saying the word\" has functioned
as a strong prompt. Strong prompts not only make performance of the
correct response highly likely, they also make errors very unlikely.
They therefore have an important role to play during the initial
learning phase.

**Weak prompts.** A weak prompt is a prompt which, while still providing
assistance, provides less assistance than a strong prompt. *A weak
prompt is a prompt which, if presented, increases the likelihood that
the learner will respond correctly but which does not increase this
likelihood as much as a strong prompt would*. If a child comes to a
reading word which they do not recognise and the teacher says \"What is
the first sound?\" and the child decodes the word step by step, then
\"What is the first sound?\" has functioned as a weaker prompt than simply
saying the word for the child to imitate. It is a weaker prompt because
the child has had to do more work in figuring out the correct response.
Weak prompts, while reducing the likelihood of learner error, leave more
room for errors to be made than is the case with strong prompts. Weak
prompts are of little use during the initial phase of learning (when the
child has yet to learn how to respond correctly) but they have an
important role to play during the transition from prompted to unprompted
(independent) performance.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Theeffectsofconsequencesderivefrombothbiologyandexperience/index.md","# The effects of consequences derive from both biology and experience \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b0d92a81136b4b5b8d6623980d7967a9}
Human beings are born with a built-in capacity to be reinforced by
certain events. Other events acquire the power to function as
reinforcers as a result of experience. The same is true of punishers.
While one can be an effective teacher without knowing how this occurs,
an understanding of how experience turns some events into reinforcers
and punishers is necessary if we are to understand why it is that the
same consequence can have different effects on the behaviour of
different individuals.

The biological reinforcers and punishers are referred to as
unconditioned (unlearned) reinforcers and punishers in some texts, and
as primary reinforcers and primary punishers in some texts.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Learnedpunishers/index.md","# Learned punishers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7d1438bd31064c9ba2e34ffcf213db91}
Punishing consequences are consequences which the individual tries to
avoid and the learned punishers are those consequences which function as
punishers by virtue of the society or culture in which one lives and by
virtue of the training which that culture provides during the
socialisation of its young. The learned punishers include those events
which have acquired the power to make us feel foolish, embarrassed,
intimidated, anxious, or fearful. For most individuals this includes
such events as the negative reactions of others, insults, jokes at our
expense, the unwanted demands of others, criticism, reprimands, negative
feedback, being treated like a younger person, and so on.

Learned punishers are culturally relative. A particular phrase which
functions as an insult or a reprimand in one society or culture may have
no meaning and hence no aversive affect in another culture. Whether or
not a particular event (such as a warning) will function as a learned
punisher also depends upon the age and learning history of the
individual child.

Because almost any event which regularly occurs in association with a
biological punisher (or previously acquired learned punisher) can
acquire punishing properties, the number of different kinds of events
which acquire punishing properties during the development of individual
children is huge. We may group these events into three general
categories: loss of access to preferred activities, the negative
reactions of others and negative feedback.

**Loss of access to desired activities**

Just as access to a desired activity will function as a reinforcing
consequence, so failure to gain access, or loss of access to a desired
activity will function as an aversive consequence. Let us say for
example, that a particular student completes more work when work
completion allows that child to work with her friend. This observation
suggests that working with the friend is reinforcing for this student.
If this is the case, then losing the right to work with the friend will
probably also function as an aversive consequence for this student. The
same will be true of any operation in which the child is deprived of
access to any activity which they have previously chosen to engage in.

**Negative reactions from others**

A negative reaction from another person is experienced as aversive by
the great majority of children and adults and the distinction between
approving and disapproving reactions is learned by most children at a
young age. Some of the kinds of social reactions which come to function
as punishers (aversive consequences) for most (but not all) children are
as follows*.*

-   *Being ignored.*
-   *Interruptions to the interaction*. For example, being asked to
    repeat an answer, being asked to explain an answer, having one\'s
    turn transferred to another student for a better answer
-   *Disagreement*. For example, \"No, I disagree with that\", \"Who agrees
    with that?\", \"No, I wouldn\'t do that\"
-   *Expressions of disappointment*. For example, \"You can do better
    than this\"
-   *Non-verbal expressions of disapproval*. For example, head shaking,
    scowl
-   *Verbal expressions of disapproval* *(reprimands).* For example,
    \"Stop doing that\", \"Please don\'t do that\", \" I don\'t like that\",
    \"We don\'t do that here\", \"You did better than this yesterday\",
    \"This is not good enough\"
-   *Loud or aggressive responses*. For example, being yelled at
-   *Threats.* For example, being told that unless your answers are
    correct, you will have to do the work over again.
-   *Reinforcer loss*. For example, having previously earned points
    taken away

**Negative feedback**

Not all responses are successful. Some are failures. In other words,
responses can produce negative feedback as well as positive feedback.
The feedback which follows incorrect responses is most commonly referred
to as \"error feedback\" or as \"negative feedback\". Feedback which tells
the learner that a behaviour is unsatisfactory in some way tends to have
a suppressive effect on that behaviour. For example, many children will
work hard not to make mistakes in their school work so that can avoid
the teacher corrections which result if the child makes a mistake. For
such children, we can see that error corrections have become aversive
consequences (because we can see the child trying hard to avoid them).
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Reinforcingaversiveandneutralconsequences/index.md","# Reinforcing, aversive, and neutral consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b74e67fdcd044ddebc2f04bd4c169411}
In modern research into learning and motivation, consequences are
classified according to their effects. A particular response may work in
the sense that it produces the consequence which we intended it to
produce. We look in the fridge and find the drink which we were seeking.
Or a particular behaviour may fail to work in the sense that it produces
consequences other than the consequence which we intended it to produce.
We look in the fridge and fail to find the drink which we were seeking.
The same is true of practice responses. These too have consequences for
the learner. The learner may be able to see that their response is
correct because it makes sense, or because it matches some model, or
because a teacher or peer acknowledges the answer as correct, and so on.

Different kinds of consequences have different kinds of effects on
practice responses. When consequences are grouped according to their
effect, three general classes of consequences are distinguished. These
three classes are:

-   consequences which make the preceding response *more likely* in the
    future,
-   consequences which make the preceding response *less likely* in the
    future and
-   consequences which have *no effect* on the response which produces
    them.

Consequences which *increase* the likelihood that the learner will
respond in the same way again in the future are referred to as
*reinforcing consequences*. Consequences which *reduce* the likelihood
that the learner will use the preceding response again in the future are
referred to as *aversive consequences*. Consequences which have no
effect on our behaviour are referred to as *neutral consequences*.

Reinforcing consequences are also referred to as \"reinforcing stimuli\"
or \"reinforcing events\" or \"positive reinforcers\" or as \"reinforcers\".
These terms are synonymous. Reinforcing consequences are sometimes
mistakenly referred to as rewards. This mistake should be avoided. A
reward is something which you hope the recipient will like. A
reinforcing consequence is an event which has a particular kind of
effect on the particular behaviour which produces it (making it more
likely that the learner will respond again in that particular way next
time the situation arises). Aversive consequences are often referred to
as \"punishing consequences\" or \"punishing stimuli\" or as \"punishers\".
These terms, too, are synonymous.

Although they are often overlooked, consequences are just as important
as presentations and prompts. This is because the question of whether or
not a certain response or way of behaving will be learned and used again
in the future depends upon the consequences produced by that response in
the past. This is a very strong research finding which has been
demonstrated hundreds of times.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Biologicalpunishers/index.md","# Biological punishers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c5fa07f7a4864c82a58941d31ff8503f}
The biological punishers are those events which pose a threat to the
safety or comfort of the individual as a human being. They are events,
the avoidance of which are essential to the survival and comfort of all
individuals regardless of culture. The biological punishers include the
events (such as rotten food) which make us feel nauseous or ill, the
events (such as sudden movements) which startle us, the events (such as
aggression from others) which frighten us, and the events (such as
blows, cuts, stings and burns) which hurt us. The biological punishers
also include lack of air, foul air, extreme heat and extreme cold,
exertion without rest, the lack of sensory stimulation which we
experience as boredom, very loud noises and foul tastes and smells.

Much of what we do we do in order to avoid the punishing effects of
naturally occurring aversive events. For example, we avoid careless
behaviour on a bike or skates or skis in order to avoid the consequences
of falling over (hurting ourselves). Someone who accidentally touches a
hot element will burn themselves and the aversive consequence is
immediate and automatic. Someone who drinks too much at a party and
starts to feel nauseous will experience a biologically determined
aversive outcome which has resulted directly from the behaviour of
drinking too much.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Learnedreinforcers/index.md","# Learned reinforcers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-44e3f83033854903b53edea9bc1a2736}
Learned reinforcers are those environmental events which acquire their
reinforcing properties as a result of experience (usually the experience
of occurring in association with events which already function as
reinforcers). The learned reinforcers include the socially mediated
encouragements, commendations, prizes, rewards, favours and so on which
the members of a given social group use in their attempts to encourage
culturally approved (rather than antisocial) behaviour in others. The
socially mediated reinforcers play a very important role not only in
learning but also in the maintenance of society. Much economic activity
and all paid work, for example, is maintained by systems of learned
reinforcers - the reinforcers which we refer to as money.

Many of the learned reinforcers are consequences which are provided by
or mediated by other people. All learned reinforcers are *culturally
relative*. A particular phrase which functions as a commendation and
hence as a reinforcer in one culture may have no meaning and hence no
reinforcing properties outside that culture. In Western cultures it is
considered appropriate to praise younger children for responding
correctly. In many Asian cultures it is considered inappropriate to
praise children simply for responding correctly because this may make
them \"conceited\". One of the reasons why teachers must know the cultural
background of each of the children their classes is because this
information is needed in order to make decisions about the kinds of
events which are likely to function as social reinforcers for individual
children.

Because learned reinforcers acquire their reinforcing properties as a
result of experience, the events which will function as learned
reinforcers for individual children *change with age*. Money does not
function as a reinforcer for very young children. It only acquires
reinforcing properties after the child has the opportunity to learn that
money can be exchanged for other things which do have reinforcing
properties.

At any given age, the events which will function as learned reinforcers
also *vary from one child to the next* as a result of differences in the
learning histories of individual children. Some children, for example,
do not find feedback reinforcing. In fact, some children (especially
those who have been raised by very inconsistent parents) do not even
find praise reinforcing. These individual differences in responsiveness
to events which often function as learned reinforcers need must be
understood and taken into account if one is to become a teacher.

Because almost any event which regularly occurs in association with
reinforcing events can acquire reinforcing properties, the number of
different kinds of events which acquire reinforcing properties during
the development of the individual is quite large. An understanding of
the wide range of different kinds of events which can function as
reinforcing consequences is essential knowledge for teachers and
teaching researchers because any event which functions as a reinforcing
event has the power to shape improvements in performance, to raise
motivation, and to create a liking for particular people and activities.
We may group the most commonly occurring learned reinforcers into three
general categories: access to preferred activities, the positive
reactions of others and positive feedback.

**Access to activities which already generate reinforcement (Premack's
Rule)**

Behaviours which the learner can already perform and which already
generate reinforcement are usually referred to as *high probability
behaviours.* They may also be referred to as preferred activities,
because they are activities which, if the learner is given a choice, he
or she will choose to engage in. During the 1950s the behavioural
scientist, David Premack, demonstrated that any activity which the
learner preferred to engage in can be used to reinforce completion of
any less preferred task (Premack, 1959). If a particular child prefers
watching TV to completing homework after school, and the parent
introduces the requirement \"In order to watch TV (consequence) you must
first complete your homework (target behaviour)\" then many children will
begin to complete their homework in order to maintain access to the TV
and the reinforcement which it provides. This general principle has come
to be known as \"Premack\'s Rule\".

Premack\'s rule identifies any activity which the learner chooses to
engage in (in preference to completing the target behaviour) as a
potential reinforcer. Premack\'s rule identifies a very large number of
reinforcers for each learner and does so for all learners regardless of
age, level of ability, or cultural background.

Of course, the particular activities which are preferred by individuals
(and which will function as reinforcers for particular individuals) vary
from one individual to the next as a function of their different
learning histories. Some people will work hard to earn the opportunity
to attend a football match. Other people do not find the opportunity to
attend football matches at all reinforcing.

However, there is enough commonality in the learning histories of
children to result in certain activities becoming preferred activities
for large numbers of children. Sulzer-Azaroff and Mayer (1991, p.
156-157), for example have listed a number of activities which are \"high
probability behaviours\" (and which will function as reinforcers) for
many children. These include:

listening to a taped story

using gym equipment

watching TV

tape-recording oneself

playing with puppets

using a computer

sitting with a friend in class

working the photocopier

listening to music

modelling with modelling clay

using items of science equipment

winning first choice of playground equipment

looking at slides

drawing on the blackboard

sitting at the teacher\'s desk

solving codes and puzzles

running errands

reading an interesting book

playing with blocks

using a typewriter

feeding the fish

playing games like noughts and crosses

having lunch with the teacher

passing out books in the classroom

colouring pictures

tutoring another child

painting

helping staff

watching cartoons

using the woodwork room

playtime

working with a friend

reading magazines

playing playground games

playing board games

stapling

One characteristic of skilled performance is that it enables the learner
to gain access to other reinforcing activities - activities which
hitherto were inaccessible. The outcome to a child of learning to ride a
bike is the additional, new reinforcing activities (such as attending
football matches) which become accessible once one has learned how to
ride a bike. It is this kind of outcome which often motivates people to
practise, and eventually to master, new skills.

**The positive reactions of others**

Social interaction, of a positive kind, acquires reinforcing properties
early in the life of most children. This is partly because of the
sensory stimulation which social interaction provides, but also because
access to so many reinforcers is mediated by the other people in the
child\'s environment. Some examples of the kinds of social reactions
(social consequences) which often function as reinforcers in Western
style cultures are as follows.

-   *Social interaction*. For example, continued conversation, having
    one\'s question answered, having one\'s request granted, receiving
    the help which has been requested
-   *Attention*. For example, nod, smile, wink, pat on the shoulder (in
    some cultures)
-   *Agreement*. For example, \"Yes I agree\", \"Yes I think you should\",
    \"Okay\"
-   *Thanks*. For example, \"That\'s very good of you\", \"Thank you\", \"How
    considerate\"
-   *Praise*. For example, \"I like that\", \"See how you have improved\",
    \"That is better than yesterday\", \"Much better\", \"Good work\", \"You
    did that well\", \"You are doing very well\", \"Wow\", \"Far out\",
    \"That\'s the way\", \"That\'s right\", \"That\'s good\", \"That\'s great\",
    \"That\'s excellent\", \"That\'s perfect\", \"That\'s the best job I\'ve
    seen today\"
-   *Descriptive praise*. For example, \"I like the way you have set that
    out\", \"You have got every single one correct - Excellent\", \"Not a
    single spelling error - Great\", \"This is very neat indeed\"
-   *Public commendation*. For example, \"You should show this to your
    parents\", \"Look what \_\_ has done\", \"Show the class your \_\_\", \"I
    think you should put this on the wall\", \"I\'m going to give you a
    \_\_ for this\"
-   *Merit awards*. For example, certificate of achievement, letter of
    merit to parent, name or photo on merit board, best performer award,
    points towards a prize, a prize for achievement
-   *Rewards*. For example, pens, pencils, felts, crayons, rubbers,
    notebooks, coloured paper, stickers, cards, badges, gold stars

**Positive feedback**

*Feedback is the term most commonly used to refer to consequences which
have the effect of informing the learner whether or not their practice
response was correct or incorrect*. Feedback may also function to tell
the learner whether or not their most recent performance constituted an
improvement and it may function to tell the learner how close they have
come to the goal of competent performance. We will refer to this kind of
consequence as \"positive feedback\" or as \"confirmation\" (because it
confirms that the preceding answer is correct or an improvement over
previous attempts).

In Western societies feedback which informs the learner that their
performance was correct, or satisfactory, or improved, or closer to the
target which they have set, often functions as a reinforcing
consequence - motivating continued practice and continued improvement.

The approving reactions of others often have a feedback component. But
feedback can also be provided independently of the reactions of others.
In handwriting, for example, feedback can be provided by providing the
learner with models of correctly formed letters for the child to compare
their own handwriting against. Cards containing the answers to worksheet
questions and exercises can be made available for the learner to compare
their own answers against. Responses to exercises and classroom
activities can be marked as correct or incorrect without, necessarily,
praising the correct responses.

The feedback which is provided by others during the course of social
interactions is often quite subtle. If a 2-year old child says something
which is not understood by, say, his mother, he will not normally be
told that his utterance is \"wrong\", he will be asked to repeat it. In
this situation, then, \"conversation proceeding\" is the feedback event
which indicates that the previous response was satisfactory and \"being
asked to say something again\" is the feedback event which indicates that
the previous response was unsatisfactory.

A similar operation occurs during question-and-answer discussions in the
classroom. The student who frames an incorrect answer during a classroom
discussion will often not be told that the answer is unsatisfactory.
Rather the teacher will ask another child what she thinks. In this
situation then, \"lesson proceeding\" is the feedback event which
indicates that the previous answer was acceptable to the teacher and
\"question redirected to another student\" is the feedback event which
indicates that the previous answer was less than satisfactory.
:::

::: referencesList
#### References

-   Premack, D. (1959). Toward empirical behavior laws: I. Positive
    reinforcement. Psychological Review, 66, 219-233.
-   Sulzer-Azaroff, B. & Mayer, G.R. (1991) Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart and Winston.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Biologicalreinforcers/index.md","# Biological reinforcers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-de43be3964d8472fbf1093520f5cdf55}
The biological reinforcers are those environmental events which are
essential to the survival and comfort of individuals as human beings.
The biological reinforcers include such things as food (after a period
without food), water (after a period without water), sugar, oxygen,
sexual stimulation (after a period without sexual stimulation),
continued warmth, rest (after exertion), sleep (after a period without
sleep) and continued sensory stimulation. Events such as these have
probably acquired their reinforcing properties during the evolutionary
history of the human species. The biological reinforcers function as
reinforcers for all members of the human species regardless of culture.
And they function as reinforcers from the earliest age. No learning is
required to turn these events into reinforcers.

Some responses immediately produce reinforcing (or punishing) outcomes
without any other person doing anything - the reinforcing (or punishing)
outcome arises directly as a result of the response. For example, if I
am hungry and prepare something to eat, the behaviour \"preparing
something to eat\" will be automatically reinforced by the taste (and the
reduction in hunger pangs) which results from eating what I have
prepared. If I read an interesting story, my behaviour (reading) is
automatically reinforced by the sensory stimulation provided by the
reading. If I am cold and turn on the heater the behaviour (turning on
the heater) will be automatically reinforced by the warmth which the
heater produces.

Of the biological reinforcers, sensory stimulation is the most important
as far as school learning is concerned. This is because there are many
things which teachers can do to maintain optimal levels of sensory
stimulation in the classroom. Teachers can also use activity change (and
the resultant increase in sensory stimulation) to reinforce attention,
effort, task completion, and improvement on the part of individual
students.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/index.md","# Consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-492a7b17f978431e8e8070a49f6aeab8}
In three-term learning interactions, practice responses have
consequences. During instruction, improvements and non-improvements in
performance typically have different consequences. For example, the
teacher may respond to improvements with praise but react to responses
which show no improvement by asking the learner to \"try again\".
Likewise, correct responses and incorrect responses tend to have
different consequences. For example, the teacher may mark correct
answers as correct and respond to incorrect answers by showing the
learner how to obtain the correct answer.

Consequences may be classified in many different ways. They may be
classified according to their effects. They may be classified according
to whether these effects are biological or acquired. They may be
classified according to whether they follow correct or incorrect
responses. And they may be classified according to whether they take the
form of feedback, the reactions of others, access to preferred
activities, and so on.

More research has been undertaken into the effects of consequences on
learning than into the effects of any other type of event. This research
indicates very clearly that a number of distinctions between different
kinds of consequences (and response-consequence relationships) are
critical to both the design of effective teaching sequences and the
design of interpretable learning and teaching experiments.
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Thetimingofconsequences/index.md","# The timing of consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b3ca38f97e4a426dad8925decb979095}
The consequence which follows a practice response may follow
immediately, or after a short delay, or after a long delay. We will
refer to the interval between responses and consequence as the
*post-response interval*. *The post-response interval is the time which
elapses between completion of the learner\'s response to the practice
stimulus and the presentation of any consequence by the teacher, or by
the instructional medium, or by the environment.* The post-response
interval is not the same as \"wait-time\" which refers to the interval of
time occurring between when a teacher asks a question and when he/she
calls on a particular student to respond.

The time which elapses between response and consequence is an important
instructional variable because reinforcing consequences have their
strongest effect when they immediately follow correct responses whereas
error corrections have their strongest effect if they follow after a
short delay (long enough for the learner to self correct if they are
able to).
:::"
".//Importantlearningandteachingevents/Learninginteractionsandtheircomponentevents/Consequences/Correctanswerconsequencesanderrorconsequences/index.md","# Correct answer consequences and error consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-99b862208ef1472fb5af6db4e8a7fa34}
Consequences may also be classified according to the type of response
which they follow. For example, reinforcing consequences may follow
improvements, they may follow correct responses, they may follow correct
and speedy responses, and so on. They may also follow errors and they
may follow inappropriate behaviour (although this is more likely to be
accidental than intentional.) In this account, the consequences which
follow correct responses will be referred to as *right answer
consequences* and the consequences which follow incorrect responses will
be referred to as *error consequences*.

Being absolutely clear about the difference between correct and
incorrect responses in the skills and understandings which are being
taught is an essential teaching competence because it is a prerequisite
to ensuring that reinforcing consequences only ever follow correct
behaviour and not misbehaviour, and that corrections and other possibly
punishing consequences only ever follow incorrect and/or inappropriate
responses.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Thecontentofthemathematicscurriculum/Achievementobjectivesformathematics/index.md","# Achievement objectives for mathematics \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4c5618f5d67145d092255a6860c9dd81}
Summaries of the achievement objectives for the first three levels of
study in number and algebra, geometry and measurement, and statistics
are as follows.

**Level 1**

*In Number and Algebra students will solve problems and model situations
that require them to:*

-   Use a range of counting, grouping, and equal-sharing strategies with
    whole numbers and fractions.
-   Know the forward and backward counting sequences of whole numbers to
    100.
-   Know groupings with five, within ten and with ten.
-   Communicate and explain counting, grouping, and equal-sharing
    strategies, using words, numbers, and pictures.
-   Generalise that the next counting number gives the result of adding
    one object to a set and that counting the number of objects in a set
    tells how many.
-   Create and continue sequential patterns.

*In Geometry and Measurement students will solve problems and model
situations that require them to:*

-   Order and compare objects or events by length, area, volume and
    capacity, weight (mass), turn (angle), temperature, and time by
    direct comparison and/or counting whole numbers of units.
-   Sort objects by their appearance.
-   Give and follow instructions for movement that involves distances,
    directions, and half or quarter turns.
-   Describe their position relative to a person or object.
-   Communicate and record the results of translations, reflections, and
    rotations on plane shapes.

*In Statistics students will solve problems and model situations that
require them to:*

-   Conduct investigations using the statistical enquiry cycle:
-   posing and answering questions;
-   gathering, sorting and counting, and displaying category data;
-   discussing the results.
-   Interpret statements made by others from statistical investigations
    and probability activities.
-   Investigate situations that involve elements of chance,
    acknowledging and anticipating possible outcomes.

**Level 2**

*In Number and Algebra students will solve problems and model situations
that require them to:*

-   Use simple additive strategies with whole numbers and fractions.
-   Know forward and backward counting sequences with whole numbers to
    at least 1000.
-   Know the basic addition and subtraction facts.
-   Know how many ones, tens, and hundreds are in whole numbers to at
    least 1000.
-   Know simple fractions in everyday use.
-   Communicate and interpret simple additive strategies, using words,
    diagrams (pictures), and symbols.
-   Generalise that whole numbers can be partitioned in many ways.
-   Find rules for the next member in a sequential pattern.

*In Geometry and Measurement students will solve problems and model
situations that require them to:*

-   Create and use appropriate units and devices to measure length,
    area, volume and capacity, weight (mass), turn (angle), temperature,
    and time.
-   Partition and/or combine like measures and communicate them, using
    numbers and units.
-   Sort objects by their spatial features, with justification.
-   Identify and describe the plane shapes found in objects.
-   Create and use simple maps to show position and direction.
-   Describe different views and pathways from locations on a map.
-   Predict and communicate the results of translations, reflections,
    and rotations on plane shapes.

*In Statistics students will solve problems and model situations that
require them to:*

-   Conduct investigations, using the statistical enquiry cycle:
-   posing and answering questions;
-   gathering, sorting, and displaying category and whole number data;
-   communicating findings based on the data.
-   Compare statements with the features of simple data displays from
    statistical investigations or probability activities undertaken by
    others.
-   Investigate simple situations that involve elements of chance,
    recognizing equal and different likelihoods and acknowledging
    uncertainty.

**Level 3**

*In* *Number and Algebra students will solve problems and model
situations that require them to:*

-   Use a range of additive and simple multiplicative strategies with
    whole numbers, fractions, decimals, and percentages.
-   Know basic multiplication and division facts.
-   Know counting sequences for whole numbers.
-   Know how many tenths, tens, hundreds, and thousands are in whole
    numbers.
-   Know fractions and percentages in everyday use.
-   Record and interpret additive and simple multiplicative strategies,
    using words, diagrams, and symbols, with an understanding of
    equality.
-   Generalise the properties of addition and subtraction with whole
    numbers.
-   Connect members of sequential patterns with their ordinal position
    and use tables, graphs, and diagrams to find relationships between
    successive elements of number and spatial patterns.

*In Geometry and Measurement students will solve problems and model
situations that require them to:*

-   Use linear scales and whole numbers of metric units for length,
    area, volume and capacity, weight (mass), angle, temperature, and
    time.
-   Find areas of rectangles and volumes of cuboids by applying
    multiplication.
-   Classify plane shapes and prisms by their spatial features.
-   Represent objects with drawings and models.
-   Use a co-ordinate system or the language of direction and distance
    to specify locations and describe paths.
-   Describe the transformations (reflection, rotation, translation, or
    enlargement) that have mapped one object on to another.

*In Statistics students will solve problems and model situations that
require them to:*

-   Conduct investigations using the statistical enquiry cycle:
-   gathering, sorting, and displaying multivariate category and whole
    number data and simple time-series data to answer questions;
-   identifying patterns and trends in context, within and between data
    sets;
-   communicating findings, using data displays.
-   Evaluate the effectiveness of different displays in representing the
    findings of a statistical investigation or probability activity
    undertaken by others.
-   Investigate simple situations that involve elements of chance by
    comparing experimental results with expectations from models of all
    the outcomes, acknowledging that samples vary.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Thecontentofthemathematicscurriculum/Shortcomingsofthemathematicscurriculum/index.md","# Shortcomings of the mathematics curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3ff4991ff9ea47668afc8c58d895d845}
Although achievement objectives are given with a greater degree of
specificity in the mathematics curriculum than they are in any of the
other seven curriculum statements, most are still expressed in terms
which are too general to be used as the basis for programme design,
lesson planning, or outcomes assessment.

A second shortcoming of the mathematics curriculum is an almost complete
failure to specify whether a given achievement objective is to be taught
as a name, as an equivalence relation, as a concept, as a general
principle, as an operation, or as a general understanding. Given that
different types of assessment are required in order to measure progress
towards each of these different kinds of learning outcomes, it is now no
longer appropriate for curriculum documents to be written by educators
who lack even this very basic knowledge of the elements of instructional
design.

Thirdly and most importantly, the curriculum contains no performance
standards. The addition and subtraction facts with sums to 20 are set
down as one of the achievement objectives for years 1, 2, 3, 4, & 5 but
there is no indication as to when mastery of these \"number facts\" is to
be achieved and there is no indication of the level of fluency which
students are to acquire before they move on to operations with larger
numbers.

Because mathematics learning is sequential and cumulative, early
concepts, facts and operations be need to be practised until they have
been memorised and can be immediately recalled. Failure to achieve this
level of fluency with early operations very greatly reduces the
likelihood that later operations will be mastered. This is why it is
essential that the mathematics curriculum specify the level of fluency
which is to be achieved with respect to all operations and especially
with respect to the early number operations such as ordering, sorting,
sharing, the single digit operations, operations with simple fractions,
and so on.

It is this failure to provide recommended assessment tasks and benchmark
fluency standards which almost certainly explains the weaknesses in
student performance which are being identified by the National Education
Monitoring Project reports of student performance in mathematics. The
2005 report, for example found that there had been a marked decline in
recall of basic number facts and in solving simple number problems
particularly at year 4, that less than half of year 8 students could
find the sum of 1⁄2 + 1⁄4, that many students were unable to calculate
simple percentage discounts on prices (e.g. 10% off \$4.50) and that
only about half of year 8 students knew how to answer division tasks
involving remainders, such as 14 ÷ 3 (Flockton, Crooks, Smith & Smith,
2006). This lack of proficiency did not go unnoticed by the national
press (Andrew & Claridge, 2006).

As with the curriculum statements for learning to read and learning to
write, the mathematics curriculum needs to be developed in a way which
provides teachers with greater guidance regarding the annual performance
benchmarks which are to be used as measures of student progress in
mathematics.
:::

::: referencesList
#### References

-   Andrew, K, & Claridge, A. (2006, August 24). Kids' maths doesn't add
    up. The Christchurch Press, p A1.
-   Education Review Office (2001). The New Zealand curriculum: An ERO
    perspective. Wellington, NZ: The author.
-   Flockton, L., Crooks, T., Smith, J., Smith, L. F. (2006).
    Mathematics assessment results 2005. National Education Monitoring
    Report 37. University of Otago, N.Z.: Educational Assessment
    Research Unit.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Thecontentofthemathematicscurriculum/index.md","# The content of the mathematics curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a3439182fff4467f8495d6e47919f765}
The achievement objectives in the Mathematics curriculum are the most
specific of the achievement objectives of the eight curriculum
statements. However even these provide little guidance with respect to
lesson planning and little which could be used to develop measures to
assess \\"national standards\\" in mathematics.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/ThecontentoftheEnglishcurriculum/Shortcomingsofthecurriculumstatementsforlearningtoread/index.md","# Shortcomings of the curriculum statements for learning to read \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a01d71f44eb14d4098fa2bace8c2513d}
The problem posed by the very broad and general achievement objectives
for reading is not overcome by the listing of \"developmental indicators\"
in *Effective literacy practice* (Ministry of Education, 2003) because
(a) developmental indicators are only listed for Years 1 and 4 and (b)
the Year 4 indicators are too poorly specified to be used as criteria
for measuring progress in learning to read. In fact, the curriculum
materials for the teaching of reading provide no information regarding
achievement objectives for any of the component skills which must be
mastered en route to becoming a competent reader. They contain no
information on the rate of progress which is to be expected with respect
to learning to discriminate between each of the 52 letters, learning to
discriminate between each of the 43 English language phonemes, learning
of the common grapheme-phoneme equivalence relations, the development of
decoding fluency, the development of word reading fluency for high
frequency words, the development of prose reading fluency, or the
development of comprehension monitoring skills.

If New Zealand is to continue in its attempts to establish \\"national
standards\\" in learning to read, the Ministry will need to develop
operational definitions of each of the component skills which are
involved in learning to read, will need to develop standardised measures
of fluency in each of these component skills and will need to engage in
the kind of epidemiological research which can provide reliable data
concerning the fluency levels which are currently being achieved in each
of these component skills by New Zealand children at each Year level.
This kind of research has been undertaken overseas and has been shown to
provide information which is extremely useful to classroom teachers (see
for example, Hasbrouck & Tindal, 1992). In their 1992 survey, Hasbrouck
and Tindal found that the median fluency level on age appropriate
narrative texts was 115 correct words per minute after 3 years at
school, 120 correct words per minute after 4 years at school and 130
correct words per minute after 5 years at school.
:::

::: referencesList
#### References

-   Hasbrouck, J. E. & Tindal, G. (1992). Curriculum-based oral reading
    fluency norms for students in Grades 2 through 5. Teaching
    Exceptional Children, 24, 41-44.
-   Ministry of Education. (2003). Effective literacy practice in Years
    1 to 4. Wellington NZ: Learning Media Ltd.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/ThecontentoftheEnglishcurriculum/Achievementobjectivesforlearningtowrite/index.md","# Achievement objectives for learning to write \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6b5d662aac8043f49ac8089d4958e6ad}
The achievement objectives for the teaching of compositional writing are
specified in the New Zealand curriculum (Ministry of Education, 2007) in
the following form.

**Level 1**

*Students will:*

-   Integrate sources of information, processes, and strategies with
    developing confidence to identify, form, and express ideas.

indicators:

-   selects and reads texts for enjoyment and personal fulfilment;
-   recognises and understands the connections between oral, written,
    and visual language;
-   integrates sources of information and prior knowledge with
    developing confidence to make sense of increasingly varied and
    complex texts;
-   selects and uses a range of processing and comprehension strategies
    with growing understanding and confidence;
-   thinks critically about texts with developing confidence;
-   monitors, self-evaluates, and describes progress with growing
    confidence.
-   Show a developing understanding of how texts are shaped for
    different purposes and audiences.

indicators:

-   recognises and understands how texts are constructed for a range of
    purposes, audiences, and situations;
-   identifies particular points of view and begins to recognise that
    texts can position a reader;
-   evaluates the reliability and usefulness of texts with increasing
    confidence.
-   Show a developing understanding of ideas within, across, and beyond
    texts.

indicators:

-   uses their personal experience and world and literacy knowledge
    confidently to make meaning from texts;
-   makes meaning of increasingly complex texts by identifying main and
    subsidiary ideas in them;
-   starts to make connections by thinking about underlying ideas in and
    between texts;
-   recognises that there may be more than one reading available within
    a text;
-   makes and supports inferences from texts with increasing
    independence.
-   Show a developing understanding of how language features are used
    for effect within and across texts.

indicators:

-   identifies oral, written, and visual language features used in texts
    and recognises their effects;
-   uses an increasing vocabulary to make meaning;
-   shows an increasing knowledge of how a range of text conventions can
    be used appropriately;
-   knows that authors have different voices and styles and can identify
    some of these differences.
-   Organise texts, using a range of appropriate structures.

indicators:

-   understands that the order and organisation of words, sentences,
    paragraphs, and images contribute to and affect text meaning;
-   identifies a range of text forms and recognises some of their
    characteristics and conventions.

**Level 2**

*Students will:*

-   Select and use sources of information, processes, and strategies
    with some confidence to identify, form, and express ideas.

indicators:

-   shows some understanding of the connections between oral, written,
    and visual language when creating texts;
-   creates texts by using meaning, structure, visual and grapho-phonic
    sources of information, and processing strategies with growing
    confidence;
-   seeks feedback and makes changes to texts to improve clarity and
    meaning;
-   is reflective about the production of texts: monitors,
    self-evaluates, and describes progress with some confidence.
-   Show some understanding of how to shape texts for different purposes
    and audiences.

indicators:

-   constructs texts that demonstrate a growing awareness of audience
    and purpose through appropriate choice of content, language, and
    text form;
-   expects the texts they create to be understood, responded to, and
    appreciated by others;
-   develops and conveys personal voice where appropriate.
-   Select, form, and express ideas on a range of topics.

indicators:

-   forms and expresses ideas and information with reasonable clarity,
    often drawing on personal experience and knowledge;
-   begins to add or delete details and comments, showing some
    selectivity in the process.
-   Use language features appropriately, showing some understanding of
    their effects.

indicators:

-   uses oral, written, and visual language features to create meaning
    and effect;
-   uses a large and increasing bank of high-frequency, topic-specific,
    and personal content words to create meaning;
-   spells most high-frequency words correctly and shows growing
    knowledge of common spelling patterns;
-   uses a range of strategies to self-monitor and self-correct
    spelling;
-   writes legibly and with increasing fluency when creating texts;
-   gains increasing control of text conventions, including some
    grammatical conventions.
-   Organise texts using a range of structures.

indicators:**:**

-   uses knowledge of word and sentence order to communicate meaning
    when creating text;
-   organises and sequences ideas and information with some confidence;
-   begins to use a variety of sentence structures, beginnings, and
    lengths.

**Level 3**

*Students will:*

-   Integrate sources of information, processes, and strategies with
    developing confidence to identify, form, and express ideas.

indicators:

-   uses a developing understanding of the connections between oral,
    written, and visual language when creating texts;
-   creates a range of texts by integrating sources of information and
    processing strategies with developing confidence;
-   seeks feedback and makes changes to texts to improve clarity,
    meaning, and effect;
-   is reflective about the production of own texts: monitors and
    self-evaluates progress, articulating learning with growing
    confidence.
-   Show a developing understanding of how to shape texts for different
    purposes and audiences.

indicators:

-   constructs texts that show a growing awareness of purpose and
    audience through careful choice of content, language, and text form;
-   conveys and sustains personal voice where appropriate.
-   Select, form, and communicate ideas on a range of topics.

indicators:

-   forms and expresses ideas and information with increased clarity,
    drawing on a range of sources;
-   adds or changes details and comments to support ideas, showing some
    selectivity in the process;
-   ideas suggest awareness of a range of dimensions or viewpoints.
-   Use language features appropriately, showing a developing
    understanding of their effects.

indicators:

-   uses oral, written, and visual language features to create meaning
    and effect and engage interest;
-   uses a range of vocabulary to communicate meaning;
-   demonstrates good understanding of all basic spelling patterns and
    sounds in written English;
-   uses an increasing range of strategies to self-monitor and
    self-correct spelling;
-   writes legibly, fluently, and with ease when creating texts;
-   uses a range of text conventions, including most grammatical
    conventions, appropriately and with increasing accuracy.
-   Organize texts, using a range of appropriate structures.

indicators:

-   organizes written ideas into paragraphs with increasing confidence;
-   organizes and sequences ideas and information with increasing
    confidence;
-   uses a variety of sentence structures, beginnings, and lengths.

Teachers have access to several supplementary publications which support
the teaching of expressive writing. The first of these *Exploring
language: A handbook for teachers* (Ministry of Education, 1996)
contains extensive descriptions of the elements of English grammar
(including parts of speech, language rules, types of meaning, phrases
and sentences, direct and indirect speech), phonemic analysis (including
consonants, vowels, diphthongs, Maori phonemes, intonation, and
prosody), the rules of conversation, genre (types of texts), and
semiotics (non-verbal signs and symbols). The main purpose of the
*Handbook* is to provide teachers with basic information about oral,
written and visual language. In this respect the *Handbook* elaborates
the content implied in some of the upper level English achievement
objectives. However, the *Handbook* does not spell out language learning
objectives in any greater detail than that contained in the English
curriculum statement.

The second, *Effective literacy practice* (Ministry of Education, 2003)
is a handbook for teachers on how to teach reading and writing to
children in years 1 to 4. It includes a very short account of the
writing process, a one paragraph account of how to access *The New
Zealand Curriculum Exemplars* to assess writing quality*,* a list of
progress indicators and some suggestions for writing activities. Under
the heading \"Approaches to writing\" are descriptions of language
experience activities, shared writing, interactive writing, guided
writing and independent writing. Under the heading \"Creating texts\" are
short descriptions of how to prompt and support topic selection,
composition, revision, presentation and publication.

*Effective literacy practice* includes, a list of \"developmental
indicators\" for writing during the first four years of schooling which
are more explicit than those provide in the New Zealand curriculum. Some
of these \"developmental indicators\\": are listed in the following table.

*Table 2223. \"Developmental indicators\" for learning to write listed in
\"Effective Literacy Practice\" (Ministry of Education, 2003)*

*End of Year 1*

-   Can hear and record most of the dominant sounds in words
-   Can write some high frequency words
-   Shows awareness of print conventions and uses some punctuations
    features
-   Leaves spaces between words
-   Is able to write simple ideas, reasons, opinions, and responses,
    often around personal experience
-   Can organise ideas and plan writing
-   Can write simple sentences
-   Can write more than one sentence in a writing session
-   Is beginning to use a variety of sentence structures
-   Attempts to use topic-specific vocabulary and to take risks in
    spelling
-   Knows where to find information about the spelling of particular
    words
-   With support can respond to feedback and make changes to their
    writing, for example, by adding detail or correcting surface
    features

*End of Year 4*

-   Can write on a range of topics
-   Can confidently express ideas and opinions and describe personal
    experiences
-   Plans and organises ideas and information logically
-   Shows awareness of audience and purpose through choice of content,
    language and text type
-   Responds to feedback and can modify writing
-   Is able to vary sentence structure and sentence length and to use
    similes and other features for impact
-   Uses varied and precise verbs, adjectives, and adverbs to convey
    ideas and uses simple conjunctions to link ideas
-   Uses print conventions and punctuation confidently
-   Uses knowledge of consonant and vowel sounds, of common spelling
    patterns, and of word derivations to spell words
-   Spells most high frequency words correctly
-   Independently checks for spelling and presentation
-   Is developing the ability to revise their writing to suit the
    purpose and to clarify its meaning and add to its impact
-   Can present and publish in a range of media
:::

::: referencesList
#### References

-   Ministry of Education. (1996). Exploring language: A handbook for
    teachers. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (2003). Effective literacy practice in Years
    1 to 4. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (2007). The New Zealand curriculum.
    Wellington, NZ: New Zealand Ministry of Education.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/ThecontentoftheEnglishcurriculum/index.md","# The content of the English curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3056db28b1be4e97a0d799953852e66a}
The English curriculum (Ministry of Education, 2007) contains
achievement objectives for six sets of skills: listening, speaking,
reading, writing, viewing, and presenting. This chapter examines the
achievement objectives for two of these skill areas; (a) learning to
read and (b) learning to write.
:::

::: referencesList
#### References

-   Ministry of Education. (2007). The New Zealand curriculum.
    Wellington, NZ: New Zealand Ministry of Education.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/ThecontentoftheEnglishcurriculum/Achievementobjectivesforlearningtoread/index.md","# Achievement objectives for learning to read \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-742a881629fe46a1a4b6ce8e939db9b8}
The achievement objectives for the teaching of reading during the first
six years of schooling are stated in the English section of the New
Zealand curriculum in the following form.

**Level 1**

*Students will:*

-   Acquire and begin to use sources of information, processes, and
    strategies to identify, form, and express ideas.

indicators:

-   selects and reads texts for enjoyment and personal fulfilment;
-   has an awareness of the connections between oral, written, and
    visual language;
-   uses sources of information (meaning, structure, visual and
    grapho-phonic information) and prior knowledge to make sense of a
    range of texts;
-   associates sounds with letter clusters as well as with individual
    letters;
-   uses processing and some comprehension strategies with some
    confidence;
-   is developing the ability to think critically about texts;
-   begins to monitor, self-evaluate, and describe progress.
-   Recognise and identify ideas within and across texts.

indicators:

-   understands that personal experience can influence the meaning
    gained from texts;
-   makes meaning of texts by identifying ideas in some texts.
-   Recognise and begin to understand how language features are used for
    effect within and across texts.

indicators:

-   begins to recognise that oral, written, and visual language features
    can be used for effect;
-   recognises a large bank of high-frequency and some topic-specific
    words;
-   shows some knowledge of the text conventions, such as capital
    letters, full stops, and word order; volume and clarity; and simple
    symbols.

**Level 2**

*Students will:*

-   Select and use sources of information, processes, and strategies
    with some confidence to identify, form, and express ideas.

indicators:

-   selects and reads texts for enjoyment and personal fulfilment;
-   recognises connections between oral, written, and visual language
-   selects and uses sources of information (meaning, structure, visual
    and grapho-phonic information) and prior knowledge with growing
    confidence to make sense of increasingly varied and complex texts;
-   uses an increasing knowledge of letter clusters, affixes, roots, and
    compound words to confirm predictions;
-   selects and uses processing strategies and an increasing range of
    comprehension strategies with some understanding and confidence;
-   thinks critically about texts with some confidence;
-   monitors, self-evaluates, and describes progress with some
    confidence.
-   Show some understanding of ideas within, across, and beyond texts.

indicators:

-   uses their personal experience and world and literacy knowledge to
    make meaning from texts;
-   makes meaning of increasingly complex texts by identifying main
    ideas;
-   makes and supports inferences from texts with some independence.
-   Show some understanding of how language features are used for effect
    within and across texts.

indicators:

-   recognises that oral, written, and visual language features can be
    used for effect;
-   uses a large and increasing bank of high-frequency, topic-specific,
    and personal content words to make meaning;
-   shows an increasing knowledge of the conventions of text;
-   recognises that authors have different voices and styles.

**Level 3**

*Students will:*

-   Integrate sources of information, processes, and strategies with
    developing confidence to identify, form, and express ideas.

indicators:

-   selects and reads texts for enjoyment and personal fulfilment;
-   recognises and understands the connections between oral, written,
    and visual language;
-   integrates sources of information and prior knowledge with
    developing confidence to make sense of increasingly varied and
    complex texts;
-   selects and uses a range of processing and comprehension strategies
    with growing understanding and confidence;
-   thinks critically about texts with developing confidence;
-   monitors, self-evaluates, and describes progress with growing
    confidence.
-   Show a developing understanding of ideas within, across, and beyond
    texts.

indicators:

-   uses their personal experience and world and literacy knowledge
    confidently to make meaning from texts;
-   makes meaning of increasingly complex texts by identifying main and
    subsidiary ideas in them;
-   starts to make connections by thinking about underlying ideas in and
    between texts;
-   recognises that there may be more than one reading available within
    a text;
-   makes and supports inferences from texts with increasing
    independence.
-   Show a developing understanding of how language features are used
    for effect within and across texts.

indicators:

-   identifies oral, written, and visual language features used in texts
    and recognises their effects;
-   uses an increasing vocabulary to make meaning;
-   shows an increasing knowledge of how a range of text conventions can
    be used appropriately;
-   knows that authors have different voices and styles and can identify
    some of these differences.

Teachers also have access to two supplementary publications (Ministry of
Education, 1996, 2003). The first of these, *The learner as a reader*
(Ministry of Education 1996), contains a simple account of how children
learn to read, description of a procedure for decoding unknown words
(prompt a guess -- prompt re-reading -- prompt decoding), guidance on
how to administer and interpret untimed running records of reading,
descriptions of the main types of classroom reading activities (shared
reading, shared writing, guided reading, personal reading), descriptions
of types of texts (genres), and classroom activities appropriate to
different types of texts. The focus is on classroom reading activities
and there are few references to achievement objectives or to expected
rates of improvement from one year to the next.

The second, *Effective literacy practice* (Ministry of Education, 2003)
is a handbook for teachers on how to teach reading and writing to
children in years 1 to 4. It reproduces many of the reading activities
described in *The learner as a reader.* It also includes several new,
research-based teaching activities (activities such as using rhymes and
word games to teach phonemic awareness, activities to teach letter-sound
relationships, activities such as reciprocal reading to teach
comprehension monitoring, and so on). *Effective literacy practice*
represents a step forward in that it includes, for the first time, a
list of \"developmental indicators\" for reading during the first four
years of schooling. Some of these \"developmental indicators\" are listed
in the following table.

*Table 2221 \"Developmental indicators\" for reading listed in \"Effective
Literacy Practice\" (Ministry of Education, 2003)*

*Year 1*

-   One-to-one matching, directionality and return sweep well
    established
-   Letter-sound relationships secure for all single letters and for
    some consonant digraphs and consonant blends
-   Can sound out simple, decodable words in text
-   Has a large and increasing bank of automatically recognised
    high-frequency words
-   Uses meaning, structure, visual and grapho-phonic information and
    prior knowledge to make sense of what is read
-   Self monitors and uses prediction and self-correction with
    increasing confidence
-   Understands the purposes of some punctuations marks
-   Can use phrasing, intonation and emphasis to read expressively
-   Reads at or beyond the Blue to Green levels on the Ready to Read
    series

*Year 4*

-   Integrates, meaning, structure, grapho-phonic information and prior
    knowledge when reading
-   Self-monitors and uses processing strategies effectively
-   Uses word-identification strategies appropriately and automatically
    when encountering unknown words
-   Can use a range of comprehension strategies: can analyse and
    interpret what the author is saying, make inferences and justify
    them, and make connections
-   Can gather, process, and evaluate information
-   Usually reads silently
-   Can read aloud with expression and fluency
-   Has a strong sense of what they like to read and can locate such
    material
-   Can read, comprehend and respond to texts at the 8 year old
    difficulty level
:::

::: referencesList
#### References

-   Ministry of Education. (1996). The learner as a reader: Developing
    reading programmes. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (2003). Effective literacy practice in Years
    1 to 4. Wellington NZ: Learning Media Ltd.
-   Ministry of Education. (2007). The New Zealand curriculum.
    Wellington, NZ: New Zealand Ministry of Education.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/ThecontentoftheEnglishcurriculum/Shortcomingsofthewritingcurriculum/index.md","# Shortcomings of the writing curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6d9204b354fd4bca8bb721a7543513bd}
The achievement objectives listed in the New Zealand curriculum for
writing are even less explicit than those for reading. These achievement
objectives are largely useless as a guide to instructional planning or
progress monitoring since that provide no indication of the level of
achievement of each of the component skills which need to be mastered
during the process of learning to write. This problem is not solved by
the inclusion of \"developmental indicators\" in *Effective literacy
practice* (Ministry of Education, 2003) because developmental indicators
are given only for two levels (year 1 and year 4), there is no reference
to any kind of performance criterion for any of the year 4 \"indicators\".

A careful search of Ministry of Education curriculum documents on the
teaching of writing finds no information on the level of performance
which children are expected to achieve with respect to any of the
components skills which must be acquired during the process of becoming
a competent writer. They contain no information on the rate of progress
which is to be expected with respect to the development of
printing/writing/keyboarding fluency, the development of phonemic
awareness, learning of the main phoneme-grapheme equivalence relations,
the development of morphographic knowledge, mastery of the spellings of
high frequency words, rate of development of spelling skills, the
acquisition of punctuation and grammatical skills, the development of
writing fluency, or the acquisition of planning, reviewing, and revising
skills. Clearly this is a deficiency in the curriculum documents which
needs to be remedied before teachers are asked to increase literacy
levels.

The develop of measurable achievement objectives and achievement
standards in primary school writing is not an impossibly difficult task
and could be accomplished relatively quickly. An example of what is
possible is provided by Graham, Berninger, Weintraub and Shafer (1998)
who asked samples of children from US grades 1 through 9 to copy an age
appropriate paragraph as quickly as possible without making any
mistakes. They found the following mean handwriting speeds at each grade
level: grade 1: 19, grade 2: 34, grade 3: 48, grade 4: 64, grade 5: 73,
grade 6: 84, grade 7: 100 and grade 8: 115 letters per minute. At all
levels, the average girl wrote at least 4 letters a minute faster than
the average boy. Van Galen (1990, cited in Graham & Weintraub, 1996)
reports that skilled writers can produce cursive script at a rate of six
strokes per second for short periods of time. If a functional level of
writing speed is defined as 80 legible letters per minute, it appears
that the average child in these US samples achieves a functional level
of handwriting fluency around about 11 years of age, that is, after
about six years at school.
:::

::: referencesList
#### References

-   Graham, S., Berninger, V., Weintraub, N., & Shafer, W. (1998). The
    development of handwriting fluency and legibility in grades 1
    through 9. Journal of Educational Research, 92, 42-52.
-   Graham, S., & Weintraub, N. (1996). A review of handwriting
    research: Progress and prospects from 1980 to 1994. Educational
    Psychology Review, 8, 7-87.
-   Ministry of Education. (2003). Effective literacy practice in Years
    1 to 4. Wellington, NZ: Learning Media Ltd.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Thecontentofthesciencecurriculum/Shortcomingsofthesciencecurriculum/index.md","# Shortcomings of the science curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-30c954040c7743049fd4f5bd98b952b0}
As can be seen from the list of achievement objectives at each level,
these are specified in quite general terms, and the content at each
level is left unspecified. In fact the curriculum does not even provide
examples of suitable teaching topics under each objective.

Like the literacy and mathematics curricula, the Science curriculum does
not provide enough detail to enable teachers to make any kind of
judgement regarding whether or not individual students are acquiring the
skills and understandings which the curriculum writers expect them to
acquire at each level. This is a weakness which it shares with the
previous science curriculum -- a weakness which was noticed by
reviewers. \"The achievement objectives are . . . quite general and
require further interpretation to provide focussed learning outcomes
that can be usefully employed to assess student learning . . . For
example, 'investigate and communicate differences in the properties of
similar types of materials' (Material World, Level 2) requires teachers
to make decisions on which properties are reasonable and feasible for
students to explore, and the depth of understanding of the property that
can be expected\" (Education Review Office, 2001). \"The achievement
objectives do not provide an adequate basis for objectively measuring
and reporting student progress in a way that is meaningful\" (Le Métais,
2002).

Publication of the supplementary materials has not solved this problem.
While the supplementary publications spell out in greater detail the
scientific principles which teachers need to understand and the topics
to be studied in each strand at each level, they remain silent on the
knowledge outcomes which all students are expected to acquire and on the
level of conceptual understanding which is expected of students at each
level. This means that teachers are receiving no guidance with respect
to either the assessment tasks which should be used or the level of
knowledge, understanding, or performance which define satisfactory and
unsatisfactory levels of development in science from year to year.
:::

::: referencesList
#### References

-   Education Review Office (2001). The New Zealand curriculum: An ERO
    perspective. Wellington, NZ: The author.
-   Le Métais, J. (2002). New Zealand stocktake: An international
    critique. Wellington, NZ: Ministry of Education.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Thecontentofthesciencecurriculum/Achievementobjectivesforscience/index.md","# Achievement objectives for science \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ac10abec88f945348bae2c12ed1394f7}
Set out in the table below are the achievement objectives for each of
the 6 strands for the first three levels (Levels 1 to 3) of the Science
area of the New Zealand Curriculum.

**Level 1**

*In the Nature of Science strand students will:*

-   Appreciate that scientists ask questions about our world that lead
    to investigations and that open-mindedness is important because
    there may be more than one explanation.
-   Extend their experiences and personal explanations of the natural
    world through exploration, play, asking questions, and discussing
    simple models.
-   Build their language and develop their understandings of the many
    ways the natural world can be represented.
-   Explore and act on issues and questions that link their science
    learning to their daily living.

*In the Living World strand students will:*

-   Recognize that all living things have certain requirements so they
    can stay alive.
-   Recognize that living things are suited to their particular habitat.
-   Recognize that there are lots of different living things in the
    world and that they can be grouped in different ways.
-   Explain how we know that some living things from the past are now
    extinct.

*In the Planet Earth and Beyond strand students will:*

-   Explore and describe natural features and resources.
-   Describe how natural features are changed and resources affected by
    natural events and human actions.
-   Share ideas and observations about the Sun and the Moon and their
    physical effects on the heat and light available to Earth.

*In the Physical World strand students will*

-   Explore everyday examples of physical phenomena, such as movement,
    forces, electricity and magnetism, light, sound, waves, and heat.
-   Seek and describe simple patterns in physical phenomena.

*In the Material World strand students will*

-   Observe, describe, and compare physical and chemical properties of
    common materials and changes that occur when materials are mixed,
    heated, or cooled.
-   Find out about the uses of common materials and relate these to
    their observed properties.

**Level 2**

*In the Nature of Science strand students will:*

-   Appreciate that scientists ask questions about our world that lead
    to investigations and that open-mindedness is important because
    there may be more than one explanation.
-   Extend their experiences and personal explanations of the natural
    world through exploration, play, asking questions, and discussing
    simple models.
-   Build their language and develop their understandings of the many
    ways the natural world can be represented.
-   Explore and act on issues and questions that link their science
    learning to their daily living.

*In the Living World strand students will:*

-   Recognize that all living things have certain requirements so they
    can stay alive.
-   Recognize that living things are suited to their particular habitat.
-   Recognize that there are lots of different living things in the
    world and that they can be grouped in different ways.
-   Explain how we know that some living things from the past are now
    extinct.

*In the Planet Earth and Beyond strand students will:*

-   Explore and describe natural features and resources.
-   Describe how natural features are changed and resources affected by
    natural events and human actions.
-   Share ideas and observations about the Sun and the Moon and their
    physical effects on the heat and light available to Earth.

*In the Physical World strand students will:*

-   Explore everyday examples of physical phenomena, such as movement,
    forces, electricity and magnetism, light, sound, waves, and heat.
-   Seek and describe simple patterns in physical phenomena.

*In the Material World strand students will:*

-   Observe, describe, and compare physical and chemical properties of
    common materials and changes that occur when materials are mixed,
    heated, or cooled.
-   Find out about the uses of common materials and relate these to
    their observed properties.

**Level 3**

*In the Nature of Science strand students will:*

-   Appreciate that science is a way of explaining the world and that
    science knowledge changes over time.
-   Identify ways in which scientists work together and provide evidence
    to support their ideas**.**
-   Build on prior experiences, working together to share and examine
    their own and others' knowledge.
-   Ask questions, find evidence, explore simple models, and carry out
    appropriate investigations to develop simple explanations.
-   Begin to use a range of scientific symbols, conventions, and
    vocabulary.
-   Engage with a range of science texts and begin to question the
    purposes for which these texts are constructed.
-   Use their growing science knowledge when considering issues of
    concern to them.
-   Explore various aspects of an issue and make decisions about
    possible actions.

*In the Living World strand students will:*

-   Recognize that there are life processes common to all living things
    and that these occur in different ways.
-   Explain how living things are suited to their particular habitat and
    how they respond to environmental changes, both natural and
    human-induced.
-   Begin to group plants, animals, and other living things into
    science-based classifications.
-   Explore how the groups of living things we have in the world have
    changed over long periods of time and appreciate that some living
    things in New Zealand are quite different from living things in
    other areas of the world.

*In the Planet Earth and Beyond strand students will:*

-   Appreciate that water, air, rocks and soil, and life forms make up
    our planet and recognize that these are also Earth's resources.
-   Investigate the water cycle and its effect on climate, landforms,
    and life.
-   Investigate the components of the solar system, developing an
    appreciation of the distances between them.

*In the Physical World strand students will:*

-   Explore, describe, and represent patterns and trends for everyday
    examples of physical phenomena, such as movement, forces,
    electricity and magnetism, light, sound, waves, and heat. For
    example, identify and describe the effect of forces (contact and
    non-contact) on the motion of objects; identify and describe
    everyday examples of sources of energy, forms of energy, and energy
    transformations.

*In the Material World strand students will:*

-   Group materials in different ways, based on the observations and
    measurements of the characteristic chemical and physical properties
    of a range of different materials.
-   Compare chemical and physical changes.
-   Relate the observed, characteristic chemical and physical properties
    of a range of different materials to technological uses and natural
    processes.

Because the 2007 science curriculum does not even specify sample topics
for each achievement objective, it is likely that most teachers will
continue to use the teaching resources developed for the 1993 science
curriculum. These include *Developing Science Programmes* (Ministry of
Education, 1995a) and *Investigating in Science* (Ministry of Education,
1995b). The first provided an expanded account of learning and teaching
processes in science and suggested a range of practical ideas for
teachers to consider at each level. The second (which is now out of
print) provided examples of different types of investigations which
students can employ to solve problems, test explanations, and try out
and clarify ideas.

A second set of resources consists of a set of four publications
(Ministry of Education, 1998, 1999a, 1999b, 2001) designed to provide
important science information for Year 1 to 8 teachers and suggestions
for curriculum-linked science activities and investigations which can be
used at these levels. The first, *Making Better Sense of the Material
World* (Ministry of Education, 1998) focuses on chemistry. The first
chapter covers programme planning and implementation and the second
describes important chemical principles that teachers need to
understand. Each of the subsequent ten chapters presents a scientific
focus on a particular material such as milk, clay, paper, and so on.

The second, *Making Better Sense of the Physical World* (Ministry of
Education, 1999a) focuses on physics. The first two chapters cover
programme planning and the important physics principles that teachers
need to understand to help year 1 to 8 students gain physics-related
knowledge and skills. The remaining six chapters focus on the science of
sound, light and colour, electricity, and so on.

The third *Making Better Sense of Planet Earth and Beyond* (Ministry of
Education, 1999b) focuses on the Planet Earth and Beyond strand and
includes chapters on programme planning, important science principles
that teachers need to understand, and chapters on landforms, weather,
and astronomy.

The fourth, *Making Better Sense of the Living World* (Ministry of
Education, 2001) includes important science principles that teachers
need to understand and chapters on classification, structure and
function; and life stages and genetics.
:::

::: referencesList
#### References

-   Ministry of Education. (1993). Science in the New Zealand
    curriculum. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (1995a). Developing Science Programmes.
    Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (1995b). Investigating in Science.
    Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (1998). Making Better Sense of the Material
    World: Levels 1 to 4. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (1999a). Making Better Sense of the Physical
    World: Levels 1 to 4. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (1999b). Making Better Sense of Planet Earth
    and Beyond: Levels 1 to 4. Wellington, NZ: Learning Media Ltd.
-   Ministry of Education. (2001). Making Better Sense of the Living
    World: Levels 1 to 4. Wellington, NZ: Learning Media Ltd.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Thecontentofthesciencecurriculum/index.md","# The content of the science curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-22662be8ecac47b2bba120c38b8fc162}
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/index.md","# Types of curriculum goals \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-551f922b32d6499bb6aecfff180f48ce}
It is only possible to seek answers to questions about the conditions
affecting learning if we have an answer to the question \"learning what?\"
Similarly it is only possible to seek answers to questions about the
effects of particular teaching strategies on student learning if we have
an answer to the question \"teaching what?\" This is because, as we saw in
the preceding chapter, there are many different types of learning
outcomes and the development of each of these types of learning outcomes
depends upon the provision or existence of different sets of
instructional conditions.

What it is that children are expected to learn while they are at school
is set out in state or national curriculum documents. While the school
curricula of individual countries contain much in common, especially
during the early years, there is also considerable variability in
national curricula from one country to the next. This variability
complicates the scientific study of learning and teaching by introducing
variability with respect to the learning outcomes which are being
selected for study and analysis. For example, studies of learning to
read in countries where the teaching of reading is introduced at age 5
(an age when many children have yet to acquire the level of phonemic
awareness necessary for learning to read) inevitably involve a different
set of considerations than is the case in countries where learning to
read is introduced at age 7 (after most children have acquired the level
of phonemic awareness necessary for success in learning to read).

In this chapter we will examine a sample of the achievement objectives
listed in the New Zealand curriculum documents and address the question
of whether any of these achievement objectives are given in sufficient
detail for them to be of use in designing a teaching programme, or in
monitoring student progress, or in studying the effects of teaching on
learning in the classroom.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Whatiscurriculum/Theeightessentiallearningareas/index.md","# The eight essential learning areas \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-88644f38ef0a4404842f91bf79bffd58}
In the latest revision of the New Zealand curriculum (Ministry of
Education, 2007) the eight essential learning areas are defined as
follows.

**English**

The English curriculum is structured around two strands: making sense of
information received (listening, reading, and viewing skills) and
creating meaning for others (speaking writing and presenting skills).
Success in English is seen as fundamental to success across the rest of
the curriculum.

**Mathematics**

The New Zealand mathematics curriculum is structured in three strands:
number and algebra, geometry and measurement, and statistics. It aims to
help children to learn how to structure and to organise, to carry out
procedures flexibly and accurately, to process and communicate
information, and to enjoy intellectual challenge.

**Science**

The science curriculum is organised into five strands: (a) the nature of
science and how scientists work, (b) the living world and ecology, (c)
the planet earth and beyond, (d) the physical world (physics) and (e)
the material world (chemistry). The aims of the science curriculum are
to develop an understanding of current scientific theories, how to use
scientific knowledge to solve problems, and how to use scientific
knowledge and skills to make informed decisions about their own lives
and sustainability of the environment.

**Technology**

The technology curriculum in organised into three strands: (a)
technological practice where students study concepts, plans,
technological models, products and systems, (b) technological knowledge
where they study how and why things work, and (c) the nature of
technology where they develop an understanding of technology as a
discipline, its impacts on society and the environment and the issues
raised by these impacts.

**Social Sciences**

The social sciences curriculum in organised in four strands: (a)
identity, culture and social organisation, (b) place and environment and
the relationships between people and the environment, (c) continuity and
change including past events and experiences and the ways in which these
have been interpreted over time, and (d) the economic world where
students learn about the production, distribution and consumption of
goods and services.

**The arts**

The arts curriculum involves students learning to work both
independently and collaboratively to construct meanings, produce works,
and respond to and value the contributions of others while at the same
time learning to use their imagination to engage with unexpected
outcomes and to explore multiple solutions. The arts curriculum includes
four disciplines; dance, drama, music (and sound arts), and the visual
arts .

**Health and physical education**

The health and physical education curriculum focuses on the well-being
of students themselves, of other people, and of society. The area is
structured in four strands: personal health and physical development,
movement concepts and motor skills, relationships with other people, and
healthy communities and environments. Seven areas of study are to be
included in each strand: mental health, sexuality education, food and
nutrition, body care and physical safety, physical activity, sport
studies and outdoor education.

**Learning languages**

The eighth curriculum area provides the opportunity to learn a language
other than the language of instruction. Learning to use the language
(communication) is central but this curriculum area also includes
knowledge about the language and cultural knowledge.
:::

::: referencesList
#### References

-   Ministry of Education. (2007). The New Zealand curriculum.
    Wellington, NZ: New Zealand Ministry of Education.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Whatiscurriculum/Thefivekeycompetencies/index.md","# The five key competencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ecb59f64db694d6280146259ffbff18f}
The New Zealand curriculum identifies five competencies which are to be
considered the key to learning in each of the eight learning areas.
Students are to be continually challenged to develop these key
competencies over time in contexts which are increasingly wide ranging
and complex. The five key competencies are:

1.Thinking (the ability to seek, use and create knowledge, ask
questions, and challenge the basis of assumptions and perceptions).

2.Using language, symbols and text (the ability to interpret and use
words, number, images, movement, metaphor and technologies in a range of
contexts).

3.Managing oneself (the ability to self-motivate, establish goals, make
plans, and set standards for oneself).

4.Relating to others (the ability to interact effectively with a diverse
range of people in a variety of contexts).

5.Participating and contributing (the ability to respond appropriately
as a member of a group, to make connections with others, and to create
opportunities for including others in group activities).
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Whatiscurriculum/FeaturesoftheNewZealandcurriculum/index.md","# Features of the New Zealand curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c3d7d08ddfd54ff7b3da395a4205833a}
The New Zealand curriculum (Ministry of Education, 2007) covers the Year
levels 1 to 13, that is, ages 5 to 17. The curriculum statements apply
to all New Zealand schools including kura kaupapa Mäori and special
education schools.

The New Zealand curriculum is divided into eight essential learning
areas, that is, areas of knowledge and understanding which all students
are expected to acquire. These are as follows:

1.English

2.The Arts (Dance, Drama, Music-Sound Arts, and Visual Arts)

3.Health and Physical Education

4.Learning Languages

5.Mathematics and Statistics

6.Science

7.The Social Sciences

8.Technology

Incorporated into and across all eight learning areas are five key
competencies which are to be developed by all students. These key
competencies are:

-   Thinking
-   Using language, symbols and texts
-   Managing self
-   Relating to others
-   Participating and contributing

The school curriculum in New Zealand is two-tiered. Under the terms of
the Education Amendment Act 1991, it is the responsibility of boards of
trustees to ensure that schools satisfy the requirements and
expectations of the New Zealand curriculum. Every school charter and
proposed charter must include the aim of meeting and following the
learning principles and achievement objectives set out in the national
curriculum.

The New Zealand curriculum statements specify the achievement outcomes
which schools are legally obliged to pursue by listing, for boards of
trustees and teachers, a progression of performance objectives
throughout the years of schooling. However, this is done in a fairly
general way. Implementation of the curriculum, that is, the way in which
these outcomes are to be taught, achieved and assessed, is left to
individual schools to determine \"in consultation with their
communities\". The reason for this is to provide \"for flexibility,
enabling schools and teachers to design programmes which are appropriate
to the learning needs of their students\". This includes the flexibility
to plan programmes to meet their particular needs; for example, kaupapa
Maori programmes, English programmes for speakers of other languages
(ESOL), Pacific Islands language courses, and so on (as long as they
incorporate the knowledge and understandings described in the eight
learning areas).
:::

::: referencesList
#### References

-   Ministry of Education. (2007). The New Zealand curriculum.
    Wellington, NZ: New Zealand Ministry of Education.
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Whatiscurriculum/index.md","# What is curriculum? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f9f0912f095449b08156f491c4a5a22a}
In most countries, the school curriculum consists of a set of documents
which set out what children are expected to learn and remember as a
result of their attendance at school. Most curricula contain a mixture
of general aims and principles, general statements describing areas of
study, lists of skills and understandings which children are expected to
acquire at school, and lists of desirable human qualities, attitudes,
and dispositions which schools are required to develop. The New Zealand
curriculum consists largely of \\"achievement objectives\\" at each of
eight \"levels\". These achievement objectives describe in very general
terms the kinds of skills which teachers might observe once a child has
reached a particular level. For example, a child achieving at Level 1 in
Mathematics would be expected to \"know the forward and backward counting
sequences with whole numbers to 100\" and, at Level 2 Mathematics, to
\"know the forward and backward counting sequences with whole numbers to
at least 1000.\"
:::"
".//Importantlearningandteachingevents/Typesofcurriculumgoals/Whatiscurriculum/Levelsofspecificityincurriculumstatements/index.md","# Levels of specificity in curriculum statements \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b5b780149eb4410ab17d56fcee9e7c1e}
Achievement objectives can be described with varying levels of
specificity. For example, a curriculum goal for the end of Year 2 in,
say, learning to read might be given at any of the following levels of
specificity (ordered from least to most specific):

-   \"shows continuing improvement in reading\"
-   \"reads a range of texts with increasing enjoyment and comprehension\"
-   \"reads a range of texts at the 6.5 year level with enjoyment and
    comprehension\"
-   \"reads a range of texts at the 6.5 year level at 90 correct words
    per minute and with at least 80% comprehension\".
-   \"reads both narrative texts (stories) and descriptive texts at the
    6.5 year level at 90 correct words per minute and with at least 80%
    comprehension\".

Generally speaking, teachers prefer curriculum goals which are couched
in fairly general terms because this gives the teacher considerable
freedom in determining the kinds of learning activities which he or she
can employ, the learning goals which can be pursued during these
activities, the assessment tasks which can be used at the end of the
activity, and the standard of student performance which defines a
\"successful\" classroom learning activity.

Parents on the other hand want to know whether their child is making
adequate progress in learning to read, learning to spell and write,
learning to relate to other children, and so on. This is only possible
if the school curriculum specifies achievement standards with a level of
specificity sufficient to allow such judgements to be made.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/Theacquisitionofnewmeanings/index.md","# The acquisition of new meanings \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9127af513f1541b286f18e86f3f3ee31}
Much learning, especially during the early years, involves learning what
particular symbols mean. Young English speaking children have to learn
the meaning of the word *dog*, young French speaking children must learn
the meaning of the word *chien*, and young German speaking children must
learn what the word *Hund* means. Initially it is the meaning of the
spoken words which must be acquired. Later the child will need to learn
the meaning of the written words. At the same time, the child will also
need to learn the meanings of symbols such as the numbers *0* to *9*,
gestures such as an outstretched hand, facial expressions such as a
glare, signs such as the \"female toilet\" sign, markings such as a zebra
crossing, and so on.

This kind of learning is referred to in a variety of ways -- as \"the
development of understanding\", as \"the construction of meaning\", as \"the
development of comprehension\" and so on. Because there is no agreed
terminology, there is also much confusion about the nature of the
learning outcome and how progress towards this type of learning outcome
should be measured. During the 1990s much was written about the
\"construction of meaning\". One of the connotations of this phrase is the
implication that learners actively or consciously \"construct\" new
meanings whereas, in fact, the research suggests that, given the right
kind of experience, new meanings are acquired almost automatically and
without conscious effort on the part of the learner (e.g. Staats, Staats
& Crawford, 1962).

In this account we will use the term *comprehension* to refer to those
cases where the learner understands or comprehends the meaning of a
particular word, symbol or sign.

**The measurement of comprehension.** There are several well established
ways of assessing comprehension. Comprehension in young children may be
tested by presenting the oral or written word and asking the child to
chose, from an array or four or five pictures (or objects), the picture
(or object) which best represents the meaning of the word. Once a child
can read, the array of four or five pictures can be replaced with four
or five definitions, of which only one represents the meaning of the
target word. Older children may simply be asked to define the word or to
\"tell me what this word means\". Because the human brain establishes the
link between a symbol and its meaning extremely quickly and without
conscious effort, it will not normally be possible to track an evolving
or developing understanding of the meaning of a symbol but only to
establish whether the child understands the meaning or not.
:::

::: referencesList
#### References

-   Staats, A. W., Staats, C. K. & Crawford, H. L. (1962). First-order
    conditioning of meaning and the parallel conditioning of a GSR.
    Journal of General Psychology, 97, 159-167.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/Theacquisitionofnewknowledge/index.md","# The acquisition of new knowledge \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d8d3b148c41a416ca8106ee81c15d3d4}
There is a third kind of correct responding which we expect of children
and this is the acquisition of new knowledge. In this third case, the
learner\'s response does not have to be an exact, word-for-word
reproduction of the original information in order to qualify as
\"correct\". The response will be judged to be correct as long as the
*meaning* of the response matches the *meaning* of the original
presentation. For example, I might ask \"What is prompting?\" and accept
as correct any of the following answers: \"helping the learner to respond
correctly\" or \"assisting the learner to make the correct response\", or
\"an action which increases the likelihood of the learner making the
correct response\".

Consider the following textbook extract on the changing states of matter

![Figure 2136. Fourteen knowledge propositions from a section of a
primary school science
textbook](../../../../../../assets/images/TECKSFig2136.png \"Figure 2136. Fourteen knowledge propositions from a section of a primary school science textbook\"){.image-inline}

*Figure 2136. Fourteen knowledge propositions from a section of a
primary school science textbook*

This passage, which is part of a textbook chapter on \"Changes in the
States of Matter\", introduces four concepts: *melting*, *vaporisation*,
*condensation*, and *solidification*. However, it is clear that
generalised correct responding is not going to be required. The concepts
are illustrated using only two examples: water (i.e. water vapour,
water, ice) and ether (i.e. ether vapour and liquid ether). Since the
passage contains only two examples, it is clear that a generalised
understanding of the four concepts is not expected. Rather the reader is
being given the definition and an example or two of each concept and it
is these which, presumably, the learner will be expected to remember.
(Note that, in this example, the writer has assumed that the reader
already understands the concepts of a *solid*, *liquid*, and *gas*.) The
passage also discusses two principles: (a) the principle that melting
and vaporisation require the addition of heat and (b) the principle that
condensation and solidification require the subtraction of heat. The
water and ether examples are again used to illustrate these two
principles.

How can we tell whether a learner has acquired the \"new knowledge\" which
he or she has been expected to acquire? What we do is to ask the student
oral or written questions about the topic. This is possible because each
of the items of information in an expository passage such as the extract
above can be expressed in the form of a proposition. Some of these
propositions are concept definitions (e.g. \"condensation refers to the
change from a gaseous to a liquid state\"). Some are statements of a
principle (e.g. \"heat is required when evaporation takes place\"). And
some are illustrations, that is, propositions about examples (e.g. \"when
heat is added, ice changes to liquid water\"). In order to ascertain
whether or not a student has learned a particular proposition (item of
information) we turn the proposition into a question. For example, \"What
happens when ice is heated?\"

It can be seen that the defining features of this type of learning
outcome are as follows

-   The learner demonstrates that learning has occurred by demonstrating
    that they can talk or write about the proposition at some later
    date. We usually refer to this behaviour as \"recalling\" or
    \"remembering\" the material.
-   Knowledge propositions may be propositions about facts; concept
    names, definitions, examples; statements of a principle, or examples
    of a principle; or any mixture of these things.
-   Knowledge responses do not have to match the wording of the original
    presentation in order to be classified as correct. Except in the
    case where particular names are being learned, it is usually
    sufficient for the meaning of the response to match the meaning of
    the original presentation for the response to be classified as
    correct.

This kind of learning goes by a variety of different names. We talk
about \"learning\" new information, we talk about \"remembering\" new
material, we talk about \"understanding\" new ideas, we talk about
\"constructing new meanings\", and we talk about acquiring new
\"knowledge\". \"Acquiring new knowledge responses\" probably comes closest
to describing this particular kind of learning outcome.

**Measuring the acquisition of new knowledge.** This kind of acquisition
is most typically assessed by writing questions about the topic of
interest and observing the student\'s verbal responses (either oral or
written) to these questions. Answers are classified as correct if the
*meaning* of the student\'s answer matches the meaning of the answer
which is sought. A word-for-word match is not required as it is during
the learning of new equivalence relations and new concepts. Increases in
the number of questions which the student can answer correctly (from one
observation to the next) provide a measure of the rate of acquisition of
new knowledge responses.

It is often a requirement that the student\'s knowledge responses be
ones which demonstrate an understanding of the material which is being
talked about. With knowledge learning, understanding of the content of a
proposition is demonstrated when the student demonstrates that they can
respond to questions about that proposition which are *paraphrases* of
the original presentation. In order to respond correctly to a
paraphrased question, the student must have understood and remembered
the meaning of the original proposition (and not just memorised the
words used in the presentation of the proposition).
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/Theacquisitionofnewequivalencerelations/index.md","# The acquisition of new equivalence relations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8cffce3ab5e1467d9191c041b991752f}
Let us say that we want a young child to learn the names of the letters
of the alphabet. Note how ambiguous this statement is. We probably
won\'t need to teach *saying the names* because the child can already
pronounce each of the names when prompted to do so. However, the child
will have to learn *how to respond to each of the letters with the
correct letter name*. In order to describe this kind of learning task we
have to specify *both (a) the form of the stimulus* or symbol which we
want the learner to respond to correctly *and (b) the correct response*
to that stimulus. Note that even the phrase \"correct response\" is a
short hand. It is a short hand way of saying \"responds to each stimulus
in the same way that adult users of the language respond.\"

Notice that this kind of acquisition outcome has two defining elements:

1.The task facing the learner is that of learning to respond correctly
to a symbol or other kind of stimulus (e.g. the letter b or the printed
word bat).

2.The stimulus always takes much the same form. The word bat always
contains the same three letters in the same order. And the response must
match the stimulus exactly. The only reading response which qualifies as
\"correct\" is saying the word \"bat\".

This kind of learning goes by a wide variety of different names. To
avoid confusion, we will refer to it by its technical name \"the
acquisition of new equivalence relations\". With this kind of acquisition
outcome, what has to be learned is a stimulus--\>response equivalence
relation, rather than how to perform a response. In fact, this kind of
learning is usually postponed until the learner has already acquired the
ability to perform the response (e.g. pronounce the word \"bat\").

Because we expect children to learn to both read and to write (and to
understand what they are reading and writing), the equivalence relations
which are involved in language learning do not come in pairs, they come
in sets -- as shown in the following example (learning to use the word
\"scissors\").

![Figure 2134. The three pairs of equivalence relations for the word
\\"scissors\\".](../../../../../../assets/images/TECKSFig2134.png \"Figure 2134. The three pairs of equivalence relations for the word \"scissors\".\"){.image-inline}

*Figure 2134. The three pairs of equivalence relations for the word
\\"scissors\\".*

As can be seen from the table there are three basic pairs of equivalence
relations: #1 & #2 comprehending the orally spoken word (and vice
versa), #3 & #4 reading the written word (and vice versa) and #5 & #6
comprehending the written word (and vice versa). Relations #4 and #6
will later become writing (writing the correct word rather than just
selecting it).

Because children must master both oral and written language, this kind
of learning outcome is an extremely common kind of learning outcome. We
expect children to learn many hundreds of thousands of
stimulus-\>response equivalences. We expect children to learn the names
of hundreds of people and the names of thousands of common objects. We
expect children to learn the names of the letters, the names of the
numerals, and the names of many other symbols such as +, -, x, ÷. We
expect children to learn to read many thousands of printed words, and we
expect children to learn to write (that is, to correctly spell) a high
proportion of the words which they can read. The learning of equivalence
relations is not confined to the early years. We expect the student of
music to learn to read musical scores, the student of chemistry to learn
to read a large number of chemical symbols, and the student of maths to
learn to read and understand a large number of mathematical symbols.

Because stimulus--\>response relations often come in sets (such as the
52 letters of the alphabet), the learner must learn to discriminate
between each of the stimuli in the set as well as learning to respond
differently and correctly to each. This poses a number of unique
difficulties in the teaching of this kind of skill. For example, one of
the critical shortcomings of school curricula is that they point to many
thousands of equivalence relations but simply fail to list the specific
equivalence relations (e.g. the specific sight words, spelling words,
and so on) which each child is expected to acquire. This means that it
is impossible for the teacher, the school, or the ERO to determine
whether expected acquisition outcomes of this type are actually being
achieved.

**Measuring the acquisition of new equivalence relations.** Improvements
in this kind of learning are typically assessed by providing samples of
the stimulus items (letters, words, reading passages, number facts,
etc.) for the learner to respond to and by coding the learner\'s
responses as correct or incorrect. Increases in the ratio of corrects to
errors from day to day provide a measure of rate of learning on this
kind of acquisition outcome.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/Theacquisitionofnewprocedures/index.md","# The acquisition of new procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6095bc8f63f44647befe84d58843db4f}
Some acquisition outcomes involve learning to perform a new operation or
procedure. A procedure is a sequence of responses which must be
performed in a particular order if the sequence is to have the desired
outcome. Initially, the learner cannot perform the sequence of responses
in the correct order (although they may be able to perform individual
responses when prompted to do so). The aim is to bring the learner to
the point where they can perform the entire sequence in order, to a
satisfactory standard, without assistance.

This kind of change is referred to using a variety of terms. Sequence of
responses are variously referred to as \"skills\", \"operations\",
\"strategies\" \"procedures\", \"chains\", \"chained tasks\" and so on. We will
refer to a skill which involves the performance of a sequence of
responses or steps as a *procedure.*

Many of the skills listed in the curriculum are skills which take the
form of procedures. Many everyday skills such as showering, getting
dressed, getting one\'s breakfast, cooking a meal, washing the dishes,
fixing a puncture, and so on are procedures. Many mathematics operations
such as multidigit addition and subtraction, long multiplication and
division, multiplying fractions, calculating areas, simplifying
algebraic expressions, and so on, are procedures. Early spelling
involves this kind of learning - the pupil must learn to write the
letters of particular words in a particular order. And many advanced
academic skills consist of procedures. For example, finding a word in a
dictionary, finding a book in a library, solving physics problems,
making summary notes, rehearsing material to memorise it, and setting
out written work according to a given convention are all examples of
procedures.

Some writers argue that we should distinguish between procedures which
involve motor responses (such as getting dressed), those which involve
verbal responses (such as working a long multiplication problem), and
metacognitive procedures (such as self-rehearsal). However research
suggests that, where the aim is to teach the learner how to perform a
new sequence of responses, the teaching procedures which are required
are much the same regardless of whether the skill is a motor skill, a
verbal skill or a metacognitive skill (Marchand-Martella, Martella,
Christensen, Agran, & Young, 1992; Rivera & Smith, 1988; Skinner,
Beatty, Turco, & Rasavage, 1989).

**Measuring the acquisition of new procedures.** Where a new skill takes
the form of a procedure (a sequence of steps), the teacher may code the
student\'s performance at each step as either \"satisfactory\" (i.e.
performed to the required standard without assistance) or
\"unsatisfactory\" (i.e. not up to standard, or performed only with
assistance). To apply this measure, the teacher asks the learner to
perform as many of the steps as they are able. A delayed prompting
procedure is used to prompt those steps which the learner cannot yet
perform (or the teacher may complete the steps which the learner cannot
yet perform). Performance of the skill at any point in time can be
measured by counting the number of steps completed to a satisfactory
standard without assistance. Increases, from day to day in the number of
steps completed without assistance provide a measure of the rate of
improvement on this kind of acquisition outcome.
:::

::: referencesList
#### References

-   Marchand-Martella, N. E., Martella, R. C., Christensen, A. M.,
    Agran, M., & Young, K. R. (1992). Teaching a first aid skill to
    students with disabilities using two training programs. Education
    and Treatment of Children, 15, 15-31.
-   Rivera, D., & Smith, D. D. (1988). Using a demonstration strategy to
    teach midschool students with learning disabilities how to compute
    long division. Journal of Learning Disabilities, 21, 77-81.
-   Skinner, C. H., Beatty, K. L., Turco, T. L., & Rasavage, C. (1989).
    Cover, copy, and compare: A method for increasing multiplication
    performance. School Psychology Review, 18, 412-420.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/index.md","# Basic types of acquisition outcomes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-87d1cbae06f44996a721cffd3a28d1fe}
A child may learn how to perform a completely new behaviour such as how
to print various letters, or learn how to perform a new operation or
procedure such as long multiplication. A child may learn the name of a
new symbol such the chemical symbol \"Fe\" or the meaning of a new concept
such as \"equals\". These examples remind us that a variety of different
kinds of *acquisition* outcomes are possible.

We distinguish between different types of acquisition outcomes, not
because the learner's behaviour differs but because different sets of
learning conditions are necessary for the achievement of different kinds
of acquisition outcomes. The conditions which must be provided in order
to teach someone to swim are different from the conditions which must be
provided in order to teach someone to read. If we classify acquisition
outcomes according the kinds of learning experiences which are required
in order to bring them about, we discover that a number of different
kinds of acquisition outcomes need to be distinguished. The most common
of types of acquisition outcomes contained in primary school curricula
are: (1) the acquisition of new meanings, (2) the acquisition of new
behaviours, (3) the acquisition of new procedures, (4) the acquisition
of new equivalence relations, (5) the acquisition of new concepts and
generalisations and (6) the acquisition of new knowledge.

Different types of acquisition outcomes need to be distinguished for two
reasons, first because their achievement depends upon the presence of
different kinds of learning experiences and secondly because the
measurement of progress towards each of these types of outcomes requires
the use of different kinds of measurement procedures. The teacher,
teacher educator, or teaching researcher who fails to distinguish
between different types of acquisition outcomes will be unable to seek
out research into the most effective ways of helping children acquire
different kinds of skills and understandings and will be unable to
devise measurement procedures which they can use to monitor children's
acquisition of new skills and understandings.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/Theacquisitionofnewgeneralisations/index.md","# The acquisition of new generalisations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-278cebacacb1476594a3639730b23289}
Many of the objects and events which children must learn to respond to
correctly belong to stimulus classes. Orange objects belong to the
stimulus class *orange*. Addition word problems belong to the stimulus
class *addition problems*. Teacher statements about what the child
should do next belong to the stimulus class *teacher instructions*.

A stimulus class consists of individual instances. (Instances are often
referred to as members, or as examples of the class.) There are
literally millions of possible instances of the stimulus class *orange
objects*, for example. The instances (examples) of a particular stimulus
class share certain common features or samenesses. The sameness which
defines membership in the stimulus class *orange objects* is their
orange colour. Individual instances also exhibit certain other features
which are irrelevant to membership in the stimulus class. Orange
objects, for example can vary widely with respect to size, function,
composition, location, and so on and all of these features are
irrelevant as far as the response \"orange\" is concerned.

Another common kind of acquisition outcome, then, is learning how to
recognise and respond correctly to the members of a stimulus class.
Often we refer to this kind of correct responding as \"understanding\"
(e.g. \"I see that you now understand the difference between nouns and
adjectives.\") But this is only one of several kinds of \"understanding\"
which are possible so, to avoid confusion, we cannot call this learning
outcome \"understanding\". Some writers refer to this kind of learning as
\"concept learning\" and this is one of the most common kinds of
generalised responding. But \"concept learning\" does not really cover the
case of recognising that a previously learned skill is appropriate in a
new setting. Some writers refer to this kind of correct responding as
\"transfer\" (which is short for \"transfer of training\") and others talk
about \"application\". Many learning researchers use the term
*generalisation* when talking about the ability to recognise that
different things belong to the same stimulus class and should be
responded to in the same way. For this reason we too will use the term
generalisation to refer to this kind of acquisition outcome.

As is the case in the learning of new equivalence relations, generalised
correct responding involves learning to respond correctly to new
stimulus items. Unlike the learning of equivalence relations (where the
stimulus always takes the same form), generalised correct responding
involves learning to recognise and to respond to the *sameness* which
defines membership in a stimulus class so that even new examples from
the stimulus class are recognised and responded to correctly.

Generalised correct responding is an extremely common kind of
acquisition outcome.

-   This is the acquisition outcome whenever the teacher seeks to
    develop an understanding of a new concept. In this case, the
    stimulus class is a class of objects, events, or qualities and the
    correct response is using the concept name correctly. This kind of
    generalised correct responding is commonly referred to as *concept
    learning* and this is appropriate.
-   Generalised correct responding is also the acquisition outcome
    whenever the teacher seeks to teach the learner how to solve a
    particular *class* of problems (such as addition word problems), or
    how to distinguish between different classes of problems. In this
    case, the stimulus class is a class of questions or problems and the
    correct response is the procedure (the operation) for solving this
    kind of problem. It is this kind of generalised correct responding
    which is often referred to as *transfer*.
-   Generalised correct responding is the acquisition outcome whenever
    the teacher seeks to ensure that the learner will learn to apply a
    new skill across a range of different settings. For example, the
    teacher might seek to teach a child to \"not to interrupt others when
    they are speaking but to wait\" and to apply this rule in all
    conversational situations. In this case, the stimulus class is
    \"other person speaking\" and the response is \"waiting until the
    speaker is finished\". This kind of learning outcome is usually
    referred to as *generalisation across settings*.

Unlike the learning of an equivalence relation (which involves a single
discrimination) mastery of a generalisation involves the mastery of two
discriminations. The first task facing the learner is that of learning
to discriminate between the features which are relevant to membership in
the stimulus class (relevant to responding) and the features which are
irrelevant. Before a child can learn to use colour names correctly, he
or she must learn to discriminate between the colour of objects (the
relevant feature) and all other features of the objects such as their
size, shape, material construction, location, function, and so on (the
irrelevant features).

Different stimulus classes are comprised of instances which possess
different defining features or samenesses. Members of the stimulus class
*orange objects* differ from members of the stimulus class *yellow
objects* by virtue of their difference in colour. So the second task
facing the learner is that of learning to discriminate between (and to
respond differently to) the different samenesses which define membership
in different stimulus classes. The child who is learning colour names,
for example, must learn to distinguish between those hues which we
customarily refer to as \"orange\" and those hues which we customarily
refer to as \"yellow\" and to respond differently to examples from the two
stimulus classes.

A child who is learning how to respond correctly to addition word
problems faces the same kind of requirement. In order to learn the
difference between addition word problems and other kinds of word
problems, the child must learn two discriminations. First, child must
learn to discriminate between that feature of the problem which is
relevant to the decision regarding the procedure which should be applied
and those features of the problem which are irrelevant to this decision.
Secondly, the child must learn to discriminate between the features
which indicate that the problem can be solved using an addition
procedure and the features which indicate that some other procedure will
need to be applied. This kind of generalised correct responding is a
common kind of learning outcome. We expect children to acquire the
ability to solve not only the problems and examples which we use during
teaching but also problems and examples other than the particular
problems used during instruction, and we expect this to happen across
all curriculum areas.

**Measuring the acquisition of generalised correct responding.** The
critical feature which distinguishes learners who have acquired a good
understanding of a new concept or generalisation from those who have not
is that the former can correctly identify new examples of the concept
while the latter can not. The level of generalisation which has been
acquired is measured by counting correct responses. The only difference
is that the \"test\" items must consist of new examples, that is, examples
which have never been encountered before. Only if the test examples are
never-before-seen examples can the teacher be sure that the child has
acquired the targeted generalisation and is not just demonstrating that
they have remembered the examples which were used during instruction.

To measure the development of a new generalisation, we provide the
learner with examples and non-examples which have not been seen before,
observe responses to both the examples and the non-examples, and
classify these responses as correct or incorrect. Increases in the ratio
of corrects to errors from day to day provide a measure of the rate of
acquisition of new generalisations such as conceptual understanding.
Generally speaking, half a dozen test items (two or three new examples
and two or three new non-examples) will be sufficient to determine
whether or not the student has mastered a new generalisation. Provided
the test consists of new examples and non-examples, a lengthy test is
not required in order to determine whether or not a student has mastered
a new generalisation.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Basictypesofacquisitionoutcomes/Theacquisitionofnewbehaviours/index.md","# The acquisition of new behaviours \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7c8c3295832f409e897433d893d5af30}
Some acquisition outcomes involve learning a response, behaviour, skill
or action which does not yet exist in the learner's repertoire. These
are behaviours and skills which the learner cannot yet perform even when
given a model to imitate. With this kind of learning outcome, the change
which the learner must accomplish is a change from being unable to
perform the target behaviour or skill (even if provided with a model to
copy) to being able to perform the target behaviour without assistance.

This is the kind of behaviour change which is involved in early language
acquisition. Initially, the young infant cannot pronounce intelligible
words and phrases even when provided with models of words and phrases by
parents and caregivers. The mother says \"bottle\" but the baby does not
and cannot say \"bottle\". Eventually, however, the infant acquires the
ability to accurately copy the verbal responses of parents, siblings and
caregivers. Learning new pronunciations is also involved in second
language learning.

This is also the kind of behaviour change which is involved during the
acquisition of many motor skills (e.g. learning to walk, to run, to
climb stairs and so on). Every infant passes through a stage where they
can stand, but they cannot walk. Although other household members
repeatedly model walking about, the infant cannot, initially, take even
one unaided step without falling over. With practice however, the child
acquires the ability to walk as competently as everyone else.

The most common classroom example of this kind of learning outcome is
the teaching of handwriting. Initially, the young child cannot even draw
a straight line and providing the child with a model of a letter or a
word to copy does not function to prompt a competent copying response.
It is only with practice that the young child acquires the ability to
make an accurate copy of each of the letters and only with further
practice that the child acquires the ability to print the letters
without a model to copy.

Many gross motor skills and fine motor skills are acquired only as a
result of extensive practice and shaping by the physical and social
environment. This is true of early locomotion and swimming skills; it is
true of early copying, printing, drawing and painting skills; it is true
of catching, throwing, batting and other ball handling skills; it is
true of gymnastic and sports skills of many kinds and it is true of many
early self-care skills such as using a knife and fork, putting on items
of clothing, filling a cup and so on. Older learners also face learning
tasks in which competent performance can only be acquired as a result of
extensive practice. Examples include learning how to ride a bike,
learning how to throw a pot on a potter\'s wheel, learning how to
perform a competent stroke in tennis or golf, learning how to execute a
smooth gear change in a car, and so on.

This kind of acquisition outcome is often referred to as \"motor
learning\" or as \"skill learning\" but, since it includes the early
acquisition of language, this does not seem a very appropriate label. We
will, therefore, refer to acquisition outcomes which cannot be
accomplished simply by presenting a model for the learner to imitate as
\"the acquisition of new behaviours\".

**Measuring the acquisition of new behaviours.** A person's ability to
perform a completely new behaviour such as printing letters accurately
is typically measured by observing and rating the quality of the
learner's performance. But it can also be measured by counting the
number of responses which achieve a given *critical effect*. Because the
rating procedure tends to be extremely unreliable, the second procedure
is the procedure of choice. The term critical effect refers to whether
or not the behaviour has the outcome which its performance was designed
to achieve. With saying a new word, the critical effect is
comprehensibility (which occurs only when pronunciation begins to fairly
closely approximate the conventional pronunciation). With printing, the
critical effect is legibility. For goal shooting, the critical effect is
getting the ball into the goal from a certain distance. For parking, the
critical effect is getting the car into the parking space without
damaging anything.

Having decided upon the critical effect, the second step is to design a
short test of improvement. In most cases, a set of approximately 10
trials will provide a measure which is sufficiently sensitive to show
whether or not improvements are occurring from day to day. Ten trial
tests are possible with the great majority of pronunciation, physical,
sporting and recreational skills. For example, it is possible to measure
performance on ten trials catching a ball from a particular distance, on
ten goal shooting trials, on ten trials putting a golf ball a certain
distance, on a ten-word printing test and so on.

To measure progress, the ten-trial test is completed by the learner at
some stage during each practice session. (It may, in fact, be part of
the practice). This will provide a measure of the *rate of improvement*
which is occurring with respect to the target behaviour. Increases (from
one observation to the next) in the number of responses which produce a
given critical effect (or which can be performed to a given standard)
will provide an accurate measure of rate of progress towards this kind
of teaching outcome.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/Implicationsofthisdefinition/index.md","# Implications of this definition \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-fc7a32cbd12a45b78ebaccf6f561a5c3}
To summarise: most human behaviours are actions, that is, they are
behaviours which are undertaken for some purpose and which have effects
in the sense that the action may be successful or unsuccessful in
achieving its intended purpose.

When evaluating a research report which claims to be about the
conditions under which learning occurs, or about the effects of teaching
on learning, the reader must first establish that what was observed and
measured was in fact learning. That is, the reader must establish that
what was observed and measured was a *change* in learner competence,
observed or measured using a procedure which enabled the researcher to
*track one or more action-and-purpose units and their effects over
time*, and *reported separately for each of the individual learners* who
took part in the experiment. An investigation which fails to meet any of
these requirements is unlikely to qualify as a scientific study of
learning. It can be seen, therefore, that, as a subject matter for study
and scientific research, learning has a number of characteristics which
make its observation and measurement somewhat difficult.
:::

::: referencesList
#### References

-   Gage, N.L. & Berliner, D.C. (1988). Educational psychology (4th
    ed.). Boston: Houghton Mifflin Co.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/Learninginvolveschange/index.md","# Learning involves change \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-08128cc25bed463f8103c087fb6728b7}
Learning involves a change in learner competence, ability,
understanding, attitude, belief, or whatever. Change is something which
occurs over time. A child who is learning to talk is a child whose
ability to talk is changing (improving) with the passage of time. A
child who is learning to read is a child whose reading skills are
changing (improving) over time.

So time is an integral component of learning as a subject matter and any
procedure which we use to study learning must, therefore, be a procedure
which is capable of tracking changes in learner competence over time.
Experience suggests that repeated observation provides the best
description of change and rate of change.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/Learningoccursinindividuals/index.md","# Learning occurs in individuals \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2058b94f951547fabc2be6f97df8fddb}
Learning is the ability to profit from experience and it is the
individual learner who profits from experience. In other words, it is
individuals who learn. The term *learning* refers to changes which are
occurring with respect to the skill, understandings, attitudes or
whatever of individual learners. In order to determine which of the
children in a class of children have learned to multiply we must observe
the multiplication skills of each individual child. When a teacher
administers a test to the children in her class, she records each
child\'s mark separately and it is this individual achievement which is
discussed with the child, reported to parents, and so on.

Any procedure which we use to study learning must, therefore, be a
procedure which is capable of tracking changes (over time) in the
competencies of individual learners. Single-case procedures meet this
requirement. Between-groups procedures do not meet this requirement
because it is impossible to generalise from the average performance of a
group of learners to the performance of any of the individual learners
in that group.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/Mosthumanactionbehaviourispurposeful/index.md","# Most human action (behaviour) is purposeful \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-01cb30ba253f4d35bdae402475ea404b}
Most behaviours are engaged in for some purpose. When a teacher gives an
instruction the teacher usually expects or intends that the instruction
will be followed. The same action may be engaged in on different
occasions for different purposes. On some occasions, a child may put her
hand up to indicate that she wants to answer the question, on other
occasions to indicate that she wants some help, on yet other occasions
to indicate that she wants to go to the toilet, and so on. Furthermore,
different actions may be engaged in for the same purpose. There are many
different actions which a child may use to attract the attention of the
teacher, for example.

In order to make sense of what people do and say and think, therefore,
we need to take into account not only what a person does, but also the
purpose which that action serves. To say that \"Anton yelled\" is not very
meaningful. To say that \"Anton yelled to attract my attention\", or that
\"Anton yelled to warn me of the approaching bus\" is more meaningful. The
same is true of learning to act and talk and think in new ways. The
actions which we learn and remember are the ones which turn out to be
the most successful ways of achieving particular purposes.

This observation suggests that, for the study of learning, the most
appropriate unit of analysis is not a particular type of action (defined
in terms of the action alone) but a unit which consists of both the
action-and-its-purpose. It follows, therefore, that any procedure which
we use to study learning must be one which is capable of tracking
changes in these action-and-purpose units over time.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/index.md","# What is learning? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6d2c9f5399d04044ae1a42e3e52d0a82}
Gage and Berliner (1988) provide a fairly mainstream definition of
learning.

\"It is a change in *behavior* which occurs in the process of learning.
Changes in physical characteristics (height, weight) do not count as
learning. Nor do changes in physical strength (lifting ability,
endurance), which occur as a result of physiological change in the size
of the muscles or the efficiency of circulatory and respiratory systems.
\... *Behavior* refers to some action, muscular or glandular, or
combination of actions. One kind of behavior is verbal - our spoken and
written actions. The changes from \"dada\" to \"father\", from an essay
about \"How I Feel Today\" to one about \"Transcendental Meditation,\" from
writing \"shcool\" to \"school\" allow us to infer that learning has taken
place. The overt behaviors of talking, writing, moving, and the like
allow us to study the cognitive behaviors that interest us - thinking,
feeling, wanting, remembering, problem solving, creativity, and so on.
\... Typically, in school learning, the change in behavior we are
looking for is the ability to remember, understand, and apply various
things and the tendency to have certain attitudes and values, of the
kind set forth in our educational objectives. And we want these kinds of
learning to be *relatively permanent.* The final component of our
definition of learning is *experience* - interchange with the
environment whereby stimuli take on meaning and relationships are
established between stimuli and responses. We want to exclude behavior
changes due primarily to maturational processes, such as a baby\'s
learning to stand and walk. We also want to exclude behavior changes
that are due to alcohol or other drugs. And we want to exclude purely
physiological changes, like the behavior changes we show when we are
overtired\" (Gage & Berliner, 1988, p 229).

Put briefly, *learning is a relatively permanent change in behaviour
which has occurred as a result of experience.*

Note that this definition of learning has four elements. First, there
must be a *change*. We must observe, with respect to a particular skill,
first, that the learner cannot perform that skill and then we must
observe (at some later time) that the learner can now perform that skill
before concluding that learning has occurred. Secondly, there must be a
change in the child\'s *behaviour*. Thirdly, we limit the use of the
term learning to changes in behaviour which are *relatively permanent*.
This excludes changes which are the result of changes in physiology:
fatigue, rest, illness, drugs and so on, and it excludes changes which
appear one day and then disappear the next. Fourthly, learning refers to
changes which have occurred as a *result of experience* - as a result of
the learner\'s interaction with his or her environment. We use the term
learning to distinguish between changes which are occurring as a result
of experience and those which are occurring as a result of growth,
maturation, or injury.

Let us elaborate this common definition of learning to identify some of
the implications and issues that arise when we try to study the
phenomena which we refer to as learning.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/Actionshaveeffects/index.md","# Actions have effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4888f0ea462c4cb7beafdc3f5f64699b}
The actions of learners also have effects. These effects may be the same
as the purpose for which the action was performed or they may be
different. In other words, an action may be successful in achieving the
goal intended, or it may be unsuccessful. A teacher may give an
instruction with the intention that it be followed, but the instruction
may or may not be followed. A child may raise her hand with the
intention of attracting the teacher\'s attention, but this action may be
successful or unsuccessful. A child may attempt to solve a new kind of
problem (using the procedure described by the teacher) and may get the
answer correct, or not get it correct. It follows, therefore, that any
procedure which we use to study learning must be one which is capable of
tracking not only particular action-and-purpose units but also their
effects (that is, whether or not they are successful) each time they
occur.

Since the actions which we use on future occasions tend to be those
which have been most successful on past occasions, the ability to track
the consequences, effects and outcomes of particular actions over time
is a matter of critical importance in the scientific study of those
changes which we refer to as learning. Attempts to study the
relationships between teaching events and behaviour change, but which
fail to track each attempt to perform the new behaviour together with
the consequences or outcomes of each of these attempts, will almost
certainly fail to collect the very data which is needed in order to
explain the changes which are observed.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Whatislearning/Learningincludesachangeinbehaviour/index.md","# Learning includes a change in behaviour \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b9f6774c6f8b40778c361a369be7c46d}
When an individual learns, both their nervous system and their behaviour
changes. However, it is on the basis of observed changes in what the
learner can say and do (their behaviour) and not on the basis of changes
in at the synaptic level that we make the decision as to whether or not
someone has learned something. We conclude that someone has become more
motivated if we see them behaving in a more motivated way. We conclude
that someone has learned a new skill if we see them doing something
which they were previously unable to do. We conclude that someone has
acquired a new understanding if they are now able to explain something
which previously they could not explain.

Note that learning researchers use the word \"behaviour\" to refer to
anything which the learner does, or says, or writes, or thinks or feels.
The term is not limited just to physical actions. Any procedure which we
use to study learning must therefore be one which is capable of tracking
changes in the behaviour (that is verbal and non-verbal actions and
interactions) of individual learners over time. Because changes in
behaviour are publicly observable, or can be made publicly observable
(e.g. by asking the learner to think out loud), changes in behaviour can
almost always be observed directly or recorded on video for later
analysis.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/index.md","# Learning processes, learning outcomes and phases of learning \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3d57246d563f4edab823b0483d60276c}
The scientific study of learning becomes possible only when
investigators reach agreement on the nature of the subject matter, that
is, the nature of the changes which are to be referred to as \"learning\".
Since the main purpose of teaching is to facilitate or bring about
learning, it follows that teachers, teacher educators, and teaching
researchers must also have a very clear understanding of just what it is
that we are referring to when we talk about \"learning\".

Most conventional definitions of learning refer to a phenomenon which
(1) involves change, (2) occurs in individuals, and (3) involves a
change in behaviour as well as a change in the central nervous system.
In Section 1 we explore some of the implications of this definition for
the observation and measurement of learning.

In addition, the term \"learning\" is used to refer to many different
kinds of change and each of these different kinds of change are
dependent upon the presence of a rather different set of conditions. In
Section 2 we identify some of these different kinds of changes: changes
in competency, changes in motivation, and changes in likes and dislikes.

Section 3 looks in greater detail at changes in competency and
identifies a number of different kinds of acquisition outcomes which
need to be distinguished because each is dependent upon the presence of
a somewhat different set of conditions before they are likely to occur.

Finally, we observe that all types of acquisition move through several
phases on the way from initial acquisition to mastery and long term
retention. These phases are described and defined in Section 4.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Threeimportantlearningprocesses/index.md","# Three important learning processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-fcb2d01ad2f5461ab7f1622a4dcc9803}
The main problem with the word learning is that it does not refer to
just a single process. \"Learning\" is a collective noun which refers to a
number of different processes.

A child who is learning to read may improve in the sense that they
acquire the ability to recognise words which they couldn't previously
recognise, or they may improve in the sense that they become more
motivated to read and hence read more often than previously, or they may
improve in the sense that they begin to like reading more than they did
previously. In other words, the phrase \"learning to read\" subsumes a
number of different change processes: the acquisition of new
competencies (the development of new abilities), changes in motivation,
and changes in attitudes, likes, and dislikes.

The ability to distinguish between acquisition, motivation, and
developing a like or dislike is extremely important because these
different types of outcomes occur as a result of different processes and
the different processes require the presence of different kinds of
experiences if they are to occur. For example, demonstrations play an
important role during acquisition but have little or no effect on the
development of a liking for, or motivation. The ratio of reinforcement
to response effort is a primary determinant of motivation but has little
effect on acquisition or liking for. The ratio of success to failure has
a major effect on liking for but has a much smaller effect on
acquisition and motivation.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Phasesoflearning/Adaptingskillstomeetnewtaskdemands/index.md","# Adapting skills to meet new task demands \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e67ea4cc1d4c4748a5133cbd569cf254}
Sometimes it is important that a particular skill be performed in much
the same way every time that it is used. This is the case in learning to
use a concept name correctly, for example. There is only one correct
name and only one way to pronounce it. The same is true of many more
complex skills. \"Behavioral variation in landing an airplane or
performing brain surgery could lead to disaster\" (Sulzer-Azaroff &
Mayer, 1991, p. 502).

In other cases, however, the learning outcome which is desired is a
highly transferable set of performances -- a set of performances which
can be adapted to new task demands without the necessity for further
training. This is inevitably the case where the learner must adapt
existing skills to a new setting (e.g. adapt cooking skills to a new
kitchen) and is often the case where a response which has been learned
on one kind of equipment must be adapted in order to operate a different
make of that equipment. When the learner has to make slight adaptations
to previously learned responses or procedures in order to continue
responding correctly to new variations of particular tasks, this is
called *adaptation*. Adaptation is required whenever the learner must
learn to give a *class of responses* to the members of a class of
stimuli.
:::

::: referencesList
#### References

-   Sulzer-Azaroff, B. & Mayer, G. R. (1991). Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart and Winston.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Phasesoflearning/Theacquisitionphase/index.md","# The acquisition phase \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e9b4b587fbcf463392a2e8aa73ea6379}
The acquisition phase is the initial period of improvement. It covers
that period of time from when the learner is unable to respond correctly
without assistance through to when they are able to respond correctly
without assistance. The acquisition phase involves a change from being
unable to perform the new skill through to being able to perform it --
but only with assistance. The skill can be performed, but not
independently, not without some assistance.

The end of the acquisition phase is marked by the emergence of
independent, or unassisted correct responding. The learner is able to
perform the new skill independently, that is, without assistance or
reminders. When a learner can respond correctly without assistance we
say that he or she has reached the *independence level* with respect to
the skill, competency, or understanding which is of interest. Note that
independent performance may still not be very skilled. It may be slow
and hesitant and still require much concentration.

When people talk about learning it is often the acquisition phase which
they are referring to and when people test for learning using some kind
of measure of correct responding, it is usually acquisition, that is,
the achievement of independent performance which they are testing for.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Phasesoflearning/Thefluencybuildingphase/index.md","# The fluency building phase \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9a27308d56a540cb994c9a588a4f88d2}
Even after students have learned how to respond correctly, we often
provide additional practice to bring them to the point where they can
respond fluently, that is, both correctly and quickly. Fluent
performance is necessary in most real-life situations and a functional
level of fluency is an expected learning outcome with respect to almost
all of the basic academic skills taught at school. Reading skills are of
no use unless the child can read quickly enough to make sense of what is
being read, writing skills are of little use until the child can write
at a reasonable speed, musical performance skills are of little use
until the learner can play quickly enough to keep up with the other
players.

The fluency building phase involves a change from slow but correct
responding to fast and correct responding. The end of the fluency
building phase is marked by a level of correct responding which is as
fast as that demonstrated by learners who have mastered the skill in
question.

The development of mastery is referred to using a variety of names.
Educators often talk about skills which have been \"memorised\" or
\"over-learned\". Cognitive scientists talk about the development of
\"automaticity\" and long term \"retention\". Neuroscientists talk about the
development of \"reflexive memory\". Behavioural scientists talk about
functional levels of fluency. In this account, will use the term
*mastery* to refer to a level of competence where the behaviour of
interest can be performed sufficiently accurately and sufficiently
quickly for it to be of use in most of those settings where it will need
to be used. In general, the ability to begin responding in less than 1
second is considered to be a functional level of fluency since it is
this level of recall speed which predicts long term retention.

The measurement of improvements in fluency requires a short test which
can be administered on a day to day basis. The test must be a timed
test. For many new behaviours such as naming, reading, calculating and
so on, an accurate estimate of fluency level can be obtained using a
1-minute test. In the case of reading, running records of oral reading
can be timed to provide a measure of the number of words read correctly
per minute. In the case of writing, the time taken to complete the
writing task can be recorded so that the number of words written
correctly per minute can be calculated. In the case of keyboarding,
fluency can be measured by recording the number of characters, or the
number of words, correctly typed per minute. In the case of new
procedures and operations, improvements in fluency are normally measured
by measuring the length of time which the learner requires in order to
complete the procedure correctly. For example, improvements in the
bed-making skills of a trainee nurse might be measured by recording the
time taken to complete this task to a predetermined standard.

One of the reasons why we have chosen to use the term *fluency* rather
than the term \"automaticity\" is because we have accurate and widely used
measures of fluency whereas those who use the term automaticity have yet
to develop a practical method for measuring level of automaticity which
is simple enough for use in the classroom. Measures of fluency provide a
much more sensitive measure of learning than do measures of accuracy
(that is, measures of correct performance). This is because accurate
responding may be achieved very quickly (in three or four trials)
whereas improvements in fluency continue to occur long after 100 per
cent accuracy has been achieved.

Teachers are often interested in the question of whether or not a
student has remembered a recently taught skill or understanding. This
dimension of performance is most commonly measured by returning after a
period of non-use of the skill and administering a test of retention.
This is a relatively time-consuming way of measuring retention and
clearly is not a procedure which teachers can use to make decisions
about whether or not further practice needs to be provided. Fortunately
we now know that retention tests are unnecessary in most situations.
This is because once a response has been sufficiently well practised to
ensure that it can be recalled in less than a second, there is an
extremely high probability (approaching 100 per cent) that the response
will be remembered for many months, if not for a lifetime. This being
the case, it is normally sufficient simply to measure fluency to see if
the targeted response can be recalled in less than 1 second. If this
outcome is achieved, the later retention test will prove to be
unnecessary and can be abandoned.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Phasesoflearning/index.md","# Phases of learning \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e91b90e9829f4baab51d39f4c5b6c726}
Learning involves change. These changes may continue for some time.
Improvements in a skill such as handwriting, for example, may continue
for several years. Both behavioural scientists and cognitive scientists
distinguish between a number of phases of the learning process. These
phases are distinguished because (a) the type of practice required in
order to move from one phase to the next changes from phase to phase and
because (b) different measurement procedures are required to measure
improvement within each of the several different phases.

In this account we will distinguish between the acquisition phase, the
fluency building phase, the endurance phase, the generalisation phase
and the adaptation phase. These distinctions are similar to the
distinctions described by Johnson and Layng (1992) and can be traced
back to the earlier work of Haughton (1972) and Lindsley (1972).
:::

::: referencesList
#### References

-   Haughton, E. C. (1972). Aims: Growing and sharing. In J. B. Jordan
    & L. S. Robbins (Eds.), Let's try doing something else kind of thing
    (pp. 20-39). Arlington, VA: Council on Exceptional children.
-   Johnson, K. R., & Layng, T. V. J. (1992) Breaking the structuralist
    barrier: Literacy and numeracy with fluency. American Psychologist,
    47, 1475-1490.
-   Lindsley, O.R. (1972). From Skinner to precision teaching: The child
    knows best. . In J. B. Jordan & L. S. Robbins (Eds.), Let's try
    doing something else kind of thing (pp. 1-11). Arlington, VA:
    Council on Exceptional children.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Phasesoflearning/Thedevelopmentofendurance/index.md","# The development of endurance \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2cf242d2e62d4350856589f896537b2a}
Some skills are still not functional even although they can be performed
at functional levels of fluency for short periods of time. For example,
it is not sufficient that a child be able to keep up with the rest of
the orchestra for a minute or two. The child must be able to keep up
with the rest of the orchestra for the entire performance and this may
last for 20 minutes or more.

Being able to maintain a given level off fluency for a reasonable period
of time is referred to as *endurance*. The endurance building phase of
learning covers that period of time from when the learner begins to
respond with functional levels of fluency through to when they are able
to demonstrate that they can respond with functional levels of fluency
for functional periods of time. Endurance is a commonly used measure of
achievement in such skills as keyboarding. Instead of using a 1 minute
fluency test, the instructor measures fluency over a longer period such
as 10 minutes.
:::"
".//Importantlearningandteachingevents/Learningprocesseslearningoutcomesandphasesoflearning/Phasesoflearning/Thegeneralisationofskillstonewsituations/index.md","# The generalisation of skills to new situations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-90963ec347754b988767b7b78f90cc9f}
There are many situations where the desired learning outcome is to learn
*when* a particular response, behaviour or operation should be used.
This often involves teaching the learner to generalise across those
situations in which the response is appropriate and to discriminate
between those situations in which the response is appropriate and those
situations where it is not. Having taught someone how to draw money from
an automatic teller machine, we expect this skill to generalise to the
various different kinds of automatic tellers. Having taught a child how
to find a word in a dictionary, we expect the child to generalise this
skill to other dictionaries and indexes which are arranged
alphabetically. Having taught a child how to solve a particular type of
maths problem, we expect the child's problem solving to generalise to
other examples of that type of problem.

The technical term for the development of these kinds of performances is
\"stimulus generalisation.\" It is also referred to as \"transfer\" -- as in
the ability to transfer a previously learned skill to a new situation.
Although the ability to generalise skills to new situation is clearly an
important kind of learning outcome, agreed procedures for measuring
changes in the degree of stimulus generalisation have yet to be
developed.
:::"
".//Importantlearningandteachingevents/index.md","# Important learning and teaching events \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-95d27fac776f42a4990d46cfa2e879f8}
Distinctions between the events which do (and do not) affect learning
are absolutely critical if we are to develop a science of learning and
teaching. Little or no progress was made in any of the established
sciences until the \"basic units\" of the subject matter had been
identified.

The same will be true in our attempts to develop a \"science of
learning\". Each of the different types of change currently subsumed
under the heading \"learning\" will need to be identified, defined, and
given an agreed name. Secondly, each of the events which are found to be
a necessary condition for, or to have an affect upon, one of these types
of change will also need to be identified, defined and given an agreed
name. Only if this can be achieved will different groups of researchers
be able to work cooperatively on the task of identifying the conditions
necessary for each different type of learning and to communicate with
each other regarding the results of their many experiments.

In Book 2 we will begin the task of identifying the many distinctions
which appear to be necessary if we are to make any kind of progress in
our attempts to identify the conditions which do and do not affect
learning.

In Chapter 1 we define learning and identify some of the more important
changes which are subsumed under the term \"learning\".

Chapter 2 lists the kinds of curriculum goals which teachers are
expected to work towards and makes the observation that most of these
are very poorly defined. In Chapter 3 we begin the task of identifying
the important learning outcomes which are hidden inside some of these
curriculum goals.

In Chapter 4 we identify the three-term learning interaction as a basic
unit of analysis and list many of the antecedent events, variations in
practice responses, and consequences (response outcomes) which have been
found, as a result of experimentation, to affect attention, motivation,
and the acquisition and retention of new responses. In Chapter 5, we
list some of the ways in which learning interactions and their component
events can be sequenced by teachers (and learners) in their attempts to
acquire and master new skills and understandings.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/Resourcesforprogressmonitoring/index.md","# Resources for progress monitoring \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-33d8be87091042fe95597f8bd1fa7d24}
The term *progress monitoring test* refers to the 1-3 minute fluency
tests which effective teachers use on a daily or twice weekly basis to
measure student progress towards defined teaching goals such as decoding
fluency, reading fluency, sight word recognition, handwriting fluency,
key boarding fluency, spelling fluency, compositional writing fluency,
fluency in specified mathematical operations, and so on. These progress
monitoring tests are most commonly referred to as probe tests, or as
*probes* for short. Some readers will recognise the practice of
measuring student progress using daily or twice-weekly fluency testing
as *curriculum based measurement*.

As far as classroom practice is concerned, the probe tests which have
the greatest impact on teaching effectiveness are those which are
immediately available from the school's resource room. The adequacy of
the materials provision for progress monitoring may be measured by
examining the school store room and counting the number of academic
skills at each year level for which sets of probe tests are immediately
available for classroom use.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/Diagnosticassessmentresources/index.md","# Diagnostic assessment resources \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-88c776d42f5f47638cd96e8e8243256d}
The term *diagnostic assessment resource* refers to standardised tests
for assessing the level of development of individual children with
respect to key academic skills such as phonemic awareness, decoding
fluency, reading fluency, vocabulary level, reading level, handwriting
fluency, spelling level, morphological knowledge, compositional writing
fluency, mathematical concept knowledge, fluency with respect to single
digit number facts, fluency with respect to expected mathematical
operations, and so on. Only if the classroom teacher has access to
diagnostic tests of known reliability can developmentally appropriate
teaching goals be identified for each student for each of the main
academic skills.

As far as classroom practice is concerned, the diagnostic resources
which have the greatest impact on teaching effectiveness are those which
are immediately available, that is, available from the school's resource
room. The adequacy of the diagnostic materials available to the teacher
may be measured by examining the school store room and counting the
number of academic skills at each year level for which diagnostic
instruments of known reliability are immediately available for classroom
use.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/Thepreviouslyacquiredknowledgeofthechildrenintheclass/index.md","# The previously acquired knowledge of the children in the class \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0e54592300eb471b9f08b84a2de78eb0}
It is important to recognise that, in a classroom of 25-30 students,
students are likely to be learning as much from each other as they are
learning from the teacher. This is because, in the context of the modern
Western classroom, the students have more contact with each other than
they do with the teacher. This means that the collective knowledge of
the students in a classroom is a variable which is likely to be having a
major impact on what is, and is not, being learned in that setting. The
effects of this variable have been the subject of very little research.
In fact, the variable does not even have an agreed name. So it is hardly
surprising to find that procedures for measuring variations in the
collective knowledge of the students in a class of students have yet to
be devised.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/Teachingresources/index.md","# Teaching resources \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2f31848d00304d2c8b3b4e9ad9e2828e}
Effective concurrent teaching of 25 to 30 students simultaneously is
only possible if reasonable supplies of teaching, practice, and fluency
building materials are immediately available for classroom use at each
year level. This is because it simply is not physically possible to
create the materials required for 25 hours of teaching and marking for
25-30 students in a 40 hour working week.

The term *teaching materials* refers to the curriculum relevant
materials which are immediately accessible to all students in the
classroom or instructional group. Included under the heading of teaching
materials are the teaching programmes, text books, printed resources,
electronic resources, instruction sheets, exercise sheets, activity
sheets, problem solving sheets, educational games, practice activities,
and so on which are available for students to use. It is important to
note that the term \"teaching materials\" also includes practice
materials. That is, it includes all of the materials which are being
used to provide practice in newly acquired skills and to build
functional levels of fluency in newly acquired skills and
understandings.

Teaching resources may be divided into two general categories: (a) those
that have been rigorously field tested and which are known to be
effective for a defined group of students and (b) those which appear to
have face validity but which have never been field tested and which are,
therefore, of unknown effectiveness. In an ideal world the teaching
materials available to classroom teachers would be teaching programmes
and teaching materials of known effectiveness. At the present time,
however, such resources are relatively rare. So it is important that
stock-takes of the teaching resources which are available to each of the
teachers in a school distinguish carefully between materials of known
effectiveness and materials of unknown effectiveness.

The extent to which the classroom teaching is supported by adequate
levels of teaching resources may be measured by examining the resources
which are immediately available to every student in the classroom for
each of the curriculum topics in each of the curriculum areas which the
teacher intends to cover during the course of the school year.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/Thecontentknowledgeandpedagogicalskillsoftheteacher/index.md","# The content knowledge and pedagogical skills of the teacher \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3659ed6dfbb94158a50819a1b958acce}
It is widely assumed that the rate of progress made by students in the
classroom setting is strongly determined by the content knowledge and
pedagogical knowledge of the teacher (e.g. Darling-Hammond, 2000; Rivers
& Sanders, 2002). It is strange, therefore, to discover that little
progress has been made in identifying the particular kinds of content
knowledge and the particular kinds of teaching skills which need to be
measured during studies of the effects of teacher knowledge on student
learning. In the majority of studies of the effects of teacher knowledge
on student learning, the teachers in the sample have been classified or
ranked using relatively crude measures such as length of the teacher
preparation course, whether the teacher has a bachelors level or masters
level qualification, or whether the teacher has completed a university
level qualification in their teaching subject (e.g. English, maths, or
whatever).

What is urgently needed are more sensitive measures of the various
dimensions of teacher competence so that we can begin to measure the
size of the effect of different pedagogical skills on student learning
and hence begin to identify the content knowledge and the pedagogical
skills which have the strongest effects on learning in the classroom.
:::

::: referencesList
#### References

-   Darling-Hammond, L. (2000). How teacher education matters. Journal
    of Teacher Education, 51, 166-173.
-   Rivers, J. C., & Sanders, W. L. (2002). Teacher quality and equity
    in educational opportunity: Findings and policy implications.
    In L. T. Izumi & W. M. Evers, Teacher Quality (pp. 33-54). Hoover
    Institution. Retrieved 12 April, 2005, from
    http://www-hoover.stanford.edu/publications/books/fulltext/teacher/
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/index.md","# The resources immediately available for classroom use \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-50d908724f534e40a150081878712b38}
The effective teaching of 25 to 30 students concurrently for 5 hours a
day, 5 days a week is a task which becomes possible only if the school
provides sufficient diagnostic, assessment, teaching and practice
materials. Without adequate diagnostic materials, the teacher will be
unable to accurately identify appropriate teaching goals for individual
students. Without adequate teaching materials, the classroom teacher is
left having to \"ad lib\" whole class lesson activities for much of the
time which means that teaching is less effective than it could be.
Without adequate practice materials for students to use, the level of
practice engaged in by many students will be insufficient to ensure that
important skills and understandings are mastered and remembered.

There are four major kinds of material resources which are essential for
effective classroom practice. These are diagnostic assessment tests,
tests for monitoring progress, teaching materials of known
effectiveness, and practice materials. Other resources which affect
learning in the context of the classroom include the collective
knowledge of the other students in the class, the extent to which the
class is functioning as a \"learning community\", and the content
knowledge and pedagogical content knowledge of the teacher.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theresourcesimmediatelyavailableforclassroomuse/Theextenttowhichstudentsaretutoringeachother/index.md","# The extent to which students are tutoring each other \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4ec404668f804f7e8c58d8e885a3b6f2}
Modern western-style classrooms tend to be organised so that the
students are spending much of their time working on tasks in peer-led
groups of various kinds. Included here are all of the peer-tutoring
activities, the co-operative group activities, and the informal peer
guidance (and interference) activities which occur throughout the
teaching day.

A number of observers (e.g. Alton-Lee, 2003; Brophy, 2001;
Darling-Hammond, 1997) have worked to popularise the concept of the
classroom as a \"learning community\" that is, the classroom as a context
in which students \"assume individual and group responsibilities for
managing instructional materials and activities and for supporting the
personal, social and academic well-being of all members of the classroom
community\" (Brophy, 2001, p. 6). This work reminds us that classrooms
can vary with respect to the degree to which students help each other,
tutor each other, and otherwise act to facilitate the learning of their
peers in the classroom.

Although much has been written on the classroom as a learning community,
little attention has been given to how we might best measure variations
in the degree to which students help each other in particular
classrooms. Clearly, until educational researchers work out how to
measure degree of \"learning communityness\" it will be difficult to
design research into the effects which this aspect of classroom life
have on the academic development of the students who comprise this
community.
:::

::: referencesList
#### References

-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, N.Z.: Ministry of
    Education.
-   Brophy, J. (Ed.) (2001). Subject-specific instructional methods and
    activities: Advances in Research on Teaching, Vol 8. New York:
    Elsevier.
-   Darling-Hammond, L. (1997). The right to learn: A blueprint for
    creating schools that work. San Francisco: Jossey-Bass.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Schoolclimate/index.md","# School climate \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0b065b3f72ec4de9a33cc400b65707f7}
Some schools provide a more positive and supportive working environment
than others. It seems safe to assume that a positive school climate will
support higher levels of teacher motivation, enthusiasm and effort than
a negative climate. School climate variables have never been adequately
defined and procedures for measuring them have yet to be devised.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Thedegreeofdiversityamongstthechildrenintheclass/index.md","# The degree of diversity amongst the children in the class \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-347ca5f7ce5042b3a245e60606d99b1c}
At any age level, an unstreamed class (untracked class) of 25 to 30
students contains students with a diverse range of learning histories,
prior knowledge, prior level of mastery of basic academic skills such as
reading, and prior mastery of basic metacognitive skills such as
self-management. This diversity tends to increase as the decile level
falls because, as the decile level falls, schools draw children from
families with increasingly diverse levels of parental education.

As the learning histories of the children in a classroom become
increasingly diverse, the teaching task becomes increasingly complex.
This is because, as the students become increasingly diverse, the
maintenance of average rates of student progress requires increasing
amounts of individualisation with respect to the selection of teaching
aims and procedures, with respect to the selection and supervision of
learning and practice activities, and with respect to progress
monitoring and the provision of remedial instruction.

The level of diversity exhibited by a class of students at any given age
level has never been adequately defined and procedures for measuring
level of diversity have yet to be devised. However, relatively simple
and accurate measures of level of diversity are easy to envisage.

*Reading age range.* For example, it is possible to specify the degree
of diversity of the students in a classroom by specifying the range of
achievement levels in a basic academic skill such as reading. A year 4
classroom in which reading achievement levels vary from a reading age of
5 years to a reading age of 12 years is a more diverse collection of
students than a year 4 classroom in which reading ages vary from 7 to 10
years. Achieving an effective reading programme in the first class will
be much more difficult than in the second class because the more diverse
class will need to operate many more reading groups, will need a much
greater range of instructional reading materials, and will require
greater amounts of time in one-to-one instruction than the less diverse
class.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Clarityofcurriculumgoals/index.md","# Clarity of curriculum goals \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ccbcd0908516445d9f501840bd668443}
National curriculum documents rarely specify just what it is students
are expected to learn, when they are expected to learn it, or how well
they are expected to learn it. This means that it is up to individual
schools to set out the specific learning goals to be achieved by
children at each year level in each of the eight essential learning
areas. Individual schools vary widely with respect to the degree of
clarity in goal specification which they have succeeded in achieving in
the school schemes which describe the programme of work and expected
achievement levels which the teachers in that school are expected to
work towards.

The existence of a school scheme with clearly specified learning
objectives for each of the essential learning areas at each age level
saves much teacher time -- time which can be spent on teaching rather
than on curriculum translation and goal specification activities.
However, there exist no working definitions of \"levels of clarity\" in
the specification of teaching objectives at the school level, and no
procedures for assessing or evaluating how well individual school
schemes have succeeding in specifying the teaching objectives which they
contain.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Thenumberofantisocialchildrenintheclass/index.md","# The number of antisocial children in the class \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6875847c51264b5a89c63357131054ae}
The presence in the classroom of one or more children who engage in
antisocial behaviour or who fail to follow teacher directions makes the
classroom teacher's task much more complex than it would otherwise be.
While the misbehaviour of normally developing children can be managed
with contingent praise, warnings, and simple class-wide reward schemes,
these procedures do not work with antisocial children. This means that
the management of each poorly socialised child requires the
implementation of an effective, individualised behaviour plan and this
greatly increases the complexity of the classroom management task.

*Proportion of poorly socialised children in the class.* A second
important measure of the level of diversity in the classroom is a simple
count of the number of students who regularly fail to follow teacher
instructions and/or who engage in higher rates of antisocial children
than same age peers.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/index.md","# The context provided by schools and classrooms \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-05afb5351e6142b3a7d3f0f015e73cbe}
Classroom teaching occurs in a social context. This social context can
vary in many ways. It can vary with respect to the extent to which the
school operates in a well organised and efficient fashion, the physical
facilities provided by the school, the collective knowledge of teaching
colleagues, the number of students in the class, the degree of diversity
amongst these students, the ability of these students to tutor each
other, and so on.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Schoolorganisation/index.md","# School organisation \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4527d7009b0e43e9910d4d51565e1bbe}
Classroom teaching occurs in schools. Schools vary with respect to the
way in which they are organised, their organisational efficiency, and
the extent to which school organisation supports classroom teaching and
learning. These variables have never been adequately defined and
procedures for measuring them have yet to be devised. However two simple
measures of the extent to which school organisation supports teaching
and learning in the classroom may be suggested.

*The number of classroom interruptions.* ** The number of unscheduled
interruptions to classroom teaching and learning activities during
school hours provides a learning sensitive measure of school
organisation in the sense that learning is more likely in classrooms
which experience a minimum of such interruptions. Unscheduled
interruptions include visits by school administration staff, other
teachers, student teachers or students from other classrooms, P.A.
announcements, evacuation drills, and so on which require the attention
of the classroom teacher.

*Total teaching time.* Schools are open for a statutory number of hours
each year. However, not all students spend all of these hours engaged in
curriculum relevant learning activities. Time is lost in transitions
from one activity to another, transitions from the classroom to other
parts of the school, school assemblies, staff meetings, sports days,
cultural activities, teacher sickness, student absenteeism, and the
withdrawal of individual students for various kinds of individual
attention. A second way of measuring the extent to which school and
classroom organisation supports learning is to calculate the time spent
by individual students in curriculum relevant learning activities as a
proportion of the total time in which the school is open.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Theamountoftimeavailableforlessonmaterialspreparation/index.md","# The amount of time available for lesson materials preparation \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-02ead1e0fa7c4962bf7c1a6e6f6a1bfe}
Teachers experience many conflicting demands on their time: classroom
teaching, assisting with the administration of the school, attending
professional development activities, supervising extra curricular
activities, attending to playground supervision, meeting with parents,
marking, materials preparation and so on. Because teachers have to
produce many of their own teaching resources, the time available for
materials preparation becomes a critical determinant of student progress
when teaching occurs in classrooms.

*Preparation time.* The time available for materials preparation is
relatively easy to measure. It is simply the time remaining, out of an
1,800 hour year, after all other work related responsibilities have been
attended to.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Thecontextprovidedbyschoolsandclassrooms/Thenumberofchildrenintheclass/index.md","# The number of children in the class \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-154cc065ea50402ca61294c8a4ce96cc}
A contextual variable which has a strong effect on classroom learning is
class size, that is, the number of students in the class. This is
because instruction which is designed to meet the learning needs of
individual students tends to be much more effective than whole-class
instruction and class size strongly constrains the amount of
individualisation which is possible.

*Class size.* Class size can be quantified either by counting the number
of children who are enrolled in the class or by counting the number of
children who attend from day to day. The former measure is the most
common but the latter measure is more appropriate.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Typesofinstructionaladaptationsmadebytheteacher/index.md","# Types of instructional adaptations made by the teacher \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-600bf91eb8d44a70b73d77809bbe3f18}
Every classroom teacher tries to adapt the curriculum and their teaching
procedures to meet the learning needs of individual students. However,
the form and frequency of these adaptations vary widely. Some teachers
make frequent adaptations others make infrequent adaptations. Some make
adaptations just for those students who have been identified as having
an intellectual disability or a specific learning disability while
others make adaptations for any student who is observed to be falling
behind. Some make adaptations just for key competencies such as reading
and others make adaptations across a range of curriculum areas. Some
teachers make adaptations intuitively, some base their adaptation on the
results of diagnostic testing and some base the adaptations on the
results of curriculum based measurement or other forms of progress
monitoring. Some make adaptations which are effective in helping
students to overcome a particular learning difficulty and others make
adaptations which have little or no effect on student learning.

All of these factors contribute to variability in classroom practice and
the resulting variability in the learning and achievements of individual
students. However, while much of this is known intuitively, there has
been very little research into the kinds of instructional adaptations
which teachers make and the effects which these have on student
learning. As a result, we have no agreed names for the different kinds
of adaptations and no agreed procedure for measuring or describing the
types or scheduling of these adaptations. This makes it almost
impossible to control (and to describe) the teaching procedures used in
experimental analyses of the effects of teaching on learning in the
classroom.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theamountofpracticeisprovided/Overcomingpracticelimitationresultingfromteacherbeliefs/index.md","# Overcoming practice limitation resulting from teacher beliefs \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7b651c471ee749098d883c79d9d0f4a6}
Although it is not often publicly stated, teachers are often not all
that knowledgeable with respect to the conditions affecting learning and
are often unaware of the amount of practice required in order to learn
and remember something, unaware of differences in the amount of practice
required in order to achieve different kinds of learning outcomes and
unaware of the way in which the scheduling of practice in time operates
to inhibit or enhance the learning and remembering of new responses and
ideas. This factor also introduces variability in the practice
experienced by students from one classroom to the next.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theamountofpracticeisprovided/Overcomingpracticelimitationsimposedbythecurriculum/index.md","# Overcoming practice limitations imposed by the curriculum \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-47d4a23c6e0048b2af7480287bc6fc72}
The curriculum for any given year level contains far more than the
average child could possibly learn and remember in a year. This means
that either certain topics and skills have to be left out or else the
time spent on many of the topics must be severely limited. In general,
teachers choose the latter course of action over the former and this
greatly reduces the amount of practice which is possible and hence
greatly reduces what is actually remembered by students.

This variable, although it has no agreed name, might be referred to as
*curriculum density.* Because the amount and scheduling of practice is a
strong determinant of what is learned by individual students, developing
measures of curriculum density, and tracking curriculum density is
obviously an operation of some importance during any attempt to study
the effects of teaching on learning in the classroom.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theamountofpracticeisprovided/index.md","# The amount of practice is provided \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-fae598a738b04207b620d01591fe6ee3}
In order for children to acquire and remember new understandings and to
become competent at new skills, a certain amount of practice is
required. However, a number of factors conspire to limit the amount of
practice engaged in by individual children and this further complicates
the classroom teaching task and affects the long term learning achieved
by both individual students and the class as a whole.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theamountofpracticeisprovided/hevariableswhichdeterminewhatcountsassufficientpractice/index.md","# he variables which determine what counts as sufficient practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-737065121ff04a379db172b8d2a3fa8c}
The variables which determine what counts as sufficient practice have
been described in an earlier chapter. In brief, the number of practice
responses which the learner must experience in order to ensure that a
given response, skill, idea, or understanding will be remembered depend
upon

-   the way in which these are scheduled in time -- with a greatly
    increased likelihood of a new response being remembered if practice
    opportunities with that response occur no more than 48 hours apart,
-   the type of learning outcome which is to be achieved -- with the
    learning of new knowledge and new generalisations requiring much
    less practice than is required for the acquisition of new skills and
    operations
-   the meaningfulness of what is being learned -- with meaningful
    ideas, concepts and generalisations requiring much less practice
    than is required in order to learn and remember less meaningful
    responses such as details, unrelated facts, new names, irregular
    spellings, non-meaningful conventions, and so on
-   the level of proficiency, fluency, or automaticity required -- with
    functional levels of fluency requiring much more reinforced practice
    than is required for initial acquisition.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theamountofpracticeisprovided/Overcomingpracticelimitationsduetoalackofpracticematerials/index.md","# Overcoming practice limitations due to a lack of practice materials \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6cf588f371404941aff3aada86c3a156}
Effective practice activities require effective practice materials. But
schools vary with respect to the type of practice materials and the
coverage of the practice materials which they keep in stock and this
also contributes to variability in the achievements of individual
students in this setting.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theamountofpracticeisprovided/Overcomingpracticelimitationsarisingfromclasssize/index.md","# Overcoming practice limitations arising from class size \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6e66f7ebf7b7423a96ad78fb447ef8a8}
In an earlier section we observed that planning, providing and
monitoring developmentally appropriate practice activities for 25-30
learners concurrently from hour to hour and day to day is an extremely
complex and difficult task. Teachers attempt to solve this problem in a
variety of ways, by organising homework, peer tutoring, computer
assisted instruction, Direct Instruction groups, and so on. However,
each of these solutions creates further problems. Homework has to be
marked. Peer tutoring cuts the time available for practice in half.
Adequately programmed computer assisted instruction is extremely
expensive. Direct Instruction programmes limit teachers' freedom to
innovate. How teachers attempt to solve these problems introduces
further variability into the complex task of measuring the effects of
teaching on learning in the classroom context.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/index.md","# Classroom and context variables \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0da3890d1ce64adebdc3a6ad4bf763e2}
When learning and teaching are occurring in schools, learning depends
not only on the variables referred to in earlier sections of this
chapter but also on a number of additional variables related to the fact
that teaching is occurring in the group setting of the classroom. When
teaching has to be carried out with groups of 25 to 30 learners
simultaneously the effects of that teaching depend upon many additional
factors: the teacher's ability to translate vaguely stated curriculum
objectives into specific lesson objectives, variability with respect to
what the learners have learned already, variability in children's
ability to tutor each other, the teaching resources which are available
to the teacher, the extent to which these resources enable the teacher
to meet the learning needs of individual children, and so on.

This chapter identifies the most important of the contextual variables
which operate to facilitate or hinder learning in the context of the
classroom. The discussion is organised under the following section
headings:

-   Section 1: school-wide and class-wide factors
-   Section 2: the diagnostic and teaching resources immediately
    available to the teacher (including teacher knowledge and the prior
    knowledge of the students)
-   Section 3: the extent to which instructional activities can be
    individualised to meet the needs of students with different learning
    histories
-   Section 4: the extent to which the context allows learning
    opportunities which are sufficient for each individual learner to
    achieve desired learning outcomes
-   Section 5: the extent to which the teacher is able to monitor the
    progress of individual students from day to day and
-   Section 6: the extent to which the teacher is able to adapt on-going
    teaching to meet the unique learning needs of individual children.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Monitoringthelearningofindividualchildren/Thenumberofchildrenmonitoredwithrespecttoeachoftheseoutcomes/index.md","# The number of children monitored with respect to each of these outcomes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-157ff37f567a49e7a7f63e14d7802844}
It is quite impossible for a single teacher to monitor the progress of
25 to 30 students on a daily basis. Teachers attempt to solve this
problem in a variety of ways: by teaching students how to self-evaluate
and self-record their performance, by sampling the students who will be
observed or tested each day, by getting students to work in pairs to
test each other, by setting up computer systems in which the students
themselves can enter the results of daily or weekly probes, and so on.
All of these procedures introduce additional variability into classroom
practice and into the effects of that practice on student learning.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Monitoringthelearningofindividualchildren/Thetypeofmonitoringprocedureused/index.md","# The type of monitoring procedure used \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7526de3024d34af28fd1aefcdffc57e2}
Many different procedures are used for monitoring student progress
towards particular teaching goals: the daily probes used in Precision
Teaching, the weekly tests used in Curriculum Based Measurement, the
periodic running records used in early reading teaching, the weekly
spelling test, and so on. Even when a particular procedure has been
selected, it may be administered in different ways by different
teachers. For example some teachers take untimed running records of
early reading and record only reading accuracy while others take timed
running records and record both accuracy and fluency. More recently,
teaching researchers have begun to develop computer administered daily
probes which students can use first to test themselves, then to enter
their test results, and finally to print out a graph showing their
current rate of progress towards particular learning outcomes.

Different monitoring procedures require differing amounts of work on the
part of the teacher, and teachers vary with respect to the motivation
and the knowledge which they bring to the monitoring task. This produces
very considerable variability across classrooms and, presumably, very
considerable variability in the effects of these practices on student
learning.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Monitoringthelearningofindividualchildren/index.md","# Monitoring the learning of individual children \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9ec31974ed014a92a9c7017f21093a5a}
Teachers who attempt to adapt teaching procedures and learning
activities on the basis of reliable data about the progress which is
being made by individual students tend to be more effective in helping
children achieve particular achievement goals. This kind of adaptive
teaching practice is only possible if the teacher has the skills and the
equipment which is required in order to monitor the progress of 25 to 30
students simultaneously. However, the task of monitoring the learning of
large numbers of students is such a complex task that very considerable
variations in monitoring procedures can exist from classroom to
classroom. Progress monitoring can vary along any of three separate
dimensions: the type of monitoring procedure used, the particular
achievement outcomes which are monitored, and the number of children who
are monitored.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Monitoringthelearningofindividualchildren/Thenumberofoutcomesmonitored/index.md","# The number of outcomes monitored \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-abbce7313ef44d97ae47303cd4a389ce}
It is quite impossible for a single teacher to monitor progress on all
of the dozens of learning objectives typically pursued during the course
of a teaching day. This means that progress monitoring must be limited
to selected learning outcomes -- presumably those which the teacher
judges to be most important.

It is likely that decisions regarding the teaching aims which are and
are not to be monitored function as major determinants of classroom
learning. Variability with respect to the particular learning outcomes
which the teacher chooses to observe and record is therefore likely to
be one of the factors which contributes to variability in the progress
of individual students in the setting of the classroom.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theextenttowhichteachingbuildsoneachchildsenteringskills/Contentprerequisitesandmethodprerequisites/index.md","# Content prerequisites and method prerequisites \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cfb56f46db264bb195c60d79bd240f64}
Prerequisite skills can be grouped into two general categories: content
prerequisites and method prerequisites.

**Content prerequisite skills.** Content prerequisites are the
curriculum relevant skills and understandings which the current teaching
aim seeks to extend or to build upon. Content prerequisites are the
skills and understandings which the teaching aim presumes have now been
acquired by each student -- presumably because they have been taught at
some earlier point in the curriculum.

Content prerequisites exist in all curricula. Early reading instruction
assumes that the child has learned the meanings of each of the words
contained in early reading books. Later reading instruction assumes that
the child has learned to recognise all the common grapheme-phoneme
relations and can decode unknown words without assistance when he or she
comes across them. In maths, the content prerequisites are particularly
clear. If the teaching aim is to teach students how to add fractions,
the instruction will assume that the students can already add whole
numbers with a reasonable degree of accuracy. In science, content
prerequisites include an understanding of those simpler concepts which
must be understood if a new and more complex concept is to be
understood.

**Method prerequisite skills.** A second general class of prerequisite
skills are those which are presumed by the teaching method or learning
activity selected by the teacher. We will refer to these prerequisite
skills as *method prerequisites*. Method prerequisites change as the
teaching method (or type of learning activity) changes. Method
prerequisites change as the child progresses through the school system
and teachers begin to make assumptions about the degree of independence
which learners are able to take for their own learning.

Even on entry to school, teachers assume that new entrant children have
already learned to attend to teacher talk, to imitate teacher
demonstrations, to follow requests and instructions, to answer
questions, to seek help when needed, to keep a track of personal
equipment (such as pencils, rubbers, rulers etc.), to respond to
organisational signals, and so on. Joseph Cobb refers to these basic
method prerequisites as *academic survival skills* (Cobb & Hops, 1973;
Hops & Cobb, 1974)). These skills are essential for progress in school
because most school instruction involves showing, telling, or asking
questions and a child who has not yet learned to respond appropriately
to these events will profit little from learning activities which rely
on these kinds of events.

During the middle school years, teachers often make use of group and
co-operative group learning activities. This kind of learning activity
also assumes that each student has acquired certain method prerequisite
skills such as turn taking, staying on task, asking for help, and
remembering instructions which have been given some time earlier. A
child who has not yet acquired one or more of these skills will be
unable to profit from co-operative group work as a learning activity.

In the upper primary school, children are often set to work on learning
activities which involve various kinds of research and independent
study. Independent study assumes that the learner can locate books in a
library, can locate desired information in a book, can read with
reasonable speed, can read for information, can write reasonably well,
can make summary notes, and so on. A student who has yet to acquire any
of these method prerequisite skills will be unable to profit much from
learning activities which involve independent study.

Some method prerequisites are so important that they need to have been
mastered, that is, to have been practiced to a high level of fluency. A
learning activity which requires students to search out information on a
particular topic assumes that the learner can read and can read
sufficiently quickly to complete the task in the time allotted. A
learning activity which requires the learner to prepare a written report
on a particular topic assumes that the learner can write and spell and
can write sufficiently quickly to complete the report within the time
available. In these cases reading and writing are method prerequisites
because their mastery has been assumed by the learning activities
selected by the teacher.

The level of fluency which has been achieved with respect to method
prerequisites is a matter of some importance because it *sets an upper
limit on the number of practice responses which can be completed per
unit of time and, hence, on the rate of acquisition of new skills*.
Twice as many practice exercises can be completed by the child who can
write letters and numbers at the rate of 80 per minute as can be
completed by the child who is only able to write letters and numbers at
the rate of 40 per minute.
:::

::: referencesList
#### References

-   Cob, J. A., & Hops, H. (1973). Effects of academic survival skill
    training on low achievement first graders. Journal of Educational
    Research, 67, 108-113.
-   Hops, H., & Cobb, J. A. (1974). Initial investigations into academic
    survival-skill training, direct instruction, and first-grade
    achievement. Journal of Educational Psychology, 66, 548-553.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theextenttowhichteachingbuildsoneachchildsenteringskills/Theextenttowhichteachingbuildsoncurrentcontentknowledge/index.md","# The extent to which teaching builds on current content knowledge \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a2e4d3418cb54b458bf10a1360b7b219}
Effective teaching involves the selection of developmentally appropriate
teaching goals, that is teaching goals which build upon those curriculum
relevant skills which have already been acquired without assuming
mastery of any curriculum relevant skills which have not yet been
acquired. Since the learning histories of the students in a class are a
given, this means that teaching goals must be selected which are
appropriate to the entering skills of each learner. The first step in
this process is to complete a task analysis of the new skill which is to
be taught and then to identify those students who have and have not yet
mastered each of the skills identified by the task analysis.

A task analysis of the skill \"adding common fractions\", for example,
would identify the following component skills:

1Is able to add and multiply quantities from 1 to 10 with reasonable
fluency

2.Is able to demonstrate an understanding of fractional numbers (perhaps
by drawing a diagram of the part representing the whole number and the
part represented by the fraction)

3.Is able to read the symbols for common fractions

4.Is able to distinguish between expressions requiring addition and
those requiring some other operation (e.g. multiplication)

5.Is able to distinguish between fractions which contain common
denominators and those which do not

6.Is able to convert fractions with unlike denominators to fractions
with common denominators

7.Is able to add fractions (by adding the numerators and writing the sum
over the common denominator) and to state the rule which governs this
operation

8.Is able to discriminate between expressions which can be simplified
and those which cannot be simplified

9.Is able to simplify expressions

The teacher might be of the view that her students can already perform
Steps 1 to 4 and that instruction can start at Step 5. When the prior
knowledge of the students is checked, this check will identify two
groups of students: (a) those who have and (b) those who have not yet
mastered all of the prerequisite skills. In the case of the second
group, there is only one *effective* course of action and that is to
*change the teaching aim for that student*. The teacher must pause and
take the time to ensure that the student in question acquires and
masters the missing prerequisite skill or understanding. Using the
fraction addition example above, pre-testing might reveal one or more
students who have not yet acquired a generalised understanding of the
concept of a fraction (Step 2). These students would need to be taught
this understanding before they were introduced to the procedure for
adding fractions otherwise they will not understand the procedure.

When pre-testing reveals considerable numbers of students who have yet
to acquire the prerequisites assumed by a particular achievement
objective, we commonly refer to this feature of classroom life as *the
level of diversity* in the classroom. In an earlier section we talked
about the additional work involved in coping with increasing levels of
diversity at the programme level (e.g. the reading programme or the
maths programme). In this section we are talking about the extra work
which is involved in coping with increasing levels of diversity at the
level of the lesson or topic.

The greater the degree of diversity amongst the students in a classroom
the greater the work which is involved in developing teaching resources
and learning activities for each of the different groups of students,
and teachers vary with respect to their motivation and their ability to
cope with this increasing complexity. This variability affects the
learning which will result from particular lessons and learning
activities and is, therefore, an important variable which needs to be
taken into account during any study of the effects of teaching on
learning in the classroom.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theextenttowhichteachingbuildsoneachchildsenteringskills/index.md","# The extent to which teaching builds on each child's entering skills \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-02b40aa38c41485d81bc108b62a92ec1}
The learners who arrive at a particular classroom invariably arrive with
a wide diversity of previously acquired beliefs, knowledge,
understandings and skills. These previously acquired skills are often
referred to as *entering skills*. It is widely assumed that instruction
must be developmentally appropriate, that is, it must build upon those
skills which have already been acquired, while at the same time
requiring the application of only those skills which have been acquired
already. It can be seen therefore, that the entering skills of the
learner combine with the choices made by the teacher to determine
whether or not a particular learning activity will provide the
opportunity for the learner to acquire additional skills or increased
levels of proficiency.

In this account, those entering skills which are *assumed* by a sequence
of learning activities will be referred to as *prerequisite skills*.
Note that prerequisite skills are only prerequisites in the sense that
the teacher is assuming that they have been learned already. They are
*not* prerequisites in the sense that the new skill can\'t be learned
until the prerequisite skill has been mastered. Independent reading can
only be considered a prerequisite skill if the teaching method for a new
topic involves reading. New knowledge can still be acquired by a student
who cannot read. It can be acquired by instructing the learner orally.
So reading is not a *necessary* prerequisite for knowledge learning in
the sense that the learner has to be able to read before she can learn
new knowledge responses.
:::"
".//Importantlearningandteachingevents/Classroomandcontextvariables/Theextenttowhichteachingbuildsoneachchildsenteringskills/Theextenttowhichmissingmethodprerequisiteskillsaretaught/index.md","# The extent to which missing method prerequisite skills are taught \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5cdfc7caea434f27a95941cd94873281}
Careful observation of the way in which individual students cope with
different kinds of classroom activities fairly quickly identifies those
students who have and have not mastered key method prerequisite skills.
What is the teacher to do if there are one or more students in the class
who have yet to master one or more of the skills which are assumed by a
learning activity which the teacher seeks to use? There are three main
options.

The first alternative is to pause and teach the missing method
prerequisite skills to the students who have yet to acquire them. All
method prerequisites can be and have been taught. The child who cannot
read quickly enough to keep up with his peers can be given fluency
building exercises to increase reading speed. We will refer to this type
of remedial teaching activity as *the teaching of missing method
prerequisite skills.*

The second alternative is to change or adapt the teaching method or
learning activity to one which involves method prerequisite skills which
the student *has*, in fact, mastered. If the student can\'t read yet,
then learning can still continue in the oral mode. If the student can\'t
write yet, then learning can still continue if the child is allowed to
work and respond orally. We will refer to this type of response as
*changing the teaching method.*

A third alternative is to provide the learner with some kind of
prosthetic device (some kind of aid) such as a calculator, a word
processor, a peer helper, and so on. For example, if the student has not
yet mastered the basic multiplication facts, they may still be able to
participate in area and volume lessons by being allowed to complete the
necessary calculations with the aid of a calculator. We will refer to
this type of action as the *provision of prosthetic support.*

All of these adaptations require additional work on the part of the
classroom teacher and individual teachers vary with respect to their
motivation and their ability to ensure that the learning activities
which are being selected from hour to hour are ones which all students
can successfully complete. Teacher variability in adapting instruction
to variations in method prerequisite skills affects student learning in
the classroom and is another variable which needs to be taken into
account during any study of the effects of teaching on learning in this
context.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Hownewmeaningsareacquired/Conditionsnecessaryfortheacquisitionofnewmeanings/index.md","# Conditions necessary for the acquisition of new meanings \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ef6f74d3f0dd4cfa9d3099467e518173}
The only condition which has been demonstrated to be necessary for the
acquisition of meaning is the repeated contiguous occurrence of the
conditioned eliciting stimulus (which already elicits the visual image
or meaning response) and the unconditioned eliciting stimulus (the word
or symbol which initially has no meaning) (Staats, 1968; Staats, Staats,
Finley & Minke, 1953; Staats, Staats, Heard & Nims, 1959; Staats &
Staats, 1957). There may well be other necessary conditions, such as the
form or intensity of the meaning elicited by the meaningful stimulus,
but the effects of variables such as these have yet to be measured.
:::

::: referencesList
#### References

-   Staats, A. W. (1968). Learning, language and cognition. New York:
    Holt, Rinehart, & Winston.
-   Staats, A. W., Staats, C. K., Finley, J. R., & Minke, K. A. (1953).
    Meaning established by classical conditioning controlling associates
    to the UCS. Journal of General Psychology, 69, 247-252.
-   Staats, A. W., Staats, C. K., Heard, W. G. & Nims, L. P. (1959).
    Replication report: Meaning established by classical conditioning.
    Journal of Experimental Psychology, 57, 64.
-   Staats, C. K. & Staats, A. W. (1957). Meaning established by
    classical conditioning. Journal of Experimental Psychology, 54,
    74-80.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Hownewmeaningsareacquired/Conditionswhichmayaffecttheacquisitionofnewmeanings/index.md","# Conditions which may affect the acquisition of new meanings \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e8fadb894e444104bc7141096c10e369}
It is to be expected that there will be a number of conditions which
will affect how speedily learners can acquire the meanings of initially
meaningless words, symbols, signs and so on. For example, it is has been
demonstrated that first order conditioning occurs more rapidly than
second-order conditioning and that the number of trials affects the
level of meaningfulness which is acquired (Staats & Staats, 1959).
However, apart from this, little is known.

Why is so little known about the acquisition of meaning? Little is known
about how children acquire new meanings because this topic has been of
little interest to learning researchers. A literature search for
analyses of the way in which children acquire meaning identifies
hundreds of articles containing theoretical accounts of how children
\"construct meaning\" and only a dozen or so experimental analyses of
children actually \"constructing meaning\".

In fact the phrase \"constructing meaning\" is probably a misleading
description of what actually happens. The phrase \"constructing meaning\"
suggests some kind of elaborate, conscious, thinking process on the part
of the learner whereas the experimental analysis of children who are in
the process of acquiring new meanings suggests that meaning responses
tend to be acquired extremely quickly and, in many cases, to be acquired
without conscious awareness (e.g. Staats, Staats & Crawford, 1962).
:::

::: referencesList
#### References

-   Staats, A. W. & Staats, C. K. (1959). Effect of number of trials on
    the language conditioning of meaning. Journal of General Psychology,
    61, 211-223.
-   Staats, A. W., Staats, C. K. & Crawford, H. L. (1962). First-order
    conditioning of meaning and the parallel conditioning of a GSR.
    Journal of General Psychology, 97, 159-167.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Hownewmeaningsareacquired/index.md","# How new meanings are acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-af355a40a6dc47889cb646d5782daf9e}
Much learning, especially during the early years, involves learning what
particular symbols mean. Young English speaking children have to learn
the meaning of the word *dog*, young French speaking children must learn
the meaning of the word *chien*, and young German speaking children must
learn what the word *Hund* means. Initially it is the meaning of the
spoken words which must be acquired. Later the child will need to learn
the meaning of the written words. At the same time the child will also
need to learn the meanings of symbols such as the numbers *0* to *9*,
gestures such as an outstretched hand, facial expressions such as a
glare, signs such as the \"female toilet\" sign, markings such as a zebra
crossing, and so on.

The learning process which is involved in the acquisition of meaning has
long been considered to be something of a mystery and many fanciful
explanations have been advanced. The explanatory difficulty probably
arises as a function of human consciousness. Because consciousness
allows us to \"visualise\" the meanings of many words (such as *dog* or
*red* or *tall*) we are often seduced into thinking that meaning must be
a stimulus. If I can see something in my mind's eye (e.g. a red light)
in the same way that I can see a red light in the real world, then the
red light in my mind's eye must be a stimulus in the same way that the
red light in the real world is a stimulus which I can see and respond
to.

It is interesting to discover that an answer to the question of how best
to conceptualise \"meaning\" has been around since the 1950s (e.g.,
Mowrer, 1954; Staats & Staats, 1957). Arthur and Caroline Staats argued
that the image in my mind's eye is not a stimulus, it is a response.
\"The basic concept is that any external stimulus to which the organism
is sensitive is actually eliciting in the organism a *sensory response*
(Staats, 1996, p. 65). Once we consider \"comprehending the meaning of a
word\" as a response, a relatively simple explanation of how words come
to acquire their meanings, and hence come to be \"comprehended\" or
\"understood\", becomes possible. \"What is the purpose of this
distinction? Centrally, considering sensations as responses says that
they can be learned, that an organism can be conditioned to have a
sensory response. As a consequence of such conditioning, a sensory
response can be elicited by a stimulus other than the stimulus that
ordinarily arouses that sensation. Such a learned sensation, which
occurs in the absence of a sensory stimulus is, in commonsense terms,
called an image. . . . An image is a sensory response that has been
*conditioned* to some extraneous stimulus and can be elicited by that
stimulus (Staats, 1996, p. 65).

The conditioning process which Staats is referring to is respondent
conditioning. The respondent conditioning process is the process whereby
a stimulus such as a word which does not initially possess the power to
elicit a response can acquire that power simply by occurring at the same
time (or slightly before) a stimulus which has already acquired the
power to elicit the response.

Staats and his colleagues designed a number of ingenious experiments to
test the theory that meaningless words can acquire meaning through
respondent conditioning (Staats & Staats, 1957; Staats, Staats &
Crawford, 1962; Staats, Staats, Finley & Minke, 1953; Staats, Staats &
Heard, 1959, 1961; Staats, Staats, Heard & Nims, 1959). As a result of
these experiments Staats and Staats and their colleagues were able to
demonstrate that words probably acquire their meanings as a result of
respondent conditioning. The respondent conditioning of word meaning may
be pictured as shown in Figure 4110a.

![Figure 4110a. Sequence of events involved in a young child acquiring
the meaning of the spoken word \"dog\" as a result of
experience.](../../../../../assets/images/Figure4110a.png \"Figure 4110a. Sequence of events involved in a young child acquiring the meaning of the spoken word “dog” as a result of experience.\"){.image-inline}

*Figure 4110a. Sequence of events involved in a young child acquiring
the meaning of the spoken word \"dog\" as a result of experience.*

Because the spoken word \"dog\" initially occurs repeatedly in the
presence of both pictures of dogs and real dogs (often accompanied by a
pointing response) and rarely at any other time, this repeated pairing
results in the spoken word \"dog\" acquiring the power to elicit a mental
image or mental response similar to that elicited by the animal itself.
That is, the spoken word comes to acquire its conventional meaning when
heard by the listener.

Staats and Staats were further able to demonstrate second order
conditioning. This refers to the way in which an initially meaningless
word can acquire meaning simply by occurring regularly in the same
context as another word or words which already have meaning. For
example, if the word \"verb\" regularly occurs in definitions which refer
to verbs as \"doing words\", or \"action words\", or \"words which describe
what someone is doing\" then this is the meaning that the word \"verb\"
acquires. This process may be pictured as shown in Figure 4110b.

![Figure 4110b. Sequence of events involved in a young child acquiring
the meaning of the spoken word \"Hund\" as a result of is association with
the spoken word
\"dog\".](../../../../../assets/images/Figure4110b.png \"Figure 4110b. Sequence of events involved in a young child acquiring the meaning of the spoken word “Hund” as a result of is association with the spoken word “dog”.\"){.image-inline}

*Figure 4110b. Sequence of events involved in a young child acquiring
the meaning of the spoken word \"Hund\" as a result of is association with
the spoken word \"dog\".*

This process has been demonstrated several times. For example, Staats,
Staats & Heard (1961) selected 12 words that all elicited a \"roundness\"
image (like *globe, hoop, wheel* and *ball*) and another set of 12 words
that all elicited an \"angularity\" image (like *steeple, triangle,
diamond,* and *pyramid*). A meaningless nonsense syllable (e.g. YOF)
which was paired with each of the first set of words was subsequently
rated as more \"round\" by a sample of students than it was when paired
with each of the second set of words.

Second order conditioning explains how it is that we can develop a
mental picture of something which we have never seen (such as an
aadvark) simply as a result of reading verbal descriptions of the object
or event. Second order conditioning also explains how it is that words
like \"ghost\" and \"ogre\" (which have no material existence) can become
meaningful words. It also helps us to understand the mechanism whereby a
person might accept as real \"the existence of various forms of witches,
hobgoblins, elves, dragons, spirits and so on\" (Staats, 1968, p. 50).

Of course, the discovery that meaning responses (such as mental images)
function as responses does not negate the fact that they can also
function as stimulus elements in a chain of responses. Just as the
actual performance of one step in the preparation of a particular meal
can elicit the next step, so too can the sequence of mental images which
have been acquired as a result of previous experience in preparing that
meal.
:::

::: referencesList
#### References

-   Mowrer, O. H. (1954). The psychologist looks at language. American
    Psychologist, 9, 660-694.
-   Staats, A. W. (1968). Learning, language and cognition. New York:
    Holt, Rinehart, & Winston.
-   Staats, A. W. (1996). Behavior and personality: Psychological
    behaviorism. New York: Springer Publishing.
-   Staats, A. W., Staats, C. K., & Crawford, H. L. (1962). First-order
    conditioning of meaning and the parallel conditioning of a GSR.
    Journal of General Psychology, 97, 159-167.
-   Staats, A. W., Staats, C. K., Finley, J. R., & Minke, K. A. (1953).
    Meaning established by classical conditioning controlling associates
    to the UCS. Journal of General Psychology, 69, 247-252.
-   Staats, A. W., Staats, C. K., & Heard, W. G. (1959). Language
    conditioning of meaning to meaning using a semantic generalization
    paradigm. Journal of Experimental Psychology, 57, 187-192.
-   Staats, A. W., Staats, C. K., & Heard, W. G. (1961). Denotative
    meaning established by classical conditioning. Journal of
    Experimental Psychology, 61, 300-303.
-   Staats, A. W., Staats, C. K., Heard, W. G., & Nims, L. P. (1959).
    Replication report: Meaning established by classical conditioning.
    Journal of Experimental Psychology, 57, 64.
-   Staats, C. K., & Staats, A. W. (1957). Meaning established by
    classical conditioning. Journal of Experimental Psychology, 54,
    74-80.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howlikesanddislikesdevelop/Conditionswhichmayaffectthedevelopmentofnewlikesanddislikes/index.md","# Conditions which may affect the development of new likes and dislikes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-70546a505e8c428ea11573baec757b09}
There are many conditions which operate in the classroom to affect the
ratio of reinforcement to punishment experienced by individual students.
This is because there are many sources of reinforcement and punishment
in these settings.

It is a fact of classroom life that it is only possible to reduce
aversive consequences to a certain level in the classroom. It is never
possible to eliminate these entirely. There will always be some
misbehaviour which has to be attended to by the teacher. Students will
always make some errors which need to be corrected. Even with the best
teaching methods there will always be some learning tasks which are, by
their very nature, not all that interesting.

This means that in order to maintain an appropriate ratio of
reinforcement to punishment it is not sufficient simply to reduce the
frequency of occurrence of aversive consequences following misbehaviour,
errors, and mistakes. It is also necessary to increase the frequency of
occurrence of reinforcement for corrects, improvements and effort.

Most of the research into teacher reactions and student liking has been
descriptive research. Experimental studies which demonstrate a cause and
effect relationship between the ratio of positively reinforcing
consequences to punishing consequences in the classroom and the
development of student liking are almost non-existent. Clearly this is a
major shortcoming in the research into learning and teaching in the
classroom. In one of the few exceptions to this observation, Alschuler
(1968, cited by Gage and Berliner, 1988, p. 372-373), designed a maths
programme in which students took part in a \"game\" in which they
contracted to get a certain percentage of maths problems correct. The
higher the standard aimed for, the greater the rewards. Students also
lost points for incorrect answers, for not reaching their goals, for
revising their contracts and for late work. End of year prizes were
given to the students with the highest points totals.

Children who did nothing in mathematics in fourth grade, except under
duress, suddenly began taking their books home on weekends. Very few
deadlines were missed. Many students began assessing themselves more
optimistically, yet realistically, and they performed up to those
standards. One boy fidgeted through the entire year in mathematics in
fourth grade. Threats and stern words could not focus his attention, nor
could they keep him in his seat. His total output reflected a small
percentage of his ability. With the new structure, however, he chose his
first goal of 70 per cent with two weeks to finish his contract. Within
three days he revised his goal upward to 100 per cent, paid the extra
fee, and did all the problems with only 11 errors out of almost 400
problems. \... it was the teacher\'s impression that in the first half
of fifth grade, enthusiasm was generated more by the game than by
intrinsic interest in mathematics. However, by the second half of the
year, buoyed by new found competence, the game, prizes and play money
became more or less irrelevant while the pace of work continued.
Mathematics itself had become more interesting (Gage & Berliner, 1988).

While there is almost no scientific research into the relative
effectiveness of different ways of building and maintaining a liking for
specific classroom tasks and activities, it is easy to visualise the
kinds of variables which would need to be analysed in any such programme
of research.

**Level of task variety**

One of the major sources of biological reinforcement is a moderate level
of sensory stimulation. Sensory stimulation is a function of change in
the environment. When a child says \"I'm bored\" they are usually saying
\"I want to do something different.\" There are many ways in which
teachers can maintain adequate levels of variety, and hence sensory
stimulation, in the classroom. It is possible to make regular changes to
lesson content. Shorter lessons on each topic generate more variety than
longer lessons. It is possible to make regular changes to the type of
learning activity in which students are engaged. Moving backwards and
forwards between observation, prompted practice, independent practice,
and fluency building activities generates more variety than
concentrating on one type of outcome for long periods of time. It is
possible to make regular changes to the mode or method of instruction,
shifting backwards and forwards between whole class activities, small
group activities, peer practice, and individual work. It is possible to
make regular changes with respect to the learning tasks which are being
used to achieve particular teaching goals. For example, new knowledge
topics can be introduced in different ways, using video, class
discussion, individual and group research activities, and so on.
Practice can be provided in a variety of ways, using different kinds of
worksheets, games, peer practice, computer assisted instruction,
homework activities, and so on.

Given the importance of developing in students a liking for learning, it
is surprising to discover that almost no research has been undertaken
into the effects on student interest of these various ways of
maintaining adequate levels of sensory stimulation in the classroom.

There are other ways of introducing variety into classroom activities as
well. Gage & Berliner (1988, p. 384) suggest that teachers make use of
simulations and games. \"Games are fun, provide important learning
experiences, keep students highly involved, and involve the teacher in
the learning experience in new and enjoyable ways. . . . There are two
questions you should ask to help you decide whether a learning game is
effective . . . (a) Does the game increase and sustain attention? (b) Is
the student keenly involved in the game?\" (Gage & Berliner, 1988, p.
384).

Since the degree of variety which is necessary to sustain interest
cannot always be predicted with accuracy, the general rule for variety
is to continuously monitor student interest. If student interest and
attention is flagging, then this should be taken as an unambiguous sign
that it is time to change activities. From time to time this will mean
abandoning an activity which has not gone according to plan even before
it has been completed. Better an incomplete activity than an activity
which is conditioning a negative attitude.

Some classroom tasks are experienced as tedious by the great majority of
students. Included under this heading are writing tasks, spelling tasks,
and some fluency building tasks. \"One difficulty with teaching spelling
skills is that the tedious task of ordering letters to produce words
engenders a negative affect in students\" (Brown, 1990, p. 370). Clearly,
it is even more important to provide an adequate variety of different
learning tasks in areas which are by their nature rather tedious than it
is in content areas which are more interesting.

**Task relevance**

It is widely argued that students find learning tasks which they
perceive as relevant to their daily lives as more reinforcing than
learning tasks which are not perceived as relevant and that students are
more likely to develop a positive attitude towards a particular subject
or topic if instruction is framed in such a way that the relevance of
the topic is made apparent (Gage & Berliner, 1988). Given that this
belief is widespread, it comes as a surprise to discover than there
appears to be no controlled research on the effects of degree of
personal relevance on the development of student liking for a given
topic.

**Task length and response effort**

The practice activities which are required of the learner can vary from
those which involve a number of relatively short responses (such reading
words, practising spelling, or answering maths questions) to those which
involve relatively long responses such as writing a story or writing a
report. When given a choice, learners usually express a liking for or a
preference for practice activities which require less time and effort to
complete (Cates & Skinner, 2000; Logan & Skinner, 1998; Wildmon,
Skinner, McCurdy & Sims, 1999). This preference has also been
demonstrated in a series of half a dozen controlled experiments
involving university students (Cates, 2005). The effect is so consistent
that students will choose a homework assignment which consists of a
mixture of shorter and longer problems over a assignment which contains
only longer problems even when the mixed assignment contains a larger
number of problems to complete (Wildmon et al., 1999).

The results of these experiments are consistent with the view that a
liking for depends upon the ratio of reinforcement to non-reinforcement
in practice tasks. Practice tasks which consist of a mixture of shorter
and longer practice responses and which produce a greater density of
reinforcement (in the form of items completed and items correct) produce
a greater level of liking for (and are selected in preference to)
practice tasks which involve longer responses or responses which greater
effort.

There are a number of ways in which teachers can manage the level of
response effort which is required to complete practice activities so
that students' liking for those activities is maintained. The teacher
can construct practice activities which require a mixture of short
responses and longer responses, or which require a mixture of easier and
more difficult items, or a mixture of previously practised and
relatively new responses, or a mixture of oral responses and written
responses (Skinner, Wallace & Neddenriep, 2002). These interspersal
practice activities allow the teacher to manage the difficulty level of
classroom activities while at the same time ensuring that students are
continually learning and practising new and more complex skills.

**Ratio of success to failure on particular learning tasks**

A major source of reinforcement in the classroom is success (or more
correctly the feedback which tells us that we have been successful) and
this is recognised by most teachers and parents. What is less well
understood is that error feedback is experienced by the great majority
of children as aversive. That this is so is shown by the fact that most
children try hard to respond correctly and to avoid errors and, if
unsure what to do, will often do nothing rather than risk making a
mistake. In technical terms, feedback which tells the learner that she
or he has responded incorrectly is one of the most common forms of
classroom punishment (using the word punishment in its technical sense).
Feedback which tells us that we have done right, done well, or done
better than before acquires reinforcing properties (and hence the power
to elicit good feelings) at quite an early age.

Classroom tasks may vary from very easy through moderately difficult to
very difficult. Easy tasks are ones in which almost all learner
responses are correct. Moderately difficult tasks are those in which 80
to 90 per cent of learner responses are correct. Difficult tasks are
those in which less than two thirds of student responses are correct.

Practical experience suggests that the classroom tasks which provide the
most reinforcement are those tasks which constitute a \"reasonable
challenge\" to the learner. A reasonably challenging task is one which
the student can complete with a little effort (and/or a little help) but
which he or she cannot complete without that effort. Margaret Clifford
(1990) makes the point that, when given the choice, younger learners
show a distinct preference for tasks which are just a little bit above
their current level of ability. If the majority of classroom tasks are
too simple or too easy, the learner quickly becomes bored and a dislike
for classroom tasks may develop. Note that \"too simple\" includes tasks
which have been designed for younger learners. \"We attribute the success
we experience on easy tasks to task ease; we attribute the success we
experience on extremely difficult tasks to luck. Neither type of success
does much to enhance self-image. It is only success at moderately
difficult or truly challenging tasks that we explain in terms of
personal effort .. and these explanations give rise to feelings of
pride, competence, determination, satisfaction, persistence and personal
control\" (Clifford, 1990, p. 22).

Tasks which are too difficult for the learner to complete (or to
complete to the expected standard) also generate little or no
reinforcement for the learner. Worse still, they may generate feelings
of frustration and misbehaviour (Center, Deitz & Kaufman, 1982). If the
student experiences too many tasks which are too difficult, a dislike
for these tasks may develop.

This suggests that a liking for, say, maths is more likely to develop in
students whose experience consists largely of learning tasks of moderate
difficulty, that is learning tasks which provide a reasonable challenge.
Very difficult learning tasks should be used only occasionally so that
any feelings of frustration which they generate do not become
conditioned to mathematics tasks in general. Likewise, very simple
learning tasks should be used only occasionally so that any feelings of
boredom which they generate do not become conditioned to mathematics
activities.

This analysis further suggests that the practice tasks engaged in by
individual learners should be adjusted until they are resulting in at
least four times as many correct responses as incorrect responses. This
can be accomplished by monitoring the accuracy rates of individual
students on practice tasks and by adjusting the interspersal ratio (the
ratio of previously acquired and yet-to-be-acquired responses) so that
the 80% success rate is maintained over time. Student preference (i.e.
liking for) practice activities which include easy items as well as
difficult items has been demonstrated with a variety of different kinds
of learning activities.

In the classroom setting, a learning task which is the right level of
difficulty for one student will be too easy for some and too difficult
for others. Practical ways of solving this problem represent a major
challenge to teachers and to teaching researchers.

**Ratio of positive to negative social reactions**

Another major source of reinforcement and punishment in the classroom is
social - the reactions of teachers and other students to appropriate and
inappropriate classroom behaviour, to improvements, and to correct and
incorrect responses on learning tasks. Experience suggests that teachers
who are consistently positive and enthusiastic (in a genuine way) tend
to be liked by students while teachers who are consistently negative and
\"crabby\" tend to be disliked by students. Furthermore, a negative
attitude towards the teacher may generalise from the teacher to the
classroom situation in general.

A number of observational studies (Beaman & Wheldall, 2000) have found
that teachers tend to comment in a disapproving way as often as they
comment in an approving way. White (1975) observed a sample of 100 U.S.
teachers. The Grade 1 teachers reacted positively to student behaviour
at a rate of .66 approvals per minute and reacted negatively at almost
the same rate on average (a rate of .63 disapprovals per minute). The
mean approval and disapproval rates for the Grade 3 teachers were .38
and .47 per minute and the rates for the Grade 4 teachers were .32 and
.64. Wyatt and Hawkins (1987) observed 35 U.S. teachers. The Grade 1
teachers used positive reactions at a rate of .58 per minute and
negative reactions at a rate of .52 per minute. Rossiter (1982) observed
a sample of 11 N.Z. junior school teachers and found approval and
disapproval rates of .62 and .73 per minute, respectively. In the
Rossiter study, individual teachers varied from one teacher who approved
only 15% of the behaviours to which she reacted to one teacher whose
reactions were 90% positive.

Not only do teachers have difficulty in being positive, they also have
difficulty in reacting positively to all students. Several studies
(e.g., Parker, Larsen & Roberts, 1981; Raber & Weisz, 1981) have shown
that teachers tend to direct fewer positive comments to low achieving
children than to high achieving children. Allington (1980) found that
teachers tended to interrupt low progress readers more often, to provide
these learners with fewer opportunities to self-correct, and to correct
these students more often. Other studies have observed teachers praising
children with intellectual disabilities *more* often than their
non-handicapped peers (e.g., Brady & Taylor, 1989; Rietveld, 1986,
1989).

In a teacher training study, Dennis Rose found that some teacher
trainees were able to achieve approval to disapproval ratios of 3:1 with
almost no training, some were able to achieve 3:1 ratios after about
eight sessions of supervised practice and some were unable to achieve a
3:1 ratio even with extensive supervised practice (Rose, 1994). This
research suggests that it is not sufficient simply to advise teachers
that they should focus upon and comment upon the behaviour that they
want rather than the behaviour which they do not want. The research
suggests that the goal of responding in a primarily positive fashion to
the behaviour to students in the classroom is a goal which many teachers
find difficult to achieve (Rose, 1994; Rossiter, 1982).
:::

::: referencesList
#### References

-   Allington, R. L. (1980). Teacher interruption behavior during
    primary-grade oral reading. Journal of Educational Psychology, 72,
    371-377.
-   Beaman, R., & Wheldall, K. (2000). Teachers\' use of approval and
    disapproval in the classroom, Educational Psychology, 20, 431-446.
-   Brady, M. P., & Taylor, R. D. (1989). Instructional consequences in
    mainstreamed middle school classes: Reinforcement and corrections.
    Remedial and Special Education, 10(2), 31-36.
-   Brown, A. S. (1990). A review of recent research on spelling.
    Educational Psychology Review, 2, 365-397.
-   Cates, G. L. (2005). A review of the effects of interspersing
    procedures on the stages of academic skill development. Journal of
    Behavioral Education, 14, 305-325.
-   Cates, G. L., & Skinner, C. H. (2000). Getting remedial mathematics
    students to prefer homework with 20% and 40% more problems: An
    investigation of the strength of the interspersing procedure.
    Psychology in the Schools, 37, 339-347.
-   Center, D. B., Deitz, S. M., & Kaufman, M. E. (1982). Student
    ability, task difficulty, and inappropriate classroom behavior: A
    study of children with behavior disorders. Behavior Modification, 6,
    355-374.
-   Clifford, M. M. (1990). Students need challenge, not easy success.
    Educational Leadership, 48(1), 22-26.
-   Gage, N. L., & Berliner, D. C. (1988). Educational psychology (4th
    ed.). Boston: Houghton Mifflin Co.
-   Logan, P., & Skinner, C. H. (1998). Improving students' perceptions
    of mathematics assignment by increasing problem completion rates: Is
    problem completion a reinforcing event? School Psychology Quarterly,
    13, 322-331.
-   Parker, R., Larsen, S., & Roberts, T. (1981). Teacher-child
    interactions of first-grade students who have learning problems. The
    Elementary School Journal, 81, 163-171.
-   Raber, S. M., & Weisz, J. R. (1981). Teacher feedback to mentally
    retarded and non-retarded children. American Journal of Mental
    Deficiency, 86, 148-156.
-   Rietveld, C. M. (1986). The adjustment to school of eight children
    with Down\'s Syndrome from an early intervention programme.
    Australia and New Zealand Journal of Developmental Disabilities, 12,
    159-175.
-   Rietveld, C. M. (1989). An evaluation of 7- to 12-year old children
    with Down\'s Syndrome in home and school settings: A follow-up study
    of children from the Christchurch Early Intervention Programme.
    Research Report No. 89-1. Christchurch, N.Z.: University of
    Canterbury, Education Department.
-   Rose, D.J. (1994). The effect of practice on the acquisition and
    maintenance of teaching skills. Unpublished PhD thesis.
    Christchurch, N.Z.: University of Canterbury, Education Department.
-   Rossiter, A. (1982). The difficult to teach junior school pupil:
    Identification and teaching strategies. Research Report No 82-1.
    University of Canterbury, Education Department.
-   Skinner, C. H., Wallace, M. A., & Neddenriep, C. E., (2002).
    Academic remediation: Educational applications of research on
    assignment preference and choice. Child & Family Behavior therapy,
    23, 51-65.
-   White, M. A. (1975). Natural rates of teacher approval and
    disapproval in the classroom. Journal of Applied Behavior Analysis,
    8, 367-372.
-   Wildmon, M. E., Skinner, C. H., McCurdy, M., & Sims, S. (1999).
    Improving secondary students' perception of the \"dreaded mathematics
    word problem assignment\" by giving them more word problems.
    Psychology in the Schools, 36, 319-325.
-   Wyatt, W. J., & Hawkins, R. P. (1987). Rates of teachers\' verbal
    approval and disapproval. Behavior Modification, 11, 27-51.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howlikesanddislikesdevelop/Conditionsnecessaryforthedevelopmentofalikingfor/index.md","# Conditions necessary for the development of a liking for \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2a0f0c14ff4f40feb9196d4aaa1d2d97}
What must the teacher do to ensure that the learner develops a liking
for a particular class of learning activities such as reading? In spite
of its importance, the question has prompted almost no controlled
experimental research.

However the answer to the question may be inferred from our
understanding of how likes and dislikes develop. It seems likely that,
*in order to develop a liking* *for a particular class of learning
activities, the learner's experiences with that activity must be ones in
which reinforcing outcomes are much more frequent than punishing
outcomes*.

Unfortunately, because the research has yet to be undertaken, we do not
yet know the ratio of reinforcing to punishing outcomes which are
necessary for (a) the development of a liking for and (b) the
development of a dislike. Various authorities have estimated that, in
order to develop a liking for a particular type of activity (such as
reading) the learner must experience (during study and practice)
somewhere between three times as many to five times as many reinforcing
outcomes as aversive outcomes.

Assuming this to be the case, the implications for parents and teachers
are profound because they will apply to every single facet of the
learner's interactions with his or her environment.

1.If a teacher wants to ensure that her students like her, she must
ensure that her interactions with students are predominantly positive
interactions and she must apply this rule equally to all students
including those whom she finds least engaging and least attractive.

2.If a teacher wants his students to develop a liking for a particular
subject, the teacher must ensure that student experiences while working
on that subject are predominantly reinforcing (successful) and he must
apply this rule equally to all students including those who are making
the least progress in that subject.

3.If teachers want their students to develop a liking for school in
general, they must ensure that their management procedures and their
disciplinary procedures involve, predominantly, reinforcement for
appropriate behaviour (rather than punishment for misbehaviour) and they
must apply this rule equally to all students including the most poorly
behaved.

4.If a teacher wants her students to develop a love of learning, she
must ensure that students experience predominantly reinforcing outcomes
(success) in all subjects including those which students generally
experience as tedious and difficult.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howlikesanddislikesdevelop/index.md","# How likes and dislikes develop \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d0ed8a17884547a89bb7876d44120dd9}
It has been known for more than 80 years that likes and dislikes also
arise as a result of respondent conditioning (Keller & Schoenfeld, 1950;
Staats & Staats, 1958; Watson & Rayner, 1920). The emotional responses
which are affected by respondent conditioning include both the positive
emotional reactions (such as elation) and the negative emotional
reactions (such as anxiety) which we experience, without thinking, as we
interact with the world around us. All emotional responses are
respondents. The stimulus situations which elicit positive emotional
reactions are commonly referred to as situations which we *like* and the
stimulus situations which elicit negative emotional reactions are
commonly referred to as situations which we *dislike* (or fear or hate).

At any particular point in the life of the learner, there are some
stimulus events which elicit positive and negative emotional responses
in the learner and other stimulus events which elicit no emotional
response in the learner. Stimulus events which already elicit an
emotional response in the learner are referred to as *unconditioned
eliciting stimuli* for that emotional response. As a result of
experimental analyses of respondent conditioning we now know that
stimulus events which initially elicit no emotional reaction in the
learner can acquire the power to do so if they regularly occur in
association with stimulus events which do already elicit an emotional
reaction (Watson & Rayner, 1920). In technical terms we say that neutral
stimuli which occur in association with unconditioned eliciting stimuli
acquire the emotion-eliciting properties of the unconditioned eliciting
stimulus (Baldwin & Baldwin, 1986).

The respondent conditioning process explains how it is that likes and
dislikes develop. Stimulus events which regularly occur in association
with those events which already elicit positive emotional reactions
(good feelings) will also acquire the power to elicit positive emotional
reactions. New stimuli can acquire the power to elicit negative
emotional reactions (bad feelings) in exactly the same manner. There is
one class of events which reliably elicits good feelings and that is the
class of events known as *reinforcing events* (reinforcers). Everyone is
attracted to the events which function as reinforcers for them.
Extending the analysis, we can see that stimuli which reliably occur in
association with reinforcement will tend to become conditioned eliciting
stimuli for good feelings (that is, they will come to be liked).

There is also a class of events which reliably elicit bad feelings and
that is the class of events which we refer to as *aversive events*
(punishers). Everyone tries to avoid the events which function as
aversive events (punishers) for them. Stimulus events which reliably
occur in association with punishment tend to become conditioned
eliciting stimulus for bad feelings (such as embarrassment, anxiety, or
fear). They also become stimulus events which we come to dislike.

In short, likes and dislikes are the result of histories of positive and
negative experiences. It is this history of experiences which operates
to determine the degree of liking (or disliking) which the student has
for different types of learning tasks for different subject matter
content, for teachers, and for school in general.

The way in which school experiences shape the child's likes and dislikes
for school type activities is essential knowledge for all teachers and
teacher educators. Children arrive at school with an interest in almost
all learning activities. Some experience a series of educational
environments and experiences in which this interest is fostered and
developed with the result that the child develops a lifelong interest in
learning. Other children experience a series of educational environments
and experiences in which interest (that is, a liking for) is gradually
eroded. A loss of interest in science or maths or reading can have
disastrous consequences for the child. As children proceed through the
school system, they are expected to take an increasing amount of
responsibility for their own learning and to engage in increasing
amounts of self-directed study and self-directed practice. If the
learner loses interest in classroom activities, this self-directed
learning may not develop. As the student falls further and further
behind, they may develop an increasing dislike for school in general -
seeking only to escape from school as soon as it becomes possible to do
so. The consequences of developing a dislike for school have been
described by Margaret Clifford:

Hundreds of thousands of apathetic students abandon their schools each
year to begin lives of unemployment, poverty, crime, and psychological
distress. \... The term *dropout* may not be adequate to convey the
disastrous consequences of the abandonment of school by children and
adolescents; *educational suicide* may be a far more appropriate label.
\... We must acknowledge that educational suicide is primarily a
motivational problem - not a physical, intellectual, financial,
technological, cultural, or staffing problem. Thus we must turn to
motivational \... research as a foundation for examining this problem
and for identifying solutions (Clifford, 1990, p. 22).

It can be seen, therefore, that the ability to engender an interest in
(that is, a liking for) academic activities is an essential teaching
skill. This makes an understanding of how likes and dislikes develop an
item of essential knowledge for teachers at all levels.
:::

::: referencesList
#### References

-   Baldwin, J.D. & Baldwin, J.I. (1986). Behavior principles in
    everyday life (2nd ed.). Englewood Cliffs, NJ: Prentice Hall.
-   Clifford, M. M. (1990). Students need challenge, not easy success.
    Educational Leadership, 48(1), 22-26.
-   Keller, F. S., & Schoenfeld, W. N. (1950). Principles of psychology.
    New York: Appleton.
-   Staats, A. W., & Staats, C. K. (1958). Attitudes established by
    classical conditioning. Journal of Abnormal Social Psychology, 61,
    211-223.
-   Watson, J. B., & Rayner, R. (1920). Conditioned emotional reactions,
    Journal of Experimental Psychology, 3, 1-14.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howfearsandanxietiesarelearnedandunlearned/Conditionsnecessaryfortheacquisitionofanewanxietyfearresponse/index.md","# Conditions necessary for the acquisition of a new anxiety/fear response \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a64d90b68c564e84a30009660e50983d}
The only condition which has been demonstrated to be necessary for the
acquisition of a conditioned anxiety or fear response (both realistic
and unrealistic) is the repeated contiguous occurrence of the
conditioned eliciting stimulus (which already elicits the anxiety or
fear response) and the unconditioned eliciting stimulus, that is, the
stimulus or event which initially has no anxiety eliciting properties
but which subsequently acquires such properties (Davey, 1997; Vasey &
Dadds, 2001; Watson & Rayner, 1920). There may well be other necessary
conditions, such as the form or intensity of the anxiety elicited during
the experience in which the conditioning occurred, but the effects of
variables such as these have yet to be measured.
:::

::: referencesList
#### References

-   Davey, G. C. L. (Ed.) (1997). Phobias: A handbook of theory,
    research and treatment. Chichester, UK: John Wiley & Sons.
-   Vasey, M. W., & Dadds, M. R. (Eds.). (2001). The developmental
    psychopathology of anxiety. New York: Oxford University Press.
-   Watson, J. B., & Rayner, R. (1920). Conditioned emotional reactions,
    Journal of Experimental Psychology, 3, 1-14.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howfearsandanxietiesarelearnedandunlearned/Conditionswhichmayaffecttheextinctionofaconditionedfearanxietyresponse/index.md","# Conditions which may affect the extinction of a conditioned fear/anxiety response \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b9544f369a15463da352281218d900a5}
In order for a dysfunctional anxiety reaction to extinguish, we have to
arrange for repeated exposure to the anxiety eliciting situation or
situations. However, this is not easy because whenever an unrealistic
fear is acquired, a number of avoidance responses are always acquired at
the same time. It is these avoidance responses which prevent extinction
from occurring naturally. Furthermore, the avoidance responses may be
quite well practised and may well be occurring without much conscious
thought. This makes treatment of the phobia difficult. It may be quite
difficult to persuade someone who is scared of dogs, or school, or maths
to put themselves in a situation where they have repeatedly to approach
the very thing that they are scared of. \"Avoidance behaviour is critical
in therapy because as long as one can successfully avoid an
anxiety-eliciting situation, there is no opportunity for the extinction
of conditioned anxiety to occur. Someone who has acquired a fear of
riding in elevators/lifts usually will not enter one. While this
prevents fear arousal it also prevents its extinction\" (Reese, 1978, p.
185).

The relative effectiveness of different procedures for extinguishing
unrealistic fears and anxieties is a topic which has been the subject of
considerable research (e.g. Misra & Schloss, 1989; Ollendick & King,
1998). The most effective and commonly used respondent extinction
procedure is *systematic desensitisation*. A desensitisation programme
has three elements:

1\. Repeated exposure to the anxiety eliciting stimulus or situation

2\. A graded series of exposures from the least to the most fearful
stimulus situation

3\. Strong reinforcement for approach responses, that is, strong
reinforcement for continued practice in the face of the anxiety
eliciting stimulus or situation.

The extinction of a dysfunctional anxiety reaction may be undertaken
either in vivo or imaginally. In vivo desensitization involves repeated
exposure to real life examples of the feared situations/stimuli in the
absence of any actual danger. With in vivo exposure, extinction proceeds
more rapidly than it does with imaginal desensitization. However, there
are certain fearsome situations (such as flying) which cannot be cheaply
and easily reproduced for the purposes of desensitization.

Imaginal desensitization involves the repeated bringing to mind of the
feared situations/ stimuli. This procedure may be used to good effect
with older children who have a good imagination but cannot be used with
younger children who have difficulty imagining themselves in the feared
situation.

In addition, the treatment of dysfunctional anxiety reactions almost
always involves an additional element designed to control or manage
avoidance responses. The most commonly used procedures for managing
avoidance responses are (a) the use of graduated exposure, (b) prompting
the fearful child to engage in a response which is incompatible with
feeling anxious or (c) the reinforcement of approach responses.

1\. *Graduated exposure.* Graduated exposure involves the gradual
exposure to a sequence of fearful situations or a sequence of fearful
visualisations graded from least to most fearsome. Repeated exposure is
necessary in order to extinguish the conditioned emotion eliciting
properties of the feared stimulus or situation and graduated exposure
allows the learner to experience success from the outset by making each
step small and easy to achieve. Stableford (1979), for example,
extinguished a fear of loud noises in a 3-year old girl who had
developed a fear of loud noises by introducing the noises, first at a
distance and then at distances which were increasingly closer to the
child. Luiselli (1978) cured a child\'s fear of riding in a school bus
by gradually increasing the time spent sitting, first in a stationary
bus, and then while travelling in a bus. Menzies and Clarke (1993) cured
a number of cases of swimming pool phobia by moving fearful children
progressively closer to the pool and then further and further into the
water.

The steps to be achieved during a programme of graduated exposure are
often referred to as a *fear hierarchy.* Let us say, for example, that
earlier experiences have resulted in a child who feels so anxious when
asked to speak in front of the class that they are unable to do so. The
development of a desensitisation programme to help the child overcome
this fear would begin with the construction of a fear hierarchy which
lists the anxiety producing situations in a graded order from the least
to the most anxiety provoking. The task of getting the anxiety provoking
situations in graded order is accomplished by asking the child to put
the feared situations in order from \"easiest\" to \"most difficult\". The
fear hierarchy might look something like this:

1.Reading to the teacher alone

2.Reading to two other students alone

3.Reading to a group of six students

4.Reading to a group of 12 students

5.Reading to the whole class

6.Describing a recent experience to the teacher alone

7.Describing a recent experience to two other students alone

8.Describing a recent experience to a group of six students

9.Describing a recent experience to a group of 12 students

10.Describing a recent experience to the whole class

Desensitisation begins with practice at the first step. In our
illustrative example, the child would be provided with opportunities to
read to the teacher and would receive strong social or tangible
reinforcement for doing so. When the child can do this without anxiety,
the child moves on to practise at the second step. If each step in the
hierarchy involves a relatively small increase in \"difficulty\", the
fearful student should be able to move from one step to the next after
about two to four experiences at each step. Gradually the child works
his or her way up the hierarchy until, in this case, the child can talk
in front of the entire class without experiencing disabling levels of
anxiety.

2\. *Engaging in an incompatible response.* Having the child engage in
behaviour which is incompatible with anxiety can also reduce avoidance
responding. The most commonly used incompatible behaviour is deep muscle
relaxation but other incompatible behaviours such as strenuous activity,
or enjoyable activities, can also be used to good effect (e.g. Croghan &
Musante, 1975).

3\. *Reinforcing approach responses.* The most commonly used procedure
for controlling avoidance responses is to provide strong reinforcement
for approach responses. Reinforcement may be made contingent upon each
step which the child takes towards the feared situation, or it may be
made contingent on approaches to increasingly fearsome situations, or it
may be made contingent upon engaging in those behaviours which the child
has been avoiding (e.g. Luiselli, 1978). Reinforcement for approach
responses provides the motivation for the learner to continue with the
programme even although he/or she continues to experience some anxiety
at each new step. Reinforcers must be sufficiently powerful to outweigh
the effects of the anxiety produced by approach behaviours if they are
to have any effect in strengthening approach responses.

The effectiveness of systematic desensitization procedures in the
treatment of specific phobias has been known since the 1950s (Wolpe,
1958). Joseph Wolpe's first book (Wolpe, 1958) described the results of
his treatment of 249 patients and reported a 98 per cent success rate
with only a 2 per cent relapse rate.

Research into the treatment of anxiety reactions indicates that almost
all of the simpler fears can be effectively treated using the
desensitisation procedure (Davey, 1997; Vasey & Dadds, 2001). Generally
speaking, a set of 20 to 40 graded practice sessions is all that is
required to assist someone to overcome a simple fear such as a fear of a
specific setting or task.
:::

::: referencesList
#### References

-   Croghan, L., & Musante, G. R. (1975). The elimination of a boy\'s
    high-building phobia by in vivo desensitization and game playing.
    Journal of Behavior Therapy and Experimental Psychiatry, 6, 87-88.
-   Davey, G. C. L. (Ed.) (1997). Phobias: A handbook of theory,
    research and treatment. Chichester, UK: John Wiley & Sons.
-   Luiselli, J. K. (1978). Treatment of an autistic child\'s fear of
    riding a school bus through exposure and reinforcement. Journal of
    Behavior Therapy and Experimental Psychology, 9, 169-172.
-   Menzies, R. G., & Clarke, J. C. (1993). A comparison of in vivo and
    vicarious exposure in the treatment of childhood water phobia.
    Behaviour Research and Therapy, 31, 9-15.
-   Misra, A., & Schloss, P. J. (1989). Respondent techniques for
    reduction of emotions limiting school adjustment: A quantitative
    review and methodological critique. Education and Treatment of
    Children, 12, 174-189
-   Ollendick, T. H., & King, N. J. (1998). Empirically supported
    treatments for children with phobic and anxiety disorders: Current
    status. Journal of Clinical Child Psychology, 27, 156-167.
-   Reese, E. P. (1978). Human operant behavior: Analysis and
    application (2nd Ed.). Dubuque, IA: Wm. C. Brown.
-   Stableford, W. (1979). Parental treatment of a child\'s noise
    phobia. Journal of Behavior Therapy and Experimental Psychiatry, 10,
    159-160.
-   Van Hasselt, V. B., Hersen, M., Bellack, A. S., Rosenblaum, N. D., &
    Lamparski, D. (1979). Tripartite assessment of the effects of
    systematic desensitization in a multi-phobic child: An experimental
    analysis. Journal of Behavior Therapy and Experimental Psychiatry,
    10, 51-55.
-   Vasey, M. W., & Dadds, M. R. (Eds.). (2001). The developmental
    psychopathology of anxiety. New York: Oxford University Press.
-   Watson, J. B., & Rayner, R. (1920). Conditioned emotional reactions.
    Journal of Experimental Psychology, 3, 1-14.
-   Wolpe, J. (1958). Psychotherapy by reciprocal inhibition. Stanford,
    CA: Stanford University Press.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howfearsandanxietiesarelearnedandunlearned/index.md","# How fears and anxieties are learned and unlearned \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-080d191662514d6a92d5d36297c4c556}
Respondent conditioning is also the learning process whereby new fears
and anxieties are acquired -- both those which are realistic and those
which are unrealistic. There are, for each of us, a set of events which
we strive to avoid. These are the events which elicit in us feelings of
anxiety and fear. When these events occur as a consequence of our
actions we refer to them as punishing consequences or aversive
consequences. These aversive events may also occur in respondent
conditioning trials where they are referred to as *unconditioned
aversive events*. Stimulus events which reliably occur in association
with punishment (that is, in association with unconditioned aversive
events) tend to become conditioned eliciting stimuli for an anxiety,
fear, or panic response similar to that elicited by the unconditioned
aversive event.

The following (hypothetical) example of how a young child might come to
fear a teacher (or parent) illustrates this process.

![Figure 4130. Sequence of events involved in a young child acquiring a
fear of a new teacher as a result of experiences with that
teacher.](../../../../../assets/images/Figure4130.png \"Figure 4130. Sequence of events involved in a young child acquiring a fear of a new teacher as a result of experiences with that teacher.\"){.image-inline}

*Figure 4130. Sequence of events involved in a young child acquiring a
fear of a new teacher as a result of experiences with that teacher.*

It is important to remember that emotional reactions such as anxiety and
fear may be functional or they may be dysfunctional. The child who
avoids large and ferocious looking dogs would not be said to have a
\"problem\". On the contrary, he probably would be commended for his
prudence. There is nothing dysfunctional about an anxiety reaction and
its associated avoidance response to large and ferocious looking dogs.
However, a child who avoided *all* dogs no matter how harmless might be
said to have acquired an unrealistic fear. The same is true in the
classroom. A child who experiences mild anxiety when corrected by a
teacher is experiencing a feeling which almost all children experience.
A child who lives in dread of being corrected by their teacher has a
problem (as does the teacher).

Note that it is not the anxiety which is dysfunctional. Anxiety is a
normal human reaction to dangerous or threatening situations. What is
dysfunctional is the fact that the teacher (in this particular case) has
become a conditioned eliciting stimulus for anxiety, that is, has
acquired the power invariably to trigger anxiety in this particular
child.

Because all teachers, from time to time, come across students who are
overly anxious or fearful in certain classroom situations a knowledge of
how unrealistic fears are acquired (and how that can be unlearned) is
essential knowledge for all classroom teachers. This is because
excessive anxiety can block the performance of highly desirable
behaviours. The child who regularly fails to participate in class may be
failing to participate because the act of speaking in front of others
elicits excessive levels of anxiety. In addition, excessive anxiety can
reinforce and maintain escape and avoidance responses which interfere
with other highly desirable responses. The classic case is the school
phobic child - the child for whom school has become so anxiety provoking
that she simply avoids school altogether.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howfearsandanxietiesarelearnedandunlearned/Conditionsnecessaryfortheextinctionofconditionedanxietyfearresponses/index.md","# Conditions necessary for the extinction of conditioned anxiety/fear responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b003776868fd43fab1be3eabf35510fc}
From time to time learners arrive in the classroom with anxiety
responses or fears which have already been conditioned to certain
learning tasks, or with well developed negative attitudes to school, to
teachers, or to certain learning tasks as a result of past experiences.
For example, a child may have developed a fear of reading activities as
a result of a prior history of failure in reading, or a child may have
developed a school phobia because of a previous history of bullying at
school, or a child may have developed a strong dislike for teachers or
schools because of a past history of punishment for misbehaviour in this
setting.

Because dysfunctional anxiety reactions to certain situations are
acquired (learned) they can be unlearned. The unlearning of a
dysfunctional anxiety response is referred to as *respondent
extinction*. The student who brings a previously conditioned anxiety
response or fear response to the classroom requires a special kind of
teaching programme - one which will break the link between the
conditioned eliciting stimulus and the emotional response which the
stimulus elicits. For example, the student who feels anxious when asked
to read requires a teaching programme which breaks the link between
books (the conditioned eliciting stimulus) and feelings of anxiety (the
emotional response which the books elicit). Programmes which function to
extinguish previously acquired anxieties and fears are referred to as
*respondent extinction* programmes.

The only essential condition which must be met in order for respondent
extinction to occur is repeated exposure to the conditioned anxiety
eliciting stimulus under circumstances in which the real fear eliciting
stimulus never occurs. When the learner is exposed repeatedly to an
anxiety eliciting stimulus without any aversive consequence, then that
stimulus gradually loses the power to elicit anxiety (e.g. Croghan &
Musante, 1975; Luiselli, 1978; Stableford, 1979; Van Hasselt, Hersen,
Bellack, Rosenblum & Lamparski, 1979).
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/Howfearsandanxietiesarelearnedandunlearned/Conditionswhichmayaffecttheacquisitionofnewfearanxietyresponses/index.md","# Conditions which may affect the acquisition of new fear/anxiety responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c554695770c345d18db4a0336588fe25}
There will be a number of conditions which affect the speed with which
particular conditioned anxiety reactions are acquired by individual
learners. For example, it is usually argued that a particularly
traumatic experience can establish a conditioned fear response to the
situation in which the trauma occurred as a result of a single
experience.

Respondent conditioning is most likely to occur in situations where the
neutral stimulus occurs *just before* the unconditioned eliciting
stimulus, signalling to the learner that the unconditioned eliciting
stimulus is about to occur. Respondent conditioning occurs most rapidly
in situations where the neutral stimulus *regularly precedes* the
unconditioned eliciting stimulus, that is, in situations where the
learner can reliably predict that the unconditioned eliciting stimulus
may follow. It is to be expected that this will also be the case during
the acquisition of conditioned anxiety and fear responses.

However, apart from a few demonstration experiments (e.g. Watson &
Rayner, 1920), research into the conditions which govern the rate of
acquisition of unrealistic fears is fairly minimal. This is because it
is not possible to get Human Ethics approval for programmes of research
which involve frightening children out of their wits in order to see
whether different kinds of frightening experiences have different
effects on the rate of acquisition of unrealistic fears.
:::"
".//Theconditionsuponwhichlearningdepends/Respondentprocesses/index.md","# Respondent processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ffa2dd76774c4dbca36d6ddc1d3a8fea}
The scientific research into learning has involved the study of a number
of different learning processes. One of the earliest lines of
investigation was investigation into a learning process which has come
to be known as *respondent conditioning*. Respondent conditioning is
also referred to as *classical conditioning* (because it was the first
learning process to be systematically studied) and as *Pavlovian
conditioning* (because it was first studied by the Russian physiologist
Ivan Pavlov).

Respondent conditioning has turned out to be an extremely important
learning process because it is the learning process whereby we acquire
an understanding of the *meaning* of words, phrases, objects, events,
and so on. It is also the process whereby anxieties and fears, likes and
dislikes, attitudes and feelings are acquired. So this makes it a
particularly important learning process as far as classroom practice is
concerned, and one which needs to be understood by teachers at all
levels.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewequivalencerelationsareacquired/Necessarycondition1Promptingofthecorrectresponses/index.md","# Necessary condition 1. Prompting of the correct responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8867fe6d01c545f895b25fc9038d5de0}
The child who is asked to name the letter w, or to read the word worst,
or to name the element referred to by the symbol Fe for the very first
time will not be able to respond correctly because they will not know
what the correct response is supposed to be. This observation reminds us
that, if the stimulus is new, then initial attempts to respond will need
to be prompted in some way.

-   New reading responses may be prompted by the context in which the
    word appears or by telling the learner what the word is (Espin &
    Deno, 1989; Keel & Gast, 1992). As the learner becomes more
    competent, new reading responses may be self-prompted by the learner
    \"sounding out the word\" (provided that the necessary
    grapheme-\>phoneme equivalence relations have been acquired).
-   The correct answer to a new maths fact may be prompted by telling
    the student the answer or by teaching the student a rule whereby
    they can work out the answer for themselves (e.g. by counting up for
    single digit addition).
-   The correct spelling of a new word may be prompted by allowing the
    student, initially, to copy the correct spelling of the word (e.g.
    Telecsan, Slaton & Stevens, 1999) or by providing a phonetic
    pronunciation of the word (provided that the necessary phoneme--\>
    grapheme equivalence relations have been acquired).
-   Sometimes the correct response can be prompted by providing a table
    of equivalence relations for the learner to refer to (e.g. a matrix
    of products for single digit multiplication facts, or a list which
    shows the chemical symbols which are used to represent each of the
    elements).

Once the learner begins to respond correctly to a particular stimulus,
prompting of the response to that stimulus should cease so that the
practice of independent responding can begin (Espin & Deno, 1989;
Hendrickson, Roberts & Shores, 1978; Johnson, Schuster & Bell, 1996;
Keel & Gast, 1992).
:::

::: referencesList
#### References

-   Espin, C. A., & Deno, S. L. (1989). The effects of modelling and
    prompting feedback strategies on sight word reading of students
    labelled learning disabled. Education and Treatment of Children, 12,
    219-231.
-   Hendrickson, J., Roberts, M., & Shores, R. E. (1978). Antecedent and
    contingent modeling to teach basic sight word vocabulary to learning
    disabled children. Journal of Learning Disabilities, 11, 524-528.
-   Johnson, P., Schuster, J., & Bell, J.K. (1996). Comparison of
    simultaneous prompting with and without error correction in teaching
    science vocabulary words to high school students with mild
    disabilities. Journal of Behavioral Education, 6, 437-458.
-   Keel, M. C., & Gast, D. L. (1992). Small group instruction for
    students with learning disabilities: Observational and incidental
    learning. Exceptional Children, 58, 357-368.
-   Telecsan, B. L., Slaton, D. B., & Stevens, K. B. (1999). Peer
    tutoring: Teaching students with learning disabilities to deliver
    time delay instruction. Journal of Behavioral Education, 9, 133-154.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewequivalencerelationsareacquired/Necessarycondition2Theopportunitytoengageindiscriminationpractice/index.md","# Necessary condition 2: The opportunity to engage in discrimination practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8981b223af57493b8d86a26d623df229}
The great majority of the equivalence relations taught in schools come
in sets: for example the 52 letters, the 43 English phonemes, the 300
words which occur most frequently in written English, the 100 single
digit multiplication facts, and so on.

In order to master a set of equivalence relations the learner must first
learn to distinguish between each of the stimulus items in the set (e.g.
the 26 letters) and, when this has been accomplished to learn the
correct response to each of these stimulus items (e.g. to say the letter
name, or the most common letter sound).

Because equivalence relations come in sets, they are most commonly
taught and practised in subsets of the entire set. This is appropriate
because it is only by practising equivalence relations in sets that the
learner comes gradually to discriminate between each of the stimulus
items (e.g. letters) in the set. Practising in sets is especially
important where the stimulus items are similar in appearance. A learner
who recognises (and responds correctly to) the printed word through on
its own, will not necessarily be able to distinguish between (and
correctly read) the words through, though, trough, tough, and thought.
In order to acquire the ability to respond correctly to *each* of these
words, instruction must include opportunities to practise responding to
these words when they are grouped together as well as when they are
presented separately. Only if the learner has the opportunity to
practise discriminating between similar looking items, will he or she
learn to discriminate between these items and to respond correctly to
each.

The unanswered question is the question of how large these practice sets
should be. Should the sets be small or large? Does the set size which is
most appropriate vary with the age of the learner? Should the set size
increase as the learner moves from the initial learning phase through to
the fluency building phase? Research into the optimum size of practice
sets suggests that these sets must be larger than the number of
responses which the learner can hold in short term memory but small
enough to allow several attempts at each item during a single practice
session (e.g., Ferkis, Belfiore & Skinner, 1997; Gleason, Carnine &
Vala, 1991; Johnson, Gersten & Carnine, 1987). Johnson et al. (1987)
found that 14- to 16-year old students who studied the meanings of
vocabulary words in sets of 10 learned the new meanings more quickly
than students who studied the words in sets of 25. Once the learner
reaches the fluency building stage however, the set size needs to be
greatly increased. At the point of this transition the set size is
normally increased to at least 80 stimulus items so that the child can
practice, using 1 minute sprints, towards the goal of 60 to 70 correct
responses per minute (Keel, Slatton & Blackhurst, 2001).
:::

::: referencesList
#### References

-   Ferkis, M. S., Belfiore, P. J., & Skinner, C. H. (1997). The effects
    of response repetitions on sight word acquisition for students with
    mild disabilities. Journal of Behavioral Education, 7, 307-324.
-   Gleason, M., Carnine, D., & Vala, N. (1991). Cumulative versus rapid
    introduction of new information. Exceptional Children, 57, 353-358.
-   Johnson, G., Gersten, R., & Carnine, D. (1987). Effects of
    instructional design variables on vocabulary acquisition of LD
    students: A study of computer-assisted instruction. Journal of
    Learning Disabilities, 20, 206-213.
-   Keel, M. C., Slaton, D. B., & Blackhurst, A. E. (2001). Acquisition
    of content area vocabulary for students with learning disabilities.
    Education and Treatment of Children, 24, 46-71.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewequivalencerelationsareacquired/Necessarycondition4Sufficientpracticetoensureretention/index.md","# Necessary condition 4: Sufficient practice to ensure retention \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c4d3152db9c8484ba9468e7403778b78}
In order to learn a set of symbol--\>response equivalence relations the
learner must have multiple opportunities to practise responding to each
of the new symbols. Research suggests that, with this kind of learning
outcome, children can acquire the ability to respond correctly after
about three to six opportunities to practice each new response. McLay
(2004) found that 4-year old children could learn new object names after
an average of just three opportunities to name each object. McWilliams
(2006) found that the average 6- to 7-year old student could acquire new
spelling responses after an average of just five opportunities to spell
each unknown word.

Generally speaking, the equivalence relations taught in schools are ones
which we expect children to master. While the acquisition of new naming,
reading and spelling responses may occur after as few as three practice
responses, mastery of these responses requires fluency building practice
until each object, symbol or sound can be responded to correctly in less
than one second (Chiang & Schilling, 1983; Keel, Slaton & Blackhurst,
2001; Rinaldi, Sells & McLaughlin, 1997). This fluency building is
typically accomplished by providing daily 1-minute fluency building
sprints on the equivalence relations targeted for mastery (e.g., Chiang
& Schilling, 1983). Modern research into the building of fluency
(automaticity) tends to set a criterion of 60 to 70 correct responses
per minute because this is the fluency level which predicts long term
maintenance (retention) of new responses and skills. Keel et al. (2001)
report that 9- to 13-year old students who had been identified as
learning disabled required about 30 practice responses per word to
achieve a fluency criterion of 70 correct responses per minute on
reading a set of content-area vocabulary words.
:::

::: referencesList
#### References

-   Chiang, B., & Schilling, M. E. (1983). Effectiveness of the \"Speed
    Spelling Program\" with five LD students. Reading Improvement, 20,
    60-63.
-   Keel, M. C., Slaton, D. B., & Blackhurst, A. E. (2001). Acquisition
    of content area vocabulary for students with learning disabilities.
    Education and Treatment of Children, 24, 46-71.
-   McLay, L. K. (2004). Acquisition, retention and generalisation of
    object names in 4 year old children during child initiated and adult
    initiated learning interactions. Unpublished M.Ed. dissertation.
    Christchurch, New Zealand: University of Canterbury, School of
    Education.
-   McWilliams, K. G. (2006). An analysis of variables affecting
    instructional efficiency. Unpublished PhD thesis. Christchurch, New
    Zealand: University of Canterbury, School of Education.
-   Rinaldi, L., Sells, D., & McLaughlin, T. F. (1997). The effects of
    reading racetracks on the sight word acquisition and fluency of
    elementary students. Journal of Behavioral Education, 7, 219-233.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewequivalencerelationsareacquired/index.md","# How new equivalence relations are acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-01613f47e0de43b087fa37439d588559}
Much human learning involves learning how to respond correctly to
letters, words, numbers, mathematical symbols, mathematical expressions,
chemical symbols, and so on. In this account we are referring to this
kind of learning outcome as the acquisition of *equivalence relations*.
We use the term *equivalence relations* because the stimulus element and
response element are equivalent. Equivalence relations include the
ability to respond correctly to actual objects (as when learning a
proper name), to written symbols (as in reading) and to spoken language
(as in spelling). The response elements of an equivalence relationship
may be an oral response, a written response, or an indication of
comprehension (e.g. pointing to the named object). It is also possible
to have an equivalence relationship between a stimulus and a motor
response -- as in the case of learning to type and the case of learning
to read and play music on a musical instrument.

Research into the learning of equivalence relations has revealed a
number of interesting features of this kind of learning.

One characteristic of this kind of learning is that, once a correct
response has been learned, the stimulus and response elements are
usually found to be reversible, that is, interchangeable. Current
thinking (e.g. Sidman, 1994) is that reversibility is a basic
characteristic of human learning (in the same way that reinforcement is
a basic characteristic of human learning). However, whether or not this
proves to be true, reversibility is clearly an extremely important
feature of human learning for it greatly simplifies both the learning
and the teaching of oral and written language skills.

Secondly, language learning does not involve single, reversible,
equivalence relations. It involves *sets* of equivalence relations.
Consider the child who is learning to use the word \"book\".

![Figure 4410. Diagram of the six equivalence relations which are
involved in learning to use, read, understand, and spell a
word](../../../../../assets/images/Figure4410.png \"Figure 4410. Diagram of the six equivalence relations which are involved in learning to use, read, understand, and spell a word\"){.image-inline}

*Figure 4410. Diagram of the six equivalence relations which are
involved in learning to use, read, understand, and spell a word*

As can be seen from the table there are three basic pairs of equivalence
relations: #1 & #2 comprehending the orally spoken word (and vice
versa), #3 & #4 reading the written word (and vice versa) and #5 & #6
comprehending the written word (and vice versa).

There have been a number of well controlled experimental analyses of the
learning of sets of equivalence relations such as these. (For a summary
of this research, see Sidman, 1994.) This research has discovered
something very interesting about the way in which these relations are
learned. If any two of these pairs of correspondences are taught, the
learner will be found to have acquired the third pair without any
further teaching. For example, if relation #1 (oral comprehension) and
#3 (reading) are taught, all six relations (including reading
comprehension) will be found to have been acquired.

The reason for this lies, in part, in the reversibility property. If,
the learner comprehends the spoken word (relation #1), then they will
also be able to correctly name the object which that word refers to
(relation #2). If the learner can read the word, that is, see the word
and say the word (relation #3, then they will also be able to select the
printed word, that is, hear the word and point to the matching printed
word (relation #4).

How it is that the learner also acquires the remaining two relations (in
this case relation #5 and relation #6) remains something of a mystery.
However, numerous experiments have demonstrated that if the learner can
(a) match an object with its spoken label and (b) match the spoken and
written labels, then they will also have acquired the ability to match
the object with the written label. Other experiments have shown that if
the child can (a) match an object with its spoken label and (b) match an
object with its written label, then they will also be able to match the
spoken and the written labels (Joyce, Joyce & Wellington, 1993: Joyce &
Wolking, 1989; Lynch & Cuvo, 1995; MacKay, 1985; Melchiori, de Souza &
de Rose, 2000).

The research on equivalence relations has many implications for the
design of effective teaching procedures.

Prior to entry to school, children acquire relation #1 (oral
comprehension) and relation #2 (naming responses) for a large number of
words. But they have acquired few of the relations involving the printed
versions of those words (relations #3 to #6). When the child arrives at
school, a large amount of time is spent teaching relation #3 (reading).
For each word which the child already comprehends (relation #1),
learning to read that word (relation #3) automatically results in the
emergence of the remaining two equivalence relations, that is,
object--\>printed word matching (relation #6), and reading comprehension
(relation #5). In other words, if the child already comprehends the
spoken word, once they have learned to read the word correctly, they
will also comprehend the written word.

However, the converse is also true. The child may be taught to read
words which he or she does not yet understand. But this will take a very
large amount of practice *and none of the remaining four equivalence
relations will emerge as a result*. It can be seen, therefore, that
teaching a child to read a word which they do not yet understand is a
fairly pointless activity. If a child does not yet understand an orally
spoken word, the child needs to be taught the meaning of that word
either before, or at the same time as, the child is taught to read the
word.

A child who understands a word in its spoken form and can read that
word, will also be able to match printed and spoken words (because they
will have acquired all six of the equivalence relations listed above).
Because the child can already match printed and spoken words, the task
of learning to spell the word is a relatively easy one. Given that it is
very much easier to learn to spell a word that one can already read, it
follows that there is little or no point in trying to teach a child to
spell words which they cannot yet read.

Students who are faced with the task of learning a second language by
academic study (rather than by conversational interaction) tend to find
this task particularly difficult. This is because learning a language by
academic study involves the simultaneous acquisition of *two*
equivalence relations. The child must learn both to read the foreign
words (relation #3 *and* learn the meaning of the foreign words
(relation #5) before the other four relations will emerge. This involves
at least twice as much practice as is required in either learning to
speak one\'s own language or learning to read one\'s own language.

The teaching of new equivalence relations is usually postponed until the
learner has learned how to perform the response. For example, the
teaching of reading is normally postponed until the child\'s oral
vocabulary has developed to the point where the child can already say
(pronounce) most of the words contained in the texts which will be used
for reading practice. The teaching of single digit maths operations is
normally postponed until the learner can both say and write the numbers
which go to make up the correct responses. The teaching of spelling is
normally postponed until the learner has acquired the ability to print
or write letters.

This makes good sense because, if the learner can already perform the
*response*, all the learner has to learn is *when* to perform the
response. If the learner cannot yet perform the response, two separate
skills must be acquired simultaneously (a) learning how to perform the
response and (b) learning when to perform the response.

This is why equivalence relations are learned very much more quickly
(and can be taught very much more easily) if the learner can already
perform the response. This is why teaching the correct responses to each
of a set of symbols should always begin with a check to ensure that the
learner can perform each of the *responses* which are involved. If this
check reveals that one or more of the responses cannot yet be performed
(when prompted by the teacher), then the learner should be taught how to
perform these responses before the teaching of equivalence relations
involving those responses begins.

The teaching of new equivalence relations is usually postponed until the
response has acquired some meaning for the learner. For example, the
vocabulary of early reading texts is normally restricted to words which
are likely to be meaningful words for the learner. Spelling practice,
likewise, is usually limited to words which are meaningful to the
learner. The teaching of maths \"facts\" is normally postponed until the
learner has a sound understanding of one and two digit number concepts.

This practice makes good sense because the learning of new
symbol--\>response relations proceeds much more quickly if the response
is one which already has some meaning for the learner. If the learner
already has a reasonable understanding of the meanings of the oral
responses \"cow\", \"cat\", and \"dog\", learning to read (i.e. learning to
respond correctly to) the printed words cow, cat, and dog tends to occur
much more rapidly than is the case if the child has not yet learned the
meanings of the orally spoken words.

It follows, therefore, that the teacher should precede instruction in
new equivalence relations by a test to check that each *response* is
meaningful to the learner. This is accomplished by checking to see
whether the learner uses the word correctly and in a way which
demonstrates understanding (comprehension) of the meaning of the word.
If this check identifies any of the *responses* in a set of new
equivalence relations as ones which do not have meaning for the learner,
then the meanings of those responses should be taught before instruction
in these stimulus--\>response relationships begins.

Note that there will be cases where this precondition cannot be met.
Individual letters of the alphabet do not have meaning, but children
must still learn letter--\>name and letter--\>sound relationships.
Individual notes on a manuscript page do not have much meaning, but the
student of music must still learn the note--\>name, and the
note--\>performance relationships during the early stages of music
instruction.

Assuming that the relevant responses have already been acquired and that
these responses have some meaning for the learner, then there are four
essential conditions which must be met in order for someone to learn to
respond correctly to symbols which they cannot yet respond to correctly.
The correct response must be prompted initially, the symbols must be
presented in sets so that the student learns to discriminate between
each of the new symbols, correct responses must be differentially
reinforced, and the learner must engage in sufficient practice to
remember each of the correct responses (e.g., Barbetta, Heward &
Bradley, 1993; Chiang & Schilling, 1983; Espin & Deno, 1989; Johnson,
Schuster & Bell, 1996; Keel, & Gast, 1992; Keel, Slaton, & Blackhurst,
2001; McNeish, Heron, & Okyere, 1992; Morton, Heward & Alber, 1998;
Rinaldi, Sells & McLaughlin, 1997).

These conditions may be provided within the context of a wide variety of
different kinds of practice activities. For example, the learning of
equivalence relations may take place within the context of authentic
activities, practice activities, self-study activities, peer tutoring
activities (e.g., Telecsan, Slaton & Stevens, 1999), computer presented
activities (e.g., Kinney, Stevens & Schuster, 1988), and so on.
:::

::: referencesList
#### References

-   Barbetta, P. M., Heward, W. L., & Bradley, D. M. C. (1993). Relative
    effects of whole-word and phonetic-prompt error correction on the
    acquisition and maintenance of sight words by students with
    developmental disabilities. Journal of Applied Behavior Analysis,
    26, 99-110.
-   Chiang, B., & Schilling, M. E. (1983). Effectiveness of the \"Speed
    Spelling Program\" with five LD students. Reading Improvement, 20,
    60-63.
-   Espin, C. A., & Deno, S. L. (1989). The effects of modelling and
    prompting feedback strategies on sight word reading of students
    labelled learning disabled. Education and Treatment of Children, 12,
    219-231.
-   Johnson, P., Schuster, J., & Bell, J.K. (1996). Comparison of
    simultaneous prompting with and without error correction in teaching
    science vocabulary words to high school students with mild
    disabilities. Journal of Behavioral Education, 6, 437-458.
-   Joyce, B. G., Joyce, J. H., & Wellington, B. (1993). Using stimulus
    equivalence procedures to teach relationships between English and
    Spanish words. Education and Treatment of Children, 16, 48-65.
-   Joyce, B. G., & Wolking, W. D. (1989). Stimulus equivalence: An
    approach for teaching beginning reading skills to young children.
    Education and Treatment of Children, 12, 109-122.
-   Keel, M. C., & Gast, D. L. (1992). Small group instruction for
    students with learning disabilities: Observational and incidental
    learning. Exceptional Children, 58, 357-368.
-   Keel, M. C., Slaton, D. B., & Blackhurst, A. E. (2001). Acquisition
    of content area vocabulary for students with learning disabilities.
    Education and Treatment of Children, 24, 46-71.
-   Kinney, P. G., Stevens, K. B., & Schuster, J. W. (1988). The effects
    of CAI and time delay: A systematic program for teaching spelling.
    Journal of Special Education Technology, 9, 61-72.
-   Lynch, D. C., & Cuvo, A. J. (1995). Stimulus equivalence instruction
    of fraction-decimal relation. Journal of Applied Behavior Analysis,
    28, 115-126.
-   Mackay, H. A. (1985). Stimulus equivalence in rudimentary reading
    and spelling. Analysis and Intervention in Developmental
    Disabilities, 5, 373-387.
-   McNeish, J., Heron, T. E., & Okyere, B. (1992). Effects of
    self-correction on the spelling performance of junior high school
    students with learning disabilities. Journal of Behavioral
    Education, 2, 17-27.
-   Melchiori, L. E., de Souza, D. G., & de Rose, J. C. (2000). Reading,
    equivalence, and recombination of units: A replication with students
    with different learning histories. Journal of Applied Behavior
    Analysis, 33, 97-100.
-   Morton, W. L., Heward, W. L., & Alber, S. R. (1998). When to
    self-correct: A comparison of two procedures on spelling
    performance. Journal of Behavioral Education, 8, 321-335.
-   Rinaldi, L., Sells, D., & McLaughlin, T. F. (1997). The effects of
    reading racetracks on the sight word acquisition and fluency of
    elementary students. Journal of Behavioral Education, 7, 219-233.
-   Sidman, M. (1994). Equivalence relations and behavior: A research
    story. Boston: Authors Cooperative.
-   Telecsan, B. L., Slaton, D. B., & Stevens, K. B. (1999). Peer
    tutoring: Teaching students with learning disabilities to deliver
    time delay instruction. Journal of Behavioral Education, 9, 133-154.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewequivalencerelationsareacquired/Necessarycondition3Differentialreinforcementforcorrectresponses/index.md","# Necessary condition 3. Differential reinforcement for correct responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3a3f7134930f4a81a380448a9499d682}
If the correct response to a new stimulus is to be learned and
remembered, correct practice responses must be differentially
reinforced, that is, correct responses must be followed by consequences
which unambiguously signal that the correct response has been made and
incorrect responses must be identified as errors (Johnson, Schuster &
Bell, 1996). The rate of learning of new equivalence relations is
largely dependent upon the number of practice opportunities provided for
each response and the extent to which correct responses are
differentially reinforced (Barbetta, Heward & Bradley, 1993; McNeish,
Heron & Okyere, 1992; Morton, Heward & Alber, 1998).

The differential reinforcement of correct responses may be accomplished
in a variety of ways. It may be accomplished by telling the learner
whether their responses are correct or incorrect, by the immediate
marking of written practice responses, by providing flash cards with the
answers on the back, by putting learners into pairs where one student
can practise while the other checks each answer as correct or incorrect,
or by providing a table of equivalences which the learner can use to
check the correctness of their own practice responses (e.g., McNeish et
al., 1992). Self-correction immediately following each error results in
faster acquisition than delayed self-correction (Morton et al., 1998).
:::

::: referencesList
#### References

-   Barbetta, P. M., Heward, W. L., & Bradley, D. M. C. (1993). Relative
    effects of whole-word and phonetic-prompt error correction on the
    acquisition and maintenance of sight words by students with
    developmental disabilities. Journal of Applied Behavior Analysis,
    26, 99-110.
-   Johnson, P., Schuster, J., & Bell, J.K. (1996). Comparison of
    simultaneous prompting with and without error correction in teaching
    science vocabulary words to high school students with mild
    disabilities. Journal of Behavioral Education, 6, 437-458.
-   McNeish, J., Heron, T. E., & Okyere, B. (1992). Effects of
    self-correction on the spelling performance of junior high school
    students with learning disabilities. Journal of Behavioral
    Education, 2, 17-27.
-   Morton, W. L., Heward, W. L., & Alber, S. R. (1998). When to
    self-correct: A comparison of two procedures on spelling
    performance. Journal of Behavioral Education, 8, 321-335.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewequivalencerelationsareacquired/Conditionswhichmayaffectthelearningofequivalencerelations/index.md","# Conditions which may affect the learning of equivalence relations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0739935dfc894bfabedfbd3a8a9dd32c}
The careful sequencing and systematic practice of new equivalence
relations can result in rapid mastery of new naming, reading and
spelling responses. Research has also identified a number of additional
conditions which, although not essential for learning, may function to
accelerate the rate at which new equivalence relations will be learned
and remembered.

**1. The size of the practice set used during initial teaching**

Research to date suggests that during the initial acquisition phase, new
equivalence relations should be taught and practised in relatively small
sets. The research suggests that, with younger learners, new responses
should be introduced in sets of half a dozen or less. Silbert, Carnine
and Stein (1981, p. 230) argue that basic maths facts should be
introduced in sets of three or four facts. With older learners the set
size can probably be increased to 8 to 10 new items at a time. The main
requirement to be met seems to be that practice sets should contain a
number of items which exceeds the short term memory capacity of the
learner so that the learner cannot simply respond to each item from
short term memory (Bryant, Drabin & Gettinger, 1981; Johnson, Gersten &
Carnine, 1987).

**2. The interspersal ratio of new to previously acquired responses**

A number of researchers have studied the effects of creating practice
sets which include both known (old) and unknown (new) stimulus items.
The technical name for this procedure is *interspersal training*
(because new and old items are interspersed within the practice set).
The most commonly used interspersal practice procedure is reading
practice using controlled vocabulary stories where at least 85 per cent
of the words in the story are words which the leaner has already learned
to read. Interspersal training almost always results in more rapid
acquisition of new correct responses than is the case when the learner
practises with sets which consist entirely of new items (Koegel &
Koegel, 1986; Neef, Iwata & Page, 1977, 1980).

Why is this? Some writers argue that the faster learning which occurs
during interspersal training is due to the fact that the learner makes
fewer errors (because many of the items are already known). With fewer
errors, the learner also receives more reinforcement for being correct.
However, it might also be because the interspersal training provides
more effective and error-free discrimination training. It will be
recalled that, in learning to respond correctly to new stimuli, the
learner must not only learn which response to give to the new stimulus
but must also to discriminate between the new stimulus and all other
stimuli in the set. By including previously mastered items in the
current practice set, it is possible for the teacher to include
(previously mastered) stimulus items which are similar in appearance to
the new items. Practice sets which include old as well as new items
provide the learner with both kinds of practice (practice in
discriminating the new stimulus from other stimuli as well as practice
in responding correctly).

**3. The extent to which easily confused items are placed in different
teaching sets**

A number of writers (e.g. Engelmann & Carnine, 1991; Kameenui & Simmons,
1990) have argued that closely similar stimulus items should not be
taught together but should be introduced several days apart. \"As a
general rule, the more similar the stimuli are, the more difficult the
discrimination will be for the learner. For example, in teaching
decoding skills, the letter-\>sound associations of b and d are well
known for the confusion they cause learners because of their similarity
both visually and auditorily. We recommend separating the introduction
of stimuli that are visually . . . similar\" (Kameenui & Simmons, 1990,
p. 136).

Although this advice runs contrary to common practice, the research
suggests that it does result in faster learning. In a series of
experiments, Carnine (1976, 1980, 1981) found that letter--\>sound
equivalence relations were always acquired more quickly when closely
similar letters were spaced far apart in the teaching sequence than when
they were introduced one after the other in the teaching sequence. This
procedure results in fewer errors during the learning of each of the
(easily confused) letter--\>sound relations and, hence, faster learning.
If the two easily confused letter--\>sound equivalences are introduced
together, the learner tends to make many more errors (because of the
similarity of the stimulus items) and, as a result, it takes the learner
much longer to learn to respond correctly to each.

**4. The degree of fluency achieved prior to introducing the next set of
new responses**

One of the major difficulties in teaching new equivalence relations is
that the retention of previously learned responses tends to be disrupted
by practice on later sets of equivalence relations. This phenomenon has
been well documented (Postman & Underwood, 1973). The interference
effect which occurs during this type of learning is referred to by
different writers as *interference,* as *retroactive inhibition,* as
*retroactive interference,* and as *competition* (Howe, 2002). The
simplest way of reducing competition (and the errors which result from
competition) is to ensure that each new item (or small set of new items)
is well learned before the next new item (or set of new items) is
introduced. By well learned is meant that the child can respond
correctly in less than 1 second. This is especially important in the
case of stimulus items which are confused by large numbers of students.

**5. The use of devices which make sets of equivalence relations more
memorable**

The mastery of new equivalence relations is a difficult task at all age
levels. So any teaching procedure or study procedure which makes the
correct responses easier to remember is likely to increase the rate at
which these are acquired. Both research and practical experience suggest
that there are a number of devices which function to make new items more
memorable. These include rhymes, songs, mnemonics, imagery and rules.

*Rhymes*. One way of making new items more memorable is to cast them
into the form of a rhyme. For some reason rhymes are easier to remember
than lists which do not rhyme. For example, most people use a rhyme to
remember the days of the month: *Thirty days hath September, April, June
and November. All the rest have thirty-one except for February alone
which has twenty eight or twenty nine.* Some teachers use the following
rhyme to help children remember 7x7=49: *Seven sevens are forty-nine*

*Forty-nine is nearly fifty*

*Seven sevens are forty-nine*

*Forty-nine is really nifty*

*Songs*. Like rhymes, songs are also more memorable than prose lists.
Many young children learn to recite the alphabet using the alphabet song
\"*A, B, C, D, E, F, G. H, I, J, K, L-M-N-O-P.\"* And there are many
children who learned to count backwards by singing

*Ten little, nine little, eight little Indians*

*Seven little, six little, five little Indians*

*Four little, three little, two little Indians*

*One little Indian boy.*

*Mnemonics*. A mnemonic is a word, acronym, or sentence which is easy to
remember and in which each of the letters or initial letters functions
as a prompt for the responses which the learner wants to remember.
Goetz, Alexander & Ash (1992, p. 443) give the following example of a
mnemonic which can be used to prompt recall of the names of the planets:
*My very elegant mother just sat upon nine porcupines.* The first letter
of each word in the sentence is also the initial letter in a planet
name. In order, the planets are: Mercury, Venus, Earth, Mars, Jupiter,
Saturn, Uranus, Neptune and Pluto. Of course, a new mnemonic will be
required now that Pluto no longer has the status of a planet. Mnemonics
have been found to function as an effective memory aid in a variety of
different kinds of equivalence relations tasks (e.g., Agramonte &
Belfiore, 2002; Greene, 1999; Mastropieri, Scruggs & Whedon 1997; Wood,
Frank & Wacker, 1998). For a review of the research into the
effectiveness of mnemonics see Scruggs and Mastropieri (1990).

*Imagery.* Sometimes a new discrimination can be made more memorable by
associating it with an image (e.g., Caban, Hambleton, Coffing, Conway &
Swaminathan, 1978). For example some children learn to discriminate
between b and d by associating these stimuli with the image of a bed.

*Patterns*. Some equivalence relations come in sets where the existence
of a pattern makes then more memorable. For example, there is a pattern
to number fact series such as *1+1=2, 2+1=3, 3+1=4, 4+1=5* which makes
them easy to remember. Number facts can also be grouped into \"families
of facts\" e.g. *3+6=9, 6+3=9, 9-6=3, 9-3=6* and, when they are grouped
in this way, the memory load for the learner is much reduced. Some
children learn the nine times table by remembering the pattern *9, 18,
27, 36, 45, 54, 63, 72, 81, 90* (e.g., Wood, Frank & Wacker, 1998).

**6. The extent to which the learner is able to apply self-rehearsal
strategies**

There are things which the learner can do to speed up the acquisition of
new symbol-\> response relationships. One of these is to actively
self-rehearse each new relationship. For example, the teacher can teach
the learner how to self-rehearse responding correctly to new stimulus
items. The simplest self-rehearsal procedure is *cover, copy, compare*.
The learner examines the stimulus item (such as a new spelling word),
covers the word, writes the spelling word, and then checks his or her
own response against the printed stimulus. Teaching children to use the
cover-copy-compare self-rehearsal procedure has been shown to accelerate
acquisition on a variety of equivalence relation learning tasks (e.g.
Conley, Derby, Roberts-Gwinn, Weber & McLaughlin, 2004; McGuffin, Martz
& Heron, 1997; Okyere, Heron & Goddard, 1997; Skinner, Beatty, Turco &
Rasavage, 1989; Stading, Williams & McLaughlin, 1996).

In New Zealand, many children learn the Spell-Write self-rehearsal
procedure for learning new spelling words. The effects on rate of
acquisition of teaching students to use the Spell-Write procedure have
been examined in a number of experiments. In almost every experiment,
teaching the learner to use the Spell-Write self-rehearsal procedure
resulted in a doubling of the number of spelling words mastered by the
learner during 10-15 minute practice sessions. This doubled learning
rate occurred with children spanning the age range from 5 to 13 years
and occurred with learning disabled children as well as normally
developing children (Church, 1992).

**7. The extent to which rules can be, and are taught**

A number of sets of symbol--\>response correspondences follow specific
rules. This is most obvious in mathematics. For example, the commutative
rule states that *3+8=8+3* and that *2x4=4x2*, for example. Teaching
this rule greatly reduces the number of maths \"facts\" which have to be
learned. Pupils can also be taught how to work out the answers to
addition facts by counting up (*4+2; count up two; 5, 6; 4+2=6),* how to
work out the answers to subtraction facts by counting on (*6-4; four
count 5, 6; this is counting on two, 6-4=2),* and how to work out the
answers to multiplication facts by counting by (*2x4 count by two four
times; 2, 4, 6, 8; 2x4=8)*. Once these rules have been learned, all of
the \"basic maths facts\" can be derived by the learner. This means that,
if a particular answer cannot be remembered during practice, it can be
derived by the learner (Lloyd, Saltzman & Kauffman, 1981; Van Houten,
1993). In the Van Houten experiment, 6- to 11-year old students who were
taught a rule for finding the answer to single digit subtraction facts
learned seven subtraction facts in half the time required without the
rule.

There are also a number of rules which can be taught to facilitate the
development of reading skills. In reading, certain letter-\>sound
correspondences recur consistently, that is, in a high proportion of
words. Kameenui and Simmons (1990, p. 213) make the point that the
following 14 vowel-vowel and vowel-consonant combinations are pronounced
in the same way more than 70% of the time:

*ai* as in bait*ou* as in ounce*oi* as in coin*ow* own/cow*ur* as in
burn

*ea* as in each*oo* as in boot*oa* as in coat*ir* as in bird*ar* as in
barn

*ee* as in bleed*au* as in cause*ay* as in day*er* as in term

Where rules exist, these rules should be taught. In reading, this means
that common grapheme--\>phoneme relationships (letter--\>sound
relationships) should be taught as rules. Practice in applying
grapheme--\>phoneme relationship rules is necessary because, once these
rules have been learned, the child will be able to decode new words
without assistance and the rate of acquisition of new reading skills
will be very greatly increased (e.g. Foorman, Francis, Novy & Liberman,
1991; Vandervelden & Siegel, 1997). For a review of the research into
teaching grapheme--\>phoneme relationships (phonics) and its effects on
learning to read, see National Reading Panel (2001).

**8. The extent to which exceptions are taught**

The thing to remember about the teaching of rules is that younger
children tend to assume that a rule applies in all cases. The technical
name for this phenomenon is *overgeneralisation*. Where the rule which
is being taught is a rule which has exceptions, it is important that at
least some of the exceptions to the rule are taught at the same time
that the rule is being taught. Otherwise, there is a high likelihood
that the learner will overgeneralise the rule. Let us say, for example,
that the teacher is teaching the rule that *\"ai makes the ai sound as in
rain and bait\"*. If this rule was being taught, the teacher should also
teach that there are exceptions such as *villain* and *captain* so the
child does not overgeneralise the rule.

Spelling rules are \"rules\" which almost always have exceptions. It
follows that any instruction in spelling rules should always include
instruction in the exceptions. The following examples (of spelling
rules) illustrate.

1.We double *l*, *f*, *s*, after a single vowel at the end of a short
word, e.g. call, tell, toss, moss, stiff, stuff. Exceptions: us, bus,
gas, if, of, this, yes, plus, nil, pal.

2.The *i* sound and the *ee* sound at the end of a word is nearly always
spelled *y*. No English words end in *i*. Exceptions: macaroni,
spaghetti, vermicelli (Italian), taxi (short for taxicab), coffee,
committee.

3.Nouns ending in a single *f* change the *f* to *v* before adding *es*
to form the plural, e.g. leaves, wolves. Exceptions: dwarfs, roofs,
chiefs.

4.The consonant *l* is always doubled before a suffix which begins with
a vowel, e.g. compelled, labelled, modelled. Exceptions: unparalleled,
naturalist, devilish, liberalism.

5.Words which end with *consonant-o*, usually add *es* to form the
plural. e.g. potatoes, tomatoes, volcanoes, torpedoes. Exceptions:
pianos, solos, Eskimos, zeros.
:::

::: referencesList
#### References

-   Agramonte, V., & Belfiore, P. J. (2002). Using mnemonics to increase
    early literacy skills in urban kindergarten students. Journal of
    Behavioral Education, 11, 181-190.
-   Bryant, N. D., Drabin, I. R., & Gettinger, M. (1981). Effects of
    varying unit size on spelling achievement in learning disabled
    children. Journal of Learning Disabilities, 14, 200-203.
-   Caban, J. P., Hambleton, R. K., Coffing, D. G., Conway, M. T. &
    Swaminathan, H. (1978). Mental imagery as an approach to spelling
    instruction. Journal of Experimental Education, 46, 15-21.
-   Carnine, D. W. (1976). Similar sound separation and cumulative
    introduction in learning letter-sound correspondences. The Journal
    of Educational Research, 69, 368-372.
-   Carnine, D. W. (1980). Two letter discrimination sequences:
    High-confusion-alternatives first versus low-confusion-alternatives
    first. Journal of Reading Behavior, 12, 41-47.
-   Carnine, D. W. (1981). Reducing training problems associated with
    visually and auditorily similar correspondences. Journal of Learning
    Disabilities, 14, 276-279.
-   Church, R.J. (1992). Measuring the effects of teaching on learning.
    Paper presented to the Second Joint AARE/NZARE Conference, Geelong,
    Australia.
-   Conley, C. M., Derby, K. M., Roberts-Gwinn, M., Weber, K. P., &
    McLaughlin, T. F. (2004). An analysis of initial acquisition and
    maintenance of sight words following picture matching and copy,
    cover, and compare teaching methods. Journal of Applied Behavior
    Analysis, 37, 339-350.
-   Engelmann, S., & Carnine, D. (1991). Theory of Instruction:
    Principles and applications (Rev. Ed.). Eugene, OR: ADI Press.
-   Foorman, B. R., Francis, D. J., Novy, D. M., & Liberman, D. (1991).
    How letter-sound instruction mediates progress in first-grade
    reading and spelling. Journal of Educational Psychology, 86,
    456-469.
-   Goetz, E. T., Alexander, P. A., & Ash, M. J. (1992). Educational
    psychology: A classroom perspective. New York: Macmillan Publishing
    Co.
-   Greene, G. (1999). Mnemonic multiplication fact instruction for
    students with learning disabilities. Learning Disabilities Research
    & Practice, 14, 141-148.
-   Howe, M. L. (2002). The role of intentional forgetting in reducing
    children's retroactive interference. Developmental Psychology, 338,
    3-14.
-   Johnson, G., Gersten, R., & Carnine, D. (1987). Effects of
    instructional design variables on vocabulary acquisition of LD
    students: A study of computer-assisted instruction. Journal of
    Learning Disabilities, 20, 206-213.
-   Kameenui, E. J., & Simmons, D. C. (1990). Designing instructional
    strategies: The prevention of academic learning problems. Columbus,
    OH: Merrill Publishing Co.
-   Koegel, L. K., & Koegel, R. L. (1986). The effects of interspersed
    maintenance tasks on academic performance in a severe childhood
    stroke victim. Journal of Applied Behavior Analysis, 19, 425-430.
-   Lloyd, J., Saltzman, N. J., & Kauffman, J. M. (1981). Predictable
    generalization in academic learning as a result of preskills and
    strategy training. Learning Disability Quarterly, 4, 203-216.
-   Mastropieri, M. A., Scruggs, T. E., Whedon, C. (1997). Using
    mnemonic strategies to teach information about U.S. Presidents: A
    classroom-based investigation. Learning Disability Quarterly, 20,
    13-21.
-   McGuffin, M. E., Martz, S. A., & Heron, T. E. (1997). The effects of
    self-correction versus traditional spelling on the spelling
    performance and maintenance of third grade students. Journal of
    Behavioral Education, 7, 463-476.
-   National Reading Panel. (2000). Teaching children to read. Retrieved
    June 25, 2000, from
    http://www.nichd.nih.gov/publications/nrp/smallbook.htm
-   Neef, N. A., Iwata, B. A., & Page, T. J. (1977). The effects of
    known-item interspersal on the acquisition and retention of spelling
    and sight reading words. Journal of Applied Behavior Analysis, 10,
    738.
-   Neef, N. A., Iwata, B. A., & Page, T. J. (1980). The effects of
    interspersal training versus high-density reinforcement on spelling
    acquisition and retention. Journal of Applied Behavior Analysis, 13,
    153-158.
-   Okyere, B. A., Heron, T. E., & Goddard, Y. (1997). Effects of
    self-correction on the acquisition, maintenance, and generalization
    of the written spelling of elementary school children. Journal of
    Behavioral Education, 7, 51-69.
-   Postman, L., & Underwood, B. J. (1973). Critical issues in
    interference theory. Memory & Cognition, 1, 19-40.
-   Scruggs, T. E., & Mastropieri, M. A. (1990). Mnemonic instruction
    for students with learning disabilities: what it is and what it
    does. Learning Disability Quarterly, 13, 271-280.
-   Silbert, J., Carnine, D., & Stein, M. (1981). Direct instruction
    mathematics. Columbus, OH: Charles E. Merrill Publishing Co.
-   Skinner, C. H., Beatty, K. L., Turco, T. L., & Rasavage, C. (1989).
    Cover, copy, and compare: A method for increasing multiplication
    performance. School Psychology Review, 18, 412-420.
-   Stading, M., Williams, R. L., & McLaughlin, T. F. (1996). Effects of
    a copy, cover, compare procedure on multiplication facts mastery
    with a third grade girl with learning disabilities in a home
    setting. Education and Treatment of Children, 19, 425-434.
-   Vandervelden, M. C., & Siegel, L. S. (1997). Teaching phonological
    processing skills in early literacy: A developmental approach.
    Learning Disability Quarterly, 20, 63-81.
-   Van Houten, R. (1993). Rote vs. rules: A comparison of two teaching
    and correction strategies for teaching basic subtraction facts.
    Education and Treatment of Children, 16, 147-159.
-   Wood, D. K., Frank, A. R., & Wacker, D. P. (1998). Teaching
    multiplication facts to students with learning disabilities. Journal
    of Applied Behavior Analysis, 31, 323-337.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewknowledgeresponsesareacquired/Necessarycondition1Allessentialinformationinaformwhichcanbereferredtorepeatedly/index.md","# Necessary condition 1. All essential information in a form which can be referred to repeatedly \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-08e85ba864cc4c91a2395a973afb985b}
In seems reasonable to assume that only those students who have access
to every item of information listed in the teaching aim will be in a
position to acquire the knowledge responses which go to make up the aim
for that lesson or activity. Knowledge learning, like any other kind of
learning, requires a certain amount of practice. This means that the
learning resources which are provided for knowledge learning must be in
a form which the learner can refer to on a number of occasions. This
requirement can be met in a number of ways: by including, as part of the
learning resource, books, notes, diagrams, videos, or any other kind of
resource which the learner can refer to repeatedly.

Of course, it is only possible to ensure that each student has access to
the knowledge to be learned and remembered, if that knowledge has been
specified *prior to instruction*. There is no way of assessing the
progress which each student is making towards the learning goal unless
the learning goal has been specified. It is also impossible to undertake
useful research into the conditions necessary for knowledge learning
unless the knowledge learning goal has been specified prior to any
experimental analysis.

The notion that knowledge learning requires the student to have access
to the knowledge to be learned stands in sharp contrast to the view that
it is sufficient simply to set students to work on research and project
activities in which they search out project-relevant information for
themselves.

We have been able to identify no research studies which have compared
the relative effectiveness or efficiency, under conditions in which the
knowledge to be acquired is known and specified in advance, of (a)
providing the necessary resources and (b) setting students to discover
the necessary resources. Clearly this is a very serious shortcoming of
the research into learning and teaching.

One of the reasons why there has been so little improvement in the
teaching of knowledge responses is that most teachers do not specify
their teaching aims with respect to this kind of learning outcome prior
to instruction. As long as this practice persists, improvements in
knowledge teaching procedures are most unlikely to occur. It is not
possible to develop more effective teaching procedures unless student
learning is being measured and it is not possible to measure student
learning unless the teaching aim has been specified before teaching
begins.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewknowledgeresponsesareacquired/index.md","# How new knowledge responses are acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-54ccb28882ab4b52b39b3abefe8ea8fd}
Much school learning involves the acquisition of new knowledge
responses. Unlike the acquisition of equivalence relations and
generalised correct responses where a response is only correct if it is
word perfect, knowledge responses are judged to be \"correct\" if the
*meaning* of the response matches the *meaning* of the original
proposition.

\"Knowledge\" can be expressed as a series of propositions. (e.g. \"when
heat is added, ice changes to water\"). In order to ascertain whether or
not a student has learned a particular proposition (item of information)
we can turn the proposition into a question. For example, \"What happens
when ice is heated?\" Like equivalence relations, the elements of
knowledge propositions, once learned, are reversible. The student who
can respond correctly the question \"What happens when ice is heated?\"
will almost certainly be able to answer the question \"What do we have to
heat to produce water?\"

It is often a requirement that the student be able to demonstrate an
understanding of the material which is being talked about. With
knowledge learning, understanding is demonstrated when the student
demonstrates that they can respond to questions about a proposition
which are *paraphrases* of the original proposition. In order to respond
correctly to a paraphrase question, the student must have understood and
remembered the meaning of the original presentation (and not just
memorised the words used in the original presentation).

Given the fact that knowledge learning is such a common classroom
teaching aim it comes as no surprise to find that there have been
thousands of studies of this kind of learning. Unfortunately, this
research has been singularly unsuccessful in identifying either the
conditions which affect knowledge learning or the teaching procedures
which result in the most rapid learning of new knowledge responses.

There are several reasons for this lack of progress. First, knowledge
learning researchers have yet to discover a *research* *method* which
can be successfully applied to study the knowledge learning process. One
of the problems which learning researchers face is that meaningful
knowledge responses tend to be acquired very quickly. During the 20th
century, learning researchers attempted to solve this problem by setting
students to learn relatively non-meaningful materials (e.g. Tulving &
Madigan, 1970). This had the effect of slowing down learning so that it
could be studied but it also generated results which could not be
applied to the classroom where teachers usually try to ensure that
knowledge learning tasks are as meaningful as possible.

The second procedure which learning researchers used in their attempts
to slow the knowledge learning process to the point where it could be
studied was to set the learner tasks which involved relatively large
numbers of knowledge responses, that is, a larger number of new
responses than could be acquired in the time available (Duchastel,
1983). This can be an appropriate strategy provided one studies the
learning of individual learners. It is necessary to study learners one
at a time because (a) each individual learner comes to a given knowledge
learning task with prior learning experiences which enable them to
answer some test questions before instruction even begins and (b) this
prior knowledge is different for each learner. Unfortunately however,
most knowledge learning researchers have chosen to study changes in the
mean test performance of groups of learners. Because each learner in a
group of learners already knows somewhat different things and, hence,
learns different things during a given knowledge learning task, the
results of these between group experiments have proved to be largely
uninterpretable.

Thirdly, a large proportion of the knowledge learning research studies
have been studies of students involved in independent study activities
of one kind of another (e.g., Andre, 1981; Andre & Womack, 1978). This
research has yielded interesting information about the study skills
which students bring to this kind of learning task but, because the
studies have not involved any kind of teaching or instruction, they have
not contributed to our understanding of how best to teach new knowledge
responses.

When the non-experimental studies, the between-group experiments, the
experiments involving non-meaningful materials, and the experiments
involving independent study rather than instruction are removed from the
research pool, almost no research is left. So far we have been able to
locate only about 60 controlled experimental analyses of knowledge
learning where the knowledge responses to be acquired have been
specified prior to the experiment. So what we actually know about how
best to teach new knowledge responses is based on a tiny corpus of
research.

Because individual items of meaningful information are very quickly
acquired, the primary problem in teaching new knowledge responses is not
so much a matter of how to teach them as it is a matter of deciding how
many knowledge responses should be taught at one time and of selecting
procedures which ensure that every student comes into contact with each
of the items of information which are to be learned and remembered.
:::

::: referencesList
#### References

-   Andre, T. (1981). The role of paraphrased adjunct questions in
    facilitating learning from prose. Contemporary Educational
    Psychology, 6, 22-27.
-   Andre, T., & Womack, S. (1978). Verbatim and paraphrased adjunct
    questions and learning from prose. Journal of Educational
    Psychology, 70, 796-802.
-   Duchastel, P. C. (1983). Interpreting adjunct question research:
    Processes and ecological validity. Human Learning: Journal of
    practical Research & Applications, 2, 1-5.
-   Tulving, E., & Madigan, S. A. (1970). Memory and verbal learning.
    Annual Review of Psychology, 21, 437-484.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewknowledgeresponsesareacquired/Necessarycondition3Differentialreinforcementforcorrectresponses/index.md","# Necessary condition 3. Differential reinforcement for correct responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0d0aa912d16448c3899ee61b7c09d2a3}
Having established that knowledge responses must be practised, it seems
reasonable to assume that these practice responses will need to be
differentially reinforced if they are to be remembered. The sources of
reinforcement which operate during knowledge learning have been little
studied and remain a matter of some conjecture. The enthusiasm with
which many children discuss their discoveries about the world suggests
that simply making these discoveries may be reinforcing for many
students. Most students are motivated to respond correctly to lesson
questions and test questions which suggests that \"being correct\" is
reinforcing for most students while \"being wrong\" is not. Primary age
children also tend to work hard to avoid the embarrassment of negative
evaluations by teachers and/or peers and this suggests that negative
reinforcement processes provide some motivation for completing classroom
tasks to the standard set by the teacher (e.g., McLaughlin, 1992;
Stowitschek, Hecimovic, Stowitschek, & Shores, 1982).

What seems to be critical is the feedback which enables the learner to
distinguish between correct and incorrect responses. While a number of
experiments have shown that feedback affects recall following knowledge
learning tasks (e.g. Anderson, Kulhavy & Andre, 1971), the question of
whether or not this feedback is a necessary condition for knowledge
acquisition has yet to be demonstrated empirically.

What little research there is suggests that the confirmation of correct
responses seems to be less important than the identification and
correction of errors (Hancock, Stock & Kulhavy, 1992; Kulhavy, Yekovich
& Dyer, 1976). It is not yet clearly understood why the confirmation of
correct responses to knowledge testing questions has so little effect on
knowledge learning. Perhaps it is because that, if the question is a
meaningful one, learners can in most cases recognise that they have
responded correctly.

What does seem to be important during the learning of new knowledge is
that errors should be corrected when they occur. Carnine (1977) studied
the effects of error correction in an experimental analysis of learning
during arithmetic lessons. \"When the teacher corrected errors, the
children said the right answer about 70 per cent of the time during
training and 65 per cent of the time during post-test. When the teacher
ignored errors, the child said the right answer about 15 per cent of the
time during training and 15 per cent during post-test\" (Carnine, 1977,
p. 177).

Errors which are not self-corrected indicate (a) that the correct
response has not yet been acquired and (b) that the student may be
unaware that he or she has made an error. It follows therefore that,
unless errors are corrected, the wrong knowledge response may be
acquired.

Of course, errors can only be identified and corrected if the learners
are engaging in overt practice responses or overt activities at least
initially. Once an error has occurred it is more effective to provide a
prompt followed by a second opportunity to respond (rather than a
correction on its own) (Drevno, Kimball, Possi, Heward, Gardner, &
Barbetta, 1994).

The rule that errors should not be left uncorrected is especially
important during any progress tests which are scheduled during the
course of instruction. Progress tests serve not only to identify items
of information which have not yet been acquired but also provide an
additional practice opportunity with respect to each of the items of
information included in the test. It is essential, therefore, that the
learner's responses be marked, and errors corrected, immediately
following the test. In the classroom, this can be accomplished using
peer marking or self marking from an answer key.
:::

::: referencesList
#### References

-   Anderson, R. C., Kulhavy, R. W., & Andre, T. (1971). Feedback
    procedures in programmed instruction. Journal of Educational
    Psychology, 62, 148-156.
-   Carnine, D. W. (1977). Direct instruction: DISTAR. In N. G. Haring
    & B. Bateman (Eds.), Teaching the learning disabled child. Englewood
    Cliffs, NJ: Prentice Hall.
-   Drevno, G.E., Kimball, J.W., Possi, M.K., Heward, W.L., Gardner, R.,
    & Barbetta, P.M. (1994). Effects of active student response during
    error correction on the acquisition, maintenance, and generalization
    of science vocabulary by elementary students: A systematic
    replication. Journal of Applied Behavior Analysis, 27, 179-180.
-   Hancock, T. E., Stock, W. A., & Kulhavy, R. W. (1992). Predicting
    feedback effects from response-certitude estimates. Bulletin of the
    Psychonomic Society, 30, 173-176.
-   Kulhavy, R. W., Yekovich, F. R., & Dyer, J. W. (1976). Feedback and
    response confidence. Journal of Educational Psychology, 68, 522-528.
-   McLaughlin, T. F. (1992). Effects of written feedback in reading on
    behaviorally disordered students. Journal of Educational Research,
    85, 312-316.
-   Stowitschek, C. E., Hecimovic, A., Stowitschek, J. J., &
    Shores, R. E. (1982). Behaviorally disordered adolescents as peer
    tutors: Immediate and generative effects on instructional
    performance and spelling achievement. Behavioral Disorders, 7,
    136-148.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewknowledgeresponsesareacquired/Conditionswhichmayacceleratethelearningofnewknowledgeresponses/index.md","# Conditions which may accelerate the learning of new knowledge responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4dbad6b34daf4df8858954d4f146c58c}
In addition to the three necessary conditions suggested by a structural
analysis of the acquisition of new knowledge, research into the
variables affecting this type of acquisition suggest that there are a
number of variables which may operate to facilitate or hinder the rate
at which new knowledge responses are acquired. These variables include
the meaningfulness of instructional presentations, the number of
learning channels activated by the presentations, the clarity of
instructional texts, the extent to which essential and non-essential
information is differentiated, the extent to which the learner receives
additional practice on difficult topics, the extent to which the teacher
provides regular tests of progress (and reinforcement for progress
towards the learning goal), and the study skills of the learner.

**1. The meaningfulness of the presentations containing the new
knowledge**

Both experience and research indicate that remembering is strongly
affected by the meaningfulness of instructional presentations and texts
(e.g., Marks, Doctorow & Wittrock, 1974). This means that acquisition
will be strongly affected by the teacher's ability to select or
construct knowledge presentations which are phrased in language which is
understood by each of the learners in the instructional group.

Because the content of meaningful presentations is learned and
remembered so much more quickly, acquisition will be affected by the
extent to which teachers check each student's comprehension of the
presentations containing to-be-learned information. If the presentations
contain words or terms which are not understood by an individual learner
then acquisition will be affected by the extent to which the teacher
provides supplementary presentations designed to teach the meanings of
these unknown words.

**2. Whether presentations activate more than one learning channel**

Presentations containing to-be-learned information may activate a single
learning channel or several learning channels. Lectures activate a
single learning channel (hearing) and textbooks activate a single
learning channel (seeing). Audio-visual presentations activate two
learning channels (hearing and seeing).

There is some between-groups research which suggests that presentations
which activate two learning channels (e.g. seeing and hearing) result in
the learner remembering more of the content of a presentation than if
only one learning channel has been activated (Mayer & Moreno, 2003).
This effect has been observed with students engaged in several different
knowledge learning tasks using printed explanations with and without
tape-recorded versions of those explanations (Mousavi, Low & Sweller,
1995; Tindall-Ford, Chandler & Sweller, 1997), with multimedia
presentations consisting of either an animation plus on-screen textual
information (visual only) or an animation plus an audio commentary
(audio-visual) (Mayer & Moreno, 1998), and with multimedia presentations
of how lightning occurs in which some students have watched an on-screen
animation plus on-screen explanations while others have been presented
with the animation, the on screen explanation, and an audio narration
(Moreno & Mayer, 2002). All of these experiments have been replicated.

So far these effects have only been shown with upper secondary and
tertiary level students. There do not appear to have been any controlled
demonstrations with younger learners of superior recall following
presentations which activate two learning channels rather than one.
Secondly, the effect is only observed under certain conditions. It is
not observed if the visual presentation contains redundant information
(such as unnecessary animations) and it is not observed if the audio
presentation contains redundant information (such as unnecessary sound
effects) (Moreno & Mayer, 2002). Presumably this is because the
additional redundant information uses processing capacity which cannot
be applied to the to-be-learned information. Thirdly, the effect is more
often observed in instructional situations where working memory is
likely to be working to capacity, that is, with complex learning tasks
or with low achieving students. It tends not to be observed in
situations where the working memory load is limited, that is with simple
learning tasks and with high achieving learners who are experienced in
handling complex tasks (Mayer & Moreno, 2003; Tindall-Ford et al.,
1997).

**3. The level of clarity and organisation of the texts which are being
studied**

An analysis of the texts which are commonly used during classroom
instruction in new knowledge topics reveals that they tend to suffer
from a number of shortcomings. Some texts are difficult to study from
because they introduce too many new concepts and provide insufficient
examples to communicate the meanings of the concepts which are being
introduced. This is a common failure of commercially produced primary
school mathematics textbooks (Carnine, Jitendra & Silbert, 1997;
Jitendra, Carnine & Silbert, 1996). When a textbook contains
insufficient explanation and/or examples to teach new concepts and
understandings, learning objectives cannot be met for many students
unless the teacher supplements the information in the text using lessons
which provide additional explanations and examples of the concepts which
are a part of the teaching aim.

Some texts are difficult to study from because they include too much
factual detail. With this kind of text, much instructional time may be
wasted while the student reads and studies material which is not part of
the teaching aim and which does not actually have to be learned. Further
instructional time may be wasted while the learner struggles to
distinguish between important and unimportant information. We will
consider this problem in the section which follows.

Some texts are difficult to study because they are poorly organised.
This may be because the information on a particular concept or topic is
scattered about rather than being grouped in one place, or because
topics are not separated by clear subheadings, or because the
subheadings provide poor descriptions of the information which follows,
or because the presentation is illogical and difficult to follow. With
these kinds of texts, it seems likely that learning might be accelerated
simply by substituting a better organised and more user friendly text on
the topic.

**4. The extent to which essential and non-essential information is
differentiated**

One of the most difficult tasks which learners face during knowledge
learning tasks is that of discriminating between those items of
information which have to be mastered (in the sense that they will be
tested at the end of the unit of study) and those items of information
which, although contained in the text or the lesson, are not part of the
teaching aim and do not actually have to be learned and remembered.

It seems reasonable to assume that learners at all levels are more
likely to attend to and learn those items of information which need to
be mastered if these items are clearly identified. There are a variety
of ways of helping learners to identify the items of information which
comprise the actual teaching aim. The following examples illustrate some
of these possibilities.

-   The teacher can build up a whiteboard summary for the students to
    copy as the lesson proceeds.
-   Written texts can be marked (using underlining or highlighting) to
    show the specific items of information which have to be learned.
-   A set of aims can be added to the written text listing the learning
    objectives for each chapter or unit of study.
-   Questions similar to those which will be used for assessment
    purposes can be inserted at regular intervals throughout the text.
-   A summary which lists the key items of information (the information
    which is to be learned and remembered) can be added to the text or
    supplied as an addition to the text.
-   The teacher can provide the learner with a copy of the test
    questions which will be asked at the end of the unit of study.
-   The learner can be given the opportunity to complete practice tests,
    or progress tests (covering the material which has to be learned and
    remembered) at regular intervals during the unit of study.

It seems reasonable to assume that any activity on the part of the
teacher which operates to clearly specify the actual content to be
mastered will result more rapid mastery of that content and this
assumption is supported by several studies (e.g. Hamilton, Siebert,
Gardner, & Talbert-Johnson, 2000; Lazarus, 1991).

**5. The extent to which the learner receives additional practice on
those aspects of the topic which are likely to cause difficulty**

Nuthall and Alton-Lee (1993) found some items of information which were
not learned and remembered even although the learner experienced the
information four times with no more than two days between each pair of
experiences. The types of knowledge learning which learners found most
difficult to remember were (a) those where the material contradicted a
strongly held belief, (b) those which introduced ideas which were new
and difficult to understand and (c) those which introduced details which
were difficult to memorise.

*Content contradicts a widely held belief.* A number of descriptive
studies have documented the fact that learners often bring previously
learned misconceptions to a unit of study, misconceptions which
interfere with their attempts to learn new concepts and principles. This
happens most often in science subjects where the scientific or \"correct\"
way of describing a particular phenomenon often differs from our
everyday way of describing that phenomenon. Nuthall and Alton-Lee (1993)
give the example of children who failed to learn the proposition *Clouds
are made of little drops of water* because most of them believed that
\"Clouds are made of white gasses\".

With well-structured instruction, these misconceptions can be readily
overcome as Muthukrishna, Carnine, Grossen & Miller (1993) have
demonstrated. But, in order for this to happen, two conditions must be
met. First, the teacher must identify those items of information which
students are having difficulty with because of previously learned
misconceptions. This can be accomplished only if the teacher includes
oral interaction or progress tests as part of the instruction. Secondly,
students must be provided with additional presentations which explain
why the new response provides a better explanation than the widely held
belief and additional practice opportunities with respect to these
particular items of information.

*Content includes a new and difficult concept*. Knowledge learning
topics often have, as one of their main aims, the introduction of
information about one or more new and unfamiliar concepts. Information
about concepts which are unfamiliar, complex, or difficult to understand
usually require the student to engage in a larger number of learning
interactions than is the case with simpler concepts. If the teacher
fails to provide the additional explanations and instructional
interactions needed in order to teach the meaning of a difficult
concept, that concept may not be learned. The meaning of new and
difficult concepts may be clarified in a variety of ways: by showing how
the term is normally employed in a variety of contexts, by the use of
definitions or explanations, by providing illustrative examples and
non-examples, by means of analogies, and so on. Another procedure which
is often suggested as a way of making new terms meaningful (and hence
more likely to be remembered) is to engage in conversational activities
which require the learner to relate new information to previously
acquired knowledge and understandings.

*Topic includes easily confused details.* The same general rule applies
to those items of information which are likely to be confused either
because the learner is being asked to recall very specific details or
because the learner is being asked to discriminate between questions
and/or answers which are closely similar and hence easily confusable.
Examples include numerical quantities, dates, proper names, and so on.
These kinds of details must be learned verbatim and accurate recall
requires additional practice. For these items, too, rate of acquisition
will depend upon the extent to which the teacher provides the learner
with additional learning opportunities and additional practice so that
the teaching aim can be achieved.

**6. The extent to which the teacher provides regular tests of progress
and reinforcement for progress towards the learning goal**

The only way in which the teacher can be sure that a given set of
knowledge responses has been acquired is to ask the learner questions
about the information which has been presented or which is being
studied. This should be done several times during the study of each new
topic so that the teacher (and the learner) can identify the targeted
knowledge responses which have and have not been acquired up to that
point. These progress tests allow the teacher (and the learner) to
identify the information which is already known, to remove this from the
pool of information which is being studied, and hence to save valuable
study time. More importantly, these tests allow the teacher (and the
learner) to identify the information which has not yet been learned and
to schedule further study of this yet-to-be-learned material.

It seems reasonable to assume that the reinforcement of progress towards
the teaching goal is as important during knowledge learning as it is
during any other kind of learning. Where the aim is to motivate
progress, reinforcement may be made contingent upon either of two
distinguishable classes of behaviour (a) engaging in activities (such as
making notes) which are likely to result in the new information being
remembered, or (b) demonstrating that increasing numbers of the targeted
knowledge responses have been learned. Although there is little evidence
one way or the other, it seems likely that reinforcing *progress*
results in more rapid progress than reinforcing study skills (Gettinger,
1989). However, it is only possible to reinforce increases in the number
of knowledge responses which have been mastered if instruction includes
regular quizzes or progress checks during the course of instruction.

For some students, studying will be reinforced by the improvement which
they are making and the feedback which they are receiving for their
answers to study questions. Others will be motivated by their desire to
avoid responding incorrectly to study questions. However, there will
always be some students for whom these sources of reinforcement are
insufficient to motivate consistent study and practice of a given unit
of knowledge. In these cases, acquisition of the new knowledge responses
can be accelerated by the application of teacher mediated reinforcement
(encouragement, praise, graphs of progress, contingent access to
reinforcing activities, and so on) made contingent upon progress towards
the learning goal.

**7. The extent to which the learner is able to apply effective study
skills**

One of the long term aims of schooling is to bring students to the point
where they can function as self-directed learners who are able to
independently locate relevant information, organise it, and learn it
effectively. The skills which are involved in the effective, independent
study of new material are variously referred to as study skills,
executive control functions, strategies, and metacognitive strategies.
We will use the term *study skills*.

Research into the skills which mature learners use during periods of
independent study has identified a number of different study skills
(e.g., Presley, Harris & Guthrie, 1992). Some of these are skills which
mature learners use to make sense of difficult or poorly organised
texts. Obviously it is important that these skills be acquired prior to
tertiary level study where their use will be assumed. At the earlier
(e.g. primary) levels of schooling, however, a choice has to be made
between the selection of well organised texts and spending time teaching
pupils to make sense of poorly organised texts. Usually it will be more
efficient simply to select clearly written and well organised texts.

However, even with well-organised texts there are still a number of
study skills which the learner can use to accelerate the acquisition of
new knowledge responses. The most important of these appear to be
self-directed comprehension monitoring, summarising, rehearsing, and
self-evaluation. While some students acquire these skills without formal
instruction, all can be directly taught and \"the research in
self-monitoring and strategy instruction has shown that students who
have been given direct or explicit instruction in strategies do better
than those who have not received such instruction\" (Goetz, Alexander &
Ash, 1992, p. 436).

**Independent reading.** In order to study new information
independently, the learner must have acquired a basic level of reading
competence. Chall (1983) argues that normally developing students make
the transition from \"learning to read\" to \"reading to learn\" at around 8
years of age. Others have argued that a reading level of about 10 years
is required for independent study. Regardless of the exact level of
reading development required, it is clear that a basic level of reading
ability is a prerequisite for independent study because, until a student
can read an expository text with sufficient comprehension and sufficient
speed to locate relevant information, little independent study is
possible. It follows therefore, that fluency in reading is the first of
the study skills which must be targeted for mastery. Until the most
basic study skill (the ability to read with fluency and comprehension)
has been acquired, the teaching of new knowledge responses is limited to
instruction in the oral mode.

**Comprehension monitoring.** Once the learner can read independently,
the next study skill to be acquired is that of monitoring one\'s
understanding of what is being read. This skill is most commonly
referred to as *comprehension monitoring*. Since we are here talking
about self-directed study skills, we will use the term *self-directed
comprehension monitoring.* Comprehension monitoring involves regularly
pausing (a) to check that the current paragraph was understood, (b) to
review the content of what has been read up until that point and (c) to
predict the content of what is to follow. Self-directed comprehension
monitoring skills have been taught using a variety of procedures of
which two, *co-operative scripts* and *reciprocal teaching*, have been
shown by research to work reasonably well.

*Co-operative scripts*. With co-operative scripts, the text to be
studied is divided into 500-600 word sections. \"Students work in pairs
and take turns summarizing sections of the material for one another.
While one student summarizes, the other listens and corrects any errors
or omissions. Then the two students switch roles, continuing in this way
until they have covered all the material to be learned\" (Slavin, 1991,
p. 173). A series of studies of the co-operative scripts procedure found
that students who study in this way obtain higher average retention test
scores than students who summarise on their own (e.g. McDonald, Larson,
Dansereau & Spurlin, 1985).

*Reciprocal teaching*. With reciprocal teaching, students work in groups
of three or four with the teacher. Once the procedure has been mastered,
students may work without the teacher. The text is divided into segments
(initially one or two paragraphs in length). Students take turns at
being the \"leader\". It is the leader\'s task to: (a) ask questions about
the text which everyone has just read, (b) frame a summary of what has
just been read, (c) predict what the author might discuss next in the
passage, (d) identify text segments which are unclear and to lead a
discussion which might clarify the meaning of that segment.

The effects of reciprocal teaching on comprehension were first described
by Palincsar and Brown (1984). Rosenshine & Meister (1994) reviewed 16
experimental evaluations of the effects of reciprocal teaching on
measures of reading comprehension. They report a median effect size of
0.32 for the 9 studies which used a standardised measure of reading
comprehension and a median effect size of 0.88 for the 10 studies which
tested comprehension on a new passage similar to those used during
practice. The higher effect sizes for the experimenter-constructed
comprehension tests was probably a function of the fact that tests
tended to be much more similar to the practice passages than the test
passages in the standardised tests of reading comprehension.

**Self-directed summarising.** The third skill which is essential for
self-directed study is the ability to construct summary notes which list
the information to be studied. These summaries may take the form of
summary notes or summary diagrams.

*Summary notes*. Learning how to construct a summary list of main points
for future study is a difficult skill to master. It may be taught by
initially providing the learner with lists of study questions which are
to be answered during reading, or by providing the learner with a set of
incomplete notes which are to be completed during study (Lazarus, 1991),
or by using a more systematic training procedure. One systematic
training procedure is that which has been described by Cook and Mayer
who developed a two-part training program in generative note taking for
science-naive students.

\"First, students learned to recognize basic prose structures such as
generalization (a main idea followed by supporting evidence),
enumeration (a list of factors or properties all pertaining to some
topic) and sequence (steps in a cause and effect process). Then,
students learned to take notes for each type of structure by writing the
generalization and supporting evidence for a generalization paragraph,
by the listing the facts and the topic for an enumeration paragraph, and
by listing the cause and effect chain for a sequence paragraph. A
teacher modelled her note-taking strategies and then students compared
their approach to that of the teacher\" (Mayer, 1992).

While the ability to make useful notes is widely regarded as an
important study skill, research into its effects on learning are
inconsistent. \"It is important to note that several studies have found
no effects of summarization, and the conditions under which this
strategy increases comprehension or retention of written material are
not well understood\" (Slavin, 1991, p. 173).

*Summary diagrams.* Summary diagrams are variously referred to as webs,
networks, concept maps and graphic organisers. *Graphic organisers* is
the term used in this account. A graphic organiser is a visual display
of key concepts in the text set out in the form of a set of linked
concepts, or a hierarchy, or a flow chart. Many people find it easier to
remember information in the form of a graphic organiser than information
in the form of summary notes. However, the research sometimes finds a
facilitating effect for graphic organisers (e.g., Darch & Carnine, 1986;
Darch, Carnine, & Kameenui, 1986; Guastello, Beasley & Sinatra, 2000)
and sometimes does not (Eggen, Kauchak & Kirk, 1978). \"There is little
direct experimental support for the utility of spatial learning
strategies as student study systems \... It may be that their best
applications occur with older (i.e. junior-high and up) students\"
(Goetz, Alexander & Ash, 1992, p. 473).

**Self-directed rehearsal.** Once the information to be learned has been
gathered together in one place, the learner is often expected to study
and learn (i.e. memorise) this information independently. This requires
a fourth set of study skills on the part of the learner. We will refer
to these skills as *self-directed rehearsal skills*. Self-directed
rehearsal of new material may take a variety of forms. It may involve
repeated reading of the material to be learned. It may involve the
repeated writing of summaries of important points. It may involve
question-and-answer sessions with peers who are studying the same
material. It may involve self-questioning or cover-copy-compare
activities of various kinds. Or it may involve a mixture of these
activities.

Students who apply self-directed rehearsal procedures to the task of
learning discrete responses such as new spelling responses learn these
more quickly than students who do not (Church, 1992). Presumably, the
same is true during the self-directed study of new information although
the question seems never to have been studied experimentally.

**Self-evaluation.** The fifth skill which needs to be acquired before a
student can engage in self-directed study is *self-evaluation*. Students
need to learn how to determine, for themselves, whether sufficient
self-directed study has been undertaken. Younger learners tend to
underestimate the amount of time (and the number of repetitions) which
are required in order to master new knowledge responses (Gettinger,
1989). (Older learners often make the same mistake as well.) It is
important, therefore, that students be taught how to make the judgement
regarding whether or not sufficient study has been undertaken to meet
the learning goal.

Self-evaluation skills can be taught by providing the learner with
repeated opportunities to engage in the following cycle of activities:
(a) set independent study goal, (b) engage in independent study, (c)
complete a test on the material, and (d) receive feedback on the
effectiveness of the independent study in which they have engaged. Mary
Beth Gettinger (1989) suggests that about six goal-study-test-feedback
cycles are sufficient to teach 8-year olds how much study is required to
meet a defined learning goal. Obviously, this training would need to be
repeated for different kinds of learning goals.
:::

::: referencesList
#### References

-   Carnine, D., Jitendra, A. K., & Silbert, J. (1997). A descriptive
    analysis of mathematics curricular materials from a pedagogical
    perspective: A case study of fractions. The Journal of Special
    Education, 18, 66-81.
-   Chall, J. S. (1983). Stages of reading development. New York:
    Academic Press.
-   Church, R. J. (1992). Measuring the effects of teaching on learning.
    Paper presented to the Second Joint AARE/NZARE Conference, Geelong,
    Australia.
-   Darch, C., & Carnine, D. (1986). Teaching content area material to
    learning disabled students. Exceptional Children, 53, 240-246.
-   Darch, C. B., Carnine, D. W., & Kameenui, E. J. (1986). The role of
    graphic organizers and social structure in content area instruction.
    Journal of Reading Behavior, 18, 275-295.
-   Eggen, P. D., Kauchak, D. P., & Kirk, S. (1978). The effect of
    hierarchical cues on the learning of concepts from prose materials.
    Journal of Experimental Education, 46(4), 7-11.
-   Gettinger, M. (1989). Effects of maximizing time spent and
    minimizing time needed for learning on pupil achievement. American
    Educational Research Journal, 26, 73-91.
-   Goetz, E. T., Alexander, P. A., & Ash, M. J. (1992). Educational
    psychology: A classroom perspective. New York: Macmillan Publishing
    Co.
-   Guastello, E. F., Beasley, T. M., & Sinatra, R. C. (2000). Concept
    mapping effects on science content comprehension of low-achieving
    inner-city seventh graders. Remedial and Special Education, 21,
    356-365.
-   Hamilton, S. L., Seibert, M. A., Gardner, R., & Talbert-Johnson, C.
    (2000). Using guided notes to improve the academic achievement of
    incarcerated adolescents with learning and behavior problems.
    Remedial and Special Education, 21, 133-140, 170.
-   Jitendra, A., Carnine, D., & Silbert, J. (1996). Descriptive
    analysis of fifth grade division instruction in basal mathematics
    programs: Violations of pedagogy. Journal of Learning Disabilities,
    6, 381-403.
-   Kelly, K., Ayllon, T., & Kandel, H. (1979). A method for building
    complex academic repertoires. In P. O. Sjoden, S. Bates, & W. S.
    Dockers (Eds.), Trends in Behavior Therapy. New York: Academic
    Press.
-   Lazarus, B. D. (1991). Guided notes, review, and achievement of
    secondary students with learning disabilities in mainstream content
    courses. Education and Treatment of Children, 14, 112-127.
-   Marks, C. B., Doctorow, M. J., & Witrock, M. C. (1974). Word
    frequency and reading comprehension. Journal of Educational
    Research, 67, 259-262, 295.
-   Mayer, R. E. (1992). Guiding students' cognitive processing of
    scientific information in text. In M. Pressley, K. R. Harris,
    & J. T. Guthrie (Eds.), Promoting academic competence and literacy
    in school. San Diego, CA: Academic Press Inc.
-   Mayer, R. E., & Moreno, R. (1998). A split-attention effect in
    multimedia learning: Evidence for dual processing systems in working
    memory. Journal of Educational Psychology, 90, 312-320.
-   Mayer, R. E., & Moreno, R. (2003). Nine ways to reduce cognitive
    load in multimedia learning. Educational psychologist, 38(1), 43-52
-   McDonald, B. A., Larson, C. D., Dansereau, D. I., & Spurlin, J. E.
    (1985). Cooperative dyads: Impact on text learning and transfer.
    Contemporary Educational Psychology, 10, 369-377.
-   Moreno, R., & Mayer, R. E. (2002). Verbal redundancy in multimedia
    learning: When reading helps listening. Journal of Educational
    Psychology, 94, 156-163.
-   Mousavi, S. Y., Low, R., & Sweller, J. (1995). Reducing cognitive
    load by mixing auditory and visual presentation modes. Journal of
    Educational Psychology, 87, 319-334.
-   Muthukrishna, N., Carnine, D., Grossen, B., & Miller, S. (1993).
    Children\'s alternative frameworks: Should they be directly
    addressed in science instruction. Journal of Research in Science
    Teaching, 30, 233-248.
-   Nuthall, G. & Alton-Lee, A. (1993). Predicting learning from student
    experience of teaching: A theory of student knowledge construction
    in classrooms. American Educational Research Journal, 30, 799-840.
-   Palincsar, A. S., & Brown, A. L. (1984). Reciprocal teaching of
    comprehension fostering and comprehension monitoring activities.
    Cognition and Instruction, 2, 117-175.
-   Pressley, M., Harris, K. R., & Guthrie, J. T. (Eds.) (1992).
    Promoting academic competence and literacy in school. San Diego, CA:
    Academic Press, Inc.
-   Rosenshine, B., & Meister, C. (1994). Reciprocal teaching: A review
    of the research. Review of Educational Research, 64, 479-530.
-   Slavin, R. E. (1991). Educational Psychology (3rd ed.). Englewood
    Cliffs, NJ: Prentice Hall.
-   Tindall-Ford, S., Chandler, P., & Sweller, J. (1997). When two
    sensory modes are better than one. Journal of Experimental
    Psychology: Applied, 4, 257-287.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Hownewknowledgeresponsesareacquired/Necessarycondition2Sufficientinteractionswitheachpropositiontoensureretention/index.md","# Necessary condition 2. Sufficient interactions with each proposition to ensure retention \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-46a3aff4bd824d7a81c5e0b06a94a21d}
There is no doubt that children can learn new knowledge from listening
to teacher talk and to the talk of other students (e.g. Doyle, Gast,
Wolery, Ault & Farmer, 1990; Gast, Doyle, Wolery & Kolenda, 1994).

It is also the case that almost any intervention which requires all
(rather than just one) of the students in a class or group to respond to
questions about knowledge topics results in a marked increase in the
amount remembered by participating students. Included under this heading
are experiments showing superior recall following lessons involving
response cards (Cavanaugh, Heward, & Donelson, 1996; Gardner, Heward &
Grossi, 1994), choral responding (Sterling, Barbetta, Heward & Heron,
1997), guided notes for students to complete (Hamilton, Siebert,
Gardner, Talbert-Johnson, 2000; Lazarus, 1991), classwide peer tutoring
(Utley, Reddy, Delquadri, Greenwood, Mortweet & Bowman, 2001),
cooperative learning groups (Maheady, Mallette, Harper & Sacca, 1991),
and guided discussion of key points (Lazarus, 1991; Wildman & Kelley,
1980).

How often does a knowledge proposition have to be heard or practised
before it will be remembered? Research by Graham Nuthall and Adrienne
Alton-Lee (Nuthall & Alton-Lee, 1992, 1993; Nuthall, 1999) provides the
beginning of an answer to this question. Nuthall and Alton-Lee tested
three upper primary school students before and after a series of lessons
and lesson activities on \"Life in the Middle Ages\" to identify those
test items which each student (a) answered incorrectly before the
lessons and (b) answered correctly after the lessons (i.e. the
propositions which had been both learned and remembered). They then went
back to their very detailed recordings of everything which the three
students had seen, heard and done during the course of the lessons and
counted the number of occasions on which each student had experienced
the remembered item of information (either by hearing it, seeing it,
saying it, or writing it).

They discovered that each of the three students learned and remembered
only those items of information which they experienced on at least four
occasions with no more than two days between any two of the four
experiences. The experience had to be with the complete proposition
although experience with definitions, analogies, examples and
non-examples could suffice provided that the pupil also experienced the
complete proposition on one or more occasions. The
four-experiences-within-two-days rule identified, with 82 per cent
accuracy, the items of information which were learned and remembered.
These results were replicated in two further studies: (a) a study of
four students who took part in a lesson on \"Cultural Differences in New
York\" (where the remembered items were predicted with 85 per cent
accuracy) and (b) a study of four students who took part in a lesson on
the weather (where the remembered items were predicted with 83 per cent
accuracy).

The Nuthall and Alton-Lee studies suggest that, in order for a new
knowledge response to be acquired and remembered, the learner must
experience the relevant item of information, in propositional form, on
at least four occasions and, furthermore, that there must be no more
than two days between each successive experience.

The Nuthall and Alton-Lee studies suggest that the mode of the
experience does not matter too much. The student may read the
information, hear it in a classroom lesson, tell it to another student,
write it down, answer a question about it, or ask a question and receive
an answer about it.

The four-times-and-no-more-than-two-days rule has several critical
implications for instruction. It means that students must come into
repeated contact with to-be-learned knowledge. It means that the timing
of practice and review is as important as the amount of practice. And it
means that new knowledge topics must be *small* enough for students to
actively review all of the to-be-learned knowledge propositions several
times over a period of a few days.

The results of the Nuthall and Alton-Lee research stand in marked
contrast to conventional classroom practice where lessons on a
particular topic generally aim to cover each important proposition once
during the course of the lesson.

The research described above identifies the amount of practice which
individual learners must experience with each of the to-be-learned items
in a knowledge learning topic. In a situation such as a classroom the
main difficulty which the teacher faces is the practical difficulty of
determining which learners have and which learners have not engaged in
this amount of practice. The simplest way of answering this question is
to provide the students with regular quizzes during the course of study
of a topic and to use these quizzes to identify those items of
information which individual students have learned and remembered and
those items of information on which further practice is required. This
procedure is particularly effective for those students who consistently
underestimate the amount of study required in order to learn and
remember new knowledge responses (Gettinger, 1989).
:::

::: referencesList
#### References

-   Cavanaugh, R. A., Heward, W. L., & Donelson, F. (1996). Effects of
    response cards during lesson closure on the academic performance of
    secondary students in an earth science course. Journal of Applied
    Behavior Analysis, 29, 403-406.
-   Doyle, P. M., Gast, D. L., Wolery, M., Ault, M. J., & Farmer, J. A.
    (1990). Use of constant time delay in small group instruction: A
    study of observational and incidental learning. The Journal of
    Special Education, 23, 369-385.
-   Gardner, R., Heward, W. L., & Grossi, T.A. (1994). Effects of
    response cards on student participation and academic achievement: A
    systematic replication with inner-city students during whole-class
    science instruction. Journal of Applied Behavior Analysis, 27,
    63-71.
-   Gast, D. L., Doyle, P. M., Wolery, M., Ault, M. J., & Kolenda, J. L.
    (1994). Instructive feedback: Effects of number and type. Journal of
    Behavioral Education, 4, 313-334.
-   Gettinger, M. (1989). Effects of maximizing time spent and
    minimizing time needed for learning on pupil achievement. American
    Educational Research Journal, 26, 73-91.
-   Hamilton, S. L., Seibert, M. A., Gardner, R., & Talbert-Johnson, C.
    (2000). Using guided notes to improve the academic achievement of
    incarcerated adolescents with learning and behavior problems.
    Remedial and Special Education, 21, 133-140, 170.
-   Lazarus, B. D. (1991). Guided notes, review, and achievement of
    secondary students with learning disabilities in mainstream content
    courses. Education and Treatment of Children, 14, 112-127.
-   Maheady, L., Mallette, B., Harper, G. F., & Sacca, K. (1991). Heads
    together: A peer-mediated option for improving the academic
    achievement of heterogeneous learning groups. Remedial and Special
    Education, 12, 25-33.
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Nuthall, G. A., & Alton-Lee, A. (1992). Understanding how students
    learn in classrooms. In M. Pressley, K. R. Harris, & J. T. Guthrie
    (Eds.), Promoting academic competence and literacy in school. San
    Diego, CA: Academic Press Inc.
-   Nuthall, G. A., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Sterling, R. M., Barbetta, P. M., Heward, W. L., & Heron, T. E.
    (1997). A comparison of active student response and on-task
    instruction on the acquisition and maintenance of health facts by
    fourth grade special education students. Journal of Behavioral
    Education, 7, 151-165.
-   Utley, C. A., Reddy, S. R., Delquadri, J. C., Greenwood, C. R.,
    Mortweet, S. L., & Bowman, V. (2001). Classwide peer tutoring: An
    effective teaching procedure for facilitating the acquisition of
    health education and safety facts with students with developmental
    disabilities. Education and Treatment of Children, 24, 1-27.
-   Wildman, B. G., & Kelly, J. A. (1980). Group news watching and
    discussion to increase the current affairs awareness of retarded
    adolescents. Child Behavior Therapy, 2, 25-36.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/Necessarycondition5Sufficientpracticetoensureretention/index.md","# Necessary condition 5. Sufficient practice to ensure retention \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d2e068bd3f1044338847e7e1978e4a96}
How much practice should the learner receive during the initial learning
phase? It is often difficult to predict just how much practice an
individual learner will require in order to acquire a generalised
correct response to the members of a stimulus class. \"Because of
individual learner differences, a specific number of examples will never
be appropriate for teaching a discrimination to all students (Becker &
Carnine, 1980, p. 456). Nevertheless, if the aim of teaching is to bring
the student to the point where they consistently respond correctly to
new examples of the stimulus class, then practice should continue until
this goal is achieved. Even when the generalisation has been acquired,
it will still need to be reviewed (practised) from time to time in order
to prevent it from being forgotten.

As new generalisations are acquired, students need to receive practice
in responding correctly to mixed sets of examples from both old and new
stimulus classes. Following instruction in recognising addition word
problems, practice can only be provided in distinguishing between
examples and non-examples of this type of problem. Following subsequent
instruction in subtraction word problems, the student should be provided
with practice in which they have to distinguish between examples of
addition problems and examples of subtraction problems. Following
instruction in how to recognise multiplication word problems, the
student can be provided with practice in what is usually referred to as
\"mixed sets\" of examples, that is, examples of addition, subtraction and
multiplication word problems. Since most curricula are cumulative, it
seems safe to assume that some practice with mixed sets should be
provided following instruction in how to recognise each major new class
of problems. Since text books rarely provide mixed sets for students to
practise on, the mixed sets which are required for this kind of practice
will, in most cases, have to be generated by the teacher.
:::

::: referencesList
#### References

-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/Necessarycondition4Differentialreinforcementforcorrectresponses/index.md","# Necessary condition 4. Differential reinforcement for correct responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8f5a49e58790494699b9f48d256c24fa}
If the child is to learn to respond differently to examples and to
non-examples of a stimulus class, then correct responding must be
differentially reinforced. Note that when the learner is practising
generalised correct responding, they may respond correctly or
incorrectly to examples and correctly or incorrectly to non-examples.
This means that there are two types of correct responses (correct
responses to examples and correct responses to non-examples). *Both
types of correct responses* must be differentially reinforced. It is as
important to reinforce correct identification of a non-example as it is
to reinforce correct identification of an example. This is the kind of
feedback which has been used in all of the experimental analyses of
concept learning cited in this section.

Although the assumption has never been studied experimentally, it seems
safe to assume that for many younger learners and for most older
learners, feedback which identifies correct responses as correct will
provide sufficient reinforcement for generalised correct responding to
develop. If learning is slow, or motivation flags, before the
generalisation has been acquired then the teacher may need to introduce
consequences for correct responding which are, in fact, reinforcing for
the individual learner.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/Necessarycondition2Exampleswhichillustratethefullextentofthegeneralisation/index.md","# Necessary condition 2.  Examples which illustrate the full extent of the generalisation \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8aa58d4944f44952ad2fc5e35857d6f4}
If the learner is to acquire a new generalisation, practice
opportunities must include a number of examples from the stimulus set
(Haring, 1985; Tateyama-Snieziek, 1989).

In order to avoid the development of misconceptions these examples must
illustrate the full range of the generalisation which is to be acquired
(Becker & Carnine, 1980; Engelmann & Carnine, 1991). Carnine (1990) **
illustrates the importance of this condition using the following
example. Young children are often taught the concept of *a fraction*
using examples which show a pie cut into fractions. This leads to the
undergeneralisation that a fraction is always smaller than 1 and leads
to errors when the teacher introduces fractions (such as two-and-a
quarter) which are greater than one. This difficulty can be avoided by
introducing examples of fractions which are both less than 1 and greater
than 1 from the outset. If this is done, the generalisation will be
acquired more rapidly because the errors which result from initially
teaching an undergeneralisation are avoided.

Although research into concept learning under classroom conditions is
relatively sparse, such research as has been undertaken supports the
conclusion that a range of positive examples, rather than just typical
examples, result in better performance on generalisation tests (Becker &
Carnine, 1980; Carnine, 1980). In one experiment, students who were
presented with a full range of positive examples of how to convert
fractions into decimals obtained higher scores on a generalisation test
(82% correct) than students who were presented with only a restricted
range of examples (40% correct) (Becker & Carnine, 1980).
:::

::: referencesList
#### References

-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
-   Carnine, D. W. (1980). Relationships between stimulus variation and
    the formation of misconceptions. Journal of Educational Research,
    74, 106-110.
-   Carnine, D. W. (1990). New research on the brain: Implications for
    instruction. Phi Delta Kapan, 72, 372-377.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications (Rev. ed.). Eugene, OR: ADI Press.
-   Haring, T. G. (1985). Teaching between-class generalization of toy
    play behavior to handicapped children. Journal of Applied Behavior
    Analysis, 18, 127-139.
-   Tateyama-Snieziek, K. M. (1989). The effects of stimulus variation
    on the generalization performance of students with moderate
    retardation. Education and Training in Mental Retardation, 24,
    89-94.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/Conditionswhichmayacceleratethelearningofnewconceptsandgeneralisations/index.md","# Conditions which may accelerate the learning of new concepts and generalisations \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f6a4939aa4404ced85892970ebf352cc}
The research into the learning of new generalisations also identifies a
number of additional teaching variables which may be managed to
accelerate the acquisition of generalised correct responding.

**1. The opportunity to experience concrete examples and non-examples**

One way of accelerating the development of generalised correct
responding is to use concrete examples and non-examples to teach the
discrimination between different stimulus classes. Teachers have long
believed that the use of concrete examples results in better
\"understanding\" and research to date is consistent with this belief
(e.g., Gersten, White, Falco & Carnine, 1982).

With younger learners and some concepts, the use of concrete examples is
almost an essential condition. \"For example, teaching the
discriminations *longer, not longer*, or *blue, not blue,* with rules or
verbal explanations, is impractical. Students who do not respond
correctly to \'Is the pencil longer than the pen?\' are unlikely to
benefit from this explanation: \'Longer means greater extension in the
horizontal dimension\'\" (Becker & Carnine, 1980, p. 453).

With other concepts, the use of concrete examples is not an essential
condition but it does help the learner to acquire the generalisation
more quickly. \"Concrete examples are used to allow the learner to
observe (e.g. by seeing, feeling, touching, holding, pushing) what
can\'t be cognitively digested and processed by the use of abstract
words\" (Kameenui & Simmons, 1990, p. 150).

**2. The opportunity to learn a definition of the stimulus class**

The process of teaching the learner to attend to and to respond to the
critical samenesses which define membership in a stimulus class can
often be accelerated by prompting attention to the critical features.
This can be accomplished in a variety of ways:

-   By teaching the definition of the stimulus class in the case of
    concepts, for example: \"An acute angle is an angle of less than 45
    degrees.\"
-   By pointing to one of the characteristics which are common to
    members of the stimulus class, for example: \"Insects have six legs.\"
-   By teaching a rule which can be used to identify members of the
    stimulus class, for example, \"If the problem asks 'How many
    altogether?' you have to add.\"
-   By teaching the student to use a previously mastered concept to
    identify examples of a new concept. For example the student who
    could identify metals but who could not identify electrical
    conductors might be told: \"All metals are conductors.\"
-   By teaching a test which can be used to identify examples: \"Does it
    feel sandy? If it feels sandy, then it is a sedimentary rock.\"

In all of these examples, the teacher is using a stimulus prompting
procedure to draw the learner's attention to the sameness which must be
attended to if the student is to respond correctly to all members of the
stimulus class. The provision of a definition at the beginning of a
concept teaching lesson greatly accelerates the acquisition of
generalised correct responding. When Ross and Carnine (1982) compared
the effects of teaching an artificial mathematics concept to 10 year old
students, 15/15 of the students who started with a definition acquired
the concept whereas only 4/15 students who received only examples and
non-examples acquired the concept.

As students become older and more knowledgeable, increasing numbers of
new generalisations can be taught in part by teaching the rule which
defines membership in the stimulus set. This is because, as the child\'s
vocabulary expands, the defining qualities of increasing numbers of
concepts can be described in words which are meaningful for the student.

Even where definitions are being taught, however, some practice with
actual examples and non-examples will almost always be necessary. There
are few students who would be able to distinguish between *similes* and
*metaphors* with a high level of accuracy after having been taught only
the definition of these two figures of speech, for example.

Note that if definitions or rules are being taught, and the rules have
exceptions, then these exceptions must also be taught. Otherwise the
student will learn an overgeneralisation. We cannot teach the concept of
fish to younger learners by defining fish as animals which live in water
without also teaching the child that whales and dolphins are not fish,
for example.

**3. Whether or not general case teaching sequences are used**

After reviewing the scientific research into the conditions which are
most effective in producing generalised correct responding, White et al.
(1988, p. 39) reached the following conclusion: \"It would appear, on the
basis of admittedly limited evidence, that general case programming is
the strategy of choice for facilitating generalisation from
instructional to applied situations\".

What is general case programming? *General case programming involves the
selection and sequencing of teaching examples in such a way as to teach
the desired generalisation.* \"A general case has been taught when, after
instruction on some tasks in a particular class, any task in that class
can be performed correctly. When a general case has been taught with
respect to a class of stimuli, we say a concept has been taught\" (Becker
& Engelmann, 1978, p. 325). A detailed account of general case
programming will be found in Engelmann and Carnine (1991).

With general case programming, a sufficient number and range of positive
examples is selected to ensure that the learner acquires the ability to
recognise the outer boundaries of the stimulus class.

With general case programming, sufficient negative examples are selected
to teach the discrimination between members and non-members of the
stimulus class.

With general case programming, examples are sequenced so that adjacent
positive examples are maximally different*.* This is the most efficient
procedure for teaching the student the outer boundaries of the stimulus
class. Faced with the fact that a yellowy-orange colour and a
reddish-orange colour are both labelled \"orange\", the learner will
quickly infer that all intermediate shades of orange must also be
labelled \"orange\" and acquisition of this colour concept will be greatly
accelerated.

With general case programming, example/non-example pairs are sequenced
so that minimally different example/non-example pairs occur together. In
teaching the concept of *vertical*, the most informative negative
example is the line which deviates only slightly from the vertical. In
teaching the concept of orange, the most informative negative example is
the one which is only slightly too yellow to be labelled \"orange\". Faced
with this example, the learner will quickly infer that all examples
which are even more yellow than this example must also be \"not orange\".
Minimally different example/non-example pairs result in faster learning
of the discrimination between examples and non-examples than
example/non-example pairs which are more obviously different (Becker &
Carnine, 1980; Carnine, 1980a, 1980b; Williams & Carnine, 1981).

With general case programming, examples and non-examples are sequenced
in such a way that only one feature changes from one example (or
non-example) to the next. To teach the difference between examples and
non-examples, the teacher presents example/non-example pairs in which
the irrelevant features are held constant and the only change from one
instance to the next is the presence or absence of the defining
characteristic. In order to respond correctly, the learner must attend
to the feature which is changing, that is, the feature which defines
membership in the stimulus class. This results in more rapid acquisition
of the two discriminations which must be acquired during the initial
learning of a new concept or generalisation (Carnine, 1980b; Schumaker,
1974; Gersten, White, Falco & Carnine, 1982; Granzin & Carnine, 1977).

A number of separate experiments have demonstrated that both normal and
learning disabled students acquire new concepts more rapidly from
teaching sequences based on the five rules of general case teaching
(e.g., Becker & Carnine, 1980; Carnine, 1980a; 1980b; Granzin & Carnine,
1977; Kelly, Gersten & Carnine, 1990; Sprague and Horner, 1984; Williams
& Carnine, 1981).

**4. The extent to which the teacher is able to keep the working memory
load low for the learner during initial teaching of the generalisation**

Children can hold in mind only a very limited number of items of
information at any one time. This must be taken into account during the
teaching of new generalisations. This is because the acquisition of a
generalised correct response typically involves practice with many more
than just three or four examples. Teachers employ a number of procedures
in their attempts to reduce working memory demands during practice with
positive and negative examples of a stimulus class.

-   The definition of the stimulus class can be presented at the
    beginning and kept in view during practice. In teaching correct use
    of the terms *integer* and *real number*, for example, the teacher
    can put the two definitions on the board and students can use these
    to prompt responding to new examples and non-examples from each
    stimulus class.
-   An example or examples from the stimulus class can be presented at
    the beginning and kept in view during practice. For example, the
    teacher could put an example of a *real number* and an example of an
    *integer* on the board and pupils could use these to prompt
    responding to new examples and non-examples from each stimulus
    class.
-   The instances can be kept in view. For example, each example could
    be written on the board under the headings *real number, integer,*
    and *neither*. If practice examples are kept in view, the samenesses
    which are common to the positive examples also remain in view
    (rather than being forgotten as new instances are presented).
-   Examples and non-examples can be sequenced so that only one feature
    changes as the learner moves from one example to the next. In this
    way the student has only to remember the single feature which has
    changed in order to continue responding correctly.

**5. The extent to which undergeneralisations and overgeneralisations
are identified and corrected**

Few generalisations are completely new to the learner. Most learners
arrive at their first geometry lesson already able to identify circles,
squares, and triangles, for example. However, these early understandings
will sometimes consist of undergeneralisations (as in the case of
students who believe that a fraction is something less than one whole)
and will sometimes consist of overgeneralisations (as in the case of
students who believe that all four sided figures are \"squares\"). (These
undergeneralisations and overgeneralisations are often referred to as
\"misconceptions\". We have avoided using the term \"misconception\" in this
account because, if a child has a misconception, we need to know what
kind of misconception it is in order to select the appropriate
corrective teaching strategy.)

The research on concept teaching shows that the teaching which is needed
to correct an undergeneralisation is different from the teaching which
is needed to correct an overgeneralisation (Engelmann & Carnine, 1991).

-   Undergeneralisations are corrected by provided additional practice
    with a wider range of positive examples.
-   Overgeneralisations are corrected by providing additional practice
    with negative examples - especially those which are being confused
    with positive examples.

These different kinds of teaching can only be provided if the teacher
has identified the type of error which the student is making (an
undergeneralisation error or an overgeneralisation error). It seems
reasonable to assume that teaching procedures which identify the
undergeneralisations and overgeneralisations held by individual
learners, and which attempt to correct these, will result in more rapid
acquisition of an accurate generalisation than will be the case with
teaching procedures which fail to identify the causes of student errors.
As far as we can determine, this assumption has yet to be tested
experimentally.
:::

::: referencesList
#### References

-   Becker, W., & Engelmann, S. (1978). Systems for basic instruction:
    Theory and application. In A. Catania & T. Brigham (Eds.), Handbook
    of applied behavior analysis: Social and instructional processes.
    New York: Irvington Publishers.
-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
-   Carnine, D. (1980a). Relationships between stimulus variation and
    the formation of misconceptions. Journal of Educational Research,
    74, 106-110.
-   Carnine, D. (1980b). Three procedures for presenting minimally
    different positive and negative instances. Journal of Educational
    Psychology, 72, 452-456.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications (Rev. ed.). Eugene, OR: ADI Press.
-   Gersten, R. M., White, W. A. T., Falco, R., & Carnine, D. (1982).
    Teaching basic discriminations to handicapped and non-handicapped
    individuals through a dynamic presentation of instructional stimuli.
    Analysis and Intervention in Developmental Disabilities, 2, 305-317.
-   Granzin, A. C., & Carnine, D. W. (1977). Child performance on
    discrimination tasks: Effects of amount of stimulus variation.
    Journal of Experimental Child Psychology, 24, 332-342.
-   Kameenui, E. J., & Simmons, D. C. (1990). Designing instructional
    strategies: The prevention of academic learning problems. Columbus,
    OH: Merrill Publishing Co.
-   Kelly, B., Gersten, R., & Carnine, D. (1990). Student error patterns
    as a function of curriculum design: Teaching fractions to remedial
    high school students and high school students with disabilities.
    Journal of Learning Disabilities, 23, 23-29.
-   Ross, D., & Carnine, D. (1982). Analytic assistance: Effects of
    example selection, subjects' age and syntactic complexity. Journal
    of Educational Research, 75, 294-298.
-   Schumaker, J. B. (1974). Training generalized receptive prepositions
    in retarded children. Journal of Applied Behavior Analysis, 7,
    611-621.
-   Sprague, J. R., & Horner, R. H. (1984). The effects of single
    instance, multiple instance, and general case training on
    generalized vending machine use by moderately and severely
    handicapped students. Journal of Applied Behavior Analysis, 17,
    273-278.
-   White, O. R., Liberty, K. A., Haring, N. G., Billingsley, F. F.,
    Boer, M., Burrage, A. et. al. (1988). Review and analysis of
    strategies for generalization. In N.G. Haring (Ed.), Generalization
    for students with severe handicaps. Seattle, WA: University of
    Washington Press.
-   Williams, P. B., & Carnine, D. W. (1981), Relationship between range
    of examples and of instructions and attention in concept attainment.
    Journal of Educational Research, 74, 144-148.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/index.md","# How conceptual responses are acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-78c3ada4e32f44a1a32ec29099f5bdda}
Much school learning involves the acquisition of new concepts,
generalisations and general principles. Common examples include learning
to identify, name and use new concepts and learning when to use and when
not to use new procedures, operations, and rules.

In a small proportion of cases, a new concept may be acquired by
learning the concept definition. For example, \"a triangle is a
three-sided figure\". In the majority of cases however, a well developed
understanding of a new generalisation such as a new concept arises only
as a result of a fairly lengthy history of contact with both examples
and non examples of the concept. The contact with these examples and
non-examples of a new concept may be specifically programmed by the
teacher or they may occur quite adventitiously as a result of exposure
to television programmes, books, study activities of various kinds,
project work, or discussion with others.

In the case where we want to ensure that the learner develops a degree
of understanding sufficient to use the new concept, the question becomes
\"How can we design a teaching communication or programme that teaches
with some examples, so that the student can then respond to any example
for the case taught?\" (Carnine & Becker, 1982, p. 249). This question
may be pictured as follows.

![Figure 4420a. The universe of positive and negative example of a new
concept which must be sampled in order to acquire a working
understanding of that
concept](../../../../../assets/images/Figure4420a.png \"Figure 4420a. The universe of positive and negative example of a new concept which must be sampled in order to acquire a working understanding of that concept\"){.image-inline}

*Figure 4420a. The universe of positive and negative example of a new
concept which must be sampled in order to acquire a working
understanding of that concept*

In order to acquire an understanding of, say, the concept of a noun the
learner must experience sufficient positive examples and sufficient
negative examples of nouns within the context of learning activities in
which correct and incorrect classification responses produce
differential feedback. The number of examples and non-examples must be
sufficient to teach the learner to respond correctly to the critical
samenesses which define membership in the stimulus class \"nouns\".

If the number or the range of positive examples experienced by the
learner is insufficient, undergeneralised responding may result. An
undergeneralisation is indicated when the learner fails to recognise
examples of the stimulus class as positive examples. If the learner
recognised some nouns as nouns but not others, this would be an example
of undergeneralisation. The following diagram illustrates the
characteristics of undergeneralised responding.

![Figure 4420b. Response characteristics of a learner who has only an
undergeneralised understanding of a new
concept](../../../../../assets/images/Figure4420b.png \"Figure 4420b. Response characteristics of a learner who has only an undergeneralised understanding of a new concept\"){.image-inline}

*Figure 4420b. Response characteristics of a learner who has only an
undergeneralised understanding of a new concept*

If the number or the range of negative examples experienced by the
learner is insufficient, overgeneralised responding may result. An
overgeneralisation is indicated when the learner responds to certain
non-examples as if they were examples of the stimulus class. If the
learner identified not only nouns but also certain other kinds of words
as nouns, this would be an example of an overgeneralisation. The
following diagram illustrates the characteristics of overgeneralised
responding.

![Figure 4420c. Response characteristics of a learner who has an
overgeneralised understanding of a new
concept](../../../../../assets/images/Figure4420c.png \"Figure 4420c. Response characteristics of a learner who has an overgeneralised understanding of a new concept\"){.image-inline}

*Figure 4420c. Response characteristics of a learner who has an
overgeneralised understanding of a new concept*

Most concept learning during the school years is cumulative. Particular
concepts are introduced at one point in the curriculum (usually as
knowledge responses) and then revisited and refined on a number of
occasions at later points in the curriculum. It is often quite
appropriate to teach a limited generalisation during, say, the early
primary school years, to extend that generalisation during, say, the
later primary school years, and perhaps not to require completely
accurate performance until the secondary school years. For example, the
stimulus class \"addition word problems\" tends to be defined during the
early school years as problems *without* irrelevant numerical
information. In the later school years, however, we would normally want
to define \"addition word problems\" more broadly to include addition
problems which *do* contain irrelevant numerical information.

The emergence of a working understanding of a new concept is signalled
when the learner is able to identify never-before-seen examples as
examples of the concept. Carnine (1990) argues that the learning of new
concepts and generalisations is greatly simplified by virtue of the fact
that human beings have an in-built ability to detect and to respond to
samenesses in the world around them. This means that generalised correct
responding can often be acquired as a result of contact with a
relatively small number of positive and negative examples -- especially
if the features which define membership in the stimulus class are
relatively easy for the learner to recognise. However it is also clear
from text book analyses that the great majority of textbooks do not
provide anything like the number of examples and non-examples which are
actually required in order to develop an accurate understanding of the
new concepts which these texts have been designed to teach. \"Students
need instruction not only on how to perform an operation correctly (such
as finding the least common denominator) but also on discriminating when
a particular operation is appropriate. This kind of discrimination
practice is lacking in most mathematics curricula\" (Kelly, Gersten &
Carnine, 1990, p. 23).

The teaching of generalised correct responding is typically postponed
until the learner can perform the response, skill or procedure which is
to be generalised. For example, the teacher normally waits until the
child can say the number words (say \"six\", \"seven\", \"eight\", and so on)
before beginning to teach understanding of the *concepts* of \"six\",
\"seven\", \"eight\" and so on. Likewise, teachers usually teach children
*how* to add using simple numerical examples before they try to teach
children how to recognise the different kinds of word problems which can
be solved by adding.

This is good practice. If the student can already perform the correct
response to at least one or two examples from the stimulus class, then
the task of teaching him or her to generalise this response to the
entire stimulus class is much simplified. If the learner can already
perform the response with a certain degree of fluency, they can give
their full attention to learning to discriminate between the target
stimulus class and other stimulus classes.

It further follows that, if the teacher wishes to teach generalised
correct responding to a student who has not yet learned how to perform
the required response (or procedure), then this response (or procedure)
should be pre-taught. That is, the learner should be taught how to
perform the response before being taught the generalisations required
for the development of generalised correct responding.

In order to acquire an accurate understanding of a new concept or
generalisation, five essential conditions must be present. Correct
responses must be prompted initially, the learner must be provided with
multiple opportunities to respond to both examples from the stimulus
class and non-examples, correct responses to examples and non-examples
must be differentially reinforced, and sufficient practice must be
provided to ensure that the new understanding is maintained (retained).
.
:::

::: referencesList
#### References

-   Carnine, D. W. (1990). New research on the brain: Implications for
    instruction. Phi Delta Kappan, 72, 372-377.
-   Carnine, D. W., & Becker, W. C. (1982). Theory of instruction:
    Generalization issues. Educational Psychology, 2, 249-262.
-   Kelly, B., Gersten, R., & Carnine, D. (1990). Student error patterns
    as a function of curriculum design: Teaching fractions to remedial
    high school students and high school students with learning
    disabilities. Journal of Learning Disabilities, 23(1), 23-29.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/Necessarycondition3Discriminationpractice/index.md","# Necessary condition 3. Discrimination practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-344b1541f9db45d29e8972683909cf80}
In order to acquire a new generalisation, the learner must learn to
distinguish between (and to respond differently to) instances which are,
and which are not, members of the stimulus class. There are few concepts
which can be taught using positive examples alone. The great majority of
concepts can only be mastered if the learner experiences both examples
and non-examples. Non-examples are necessary to teach what the concept
is *not*.

To learn the discrimination between nouns and other parts of speech, for
example, the learner must have practice in identifying (and naming)
nouns in exercises which include examples of both nouns and other parts
of speech. In order to learn the discrimination between multiplication
word problems and other kinds of problems, the learner must be provided
with practice exercises which include both multiplication problems and
other types of word problems.

The non-examples which are most informative, and which result in the
most rapid concept formation are the close-in non-examples, that is,
non-examples which are closely similar to the positive examples selected
for instruction (Becker & Carnine, 1980; Carnine, 1980a, 1980b; Williams
& Carnine, 1981).
:::

::: referencesList
#### References

-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
-   Carnine, D. (1980a). Relationships between stimulus variation and
    the formation of misconceptions. Journal of Educational Research,
    74, 106-110.
-   Carnine, D. (1980b). Three procedures for presenting minimally
    different positive and negative instances. Journal of Educational
    Psychology, 72, 452-456.
-   Williams, P. B., & Carnine, D. W. (1981), Relationship between range
    of examples and of instructions and attention in concept attainment.
    Journal of Educational Research, 74, 144-148.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/Howconceptualresponsesareacquired/Necessarycondition1Promptingofcorrectresponses/index.md","# Necessary condition 1. Prompting of correct responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9029ee3c96d04724a21bcb9249a8e26c}
When the child is first asked to distinguish between (and to name)
examples of real numbers and examples of integers, or examples of verbs
and examples of adverbs, or examples of mass and examples of weight,
they will not be able to respond correctly because they will not \"know\"
what the correct response is supposed to be. In other words, the
*response* which is appropriate to examples from an unknown stimulus
class must initially be prompted in some way. Where the response is a
concept name (which it will be in many cases), this response can be
prompted simply by telling the learner the correct name.

Although not essential, it is customary to pair the *name* of the
concept or stimulus class with a definition of the concept, that is with
a reference to the critical *sameness* which defines membership in the
stimulus class, for example \"These words are the names of things. They
are called nouns\", or \"In these problems there are a number of equal
sized sets. These problems are multiplication problems\". While the
research into concept formation is extensive (Bourne, 1966) most of this
research has involved withholding the definitions of the experimental
concepts in order to study the effects of variations in the examples and
non-examples provided. During concept teaching, in contrast, it is
customary to present the definition of a new concept from the outset and
this is clearly an appropriate practice (Ross & Carnine, 1982).

Of course, any prompts which are required during the initial stages of
instruction must be withdrawn as soon as the student can respond without
them otherwise the development of independent performance will be
postponed.
:::

::: referencesList
#### References

-   Bourne, L. E., Jr. (1966). Human conceptual behavior. Boston: Allyn
    and Bacon.
-   Ross, D., & Carnine, D. (1982). Analytic assistance: Effects of
    example selection, subjects\' age and syntactic complexity. Journal
    of Educational Research, 75, 294-298.
:::"
".//Theconditionsuponwhichlearningdepends/Verballearningprocesses/index.md","# Verbal learning processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-66e1dc3aff614a5dbc44a295aafeb9f3}
In the previous section we identified the conditions which appear to be
necessary for the acquisition of completely new behaviours, motor
skills, procedures, and other types performances (including speech). In
addition to acquiring a wide variety of performance skills, human
learners also acquire a wide variety of verbal and conceptual behaviours
and skills.

Just as we distinguished between two major types of performance learning
outcomes (the acquisition of new behaviours and the acquisition of new
procedures) so we must distinguish between several types of verbal and
conceptual learning outcomes.

The first of these, the acquisition of equivalence relations described
in Section 1, covers the case where there is a stimulus-response
relationship to be learned and there is a one-to-one correspondence
between the stimulus and the correct response.

The second of these, the acquisition of generalised correct responding
described in Section 2, covers the case where the learner has to learn
to respond correctly to a class of stimuli or events and where there is
but a single response which is conventionally considered to be correct.

The third case, the acquisition of new knowledge responses described in
Section 3, covers the case where the stimulus can take a variety of
forms and correct responses can take a variety of forms also. These
three types of learning outcomes must always be distinguished during
both teaching and research because the conditions which are necessary
for acquisition differ in each of the three cases.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Hownewproceduresareacquired/Conditionswhichmayaffecttheacquisitionofnewprocedures/index.md","# Conditions which may affect the acquisition of new procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-44770e23cdaa4e1c97e991c249a327e4}
The careful and explicit prompting of each of the steps in a procedure
results in quite rapid learning of new procedures. However, research has
identified a number of additional conditions which, although not
essential for learning, may function to accelerate the rate at which new
procedural skills are acquired.

**1. Whether the learner learns to describe the target behaviour**

Some writers have argued that new procedures can be learned more rapidly
if the learner first learns to describe (in order) the steps to be
performed (e.g., Montague & Bos, 1986) -- because the learner can then
self-prompt performance of each step in the correct order. The technical
name for this technique is *correspondence training.* It is also
referred to as *self-instruction.* There is little research evidence
demonstrating that this does, in fact happen.

**2. The extent to which troublesome components of the target skill are
identified for additional practice**

Sometimes particular steps in a procedure are more difficult to master
than others. If a particular step is proving difficult to master, faster
acquisition and mastery can often be achieved if the learner has the
opportunity for extra practice on the most difficult steps (e.g., Young,
West, Howard & Whitney, 1986).

Sometimes children want to learn new procedures although they are unable
to perform one or two of the steps in the procedure even when prompted.
For example, a child might want to learn how to find words in a
dictionary even though they cannot yet quickly recite the alphabet. The
current view is that it is more efficient to teach missing responses
separately, before introducing instruction on the procedure than to try
and shape the missing response while at the same time trying to teach
the new procedure. \"Once that has been accomplished, the chain can be
developed more readily\" (Sulzer-Azaroff & Mayer, 1991, p. 348). In the
dictionary skills example, it would almost certainly be more efficient
to bring the student to the point where they could recite the alphabet
starting from any point, *before* beginning to teach the student the
procedure for finding words in a dictionary.

**3. The type of practice schedule experienced**

Regular practice (e.g. daily practice) results in more rapid mastery of
new procedures than more widely spaced practices (Dempster & Farris,
1990). This is particularly true in cases where the teaching aim is to
develop a higher level of skill or fluency (Mayhall & Jenkins, 1977).
This is probably because more forgetting occurs between widely spaced
practices than between more closely spaced practices.
:::

::: referencesList
#### References

-   Dempster, F. N., & Farris, R. (1990). The spacing effect: Research
    and practice. Journal of Research and Development in Education, 23,
    97-101.
-   Mayhall, W. F., & Jenkins, J. R. (1977). Scheduling daily or
    less-than-daily instruction: Implications for resource programs.
    Journal of Learning Disabilities, 10, 159-163.
-   Montague, M., & Bos, C. S. (1986). The effect of cognitive strategy
    training on verbal math problem solving performance of learning
    disabled adolescents. Journal of Learning Disabilities, 19, 26-33.
-   Sulzer-Azaroff, B., & Mayer, G.R. (1991). Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart & Winston.
-   Young, K. R., West, R. P., Howard, V. F., & Whitney, R. (1986).
    Acquisition, fluency training, generalization, and maintenance of
    dressing skills of two developmentally disabled children. Education
    and Treatment of Children, 9, 16-29.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Hownewproceduresareacquired/Necessarycondition3Differentialreinforcementofsatisfactoryperformances/index.md","# Necessary condition 3: Differential reinforcement of satisfactory performances \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e3b6d70339b8406e9b9716526bff0828}
During the initial acquisition phase of learning a new procedure, it is
appropriate to differentially reinforce the successful completion of
each step in turn (e.g., Grimm, Bijou & Parsons, 1973). Once the learner
can perform a step correctly, the reinforcement for that step needs to
be removed so that the acquisition of proficiency is not delayed. Once
the learner can perform the entire procedure, it is satisfactory
completion of the entire procedure which needs to be differentially
reinforced (e.g., Luiselli & Downing, 1980) if independent performance
is to be acquired.

For some procedures (such as finding a book in the library) successful
completion of the procedure will generate its own reinforcement. For
other procedures (such as those required to work particular types of
mathematical problems) reinforcement arises from getting the correct
answer. This means that the exercises which are provided for the
practice of, say, a new maths procedure should be promptly marked so
that satisfactory performance of the new procedure is promptly
reinforced.

For some procedures (such as the procedure for studying from a text
book) satisfactory performance of the procedure may generate no
immediate reinforcement. It may not be until the learner is later tested
on the text book content that the use of a particular study procedure
generates reinforcement for the learner. Continued use of a procedure
which does not generate its own reinforcement is unlikely unless the
learner is reinforced for using the procedure. Without some immediate
reinforcement for using the new procedure, the student\'s use of the
procedure may extinguish (the student may cease to use the procedure).
:::

::: referencesList
#### References

-   Grimm, J. A., Bijou, S. W., & Parsons, J. A. (1973). A
    problem-solving model for teaching remedial arithmetic to
    handicapped young children. Journal of Abnormal Child Psychology, 1,
    26-39.
-   Luiselli, J. K., & Downing, J. N. (1980). Improving a student\'s
    arithmetic performance using feedback and reinforcement procedures.
    Education and Treatment of Children, 3, 45-49.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Hownewproceduresareacquired/Necessarycondition4Sufficientpracticetoensuremastery/index.md","# Necessary condition 4: Sufficient practice to ensure mastery \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ed469356e5f34939b03f3f07e1b86554}
Where the student can already perform most of the steps which go to make
up the procedure, acquisition may be quite rapid (e.g., Joseph & Cooper,
1991; Rivera & Smith, 1987). Nevertheless, some practice will be
required in order to learn the sequence of steps and to learn to execute
the steps in a smooth fashion (e.g., Jones, Ollendick & Shinske, 1989;
Peterson, 1984; Yeaton & Bailey, 1983).

A new skill is not usually of much use until it can be performed with a
certain amount of speed or fluency. We would not say that a student had
mastered the long multiplication procedure if he or she still needed
three minutes to work a problem which most students can work in one
minute. At the end of the acquisition phase the learner will be able to
perform the entire procedure without prompting, but the performance may
be slow and hesitant. To build fluency, a time limit should be set,
further practice opportunities provided, and performances which are both
correct and within the time limit differentially reinforced (e.g.,
Young, West, Howard, & Whitney, 1986).

Practice should take place in those situations and under those
conditions where the procedure will need to be used (e.g., Yeaton &
Bailey, 1983). If the student is able to perform the procedure but is
unsure as to when it should be used, some generalisation training will
need to be provided (e.g., Lloyd, Saltzman & Kauffman, 1981). This is
true not only for specific academic procedures such as solving
particular classes of maths problems but also for metacognitive
procedures. \"Good \[metacognitive\] strategy instruction involves
substantial teaching and practice over a long period of time and across
multiple tasks. This provides . . . ample opportunities for students to
discover when and where to use particular strategies and to adapt these
procedures to new situations\" (Borkowski & Muthukrishna, 1992, p. 491).
:::

::: referencesList
#### References

-   Borkowski, J.G., & Muthukrishna, N. (1992). Moving metacognition
    into the classroom: \"Working models\" and effective strategy
    teaching. In M. Pressley, K. R. Harris, & J. T. Guthrie (Eds.),
    Promoting academic competence and literacy in school. San Diego, CA:
    Academic Press Inc.
-   Jones, R. T., Ollendick, T. H., & Shinske, F. K. (1989). The role of
    behavioral versus cognitive variables in skill acquisition. Behavior
    Therapy, 20, 293-302.
-   Joseph, L., & Cooper, J. O. (1991). Fourth-grade students\' math
    performance with the criterion referenced curriculum. Behavior
    Modification, 15, 228-249.
-   Lloyd, J., Saltzman, N. J., & Kauffman, J. M. (1981). Predictable
    generalization in academic learning as a result of preskills and
    strategy training. Learning Disability Quarterly, 4, 203-216.
-   Peterson, L. (1984). Teaching home safety and survival skills to
    latch-key children: A comparison of two manuals and methods. Journal
    of Applied Behavior Analysis, 17, 279-295.
-   Rivera, D. M., & Smith, D. D. (1987). Influence of modeling on
    acquisition and generalization of computational skills: A summary of
    research findings from three sites. Learning Disability Quarterly,
    10, 69-80.
-   Yeaton, W. H., & Bailey, J. S. (1983). Utilization analysis of a
    pedestrian safety training program. Journal of Applied Behavior
    Analysis, 16, 203-216.
-   Young, K. R., West, R. P., Howard, V. F., Whitney, R. (1986).
    Acquisition, fluency training, generalization, and maintenance of
    dressing skills of two developmentally disabled children. Education
    and Treatment of Children, 9, 16-29.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Hownewproceduresareacquired/Necessaryconditions1Theopportunitytolearnthesequenceofsteps/index.md","# Necessary conditions 1: The opportunity to learn the sequence of steps \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-cb6a76b3a59c4b1686df76a2c593698f}
When learning a new procedure, the first thing to be learned is the
sequence of steps. This is only possible if each step is somehow
prompted in turn. These sequential prompts may take the form of
demonstrations which show the learner what to do at each step (e.g.,
Blankenship, 1978; Blankenship & Baumgartner, 1982), instructions which
tell the learner what to do (e.g., Joseph & Cooper, 1991; Kameenui,
Carnine, Darch & Stein, 1986), a combination of demonstrations plus
instructions, a permanent model which the learner can refer to (e.g.,
Rivera & Smith, 1987; Smith & Lovitt, 1975) or a demonstration plus a
permanent model (Mercer & Miller, 1992). A demonstration usually
provides a better indication than a verbal description of *how* to
perform each of the component responses. It is also possible for the
student to learn to recite the steps and to use this knowledge to
self-prompt performance of each of the steps in turn (e.g., Montague &
Bos, 1986).

In some cases, the student will also need to learn how to make decisions
about when to perform the next response, or how to make decisions about
which of several options to choose. For example, one of the steps to be
mastered in learning to cook a new recipe is that of deciding when a
dish is cooked so that the next action (removing the dish from the oven
or stove) can be taken. In order to acquire this part of the new skill,
the novice cook may need prompting regarding the stimuli which must be
attended to in order to make this decision accurately (e.g. \"Has the
meat come away from the bone?\" or \"Has it browned enough?\" or \"Does the
skewer go through without resistance?\" or \"Has it been boiling for 17
minutes?\" and so on).

Although most of the controlled research into prompting has been
undertaken by behavioural scientists (e.g., Wolery, Bailey & Sugai,
1988) the importance of clear prompting is also recognised by cognitive
scientists. \"Direct explanation with teacher modelling, helps children
acquire metacognitive knowledge, that is, explicit instruction with
feedback during strategy training is superior to asking students to
infer or abstract a strategy\'s characteristics\" (Borkowski &
Muthukrishna, 1992, p. 489).
:::

::: referencesList
#### References

-   Blankenship, C. S. (1978). Remediating systematic inversion errors
    in subtraction through the use of demonstration and feedback.
    Learning Disability Quarterly, 1, 12-22.
-   Blankenship, C. S., & Baumgartner, M. D. (1982). Programming
    generalization of computational skills. Learning Disability
    Quarterly, 5, 152-162.
-   Borkowski, J. G., & Muthukrishna, N. (1992). Moving metacognition
    into the classroom: \"Working models\" and effective strategy
    teaching. In M. Pressley, K. R. Harris, & J. T. Guthrie (Eds.),
    Promoting academic competence and literacy in school. San Diego, CA:
    Academic Press Inc.
-   Joseph, L., & Cooper, J. O. (1991). Fourth-grade students\' math
    performance with the criterion referenced curriculum. Behavior
    Modification, 15, 228-249.
-   Kameenui, E. J., Carnine, D. W., Darch, C. B., & Stein, M. (1986).
    Two approaches to the development phase of mathematics instruction.
    The Elementary School Journal, 86, 632-650.
-   Mercer, C. D., & Miller, S. P. (1992). Teaching students with
    learning problems in math to acquire, understand, and apply basic
    math facts. Remedial and Special Education, 13(3), 19-35.
-   Montague, M., & Bos, C. S. (1986). The effect of cognitive strategy
    training on verbal math problem solving performance of learning
    disabled adolescents. Journal of Learning Disabilities, 19, 26-33.
-   Rivera, D. M., & Smith, D. D. (1987). Influence of modeling on
    acquisition and generalization of computational skills: A summary of
    research findings from three sites. Learning Disability Quarterly,
    10, 69-80.
-   Smith, D. D., & Lovitt, T. C. (1975). The use of modeling techniques
    to influence the acquisition of computational arithmetic skills in
    learning-disabled children. In E. Ramp, & G. Semb (Eds.), Behavior
    analysis: Areas of research and application (pp. 283-308). Englewood
    Cliffs, NJ: Prentice Hall.
-   Wolery, M., Bailey, D. B., Jr., & Sugai, G. M. (1988). Effective
    teaching: Principles and procedures of applied behavior analysis
    with exceptional students. Boston. MA: Allyn and Bacon.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Hownewproceduresareacquired/index.md","# How new procedures are acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-145478570f4d48398fcdb8f2e1a26aec}
While some new performances must be laboriously acquired by successive
approximation, others can be acquired simply by combining previously
acquired response elements into new sequences. In this account, skills
which consist of a sequence of responses or steps (where most of the
component responses have already been acquired) are being referred to as
*procedures*. Procedures are also referred to as \"operations\" and as
\"chained tasks\". A procedure consists of a sequence of steps or
responses which must be performed in a particular order if the sequence
is to have the desired outcome. Many of the routines which we perform on
a daily basis are procedures. All mathematical operations are
procedures. Compositional writing is a procedure. Most of the skills
which are referred to as \"learning strategies\" and most of the skills
which are referred to as \"meta-cognitive skills\" are procedures.

Children are not normally asked to learn a new procedure until they can
perform each of the component responses which go to make up the
procedure. For example, the long multiplication procedure is not usually
taught until the student has mastered single digit multiplication. If
the learner can already perform each of the steps which go to make up a
new procedure, learning the new procedure is a relatively
straight-forward task. It simply involves the learner following a series
of prompts and performing each of the steps in turn. With practice, the
completion of each step will become the cue for beginning the next step
and, with further practice, performance of the entire sequence of steps
becomes automatic.

Assuming that the learner has already acquired the behaviours which will
be needed at each step, acquisition of a new procedure depends upon the
presence of four essential conditions: (a) the learner needs to
experience prompts (scaffolds) which describe what is to be done at each
step, (b) the procedure needs to be practised until prompting is no
longer required, (c) improvements during practice need to be
differentially reinforced, and (d) practice needs to continue until a
functional level of performance fluency has been achieved (Blankenship,
1978; Dunlap & Dunlap, 1989; Jitendra & Hoff, 1996; Jones, Ollendick &
Shinske, 1989; Lim, Dixon & Moore, 1996; Lloyd, Saltzman & Kauffman,
1981; Luiselli & Downing, 1980; Paine, Carnine, White & Walters, 1982;
Peterson, 1984; Rivera & Smith, 1988; Sugai & Smith, 1986; Yeaton &
Bailey, 1983).
:::

::: referencesList
#### References

-   Blankenship, C. S. (1978). Remediating systematic inversion errors
    in subtraction through the use of demonstration and feedback.
    Learning Disability Quarterly, 1, 12-22.
-   Dunlap, L. K., & Dunlap, G. (1989). A self-monitoring package for
    teaching subtraction with regrouping to students with learning
    disabilities. Journal of Applied Behavior Analysis, 22, 309-314.
-   Jitendra, A. K., & Hoff, K. (1996). The effects of schema-based
    instruction on the mathematical word-problem-solving performance of
    students with learning disabilities. Journal of Learning
    Disabilities, 29, 422-431.
-   Jones, R. T., Ollendick, T. H., & Shinske, F. K. (1989). The role of
    behavioral versus cognitive variables in skill acquisition. Behavior
    Therapy, 20, 293-302.
-   Lim, E. L., & Dixon, R. S., & Moore, D. W. (1996). Worked examples
    versus non-goal-specific problems: a test of schema development in
    geometry. Educational Psychology, 16, 421-431.
-   Lloyd, J., Saltzman, N. J., & Kauffman, J. M. (1981). Predictable
    generalization in academic learning as a result of preskills and
    strategy training. Learning Disability Quarterly, 4, 203-216.
-   Luiselli, J. K., & Downing, J. N. (1980). Improving a student\'s
    arithmetic performance using feedback and reinforcement procedures.
    Education and Treatment of Children, 3, 45-49.
-   Paine, S. C., Carnine, D. W., White, W. A. T., & Walters, G. (1982).
    Effects of fading teacher presentation structure (covertization) on
    acquisition and maintenance of arithmetic problem-solving skills.
    Education and Treatment of Children, 5, 93-107.
-   Peterson, L. (1984). Teaching home safety and survival skills to
    latch-key children: A comparison of two manuals and methods. Journal
    of Applied Behavior Analysis, 17, 279-295.
-   Rivera, D., & Smith, D. D. (1988). Using a demonstration strategy to
    teach mid-school students with learning disabilities how to compute
    long division. Journal of Learning Disabilities, 21, 77-81.
-   Sugai, G., & Smith, P. (1986). The equal additions method of
    subtraction taught with a modeling technique. Remedial and Special
    Education, 7, 40-48.
-   Yeaton, W. H., & Bailey, J. S. (1983). Utilization analysis of a
    pedestrian safety training program. Journal of Applied Behavior
    Analysis, 16, 203-216.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Hownewproceduresareacquired/Necessaryconditions2Theopportunitytoengageinunpromptedpractice/index.md","# Necessary conditions 2: The opportunity to engage in unprompted practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c1aef89101774042a895aa852b242b06}
The aim of procedural learning is to get to the stage where one can
perform the procedure independently, that is, without assistance. To
achieve this goal the learner must have the opportunity to engage in
unprompted practice. This means that, as the student acquires the
ability to perform parts of the procedure without error, the prompts for
those steps should be removed so that acquisition is not delayed (e.g.,
Chandler, Schuster & Stevens, 1993; Paine, Carnine, White, & Walters,
1982; Wolery, Ault, Gast & Doyle, 1990).
:::

::: referencesList
#### References

-   Chandler, W., Schuster, J. W., & Stevens, K. B. (1993). Teaching
    employment skills to adolescents with mild and moderate disabilities
    using a constant time delay procedure. Education and Training in
    Mental Retardation, 28, 155-168.
-   Paine, S. C., Carnine, D. W., White, W. A. T., & Walters, G. (1982).
    Effects of fading teacher presentation structure (covertization) on
    acquisition and maintenance of arithmetic problem-solving skills.
    Education and Treatment of Children, 5, 93-107.
-   Wolery, M., Ault, M. J., Gast, D., & Doyle, P. M. (1990). Comparison
    of constant time delay and the system of least prompts in teaching
    chained tasks. Education and Training in Mental Retardation, 25,
    243-257.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Howcompletelynewbehavioursandskillsareacquired/Conditionswhichcanacceleratetheacquisitionofnewbehaviours/index.md","# Conditions which can accelerate the acquisition of new behaviours \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bcd07c6e68094613a07e19271f8bd1dd}
Research has identified a number of additional conditions which,
although not essential for learning, may function to accelerate the rate
at which new behaviours and skills are acquired.

**1. Teaching the learner to describe the target behaviour**

Sometimes the learner is taught to recite a description of the movements
which go to make up the new performance. For example, the child who is
learning to write the letter U might be taught to say \"Down and up and
down.\" The technical name for this technique is *correspondence
training.* It is also referred to as *self-instruction.* There is some
experimental evidence to suggest that correspondence training may speed
up the acquisition of new behaviours (Blandford & Lloyd, 1987; Vintere,
Hemmes, Brown, & Poulson, 2004; Ziegler, 1987). Presumably this is
because correspondence training allows the learner to self-evaluate
their own performance and their progress towards the goal of skilled
performance. Obviously this technique can only be used with older
learners, that is, learners who can quickly master the verbal
description of competent performance. Also, many motor skills are
virtually impossible to describe in words.

**2. The quality of the demonstrations/models provided**

A logical analysis of prompting indicates that prompts may vary with
respect to informativeness -- with written descriptions and oral
descriptions being less informative than video models and live models.
However, there has been little controlled research into the relative
effectiveness of different kinds of prompts in accelerating the
acquisition of completely new behaviours. Sometimes new performances can
be prompted using physical guidance. For example a coach may guide the
novice golfer's initial attempts to execute a stroke, or the teacher may
guide the novice printer\'s hand through the initial attempts to print a
new letter. Although this practice has been little studied, practising
teachers attest to its effectiveness presumably because it functions to
show the learner what a competent response \"feels like\" and hence
enhances the learner's ability to self-evaluate their own practice
responses.

**3. The extent to which troublesome components of the target skill are
identified for additional practice**

Sometimes there are particular parts or components of a skill which
prove particularly troublesome or difficult to master. For example, a
young child may be having difficulty in pronouncing the \|s\| sound, or
the novice typist may be having difficulty in mastering a particular key
stoke, or the novice soccer player may be having difficulty in trapping
a ball which has been passed to them. When this kind of difficulty
arises, coaches often schedule additional practice on the difficult
movement and this has been shown to be an effective technique (Alison &
Ayllon, 1980; Koop & Martin, 1983) provided the learner returns to
practising the entire skill as soon as the difficulty has been overcome.
Of course, some skills consist of components which cannot be practised
separately because they are part of a single co-ordinated movement. It
is not possible to practise just part of a forward roll for example.

**4. The type of practice schedule experienced**

The acquisition of new behaviours and skills almost always proceeds more
rapidly if the learner experiences frequent short practices (e.g. daily
practices) rather than longer, more widely spaced practices. This is
particularly true in cases where the teaching aim is to develop a higher
level of skill or fluency (Mayhall & Jenkins, 1977). For a review of
research on the spacing effect, see Dempster and Farris (1990).

**5. The quality of the feedback provided**

Feedback following practice responses can vary with respect to its
informativeness. Quite dramatic increases in the rate of acquisition of
new behaviours has been demonstrated simply by increasing the quality of
the feedback which the learner receives following practice responses
(e.g., Trap, Milner-Davis, Joseph & Cooper, 1978).

**6. The extent to which the learner is able to self-evaluate their own
practice responses**

Sometimes the learner is taught how to self-evaluate their own practice
responses. For example, the novice printer can be shown how to use
acetate copies of letters to evaluate the accuracy of their printing
attempts, the novice sportswoman can be taught how to administer their
own ten-trial tests, and so on. The advantage of teaching the learner
how to evaluate their own performance is that this frees the learner to
engage in independent practice instead of having to wait until a teacher
or coach is available to evaluate their performance (Sweeney, Salva,
Cooper & Talbert-Johnson, 1993). This allows learners to practise on
their own and hence to make faster rates of progress.
:::

::: referencesList
#### References

-   Allison, M. G., & Ayllon, T. (1980). Behavior coaching in the
    development of skills in football, gymnastics, and tennis. Journal
    of Applied Behavior Analysis, 13, 297-314.
-   Blandford, B. J., & Lloyd, J. W. (1987). Effects of a
    self-instructional procedure on handwriting. Journal of Learning
    Disabilities, 20, 342-346.
-   Brown, R. E., Copeland, R. E., & Hall, R. V. (1986). Effects of
    principal implemented procedures on student acquisition of
    multiplication facts. Education and Treatment of Children, 9,
    202-220.
-   Dempster, F. N., & Farris, R. (1990). The spacing effect: Research
    and practice. Journal of Research and Development in Education, 23,
    97-101.
-   Koop, S., & Martin, G. L. (1983). Evaluation of a coaching strategy
    to reduce swimming stroke errors with beginning age-group swimmers.
    Journal of Applied Behavior Analysis, 16, 447-460.
-   Mayhall, W. F., & Jenkins, J. R. (1977). Scheduling daily or
    less-than-daily instruction: Implications for resource programs.
    Journal of Learning Disabilities, 10, 159-163.
-   Sweeney, W. J., Salva, E., Cooper, J. O., & Talbert-Johnson, C.
    (1993). Using self-evaluation to improve difficult-to-read
    handwriting of secondary students. Journal of Behavioral Education,
    3, 427-443.
-   Trap, J. J., Milner-Davis, P., Joseph, S., & Cooper, J. O. (1978).
    The effects of feedback and consequences on transitional cursive
    letter formation. Journal of Applied Behavior Analysis, 11, 381-393.
-   Vintere, P., Hemmes, N. S., Brown, B. L., & Poulson, C. L. (2004).
    Gross-motor skill acquisition by preschool dance students under
    self-instruction procedures. Journal of Applied Behavior Analysis,
    37, 305-322.
-   Ziegler, S. G. (1987). Effects of stimulus cueing on the acquisition
    of ground strokes by beginning tennis players. Journal of Applied
    Behavior Analysis, 20, 405-411.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Howcompletelynewbehavioursandskillsareacquired/Necessarycondition3Thedifferentialreinforcementofimprovementsinperformance/index.md","# Necessary condition 3: The differential reinforcement of improvements in performance \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-1d9e4620bf974a86843fc298354e1576}
The third essential condition which must be met in order for new
behaviours to be acquired is the differential reinforcement of
improvements in performances during practice. Unless improvements
generate more reinforcement than non-improvements, improvement does not
occur. There has been fairly extensive research into what happens to
skill development when the learner is required to practise without any
feedback regarding the accuracy of their practice responses. Without
this feedback, no improvement in accuracy occurs (Allison & Ayllon,
1980; Buzas & Ayllon 1981; Fitterling & Ayllon, 1983; Koop & Martin,
1983; Lahey, Busemeyer, O\'Hara & Beggs, 1977; Shapiro & Shapiro, 1985;
Sweeney, Salva, Cooper & Talbert-Johnson, 1993; Trap, Milner-Davis,
Joseph & Cooper, 1978; Ward, Crouch & Patrick, 1998).

*Differential reinforcement provided by the natural environment.* Often
the differential reinforcement of improvements in performance is
provided by the natural environment and occurs automatically and without
any intervention on the part of a human teacher or coach.

-   When the child is learning to walk, to run, to ride a bicycle, to
    skate, or to ski, improvements in skill are reinforced by the
    increased mobility which the child achieves. Incompetent
    performances, on the other hand, result in falls which, if not
    painful, are certainly embarrassing. In other words, competent
    performances are automatically reinforced and incompetent
    performances are automatically punished.
-   The same is true of many sports skills. As competence increases, the
    child\'s ability to win points, runs, goals, baskets, and so on,
    increases. Increasingly skilled performance in the game or sport
    produces increasingly higher scores and increasing amounts of
    reinforcement.
-   Musical performance skills are also differentially reinforced by the
    product of the behaviour. The initial, unskilled and hesitant
    attempts to play a new tune generate little reinforcement. But each
    improvement in performance is reinforced by an increasingly melodic
    and better sounding result.

*Differential reinforcement provided by the social environment.* Where
increases in competence are not automatically reinforced by the results
of the performance, this differential reinforcement must be provided by
another person. This is the case with all social skills such as learning
to talk, learning what to say in different situations and how to say it,
and learning the eye contact, demeanour and body language responses
which are appropriate to different situations. Where the physical
environment fails to provide differential reinforcement, this
reinforcement may be provided by a teacher (e.g. Trap et al., 1978), a
coach (e.g. Buzas & Ayllon, 1981), a parent (e.g., Hart & Risley, 1995)
or a peer (e.g. Ward et al., 1998).

One of the reasons why oral language is acquired so rapidly during the
first four years of life is because the social environment provides all
three of the essential conditions just listed. The young child is
constantly surrounded by models of competent language use as adults talk
with each other and with the child. The child is involved in literally
hundreds of practice trials every day as caretakers and siblings
interact with the child (Hart & Risley, 1995). And the nature of
conversational interactions is such that when the utterances of the
child are comprehensible to others, the conversation proceeds (that is,
comprehensible utterances are reinforced) whereas when the utterances of
the child are not comprehensible the conversation comes to a halt (that
is, incomprehensible utterances are not reinforced).

Note that increasingly competent language responses are reinforced in
many different ways. Let us say, for example, that the child says
\"drink\". If the request is articulated sufficiently well for the
listener to understand it, the child's attempt to say the word \"drink\"
is likely to be reinforced with a drink whereas, if the utterance is
only a poor approximation and is not understood, the request may not be
met. The technical term for an utterance which is a request for
something is a \"mand\". Many of the child\'s earliest language responses
are mands and well formed mands (oral requests) generate reinforcement
every time a caretaker complies with the request.
:::

::: referencesList
#### References

-   Allison, M. G., & Ayllon, T. (1980). Behavior coaching in the
    development of skills in football, gymnastics, and tennis. Journal
    of Applied Behavior Analysis, 13, 297-314.
-   Buzas, H. P., & Ayllon, T. (1981). Differential reinforcement in
    coaching tennis skills. Behavior Modification, 5, 372-385.
-   Fitterling, J. M., & Ayllon, T. (1983). Behavioral coaching in
    classical ballet: Enhancing skill development. Behavior
    Modification, 7, 345-368.
-   Hart, B., & Risley, T. R. (1995). Meaningful differences in the
    everyday experience of young American children. Baltimore: Paul H.
    Brookes.
-   Koop, S., & Martin, G. L. (1983). Evaluation of a coaching strategy
    to reduce swimming stroke errors with beginning age-group swimmers.
    Journal of Applied Behavior Analysis, 16, 447-460.
-   Lahey, B. B., Busemeyer, M. K., O\'Hara, C., & Beggs, V. E. (1977).
    Treatment of severe perceptual-motor disorders in children diagnosed
    as learning disabled. Behavior Modification, 1, 123-140.
-   Shapiro, E. S., & Shapiro, S. (1985). Behavioral coaching in the
    development of skills in track. Behavior Modification, 9, 211-224.
-   Sweeney, W. J., Salva, E., Cooper, J. O., & Talbert-Johnson, C.
    (1993). Using self-evaluation to improve difficult-to-read
    handwriting of secondary students. Journal of Behavioral Education,
    3, 427-443.
-   Trap, J. J., Milner-Davis, P., Joseph, S., & Cooper, J. O. (1978).
    The effects of feedback and consequences on transitional cursive
    letter formation. Journal of Applied Behavior Analysis, 11, 381-393.
-   Ward, P., Crouch, D. W., & Patrick, C. A. (1998). Effects of
    peer-mediated accountability on opportunities to respond and correct
    skill performance by elementary school children in physical
    education. Journal of Behavioral Education, 8, 103-114.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Howcompletelynewbehavioursandskillsareacquired/Necessarycondition2Theopportunitytopractise/index.md","# Necessary condition 2: The opportunity to practise \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-386c8f239064463a840a8981e11010ae}
The second condition which must be present, if the learner is to acquire
the ability to perform a completely new behaviour, is the opportunity to
practise that behaviour. When the behaviour to be acquired is completely
new, initial attempts to imitate the model only result in approximations
to the final skilled performance. Further improvements require further
practice with improvements being differentially reinforced. In many
cases, extensive amounts of practice are required. Learning to pronounce
correctly all of the English language phonemes requires two to three
years of daily practice. Mastering the basic handwriting skills also
takes several years (although the amount of practice each day is usually
much less than it is for learning to talk). Mastery of a musical
instrument may take six to eight years of daily practice.

Generally speaking, the speed with which new behaviours are acquired is
directly related to the amount of practice engaged in by the learner.
The infant who has many conversations with caregivers each day acquires
the ability to pronounce new words (and an understanding of the meanings
of those words) more quickly than the infant who has few conversations
with caregivers (Hart & Risley, 1995).
:::

::: referencesList
#### References

-   Hart, B., & Risley, T. R. (1995). Meaningful differences in the
    everyday experience of young American children. Baltimore: Paul H.
    Brookes.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Howcompletelynewbehavioursandskillsareacquired/Necessarycondition1Theopportunitytoobservemodelsofcompetentperformance/index.md","# Necessary condition 1: The opportunity to observe models of competent performance \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3675b199322d4e2f9289e888dc439329}
The first condition necessary for the acquisition of a completely new
behaviour is for the learner to be able to observe someone else
performing the behaviour. This is often referred to as the opportunity
to watch a model of the new behaviour. This model may take the form of a
teacher demonstration, the opportunity to observe others performing the
skill in real life, or the opportunity to view a filmed or videotaped
demonstrations of others performing the skill.

There is some debate as to whether or not a model of competent
performance is strictly necessary in order to acquire a new skill. It is
possible to shape completely new behaviours in laboratory animals simply
by differentially reinforcing approximations to the final behaviour and
this suggests that the opportunity to observe a model is not strictly
necessary during the acquisition of new behaviours. On the other hand,
young children who have been completely deprived of models of human
speech (either through severe neglect or as a result of complete
deafness) do not acquire speech (Curtis, 1977; Shaffer, 1989) and this
suggests that listening to models of oral language are necessary for the
development of language. Either way, the learning of new behaviours
occurs so very much more quickly when the learner has a model of the
target behaviour to copy that, for all practical purposes, such models
may be considered a necessary condition for the human learning of new
skills (e.g. Allison, & Ayllon, 1980; Buzas & Ayllon 1981; Fitterling &
Ayllon, 1983).
:::

::: referencesList
#### References

-   Allison, M. G., & Ayllon, T. (1980). Behavior coaching in the
    development of skills in football, gymnastics, and tennis. Journal
    of Applied Behavior Analysis, 13, 297-314.
-   Buzas, H. P., & Ayllon, T. (1981). Differential reinforcement in
    coaching tennis skills. Behavior Modification, 5, 372-385.
-   Curtis, S. (1977). Genie: A psycholinguistic study of a modern-day
    \"wild child\". Orlando, FL: Academic Press.
-   Fitterling, J. M., & Ayllon, T. (1983). Behavioral coaching in
    classical ballet: Enhancing skill development. Behavior
    Modification, 7, 345-368.
-   Shaffer, D. R. (1989). Developmental psychology: Childhood and
    adolescence (2nd ed.). Pacific Grove, CA: Brooks/Cole.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/Howcompletelynewbehavioursandskillsareacquired/index.md","# How completely new behaviours and skills are acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2169eea191dd4f54aa8c6822fcfc13ff}
Much learning involves learning how to perform new responses, behaviours
and actions, that is, ones which cannot currently be performed. In this
account we are referring to this type of learning outcome as the
acquisition of new behaviours.

The critical defining characteristic of this kind of learning outcome is
that the new skills cannot be acquired simply by imitation. Practice
(often considerable practice) is also required. Practice is required in
order to develop the sensory-motor coordination which is characteristic
of competent performance. Included under the heading *acquisition of new
behaviours* is the acquisition of all large motor skills (such as ball
handling skills), all fine motor skills (such as handwriting) and early
speech development (which involves learning to coordinate the movement
of the lips, mouth, tongue, larynx and lungs).

Descriptive studies of the development of pronunciation skills, eye-hand
co-ordination skills, and large motor skills provide strong support for
the view that completely new behaviours and skills are acquired by a
process of successive approximations. Central to the process of
successive approximation is the process of induction. These processes
are described by Baldwin and Baldwin (1986) as follows.

How are new responses created in an individual's repertoire? . . .
Variability is a natural part of human behavior. Each time we greet a
friend or say our names, there are usually variations in pitch,
loudness, tone of voice, inflections and other subtleties. We rarely
repeat any behavior in exactly the same way on two different occasions.
Whenever people's behavior is variable and some of these variations lead
to reinforcement but others do not, the behavior is under differential
reinforcement. As you would expect, the reinforced variations become
more frequent while the nonreinforced or punished variations become less
frequent. When a young child is first given a spoon while eating, the
child may stick the spoon into the apple sauce in any of a variety of
different ways. If the spoon is upside down, it fails to pick up much
apple sauce and fails to produce much reinforcement. If the spoon is
right side up, the child may succeed in loading it with a mouthful of
apple sauce (Baldwin & Baldwin, 1986, p. 148-9).

There are processes that often accompany differential reinforcement that
result in the creation of new behaviour. These creative processes are
*induction* and *shaping*, both of which allow us to develop new
behavior patterns that lie beyond old response classes. When an operant
is reinforced and increases in frequency, similar responses may also
appear and increase in frequency even though they have not been
reinforced. This process is called induction to indicate that
reinforcement has induced changes in behaviors that are similar to those
that were reinforced (Baldwin & Baldwin, 1986, p. 156).

Baldwin and Baldwin give the example of someone who is acquiring
increasingly competent high jumping skills.

When a person first learns to high jump, there is usually a broad range
of variation in the height of the early jumps. Some may be only 5 feet,
the majority may be 5.5 feet, and the highest may be 6 feet . . . When
differential reinforcement is initiated, reinforcement may be given for
all jumps of 5.5 to 6 feet, but not for other heights. The person soon
learns to produce more of the higher jumps and fewer shorter jumps. The
high jumper may be learning many skills for approaching the crossbar
from the best angle, selecting the correct spot for jumping, tensing the
muscles more, thrusting harder with the takeoff leg, turning more
smoothly in midair to avoid hitting the bar, and so forth. All these
skills are reinforced when they result in higher jumps; and eventually
the average jump increases from 5.5 to 5.75 feet . . . As these skills
are mastered, the person may actually be able to produce jumps higher
than the original 6-foot maximum jump. New behavior has been created via
induction. This new behavior . . . appears as a natural consequence of
learning the skills for higher jumping, even if no jumps above 6 feet
are ever reinforced. Typically, newly induced behaviour *is* reinforced.
A coach who is reinforcing 6-foot jumps is very likely to give even more
reinforcement for jumps higher than 6 feet (Baldwin and Baldwin, 1986,
p. 156-7).

Notice that differential reinforcement, whether provided by the natural
environment or by a coach can function to shape many different
dimensions of performance. Differential reinforcement can function to
shape accurate pronunciation, more skilful performance (as in the high
jumping example above), more forceful responding (as in learning to kick
or throw a ball further), faster responding, and so on.

In order for a completely new response or behaviour to be acquired by
the learner, three essential conditions must be present. The learner
must have models of competent performance which he or she can emulate,
the learner must have the opportunity to practice the new behaviour, and
improvements in performance must be differentially reinforced either by
the natural environment or else by another person.
:::

::: referencesList
#### References

-   Baldwin, J. D. & Baldwin, J. I. (1986). Behavior principles in
    everyday life (2nd ed.). Englewood Cliffs, NJ: Prentice Hall.
:::"
".//Theconditionsuponwhichlearningdepends/Shapingprocesses/index.md","# Shaping processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e1100063d85b443daf3de2d1f26e7913}
Most research into the conditions affecting learning has been research
into acquisition. Here too, the conditions which are necessary for
learning depend upon the type of competency which the learner is
attempting to acquire. Acquisition outcomes may be grouped into two
general classes: (a) the acquisition of new behaviours and motor skills
of various kinds, and (b) the acquisition of competencies which are
primarily verbal or conceptual. In this section we will attempt to
identify the conditions which are necessary for the acquisition of new
performance and motor skills of various kinds.

There are two general classes of performance outcomes which need to be
distinguished: (a) the acquisition of completely new behaviours and
skills (that is, behaviours which have never been performed before) and
(b) the acquisition of new procedures, operations, and competencies
which involve the recombination of previously acquired skills. In this
section and the section which follows we will attempt to identify the
conditions which are necessary for (a) the acquisition of completely new
behaviours and (b) the acquisition of new procedures and operations.
:::"
".//Theconditionsuponwhichlearningdepends/Motivationalprocesses/index.md","# Motivational processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9319e52561344e7188b1c41ff45c6d98}
The concept of motivation has had a chequered history in psychology and,
as a result, has accrued many different meanings. Frequently the term
motivation is used to refer to some kind of biological force or internal
state, an internal state which directs behaviour and governs the degree
of effort which the learner is willing to put into particular tasks. In
this book we will use the term motivation to refer to the level of
effort which a learner is observed to be putting into completing a
particular task or activity without making any inferences about the
learner's inner state. This will enable us to measure motivation by
measuring productivity, that is the work accomplished while completing
particular tasks or while engaged in particular classes of activity.

Closely allied to the concept of motivation (in the productivity sense)
is the concept of persistence. We will use the term persistence to refer
to productivity over time. This is close to the dictionary definition of
persistence as the tendency to continue working in the face of
difficulties or obstacles.
:::"
".//Theconditionsuponwhichlearningdepends/Motivationalprocesses/Howmotivationandpersistencedevelop/Necessarycondition2Thematchinglawfornegativereinforcement/index.md","# Necessary condition 2. The matching law for negative reinforcement \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f45583bb2ec04def94c9db00e2d25f63}
In some classrooms (and families) teachers (and parents) attempt to
maintain the motivation to complete classroom (and household) tasks
using negative reinforcement contingencies. In these situations, the
level of motivation to complete particular tasks will be directly
related to the extent to which compliance has been successful in
avoiding punishment (or more successful than alternative responses in
avoiding punishment) in the past. Experimental demonstrations of the use
of negative reinforcement to increase or maintain motivation or
productivity in the classroom are rare and those that have been
undertaken tend to show that positive reinforcement and negative
reinforcement contingencies have similar effects on effort (e.g.
Broughton & Lahey, 1978; Leach & Tan, 1996). However, as motivators,
negative reinforcement contingencies have an important unwanted side
effect and that is they often result in a decreased liking for both the
task and the teacher (Morris & Redd, 1975).

One of the ways of avoiding the negative effects on liking for the task
is to combine positive and negative reinforcement contingencies so that
task completion earns part of a reward while failure to complete the
task loses part of a reward. This type of differential reinforcement
contingency can have an even stronger motivating effect than the
reinforcement contingency on its own (Kelley & McCain, 1995; McLaughlin
& Malaby, 1974; Morris & Redd, 1975; Pfiffner & O'Leary, 1987).
:::

::: referencesList
#### References

-   Broughton, S. F., & Lahey, B. B. (1978). Direct and collateral
    effects of positive reinforcement, response cost, and mixed
    contingencies for academic performance. Journal of School
    Psychology, 16, 126-136.
-   Kelley, M. L., & McCain, A. P. (1995). Promoting academic
    performance in inattentive children: The relative efficacy of
    school-home notes with and without response cost. Behavior
    Modification, 19, 357-375.
-   Leach, D. J., & Tan, R. (1996). The effects of sending positive and
    negative letters to parents on the classroom behaviour of secondary
    school students. Educational Psychology, 16, 141-154.
-   McLaughlin, T. F., & Malaby, J. E. (1974). Note on combined and
    separate effects of token reinforcement and response cost on
    completing assignments. Psychological Reports, 35, 1132.
-   Morris, E. K., & Redd, W. H. (1975). Children's performance and
    social preference for positive, negative, and mixed adult-child
    interactions. Child Development, 46, 525-531.
-   Pfiffner, L. J., & O\'Leary, S. G. (1987). The efficacy of
    all-positive management as a function of the prior use of negative
    consequences. Journal of Applied Behavior Analysis, 20, 265-271.
:::"
".//Theconditionsuponwhichlearningdepends/Motivationalprocesses/Howmotivationandpersistencedevelop/Conditionswhichmayaffectmotivation/index.md","# Conditions which may affect motivation \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a120f69f174c4ecf8299f0bf1cbb8905}
While a minimum level of reinforcement, success, recognition, or reward
is an essential condition for continued motivation, the actual level of
motivation of individual children is also affected by a number of other
variables. A child's motivation to work at a particular type of task or
activity, for example, is affected by the extent to which that activity
has previously generated reinforcement, the schedule of reinforcement
generated, the type of reinforcement generated, the amount of effort
involved in generating reinforcement, the nature of the performance
required in order to generate reinforcement, the ratio of reinforcing to
aversive outcomes generated, and the degree to which the learner is able
to control the activity and the consequences of that activity.

**1. Variations in the prior history of reinforcement generated by an
activity**

Some children have experienced frequent reinforcement for engaging in a
particular class of activities (such as writing) in the past. For such
children, the introduction of additional reinforcement (such as a reward
for writing) has little or no additional effect. This observation has
led some writers to conclude, not that rewards may sometimes have no
effect on motivation, but that they actually undermine motivation (Kohn,
1999). This is often referred to as the \"overjustification effect\" or as
the \"undermining effect\". In an extensive review of the scientific
literature, Judy Cameron and David Pierce have shown that the
overjustification effect does not occur and that reinforcing children
who are already highly motivated simply has no effect, not an
undermining effect (Cameron & Pierce, 2002).

What the Cameron and Pierce review does show is that the effects of
reinforcement depend upon the extent to which a particular behaviour or
activity has been reinforced in the past and that it is the students who
are lacking in motivation to complete a particular type of learning task
(such as writing) whose performance is most strongly affected when the
teacher introduces a reinforcement contingency for completing that task
or for completed that task to a particular standard.

**2. Variations in the schedule of reinforcement generated by an
activity**

Desired student behaviours sometimes generate reinforcement for the
student and sometimes do not. The frequency with which a particular
behaviour generates reinforcement is referred to as the schedule of
reinforcement for that behaviour. Experimental research has identified a
number of schedule effects, that is, a number of ways in which
motivation is differentially affected by different schedules of
reinforcement.

*Continuous schedules produce the most rapid changes.* Continuous
schedules are schedules in which each instance of a particular response
results in reinforcement (or punishment). One of the most obvious
effects of introducing a continuous schedule of reinforcement for
improvements in performance is that this results in the most rapid
improvement in performance. If a poorly motivated child suddenly begins
to receive reinforcement for each task completed, task completion
increases rapidly. If every improvement is reinforced, behaviour tends
to improve much more rapidly than if improvements are only reinforced
from time to time. If every misbehaviour is punished, misbehaviours are
suppressed much more rapidly than is the case where misbehaviours are
punished only from time to time (Pfiffner, O'Leary, Rosén & Sanderson,
1985).

However, continuous schedules of reinforcement, although they tend to
produce rapid improvements in performance, also result in performances
which are the least resistant to extinction. If every response has been
reinforced, and for some reason or another reinforcement ceases, then
the person concerned may simply cease using that behaviour. This is
because a change from continuous reinforcement to non-reinforcement is
very obvious when it occurs. If a child has been regularly reinforced in
the past for completing their writing and reinforcement ceases, it is
very obvious to the child that reinforcement has ceased so we would not
be surprised if effort ceased as well.

*Intermittent schedules generate more consistent effort than predictable
schedules.* If a teacher is using a reinforcement contingency to
motivate task completion in the classroom, an intermittent schedule of
reinforcement will usually generate more effort than the same amount of
reinforcement earned on a fixed interval schedule or a fixed ratio
schedule (McLaughlin & Malaby, 1975, 1976; Saudargas, Madsen & Scott,
1977). This is because, once the learner discovers the schedule, it is
possible for them to obtain reinforcement by just completing sufficient
work to meet the requirement, rather than by working consistently.

*Intermittent schedules produce persistence.* Intermittent schedules of
reinforcement also generate performances which are resistant to
extinction. Intermittent schedules produce persistent behaviour -
produce behaviour which is likely to continue even in the face of
non-reinforcement. Another advantage is that it is easier to thin
(gradually withdraw) extrinsic reinforcement on an intermittent schedule
without reducing student motivation (Henderson, Jenson & Erken, 1986).

*When reinforcement becomes too infrequent, effort decreases (and may
even cease altogether)*. With poorly motivated students, the amount of
effort expended tends to be directly related to the frequency with which
that effort is reinforced (Sutherland, Wehby & Copeland, 2000). If the
reinforcement generated by a particular behaviour becomes too
infrequent, the learner may simply cease to engage in that behaviour. If
the learner gets little enjoyment out of reading tasks, they may lose
interest in reading. If the learner ceases to make progress as a result
of practising a particular skill, they may lose interest in practising
that skill. This has a major implication for classroom teaching. It
means that in order to maintain the motivation of children who are not
intrinsically motivated to complete a particular task (who are not
particularly interested in that task), some kind of extrinsic
reinforcement contingency becomes an essential teaching condition if
task engagement is to be maintained.

A major source of reinforcement in the classroom is the positive teacher
reactions which students receive for their efforts. However, many
descriptive studies have found that many classroom teachers use praise
quite infrequently. A study of American first grade teachers found that
the teachers praised only about 11 per cent of correct student answers.
Thomas, Presland, Grant and Glynn (1978) found that N.Z. teachers gave
explicit approval not much more than about 12 times an hour. Rossiter\'s
observations of N.Z. Year 1 and Year 2 teachers revealed that the
teachers who were observed provided positive reactions something less
than 25 times an hour (Rossiter, 1982). However, the same study also
showed that when teachers were trained to accentuate the positive and to
praise even small improvements, they were able to achieve 80 to 90
encouraging remarks per hour. So it is clear that improvements in
typical classroom practice are possible.

One of the ways of increasing teacher attention to and praise for task
engagement is for the teacher to set goals with respect to what will be
praised and how often while a mentor or senior colleague provides the
teacher with performance feedback as to whether this goal is being
achieved from day to day (Martens, Hiralall & Bradley, 1997; Rose, 1994;
Sutherland et al., 2000).

Another way of increasing positive teacher reactions to student
behaviour is to teach the *students* to recruit teacher attention. In a
review of this research, Alber and Heward (2000) report that there have
been at least 10 controlled evaluations of the effects of teaching
students to recruit teacher attention. These studies have included
children in early childhood centres, primary school children with and
without learning disabilities, and adolescents. In all of these studies,
the children quickly learned how to solicit feedback on their work and
in several studies the investigators were able to demonstrate that
soliciting feedback not only resulted in increased teacher praise but
also resulted in increased work completion on the part of the students
(Alber, Heward & Hippler, 1999; Craft, Alber & Heward, 1998).

**3. Variations in the response effort required for success on an
activity**

Motivation depends in part upon task difficulty. For example, very easy
tasks and tasks which lack challenge tend to motivate little effort
(because little effort is required) and may even be experienced as
boring. In cases such as these, simply increasing task difficulty may
result in an improvement in motivation (Umbreit, Lane & Dejud, 2004).

The kinds of tasks which students find most motivating are those which
involve a reasonable challenge. This is probably because of the sense of
achievement which is generated by completing a task which involves a
reasonable challenge.

However, classroom tasks can also be too difficult, and in these cases,
sustaining student motivation requires a procedure in which the amount
of reinforcement which can be earned increases as task difficulty and
the risk of failure increases (e.g., Bucher & Okovita, 1977). Experience
suggests that students will be motivated to select more challenging
tasks in the classroom if they know that the rewards which can be earned
outweigh the risks of failure. \\"Students do, in fact, freely choose
more difficult problems (a) when the number of points offered increases
with the difficulty level of problems (b) when the risk-taking task is
presented within a game or practice situation and (c) when additional
opportunities for risk taking are anticipated\\" (Clifford, 1990, p. 24).

**4. Variations in the performance dimension on which reinforcement
depends**

The reinforcement which results from sustained effort may occur as a
result of achieving any one of a number of different performance
standards: staying on task, completing tasks, completing tasks to a
particular standard (i.e. responding correctly), responding correctly
and quickly (i.e. responding fluently), showing improvement, and so on.
In technical terms we say that reinforcement may be contingent on any
one of a number of different dimensions of performance.

*Reinforcing on-task behaviour*. One way of defining success is in terms
of the degree of attention to and engagement in learning activities.
Attention to practice stimuli, engagement with learning tasks, and
staying on task until learning activities are completed are essential
prerequisites for learning. Many dozens of classroom experiments have
demonstrated that engagement with learning tasks is extremely sensitive
to positive reinforcement (e.g., Fontenelle & Holliman, 1983; Glynn,
1972; Maag, Rutherford & DiGangi, 1992). However, reinforcing time on
task does not necessarily result in students completing more work or in
improvements in performance (Ferritor, Buckholdt, Hamblin & Smith,
1972).

*Reinforcing task completion.* A second way of defining success is in
terms of the amount of work completed. With these kinds of
contingencies, the student is reinforced for engaging in the learning
activity regardless of the quality of the work which is completed. Where
the consequences which are being earned are reinforcing for the pupil
concerned, this kind of contingency produces rapid and marked increases
in both time on task and work completed (e.g., Fontenelle & Holliman,
1983). Note, however, that because reinforcement is not dependent upon
the accuracy or quality of the work completed this increased
productivity tends not to be accompanied by improvement in the quality
of the work completed (e.g., Ferritor et al., 1972; Hundert, Bucher &
Henderson, 1976; McLaughlin & Malaby, 1975).

*Reinforcing correct responses.* Thirdly, success may be defined in
terms of improvements in accuracy or the proportion of correct
responses. When reinforcement is contingent on responding correctly, the
number of correct responses almost always increases as does task
completion (Marholin & Steinman, 1977; Scriven & Glynn, 1983) and task
engagement (Broughton & Lahey, 1978; Ferritor et al., 1972; Hundert et
al., 1976; Kastelen, Nickel & McLaughlin, 1984; Scriven & Glynn, 1983).
This is because, unless the student attends, concentrates, and works at
producing correct or improved responses, no reinforcement is
forthcoming.

However, reinforcing accurate performance has a down side as well. If
reinforcement is made contingent upon the number of correct responses,
there is no incentive to respond quickly. In fact, the learner may be
motivated to work conscientiously, that is, *slowly* and carefully in an
attempt to maximise the number of correct responses (Eisenberger,
Mitchell, McDermitt & Masterson, 1984). Reinforcing accuracy, in other
words, may work against the development of mastery.

*Reinforcing correct and speedy responses.* In order to master or
\"memorise\" a new skill or a set of correct responses, practice must
continue until the learner can respond both correctly and *quickly*. So
a fourth way of defining success is in terms of improvements in accurate
and speedy responding, that is fluent responding. When classroom
reinforcers are made contingent upon responding both correctly and
quickly, speed improves and accuracy also continues to improve (e.g.,
Chadwick & Day, 1971). Task engagement also tends to be very high during
timed practices.

*Reinforcing improvements in performance.* Classroom reinforcers may be
made contingent on responding correctly or fluently but they may also be
contingent on *improvements* in accuracy or fluency. By making
reinforcers contingent upon improvements in performance (rather than the
absolute level achieved), all students in the class (regardless of
ability) have an equal opportunity to earn available reinforcers and
hence to experience learning as a positive experience.

Slavin (1991, p. 346-347) suggests that all assessed work in the
classroom should receive two marks, a mark or grade showing the standard
of work achieved and a mark showing the number of \\"improvement points\\"
which have been earned. Before improvement points can be calculated, the
teacher must collect several samples of work, or test scores, and must
work out the average standard achieved in these. This then becomes the
base score against which improvements will be calculated. Slavin
suggests that work which is as good as the base score should earn one
improvement point, work which is up to 10 per cent better than the base
score should earn two improvement points and work which shows a better
than 10 per cent improvement (together with work which earns a perfect
score) should receive three improvement points. These improvement points
can then be exchanged for specific rewards. This procedure is relatively
easy to operate in the case of work which is done in exercise books but
more difficult to operate in the case of tests and project work. In the
latter cases the teacher must keep a sufficiently accurate record of
achievement on assessed tasks to enable the calculation of improvement
points on new work. This is the procedure which Slavin has used in a
number of studies of the effectiveness of specific co-operative learning
procedures.

Reinforcing improvements has a number of advantages. First, it results
in an accelerated rate of improvement (Barton, 1981, Brigham, Burt &
Edwards, 1976; Swanson, 1981) while at the same time producing increases
in productivity and time on task.

**5. Variations in the type of reinforcement generated by success on an
activity**

The type of reinforcing outcome which is used to motivate increased
effort may take many different forms: free time, access to prized
activities, small rewards such as stickers, snacks, vouchers, tradable
tokens, positive social reactions such as praise, positive feedback, and
so on. Applications of Premack's rule, where a certain level of effort,
productivity or improvement earns a certain amount of time in a
preferred, desired or prized activity have been studied extensively and
have been found to function as reinforcing outcomes for almost all
learners (e.g. Edgar & Clement, 1980; Miller & Schneider, 1970; Witt,
Hannafin & Martens, 1983).

Home rewards, privileges, preferred activities and pocket money have
also been used to good effect (Bailey, Wolf & Phillips, 1970; Drew,
Evans, Bostow & Drash, 1982; McKenzie, Clark, Wolf, Kothera & Benson,
1968). The effect also tends to be very strong because students often
have access to a much wider range of reinforcing leisure activities at
home than they do at school. However, the contingent access must be to
an activity to which access has been restricted so that a deprivation
state exists with respect to that activity (Konarski, Crowell, Johnson &
Whitman, 1982; Konarski, Johnson, Crowell & Whitman, 1980).

Contingent access to desired activities, when used appropriately, tends
to have a much more motivating effect than positive feedback or social
reinforcement (e.g. praise) (e.g., Zanolli, Paden & Cox, 1997). Token
systems in which tokens earn school appropriate rewards also have a more
motivating effect than praise alone (Glynn, 1972).

Extrinsic reinforcement contingencies are usually regarded as a
temporary device to be used until the child experiences success and this
success is sufficient to maintain motivation and effort. Interestingly,
the right to earn one's self off a token reinforcement system is itself
reinforcing and can result in further effort (e.g., Kazdin & Mascitelli,
1980).

**6. Variations in the ratio of reinforcing and aversive consequences
generated by a particular activity**

It is possible for desirable, appropriate, and correct responses to
generate aversive consequences as well as reinforcing consequences. A
child may work hard in class and complete all the set work ahead of time
only to discover that they are given more work to do -- a potentially
aversive consequence for working hard. A child may solve a maths problem
using an unusual procedure and have the solution marked wrong (because
they used the wrong procedure) -- a potentially aversive consequence for
both creativity and producing the correct answer. A child may work hard
at a task which they find very difficult, only to be reprimanded for
failing to complete the task -- a potentially aversive consequence for
working as well as one is able to on an inappropriate task. A child may
work conscientiously in class and be teased or bullied at a later time
for failing to conform to student norms of conduct in the school
setting. The classroom may be too hot, too cold, or poorly lit, or too
noisy.

It follows therefore that the motivation to continue engaging in a
particular kind of classroom activity depends not just on the amount,
type and schedule of reinforcement generated by success on that activity
but on the *net* reinforcement, that is the motivating effects of
reinforcement less the avoidance motivating effects of the aversive
outcomes which also result from engaging in that activity.

**7. Variations in the degree of learner control over learning tasks and
performance goals**

Practical experience suggests that children and adults alike much prefer
to work under conditions in which they have some say regarding the goals
to be pursued and the order in which tasks should be completed. \"One
fundamental principle of human motivation is that people work harder for
goals they themselves set than for goals set for them by others\"
(Slavin, 1991, p. 342). It is not surprising therefore to find that
there have been a number of experimental studies of the effects of
choice on the motivation of poorly motivated students in the classroom
setting (Kern, Vorndran, Hilt, Ringdahl, Adelman & Dunlap, 1998).

There have been number of experimental demonstrations of the effects of
giving students choice over the learning activities to be completed.
Cosden, Gannon and Haring (1995) found that two misbehaving upper
primary school students completed more work when allowed to choose
learning tasks from a list generated by the teacher. Dunlap, DePerzcel,
Clark, Wilson, Wright and Gomez (1994) report that two misbehaving
primary school boys spent more time on task when given the opportunity
to choose spelling and language assignments from half a dozen options
than when given an assignment by the teacher. Seabaugh and Schumaker
(1994) found that when six low achieving secondary school students were
given choices in the way in which they organised their school work (as
part of a training package in self-regulation) they accomplished much
more than they had previously. The same effect has been observed for
children with intellectual disabilities (Umbriet & Blair, 1996) and
children with autism (Moes, 1998).

It seems likely that the choice effect occurs only under certain
conditions. For example, it appears only to occur on less preferred, and
not on preferred learning tasks (Killu & Clare, 1999; Killu, Clare & Im,
1999). Furthermore, the effect on motivation arises primarily as a
result of being permitted to work on tasks which are liked (preferred
tasks) rather than from the act of being permitted to choose (Cole,
Davenport, Bambara & Ager, 1997; Killu, Clare et al., 1999).

This suggests that the apparently motivating effects of choice are due
to the fact that when students are free to choose, they are able to
choose the most reinforcing activity from amongst those which are
available at that time. In addition, when students are free to choose,
they are able to avoid or to postpone less reinforcing activities in
favour of more reinforcing activities. It is also the case that where
the teacher controls the scheduling of activities, the end of a period
means that work on the current activity must stop regardless of how
interesting it has become to the student. When the learner has some
control over scheduling, he or she may continue to work on an
interesting task until it is finished and can avoid having to stop work
on an interesting activity in the middle of that activity. Having to
stop work in the middle of an interesting activity is experienced as
aversive by most people.

Giving the learner some control over the learning tasks to be completed
is usually believed to be important in the development of
self-management skills and independence and it certainly provides
practice in these skills. However, there will be many situations where
it is impractical to provide poorly motivated students with a choice of
activities. \"There are some academic assignments that students should
not be allowed to avoid (e.g., avoid engaging in narrative writing
assignments by choosing to do grammar worksheets)\" (Skinner, Wallace &
Neddenriep, 2002, p. 54). Giving choices may also result in the poorly
motivated student consistently choosing easier and less valuable
learning tasks over more challenging tasks with greater instructional
value.

Just as learners may be given responsibility for the order in which
learning tasks are scheduled, so they may be given varying levels of
responsibility for choosing the rewards which they will enjoy for
meeting selected learning goals. Provided the system is monitored,
student selected reinforcers can be just as motivating as teacher
selected reinforcers (Cosden et al., 1995) and sometimes more so (Edgar
& Clement, 1980). However the effects are variable with some studies
showing self evaluation and self-reinforcement to have little or no
effect on time on task (Glynn & Thomas, 1974) and others showing that
the introduction of self-reinforcement can result in inflated
self-evaluation scores (Speidel & Tharp, 1980).

Competitions of various kinds are often used by teachers to motivate
greater effort on less interesting learning tasks. However, competition
can have serious negative effects on motivation. This is because, in a
competition, there is always a loser as well as a winner and students
who consistently end up as the losers in classroom competitions quickly
lose interest in competing. Competitive classroom arrangements \"can be
criticised for discouraging students from helping one another learn, for
tending to set up a 'pecking order' in the classroom and for
establishing a situation in which low achievers have little chance of
success\" (Slavin, 1991, p. 353). The detrimental effects of classroom
competition have been widely recognised.

\"Eccles et al. (1984) reviewed a number of studies that examined the
effect of grading practices, competitive vs. cooperative goal
structures, and ability grouping. They concluded that traditional,
external, ability based evaluation and grading increased students\'
focus on how they compared to their peers and depressed student
motivation, compared to alternative procedures that involved student
self-evaluation or evaluation against student-controlled objectives.
Competitive goal structures in which one student\'s success is earned at
the cost of another's failure were found to produce lower motivation to
learn, less favourable attitudes toward school teachers and other
students, and lower self-esteem than cooperative goal structures in
which success is a shared outcome\" (Goetz, Alexander, & Ash, 1992, p.
562-563).

If competition is to be used as a motivational device, without damaging
attitudes and self-esteem, then it must be structured in such a way that
all competitors have an equal chance of winning. That is, it must be
limited to group activities where the groups are evenly matched and have
an equal chance of success. Slavin (1991, p. 342) makes the point that
team games are better than individual games because they provide
opportunities for team-mates to help one another and avoid the situation
where the more able students always win. The use of mixed ability teams
means that teams are more evenly matched so that all have an equal
chance of winning.
:::

::: referencesList
#### References

-   Alber, S. R. & Heward, W. L. (2000). Teaching students to recruit
    positive attention: A review and recommendations. Journal of
    Behavioral Education, 10, 177-204.
-   Alber, S. R., Heward, W. L., & Hippler, B. J. (1999). Teaching
    middle school students with learning disabilities to recruit
    positive teacher attention. Exceptional Children, 65, 253-270.
-   Bailey, J. S., Wolf, M. M., & Phillips, E. L. (1970). Home-based
    reinforcement and the modification of pre-delinquents' classroom
    behavior. Journal of Applied Behavior Analysis, 3, 223-233.
-   Barton, E. J. (1981). Developing sharing: An analysis of modeling
    and other behavioral techniques. Behavior Modification, 5, 386-398.
-   Brigham, T. A., Burt, D., & Edwards, R. (1976). An application of
    operant principles to instruction. Educational Technology, 16,
    45-48.
-   Broughton, S. F., & Lahey, B. B. (1978). Direct and collateral
    effects of positive reinforcement, response cost, and mixed
    contingencies for academic performance. Journal of School
    Psychology, 16, 126-136.
-   Bucher, B., & Okovita, H. (1977). Effects of differential
    reinforcement and task difficulty on preschoolers' compliance with
    teacher instructions. Journal of Experimental Child Psychology, 23,
    226-236.
-   Cameron, J., & Pierce, W. D. (2002). Rewards and intrinsic
    motivation: Resolving the controversy. Westport, CT: Bergin &
    Garvey.
-   Chadwick, B. A., & Day, R. C. (1971). Systematic reinforcement:
    Academic performance of underachieving students. Journal of Applied
    Behavior Analysis, 4, 311-319.
-   Clifford, M. M. (1990). Students need challenge, not easy success.
    Educational Leadership, 48(1), 22-26.
-   Cole, C. L., Davenport, T. A., Bambara, L. M., Ager, C. L. (1997).
    Effects of choice and task preference on the work performance of
    students with behavior problems. Behavioral Disorders, 22, 65-74.
-   Cosden, M., Gannon, C., & Haring, T. G. (1995). Teacher-control
    versus student-control over choice of task and reinforcement for
    students with severe behavior problems. Journal of Behavioral
    Education, 5, 11-27.
-   Craft, M. A., Alber, S. R., & Heward, W. L. (1998). Teaching
    elementary students with developmental disabilities to recruit
    teacher attention in a general education classroom: Effects on
    teacher praise and academic productivity. Journal of Applied
    Behavior Analysis, 31, 399-415.
-   Drew, B. M., Evans, J. H., Bostow, G. G., & Drash, P. W. (1982).
    Increasing assignment completion and accuracy using a daily report
    card procedure. Psychology in the Schools, 19, 540-547.
-   Dunlap, G., DePerzcel, M., Clark, S., Wilson, D., Wright, S., &
    Gomez. A. (1994). Choice making to promote adaptive behavior for
    students with emotional and behavioral challenges. Journal of
    Applied Behavior Analysis, 27, 505-518.
-   Eccles, J., Midgley, C. & Adler, T. (1984). Grade-related changes in
    the school environment: Effects on achievement motivation. In J.
    Nicholls (Ed.), Advances in motivation and achievement (Vol 3, pp.
    283-331). Greenwich, CT: JAI Press.
-   Edgar, R., & Clement, P. W. (1980). Teacher-controlled and
    self-controlled reinforcement with underachieving black children.
    Child Behavior Therapy, 2, 33-56.
-   Eisenberger, R., Mitchell, M., McDermitt, M., & Masterson, F. A.
    (1984). Accuracy versus speed in the generalized effort of
    learning-disabled children. Journal of the Experimental Analysis of
    Behavior, 42, 19-36.
-   Ferritor, D. E., Buckholdt, D., Hamblin, R. L., & Smith, L. (1972).
    The non-effects of contingent reinforcement for attending behavior
    on work accomplished. Journal of Applied Behavior Analysis, 5, 7-17.
-   Fontenelle, S., & Holliman, W. (1983). Social management techniques
    for classroom teachers. Psychological Reports, 52, 815-818.
-   Glynn, E. L. (1972). Verbal and token reinforcement: Elements of
    behaviour control in a problem class. New Zealand Psychologist, 1,
    13-20.
-   Glynn, E. L., & Thomas, J. D. (1974). Effect of cueing on
    self-control of classroom behavior. Journal of Applied Behavior
    Analysis, 7, 299-306.
-   Goetz, E. T., Alexander, P. A., & Ash, M. J. (1992). Educational
    psychology: A classroom perspective. New York: Macmillan Publishing
    Co.
-   Henderson, H. S., Jenson, W. R., & Erken, N. F. (1986). Using
    variable interval schedules to improve on-task behavior in the
    classroom. Education & Treatment of Children, 9, 250-263.
-   Hundert, J., Bucher, B., & Henderson, M. (1976). Increasing
    appropriate classroom behavior and academic performance by
    reinforcing correct work alone. Psychology in the Schools, 13,
    195-200.
-   Kastelen, L., Nickel, M., & McLaughlin, T. F. (1984). A performance
    feedback system: Generalization of effects across tasks and time
    with eighth-grade English students. Education & Treatment of
    Children, 7, 141-155.
-   Kazdin, A. E., & Mascitelli, S. (1980). The opportunity to earn
    oneself off a token system as a reinforcer for attentive behavior.
    Behavior Therapy, 11, 68-78.
-   Kern, L., Vorndran, C., Hilt, A., Ringdahl, J., Adelman, B., &
    Dunlap, G. (1998). Choice as an intervention to improve behavior: A
    review of the literature. Journal of Behavioral Education, 8,
    151-169.
-   Killu, K., & Clare, C. (1999). Choice vs. preference: The effects of
    choice and no choice of preferred and non preferred spelling tasks
    on the academic behavior of students with disabilities. Journal of
    Behavioral Education, 9, 239-253
-   Killu, K., Clare, C. M., & Im, A. (1999). Choice vs. preference: The
    effects of choice and no choice of preferred and non preferred
    spelling tasks on the academic behaviour of students with
    disabilities. Journal of Behavioral Education, 9, 239-253.
-   Kohn, A. (1999). Punished by rewards: The trouble with gold stars,
    incentive plans, A\'s, praise, and other bribes (New ed.). Boston,
    MA: Mariner Books.
-   Konarski, E. A., Crowell, C. R., Johnson, M. R., & Whitman, T. L.
    (1982). Response deprivation, reinforcement, and instrumental
    academic performance in an EMR classroom. Behavior Therapy, 13,
    94-102.
-   Konarski, E. A., Johnson, M. R., Crowell, C. R., & Whitman, T. L.
    (1980). Response deprivation and reinforcement in applied settings:
    A preliminary analysis. Journal of Applied Behavior Analysis, 13,
    595-609.
-   Maag, J. W., Rutherford, R. B., & DiGangi, S. A. (1992). Effects of
    self-monitoring and contingent reinforcement on on-task behavior and
    academic productivity of learning-disabled students: A social
    validation study. Psychology in the Schools, 29, 157-172.
-   Marholin, D., & Steinman, W. M. (1977). Stimulus control in the
    classroom as a function of the behavior reinforced. Journal of
    Applied Behavior Analysis, 10, 465-478.
-   Martens, B. K., Hiralall, A. S., & Bradley, T. A. (1997). A note to
    teacher: Improving student behavior through goal setting and
    feedback. School Psychology Quarterly, 12, 33-41.
-   McKenzie, H. S., Clark, M., Wolf, M. M., Kothera, R., & Benson, C.
    (1968). Behavior modification of children with learning disabilities
    using grades as tokens and allowances as back up reinforcers.
    Exceptional Children, 34, 745-752.
-   McLaughlin, T. F., & Malaby, J. E. (1975). The effects of various
    token reinforcement contingencies on assignment completion and
    accuracy during variable and fixed token exchange schedules.
    Canadian Journal of Behavioural Science, 7, 411-419.
-   McLaughlin, T. F., & Malaby, J. E. (1976). An analysis of assignment
    completion and accuracy across time under fixed, variable, and
    extended token exchange periods in a classroom token economy.
    Contemporary Educational Psychology, 1, 346-355.
-   Miller, L. K., & Schneider, R. (1970). The use of a token system in
    Project Head Start. Journal of Applied Behavior Analysis, 3,
    213-220.
-   Moes, D. R. (1998). Integrating choice-making opportunities within
    teacher-assigned academic tasks to facilitate the performance of
    children with autism. TASH, 23, 319-328.
-   Pfiffner, L. J., O\'Leary, S. G., Rosén, L. A., & Sanderson, W. C.
    (1985). A comparison of the effects of continuous and intermittent
    response cost and reprimands in the classroom. Journal of Clinical
    Child Psychology, 14, 348-352.
-   Rose, D. J. (1994). The effect of practice on the acquisition and
    maintenance of teaching skills. Unpublished PhD thesis.
    Christchurch, N.Z.: University of Canterbury, Education Department.
-   Rossiter, A. (1982). The difficult to teach junior school pupil:
    Identification and teaching strategies. Research Report No 82-1.
    Christchurch, N.Z.: Education Department, University of Canterbury.
-   Saudargas, R. W., Madsen, C. H., & Scott, J. W. (1977). Differential
    effects of fixed- and variable-time feedback on production rates of
    elementary school children. Journal of Applied Behavior Analysis,
    10, 673-678.
-   Scriven, J., & Glynn, T. (1983). Performance feedback on written
    tasks for low-achieving secondary students. New Zealand Journal of
    Educational Studies, 18, 134-145.
-   Seabaugh, G. O., & Schumaker, J. B. (1994). The effects of
    self-regulation training on the academic productivity of secondary
    students with learning problems. Journal of Behavioral Education, 4,
    109-133.
-   Skinner, C. H., Wallace, M. A., & Neddenriep, C. E. (2002). Academic
    remediation: Educational applications of research on assignment
    preference and choice. Child & Family Behavior Therapy, 24, 51-65.
-   Slavin, R.E. (1991). Educational psychology (3rd ed.). Englewood
    Cliffs, NJ: Prentice Hall.
-   Speidel, G. E., & Tharp, R. G. (1980). What does self-reinforcement
    reinforce? An empirical analysis of the contingencies in
    self-determined reinforcement. Child Behavior Therapy, 2, 1-22.
-   Sutherland, K. S., Wehby, J. H., & Copeland, S. R. (2000). Effect of
    varying rates of behavior-specific praise on the on-task behavior of
    students with EBD. Journal of Emotional and Behavioral Disorders, 8,
    2-8, 26.
-   Swanson, L. (1981). Modification of comprehension deficits in
    learning disabled children. Learning Disability Quarterly, 4,
    189-202.
-   Thomas, J. D., Presland, I. E., Grant, M. D. & Glynn, T. L. (1978).
    Natural rates of teacher approval and disapproval in Grade 7
    classrooms. Journal of Applied Behavior Analysis, 11, 91-94.
-   Umbriet, J., & Blair, K. (1996). The effects of preference, choice,
    and attention on problem behavior at school. Education and Training
    in Mental Retardation and Developmental Disabilities, 31, 151-161.
-   Umbreit, J., Lane, K. L., & Dejud, C. (2004). Improving classroom
    behavior by modifying task difficulty: Effects of increasing the
    difficulty of too-easy tasks. Journal of Positive Behavior
    Interventions, 6, 13-20.
-   Witt, J. C., Hannafin, M. J., & Martens, B. K. (1983). Home-based
    reinforcement: Behavioral covariation between academic performance
    and inappropriate behavior. Journal of School Psychology, 21,
    337-348.
-   Zanolli, K.M., Paden, P., & Cox, K. (1997). Teaching prosocial
    behavior to typically developing toddlers. Journal of Behavioral
    Education, 7, 373-391.
:::"
".//Theconditionsuponwhichlearningdepends/Motivationalprocesses/Howmotivationandpersistencedevelop/index.md","# How motivation and persistence develop \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-456b8ea0c6184f378400adea1ebf7fdd}
Traditionally it was thought that motivation was primarily a function of
the tasks which learners were being asked to perform. This led to what
turned out to be a fruitless search for the task characteristics which
fostered \"motivation\". These discussions tended to focus in on task
characteristics such as task relevance, authenticity, interest level,
difficulty level, and so on. Research into the effects of interest and
interestingness continues to the present.

Following the discovery of the role of contingencies of reinforcement
and punishment as determinants of future behaviour during the first half
of the 20th century, a very large number of experimental analyses of
contingencies of reinforcement and punishment and their effects on
productivity, effort and persistence were undertaken during the second
half of the 20th century. The research base for the effects of different
types of contingencies and schedules of reinforcement and punishment is
now larger than that for any other aspect of human learning and consists
of many hundreds of well controlled experimental analyses.

The research base for contingency effects is so large and the
conclusions from this research so compelling that several chapters are
always devoted to this research in modern, scientifically oriented text
books on learning (e.g., Alberto & Troutman, 2009; Malott, Whaley &
Malott, 1993; Miltenberger, 2004; Sulzer-Azaroff & Mayer, 1991). As a
result of these analyses we now have a very clear idea of the way in
which motivation and persistence develop and of the conditions necessary
for both motivation and persistence.

What is now known is that the major determinants of motivation are the
consequences experienced by the learner when they engage in particular
activities (including the consequences which have been experienced while
engaged in that activity in the past). The tendency to engage in a
particular behaviour under certain circumstances is motivated by both
positive reinforcement and by negative reinforcement contingencies. The
tendency not to engage in a particular behaviour under certain
circumstances is motivated by aversive consequences in the form of both
positive punishment and negative punishment contingencies.

Changes in motivation occur over time because repeated performance of a
particular class of responses results in a sequence of consequences from
one response opportunity to the next. Over time, the consequences which
result from working on a particular task may be primarily reinforcing
(in which case motivation to continue working on that task will be
high), the consequences may be predominantly aversive (in which
motivation will be low or non-existent), or the consequences may
sometimes be reinforcing and sometimes aversive (in which case
motivation will fluctuate because the reinforcement generated by task
completion is variable).
:::

::: referencesList
#### References

-   Alberto, P. A., & Troutman, A. C. (2009). Applied behavior analysis
    for teachers (8th ed.). Upper Saddle River, NJ: Prentice-Hall.
-   Malott, R. W., Whaley, D. L., & Malott, M. E. (1993). Elementary
    principles of behavior (2nd ed.). Englewood Cliffs, NJ: Prentice
    Hall.
-   Miltenberger, R. G. (2004). Behavior modification: Principles and
    procedures (3rd ed.). Belmont, CA: Wadsworth/Thomson Learning.
-   Sulzer-Azaroff, B., & Mayer, G. R. (1991) Behavior analysis for
    lasting change. Fort Worth, TX: Holt, Rinehart and Winston.
:::"
".//Theconditionsuponwhichlearningdepends/Motivationalprocesses/Howmotivationandpersistencedevelop/Necessarycondition1Thematchinglawforpositivereinforcement/index.md","# Necessary condition 1. The matching law for positive reinforcement \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e915af993c674e948dea2826008e3e26}
Most classroom learning tasks generate a mixture of positively
reinforcing consequences and aversive consequences for the learner.
Under these circumstances, student motivation (the degree of effort
which the student puts into the task) can be predicted from the Matching
Law (Herrnstein, 1961). \"The matching law states that an individual will
distribute his or her behavior between alternatives in the same ratio
that reinforcements have been obtained for these alternatives\" (Meyerson
& Hale, 1984, p. 367).

While the Matching Law was first observed in the laboratory, it has been
demonstrated on a number of occasions to apply in the classroom setting
as well. A number of applied experiments have demonstrated that when
students are given a choice between two learning tasks each of which
generates a differing rate of reinforcement, they distribute their time
between these tasks in proportion to the rate of reinforcement provided
for these tasks (e.g., Martens, Lochner & Kelly, 1992; Mace, Neef, Shade
& Mauro, 2996; Neef, Mace, Shea & Shade, 1992). It can be seen
therefore, that the motivation to engage in a particular activity
depends primarily on the reinforcement generated by that activity on
previous occasions (e.g., Simon, Ayllon & Millan, 1982; Zanolli &
Daggett, 1998).

In other words, there is a single essential condition on which
motivation, productivity, and persistence depends and that is the level
of reinforcement previously experienced while engaged in tasks similar
to the present task. Children who have experienced success and other
kinds of reinforcing outcomes while engaged in tasks similar to the
current task will be highly motivated to complete the task. Children who
have experienced less reinforcement while engaged in this type of task
will be less motivated to complete the task.

The research base for this general rule is extensive. The motivating
effect of positive reinforcement on future performance has been
demonstrated for preschoolers (e.g., Barton, 1981; Miller & Schneider,
1970), primary school students (e.g., Chadwick & Day, 1971; Kazdin,
1973) and secondary level students (e.g., LaNunziata, Hill & Krause,
1981; Reese, Murphy & Filipczac, 1981). It has been demonstrated for
normally developing students (e.g. Drew, Evans, Bostow & Drash, 1982;
Kazdin, 1973), students with severe behaviour problems (e.g., Bailey,
Wolf & Phillips, 1970; LaNunziata, et al., 1981), students with learning
disabilities (e.g., Fontenelle & Holliman, 1983; Maag, Rutherford &
DiGangi, 1992), hearing impaired students (Simon et al., 1982), and
students with intellectual disabilities (e.g., Kazdin & Geesey, 1980;
Mayhew & Anderson, 1980).

The effects of reinforcement on motivation have been demonstrated across
a variety of different types of classroom tasks including cooperative
group activities (e.g. Greenwood, Hops, Delquadri & Guild, 1974), whole
class activities (e.g., Chadwick & Day, 1971), maths activities (e.g.,
Marholin & Steinman, 1977; McLaughlin & Malaby, 1975b), reading
activities (e.g., Hamblin & Hamblin, 1972; Swanson, 1981), spelling
activities (e.g., Kastelen, Nickel & McLaughlin, 1984), writing
activities (e.g., Scriven & Glynn, 1983), note taking activities
(McLaughlin & Malaby, 1975a), and social learning activities (e.g.,
Sawyer, Luiselli, Ricciardi & Gower, 2005; Zanolli, Paden & Cox, 1997).

The relationship between positive reinforcement and motivation has been
demonstrated across a wide variety of reinforcing contingencies
including those in which student effort results in feedback (e.g.
Greenwood et al., 1974), in teacher praise (e.g., Fontenelle & Holliman,
1983; Maag et al., 1992; Yawkey, 1971), in peer praise (e.g., Greer &
Polirstok, 1982), in free time (e.g. Simmons & Wasik, 1976), in
contingent access to preferred activities (e.g., Glynn & Thomas, 1974;
Konarski, Johnson, Crowell & Whitman, 1980), in small rewards (e.g.,
Winett, Richards, Krasner & Krasner, 1971; Zanolli et al., 1997), in
reports to parents (e.g., Drew et al., 1982), in selected home
privileges (e.g., Bailey et al., 1970; McKenzie, Clark, Wolf, Kothera &
Benson, 1968), in performance feedback systems (e.g., Kastelen, et al.,
1984), and in token reinforcement systems (e.g., Kazdin, 1973; Libb,
Sachs & Boyd, 1973).

This research base has been reviewed several times. In their 1981
review, Lysakowski and Walberg concluded that reinforcement variables
have a stronger effect on learning and motivation than almost any other
variable apart from practice itself. They further concluded that:
\\"Contrary to previous theory and opinions, the strong effects of
instructional reinforcement appear constant across grades (kindergarten
through college), socio-economic levels, race, private and public
schools, and community types\\" (Lysakowski & Walberg, 1981, p. 69).
:::

::: referencesList
#### References

-   Bailey, J. S., Wolf, M. M., & Phillips, E. L. (1970). Home-based
    reinforcement and the modification of pre-delinquents' classroom
    behavior. Journal of Applied Behavior Analysis, 3, 223-233.
-   Barton, E. J. (1981). Developing sharing: An analysis of modeling
    and other behavioral techniques. Behavior Modification, 5, 386-398.
-   Chadwick, B. A., & Day, R. C. (1971). Systematic reinforcement:
    Academic performance of underachieving students. Journal of Applied
    Behavior Analysis, 4, 311-319.
-   Drew, B. M., Evans, J. H., Bostow, G. G., & Drash, P. W. (1982).
    Increasing assignment completion and accuracy using a daily report
    card procedure. Psychology in the Schools, 19, 540-547.
-   Fontenelle, S., & Holliman, W. (1983). Social management techniques
    for classroom teachers. Psychological Reports, 52, 815-818.
-   Glynn, E. L., & Thomas, J. D. (1974). Effect of cueing on
    self-control of classroom behavior. Journal of Applied Behavior
    Analysis, 7, 299-306.
-   Greenwood, C. R., Hops, H., Delquadri, J., & Guild, J. (1974). Group
    contingencies for group consequences in classroom management: A
    further analysis. Journal of Applied Behavior Analysis, 7, 413-425.
-   Greer, R. D., & Polirstok, S. R. (1982). Collateral gains and
    short-term maintenance in reading and on-task responses by
    inner-city adolescents as a function of their use of social
    reinforcement while tutoring. Journal of Applied Behavior Analysis,
    15, 123-139.
-   Hamblin, J. A., & Hamblin, R. L. (1972). On teaching disadvantaged
    preschoolers to read: A successful experiment. American Educational
    Research Journal, 9, 209-216.
-   Herrnstein, R. J. (1961). Relative and absolute strength of response
    as a function of frequency of reinforcement. Journal of the
    Experimental Analysis of Behavior, 4, 267-272.
-   Kastelen, L., Nickel, M., & McLaughlin, T. F. (1984). A performance
    feedback system: Generalization of effects across tasks and time
    with eighth-grade English students. Education & Treatment of
    Children, 7, 141-155.
-   Kazdin, A. E. (1973). Role of instructions and reinforcement in
    behavior changes in token reinforcement programs. Journal of
    Educational Psychology, 64, 63-71.
-   Kazdin, A. E., & Geesey, S. (1980). Enhancing classroom
    attentiveness by preselection of back-up reinforcers in a token
    economy. Behavior Modification, 4, 98-114.
-   Konarski, E. A., Johnson, M. R., Crowell, C. R., & Whitman, T. L.
    (1980). Response deprivation and reinforcement in applied settings:
    A preliminary analysis. Journal of Applied Behavior Analysis, 13,
    595-609.
-   LaNunziata, L. J., Hill, D. S., & Krause, L. A. (1981). Teaching
    social skills in classrooms for behaviorally disordered students.
    Behavioral Disorders, 6, 238-246.
-   Libb, J. W., Sachs, C., & Boyd, W. (1973). Reinforcement strategies
    for token economies in a special classroom setting. Psychological
    Reports, 32, 831-834.
-   Lysakowski, R. S., & Walberg, H. J. (1981). Classroom reinforcement
    and learning: A quantitative synthesis. Journal of Educational
    Research, 75, 69-77.
-   Maag, J. W., Rutherford, R. B., & DiGangi, S. A. (1992). Effects of
    self-monitoring and contingent reinforcement on on-task behavior and
    academic productivity of learning-disabled students: A social
    validation study. Psychology in the Schools, 29, 157-172.
-   Mace, F. C., Neef, N. A., Shade, D., & Mauro, B. C. (1996). Effects
    of problem difficulty and reinforcer quality on time allocated to
    concurrent arithmetic problems. Journal of Applied Behavior
    Analysis, 29, 11-24.
-   Marholin, D., & Steinman, W. M. (1977). Stimulus control in the
    classroom as a function of the behavior reinforced. Journal of
    Applied Behavior Analysis, 10, 465-478.
-   Martens, B. K., Lochner, D. G., & Kelly, S. Q. (1992). The effects
    of variable-interval reinforcement on academic engagement: A
    demonstration of matching theory. Journal of Applied Behavior
    Analysis, 25, 143-151.
-   Mayhew, G. L., & Anderson, J. (1980). Delayed and immediate
    reinforcement: Retarded adolescents in an educational setting.
    Behavior Modification, 4, 527-545.
-   McKenzie, H. S., Clark, M., Wolf, M. M., Kothera, R., & Benson, C.
    (1968). Behavior modification of children with learning disabilities
    using grades as tokens and allowances as back up reinforcers.
    Exceptional Children, 34, 745-752.
-   McLaughlin, T. F., & Malaby, J. E. (1975a). Increasing and
    maintaining note-taking behavior in a sixth grade token classroom:
    An analysis of consequences presented in a delayed manner.
    Psychology: A Journal of Human Behavior, 12, 15-23.
-   McLaughlin, T. F., & Malaby, J. E. (1975b). The effects of various
    token reinforcement contingencies on assignment completion and
    accuracy during variable and fixed token exchange schedules.
    Canadian Journal of Behavioural Science, 7, 411-419.
-   Meyerson, J., & Hale, S. (1984). Practical implications of the
    matching law. Journal of Applied Behavior Analysis, 17, 367-380.
-   Miller, L. K., & Schneider, R. (1970). The use of a token system in
    Project Head Start. Journal of Applied Behavior Analysis, 3,
    213-220.
-   Neef, N. A., Mace, F. C., Shea, M. C., & Shade, D. (1992). Effects
    of reinforcer rate and reinforcer quality on time allocation:
    Extension of matching theory to educational settings. Journal of
    Applied Behavior Analysis, 25, 691-699.
-   Reese, S. C., Murphy, R. J., & Filipczak, J. (1981). Assessment of
    multiple behavioral procedures on academic and social classroom
    behavior. Psychology in the Schools, 18, 349-355.
-   Sawyer, L. M., Luiselli, J. K., Ricciardi, J. N., & Gower, J. L.
    (2005). Teaching a child with autism to share among peers in an
    integrated preschool classroom: Acquisition, maintenance, and social
    validation. Education and Treatment of Children, 28, 1-10.
-   Scriven, J., & Glynn, T. (1983). Performance feedback on written
    tasks for low-achieving secondary students. New Zealand Journal of
    Educational Studies, 18, 134-145.
-   Simmons, J. T., & Wasik, B. H. (1976). Grouping strategies, peer
    influence, and free time as classroom management techniques with
    first- and third-grade children. Journal of School Psychology, 14,
    322-332 .
-   Simon, S. J., Ayllon, T., & Milan, M. A. (1982). Behavioral
    compensation: Contrast like effects in the classroom. Behavior
    Modification, 6, 407-420.
-   Swanson, L. (1981). Modification of comprehension deficits in
    learning disabled children. Learning Disability Quarterly, 4,
    189-202.
-   Winett, R. A., Richards, C. S., Krasner, L., & Krasner, M. (1971).
    Child-monitored token reading program. Psychology in the Schools, 8,
    259-262.
-   Yawkey, T. D. (1971). Conditioning independent work behavior in
    reading with seven-year-old children in a regular early childhood
    classroom. Child Study Journal, 2, 23-34.
-   Zanolli, K., & Daggett, J. (1998). The effects of reinforcement rate
    on the spontaneous social initiations of socially withdrawn
    preschoolers. Journal of Applied Behavior Analysis, 31, 117-125.
-   Zanolli, K.M., Paden, P., & Cox, K. (1997). Teaching prosocial
    behavior to typically developing toddlers. Journal of Behavioral
    Education, 7, 373-391.
:::"
".//Theconditionsuponwhichlearningdepends/index.md","# The conditions upon which learning depends \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a6c73b4ef1bd45e68571129c1a14b0b3}
Central to any research base for teaching is the research into how
learning occurs, that is, research into the conditions necessary for
learning. The first thing which we discover when examining the
scientific research into learning is that learning does not involve a
single process. The term \"learning\" refers to a collection of processes:
respondent learning processes, motivational processes, the processes
involved in the acquisition of new performance skills, verbal learning
processes, social learning processes and so on. Research into the
conditions necessary for learning shows that that the conditions
necessary for learning differ from one learning process to the next.

Research into the conditions necessary for learning is further
complicated by the fact that, while learning researchers divide learning
up into different processes on the basis of the conditions which each
requires, curriculum writers, teachers and teacher educators divide
learning into quite different categories: language learning, literacy
learning, social learning, the learning of mathematics, science, social
studies and so on. These divisions do not map on to the learning
processes delineated by learning scientists in any simple manner and
this further complicates any discussion of the conditions necessary for
learning.

In this book we will explore the learning processes which have been
identified by the scientific research into learning and the conditions
which have been identified, from controlled research, as those
conditions which are necessary in order for each of these kinds of
learning to occur.

This book consists of 5 chapters.

Chapter 1 considers the research on respondent conditioning processes
and identifies the conditions which are necessary for the development of
(a) new meanings (comprehension responses), (b) new likes and dislikes
and (c) new anxieties and fears.

Chapter 2 considers the research on motivation and identifies the
conditions which are necessary for the development of motivation and
persistence.

Chapter 3 considers the processes which result in the acquisition of new
behaviours and skills and identifies the conditions necessary for (a)
the shaping of completely new behaviours and skills and (b) the
acquisition of new procedural skills and operations.

Chapter 4 considers three important verbal learning processes: (a) the
acquisition of new equivalence relations, (b) the acquisition of new
conceptual understandings, and (c) the acquisition of new knowledge and
identifies the essential conditions upon which each of these types of
acquisition depend.

Chapter 5 considers the conditions which are necessary for the
development of mastery where mastery is defined as the ability to
perform a particular response, skill, or task fluently and without
error.
:::"
".//Theconditionsuponwhichlearningdepends/Fluencybuildingprocesses/Howfluencyisacquired/Necessarycondition1Practiceactivitiesinwhichincreasesinspeedarepossible/index.md","# Necessary condition 1. Practice activities in which increases in speed are possible \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-4bae0d5e5b674fc5ac6eb8622e1e5f5c}
Fluency building activities may take a wide variety of forms: oral
quizzes, flash cards, 1-minute sprints on sheets of practice items
(e.g., Rhymer, Skinner, Hennington, D'Reaux & Sims, 1998), and games of
various kinds (e.g., Church, Nixon, Williams & Zintl, 2005). These
activities may or may not involve the teacher and may be conducted with
students individually, in pairs, in small groups, or in class size
groups (e.g., Pigott, Fantuzzo & Clement, 1986; Speltz, Shimamura &
McReynolds, 1982). Regardless of the fluency building activities which
are selected for use, those activities must be ones in which increases
in the rate of responding are, in fact, possible.

This means that fluency building activities must be activities in which
the rate of presentation is controlled by the learner. In order for the
learner to demonstrate that they can complete a task, or a set of test
items, more speedily than previously, progress through that task must be
under the control of the learner. Some kinds of practice activities do
not meet this requirement. A young child who has mastered letter names,
for example, may be able to name letters at a rate in excess of 80
letters per minute. If, during fluency building, letters are presented
to the child on cards at the rate of one every 3 seconds, the highest
level of fluency which the child can demonstrate is 20 letters per
minute (Church & Liberty, 1992). The problem described in the preceding
example can be avoided by using practice activities in which the learner
herself (or himself) controls the rate at which items are presented.
Sheets of questions meet this requirement.

Secondly, practice activities must contain a sufficient number of items.
During the initial learning of a new set of correct responses (such as
the names of the letters), it is more efficient for the learner to
practise these in relatively small groups of half a dozen items at a
time. During the fluency building phase of learning, however, we want
the student to become proficient at discriminating between all of the
items and in responding correctly to all of the items in the set. During
fluency building practice, therefore, it is appropriate that the student
practise with all of the items in the set (e.g. all 52 letters). When
proficient, however, most children can name letters at better than 80
letters per minute. It follows, therefore, that for a 1 minute sprint,
the practice sheet should contain at least 100 letters. Alternatively,
the child can practice with the 52 letters but the practice time can be
reduced to half a minute. Where the teaching aim is to teach mastery of
a new procedure, measuring the time which the student takes to complete
the procedure without assistance is the preferred way of measuring
improvements in fluency.
:::

::: referencesList
#### References

-   Church, R. J. & Liberty, K. A. (1992). The experimental analysis of
    learning. Christchurch, New Zealand: University of Canterbury:
    Education Department.
-   Church, R. J., Nixon, J., Williams, D., & Zintl, S. (2005). Building
    decoding fluency in 8- to 9-year old poor readers. Paper presented
    to the Annual conference of the New Zealand Association for Research
    in Education, Dunedin, New Zealand.
-   Pigott, H. E., Fantuzzo, J. W., & Clement, P. W. (1986). The effects
    of reciprocal peer tutoring and group contingencies on the academic
    performance of elementary school children. Journal of Applied
    Behavior Analysis, 19, 93-98.
-   Rhymer, K. N., Skinner, C. H., Henington, C., D'Reaux, R. A., &
    Sims, S. (1998). Effects of explicit timing on mathematics problem
    completion rates in African-American third-grade elementary
    students. Journal of Applied Behavior Analysis, 31, 673-677.
-   Speltz, M. L., Shimamura, J. W., & McReynolds, W. T. (1982).
    Procedural variations in group contingencies: Effects on children\'s
    academic and social behaviors. Journal of Applied Behavior Analysis,
    15, 533-544.
:::"
".//Theconditionsuponwhichlearningdepends/Fluencybuildingprocesses/Howfluencyisacquired/Necessarycondition3Sufficienttimedpracticetoachievethefluencygoal/index.md","# Necessary condition 3. Sufficient timed practice to achieve the fluency goal \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-1190f5115abf437ca287c6c5feeb97b9}
Fluency development is primarily a function of additional practice. This
practice needs to continue until the fluency goal is reached. A
considerable amount of research has been undertaken into the fluency
levels which predict long term retention. Most of this research has been
undertaken by teachers and researchers working within the domain of
Precision Teaching. Reviews of the results of the Precision Teaching
research will be found in Binder (1993, 1996), Binder, Haughton and
Bateman (2002), Binder and Watkins (1990), Kubina and Morrison (2000)
and Lindsley (1992).

Research based lists of the fluency levels which have been found to
predict long term retention have been provided by a number of authors
(e.g., Binder et al., 2002; Freeman & Haughton, 1993a, 1993b; Haring,
Liberty & White, 1981; Hasbrouck & Tindal, 1992; Haughton, 1980; Howell
& Lorson-Howell, 1990; Koorland, Keel & Ueberhorst, 1990; Mercer, Mercer
& Evans, 1982). Figure 4513 provides a summary of the research-based
fluency levels which are currently being used to define mastery with
respect to selected basic skills.

Where the skill which is to be mastered is one which is going to be used
every day, (as is the case with most everyday skills such as dressing,
cooking, driving and so on), these additional practice opportunities
will occur as the learner sets about his or her daily activities. An
example of the amount of additional practice which is necessary to bring
a skill such as getting dressed to fluency will be found in Young, West,
Howard & Whitney (1986).

Where the learning task involves the mastery of new equivalence
relations, the amount of practice which is required to build fluency may
be considerable. \"The number of trials needed by nine first and second
graders with learning problems to reach 30 digits correct per minute
with two or fewer errors on subtraction facts 0 to 9 ranged from 632 to
1,168 with a mean of 840\" (Mercer & Miller, 1992, p. 32). Silbert,
Carnine & Stein (1981, p. 248) report that primary school learners take,
on average, twenty, 8-minute sessions (160 minutes) to achieve fluency
on one set of nine facts (e.g. 1 + 4, 2 + 4, 3 + 4, 4 + 4, 5 + 4, 6 + 4,
7 + 4, 8 + 4, 9 + 4).

![Figure 4513. Fluency levels which have been found to predict
maintenance (long term retention) for selected academic
skills.](../../../../../../assets/images/Figure4513.png \"Figure 4513. Fluency levels which have been found to predict maintenance (long term retention) for selected academic skills.\"){.image-inline}

*Figure 4513. Fluency levels which have been found to predict
maintenance (long term retention) for selected academic skills.*

In the great majority of cases, fluency building activities will need to
be generated by the teacher. An analysis of the practice exercises
provided in textbooks indicates that the great majority of textbooks do
not contain sufficient practice exercises to build fluency. Early
reading texts do not contain sufficient reading to build fluency in
reading (Church & Martin, 1992), early maths textbooks do not contain
sufficient exercises to build fluency in basic maths skills (Silbert,
Carnine & Stein, 1981), and spelling textbooks do not contain sufficient
exercises to build fluency in spelling (Brown, 1990).
:::

::: referencesList
#### References

-   Binder, C. (1993). Behavioral fluency: A new paradigm. Educational
    Technology, 33, 8-14.
-   Binder, C. (1996). Behavioral fluency: Evolution of a new paradigm.
    The Behavior Analyst, 19, 163-197.
-   Binder, C., Haughton, E., & Bateman, B. (2002). Fluency: Achieving
    true mastery in the learning process. Retrieved January 29, 2004,
    from http://www.haughtonlearningcenter.com
-   Binder, C., & Watkins, C. L. (1990). Precision teaching and direct
    instruction: Measurably superior instructional technology in
    schools. Performance Improvement Quarterly, 3(4), 74-96.
-   Brown, A. S. (1990). A review of recent research on spelling.
    Educational Psychology Review, 2, 365-397.
-   Church, R. J. & Martin, T. (1992). The Co-operative Reading Resource
    and how it changed the reading skill of 8- and 9-year olds. Set, No
    2, Item 6.
-   Freeman, G., & Haughton, E. (1993a). Building reading fluency across
    the curriculum. Journal of Precision Teaching, 10(2), 29-30.
-   Freeman, G., & Haughton, E. (1993b). Handwriting fluency. Journal of
    Precision Teaching, 10 (2), 31-32.
-   Haring, N. G., Liberty, K. A., & White, O. R. (1981). Handbook of
    experimental procedures. In: An investigation of phases of learning
    and facilitating instructional events for the severely/profoundly
    handicapped (Final project report). Appended. (U.S. Department of
    Education, Contract No. G00750093). Seattle: University of
    Washington, College of Education.
-   Hasbrouck, J. E. & Tindal, G. (1992). Curriculum-based oral reading
    fluency norms for students in Grades 2 through 5. Teaching
    Exceptional Children, 24, 41-44.
-   Haughton, E. (1980). Practicing practices: Learning by activity.
    Journal of Precision Teaching, 1(3), 3-20.
-   Howell, K. W., & Lorson-Howell, K. A. (1990). Fluency in the
    classroom. Teaching Exceptional Children, 22(3), 20-23.
-   Johnson, K. R., & Layng, T. V. J. (1992). Breaking the structuralist
    barrier: Literacy and numeracy with fluency. American Psychologist,
    47, 1475-14-90.
-   Koorland, M. A., & Keel, M. C., Ueberhorst, P. (1990). Setting aims
    for precision learning. Teaching Exceptional Children, 22(3), 64-66.
-   Kubina, R. M. Jr., & Morrison, R. S. (2000). Fluency in education.
    Behavior & Social Issues, 10, 83-99.
-   Lindsley, O. R. (1992). Precision teaching: Discoveries and effects.
    Journal of Applied Behavior Analysis, 25, 51-57.
-   Mercer, C. D., Mercer, A. R., & Evans, S. (1982). The use of
    frequency in establishing instructional aims. Journal of Precision
    Teaching, 3(3), 57-63.
-   Mercer, C. D. & Miller, S. P. (1992). Teaching students with
    learning problems in math to acquire, understand, and apply basic
    math facts. Remedial and Special Education, 13(3), 19-35, 61.
-   Silbert, J., Carnine, D., & Stein, M. (1981). Direct instruction
    mathematics. Columbus: Charles E. Merrill Publishing Co.
-   Young, K. R., West, R. P., Howard, V. F. & Whitney, R. (1986).
    Acquisition, fluency training, generalization, and maintenance of
    dressing skills of two developmentally disabled children. Education
    and Treatment of Children, 9, 16-29.
:::"
".//Theconditionsuponwhichlearningdepends/Fluencybuildingprocesses/Howfluencyisacquired/index.md","# How fluency is acquired \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7b202005c6ce49c5b30af80d1e04eb02}
The change from correct but slow responding (acquisition) to correct and
fast responding (mastery) requires additional practice. It may require a
considerable amount of practice. In this site we will refer to teaching
activities which aim to build increased fluency as *fluency building*
activities. This chapter describes the teaching procedures which have
been found to be most effective during the fluency building phase of
instruction. In order to build fluency, the teacher must provide
practice tasks on which improvements in speed are possible. In addition,
improvements in accuracy rate must be reinforced. This, in turn,
requires that the teacher have some way of determining when an increase
in accuracy rate has occurred.
:::"
".//Theconditionsuponwhichlearningdepends/Fluencybuildingprocesses/Howfluencyisacquired/Necessarycondition2Regularassessmentofaccuracyrateandreinforcementforincreasesinaccuracyrate/index.md","# Necessary condition 2. Regular assessment of accuracy rate and reinforcement for increases in accuracy rate \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7555aa198cec4b259f5ff68881de2864}
During fluency building, *two* dimensions of the learner's performance
need to be reinforced. The teaching procedure must be one which
continues to differentially reinforce *correct* responses because the
aim of fluency building is to build fast *and correct* responding but
reinforcement must also be provided for increases in *the rate* of
correct responding. In order to reinforce increases in fluency, those
increases must be made visible so that, when they occur, they can be
identified and reinforced.

This is most commonly achieved in one of two ways. The first is to
progressively reduce the time available for completing a standard task
(such as completing a certain number of lines of writing) (e.g., Ayllon,
Garber & Pisor, 1976; Hopkins, Schutte & Garton, 1971). The second is to
provide a timed exercise or self-test, to set, say, a 1-minute time
limit and to provide some kind of reinforcement for improvements in the
number of correct responses which can be performed per minute. Since the
increases in fluency which occur from one practice session to the next
may be quite small, the teacher must use a reasonably accurate and
sensitive measure of fluency.

Fluency can be measured by counting the number of correct responses
provided by the learner during a given period of time such as one minute
(e.g. Church, et al., 2005). Or it can be measured by the recording the
time which the learner takes to complete a procedure or task, or to
produce a specified number of correct responses (e.g. Young, West,
Howard & Whitney, 1986). Increases (from one test to the text) in the
number of correct responses which can be performed per unit of time
provide a measure of improvements in fluency.

In order to make improvements in fluency visible, fluency tests must
contain a reasonable number of items. To show a 3% improvement, the
fluency test must contain 33 items. To show a 2% improvement, the test
must contain 50 items, and to show a 1% improvement the test must
contain 100 items. Generally speaking, a fluency test of basic academic
skills should never consists of less than 33 items. This is because, the
rate of improvement which results *from daily testing alone* is an
increase of about 3% correct answers per minute per day.

Regardless of the procedure which is used to measure improvements in
fluency, it is essential that fluency be assessed regularly so that
improvements in accuracy rate are identified and reinforced when they
occur. If fluency building practice is occurring each day (as would
normally be the case), then the accuracy rate achieved by the learner
should be measured each day or at least every second day. This will not
involve extra teacher time since most measures of fluency can be applied
by the child herself (or by a peer if the children are working in
pairs).

The reinforcement for improvements in accuracy rate may take any of a
variety of forms: performance feedback (e.g., Rhymer, Ditmer, Skinner &
Jackson, 2000), praise (e.g., Kirby & Shields, 1972), contingent access
to preferred activities (e.g., Sandford, 1991; Hopkins, Schuttte &
Garton, 1971), notes to parents (e.g., Schloss, Sedlak, Elliot &
Smothers, 1982), and so on. One procedure which works well for most
students is for the student to keep a record of the results of daily
fluency tests on a personal graph. Being able to see improvements in
one\'s own fluency (and progress towards the fluency goal) functions as
a reinforcing consequence for a high proportion of students. If
self-recording does not provide sufficient motivation, the teacher may
make access to certain classroom privileges, games, or preferred
activities available to students contingent upon meeting successively
higher fluency targets.

During fluency building, it is no longer appropriate to provide feedback
following each individual response because this would interfere with the
learner's attempts to go faster. During fluency building, the assessment
of responses as correct and incorrect, and the correction of incorrect
responses, should occur at the end of blocks or sets of practice
responses (e.g., Miller, Hall & Heward, 1995).
:::

::: referencesList
#### References

-   Ayllon, T., Garber, S., & Pisor, K. (1976). Reducing time limits: A
    means to increase behavior of retardates. Journal of Applied
    Behavior Analysis, 9, 247-252.
-   Church, R. J., Nixon, J., Williams, D., & Zintl, S. (2005). Building
    decoding fluency in 8- to 9-year old poor readers. Paper presented
    to the Annual conference of the New Zealand Association for Research
    in Education, Dunedin, New Zealand.
-   Hopkins, B. L., Schutte, R. C., & Garton, K. L. (1971). The effects
    of access to a playroom on the rate and quality of printing and
    writing of first and second-grade students. Journal of Applied
    Behavior Analysis, 4, 77-87.
-   Kirby, F. D., & Shields, F. (1972). Modification of arithmetic
    response rate and attending behavior in a seventh-grade student.
    Journal of Applied Behavior Analysis, 5, 79-84.
-   Miller, A. D., Hall, S. W., & Heward, W. L. (1995). Effects of
    sequential 1-minute time trials with and without inter-trial
    feedback and self-correction on general and special education
    students' fluency with math facts. Journal of Behavioral Education,
    5, 319-345.
-   Rhymer, K. N., Dittmer, K. I., Skinner, C. H., & Jackson, B. (2000).
    Effectiveness of a multi-component treatment for improving
    mathematics fluency. School Psychology Quarterly, 15, 40-51.
-   Rhymer, K. N., Henington, C., Skinner, C. H., & Looby, E. J. (1999).
    The effects of explicit timing on mathematics performance in
    second-grade Caucasian and African American students. School
    Psychology Quarterly, 14, 397-407.
-   Sandford, C. (1991). Effects of contingent access to a menu of free
    time activities on the reading rate of two third form boys.
    Unpublished EDUC 650 Case Study report. Christchurch, New Zealand:
    University of Canterbury, Education Department.
-   Schloss, P. J., Sedlak, R. A., Elliot, C., & Smothers, M. (1982).
    Application of the changing-criterion design in special education.
    The Journal of Special Education, 16, 359-367.
-   Young, K. R., West, R. P., Howard, V. F., Whitney, R. (1986).
    Acquisition, fluency training, generalization, and maintenance of
    dressing skills of two developmentally disabled children. Education
    and Treatment of Children, 9, 16-29.
:::"
".//Theconditionsuponwhichlearningdepends/Fluencybuildingprocesses/Howfluencyisacquired/Conditionswhichmayaffectthedevelopmentoffluency/index.md","# Conditions which may affect the development of fluency \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-1d86974214d74f1ba8e8dac02c5e0968}
In addition to the conditions which are necessary for fluency building,
there are several other variables which may operate to affect the rate
of progress towards a criterion level of fluency.

**1. When fluency building begins**

When should fluency building begin? Obviously fluency building cannot
begin until the learner has acquired the ability to respond correctly or
at least to respond correctly most of the time. However, experience
suggests that it is not necessary to wait until the learner can respond
correctly to every single item. Fluency building may begin before
completely correct responding has been achieved. \"At about the time when
the child is making 20 or more correct movements during the assessment
with only half as many errors, we should consider a new program to
increase his fluency. . . . There is some evidence that, once a child
\"gets the hang\" of a basic skill, an emphasis on fluency will decrease
his errors almost as much as it increases his correct rate\" (White &
Haring, 1980, p. 236). The general rule seems to be that fluency
building should begin as soon as possible. The sooner fluency building
begins, the sooner it will be achieved. Also, it is important that
fluency building begin as soon as possible so that the teacher does not
accidentally shape up accurate but slow responding (White & Haring,
1980).

**2. How fluent responding is prompted**

In order to shape more skilled responding we prompt skilled responding.
In order to shape correct responding, we prompt correct responding. In
order to shape fluent responding we must prompt fluent responding. This
can be achieved in a variety of ways. Sometimes the simple act of
introducing timed practice and telling the students that they are now
going to be timed is sufficient to produce considerable increases in
fluency (Rhymer, Henington, Skinner & Looby, 1999). Other prompting
procedures include the teacher modelling fluent performance, the teacher
drawing the learner's attention to the responding of a child who has
already mastered the target skill and the teacher directly requesting
faster responses, e.g. \"Today, I want you to see how many you can get
right in two minutes\", or \"Hurry up or you will miss out on PE\". Thirdly
the teacher can clearly describe the fluency aim, or draw the fluency
aim on the student\'s fluency progress graph (Smith & Lovitt, 1974; Van
Houten & Thompson, 1976).

**3. The extent to which slow responses are identified for additional
practice**

At each point during fluency building there will be some items which the
learner still responds to incorrectly from time to time and some items
which the learner takes longer to respond to than others. (This may be
because these items are more difficult or because the learner has had
less practice on these items than on others.) A number of unpublished
EDUC 330 student projects at the University of Canterbury have
demonstrated that, where some of the items are less well learned than
others, fluency development can be accelerated by providing extra
practice on these items. There are a number of practice procedures which
function to provide extra practice on the least well learned items.

-   If flash cards are being used, the items which the learner fails to
    respond to immediately (or fails to respond to correctly) can be
    returned to the pack one-fifth of the way down the pack instead of
    being placed at the back of the pack. This will function to provide
    additional practice on these items.
-   The least well learned items can be identified by the learner or by
    a peer during a timed test by underlining these items. Flash cards
    can be made up for these items for the learner to practise in his or
    her own time, or the learner can practise these items during fluency
    practice sessions for a few days before returning to practise on the
    complete set of items.
-   The learner can use a flash card fluency test, setting aside the
    cards which the learner cannot respond to immediately. Extra
    practice on these cards can be scheduled for the next few days.

Because the items which are least well known will differ from learner to
learner (as a function of differences in the practice histories of each
learner) it follows that fluency building will proceed more rapidly if
this practice is individualised. While group games and class practice
activities have an important role to play in providing variety during
practice, it will only be possible to provide additional practice on the
least well learned items if a high proportion of the fluency practice is
individualised.

**4. The way in which practice sessions are scheduled**

Regular short practices result in the most rapid development of fluency.
This means that, where fluency is the teaching aim, some fluency
building practice should be scheduled each day. In fact, some writers
(e.g. Kameenui & Simmons, 1990; White & Haring, 1980) suggest that
several fluency practices may be scheduled each day. Since fluency
building practices will normally be quite short (3 to 5 minutes), the
scheduling of these practices is a relatively simple matter. They can
simply be scheduled in between longer instructional tasks. The
scheduling of fluency practices is further simplified if each student
has their own individual set of flashcards or fluency building
materials. This enables individual students to engage in fluency
building practice whenever they have a minute or two to spare.

**5. The way in which increases in fluency are reinforced**

Although fluency building practice is not the most exciting form of
instructional activity most children enjoy the challenge of seeing how
fast they can respond. Interest can also be maintained by using a
variety of different kinds of practice activities (e.g. Church, Nixon,
Williams & Zintl, 2005). In addition to solitary practice, students can
work together in pairs or in groups \"testing\" each other. In addition to
practising on worksheets, students can practise using a variety of
different kinds of games. In addition to competing against oneself,
children who have achieved similar fluency levels can compete against
each other. \"Given that practice can become boring, the teacher must put
forth an effort to make practice interesting or fun. Instructional
games, peer teaching, computer-assisted instruction, self-correcting
materials, and reinforcement are helpful in planning practice-to-mastery
activities\" (Mercer & Miller, 1990, p. 23).

The rate of improvement during fluency building is also affected by the
strength of the reinforcement received for improvements in fluency.
While weak reinforcers may be sufficient to motivate some improvement,
the use of stronger reinforcers will motivate greater effort and more
rapid improvement. The strongest reinforcers are contingent access to
preferred activities, that is, access to activities which already
generate reinforcement for the student. In other words, faster rates of
improvement in fluency may be motivated by setting individualised,
intermediate fluency goals and by allowing the students who achieve
these goals to take part in the classroom activities which they like
best, the fluency building games and races which they like best, and the
recreational activities which they like best. \"There is a very good
chance that simple feedback will not maintain the child's best efforts.
Be prepared, therefore, to institute some other program of consequation
if the child fails to accelerate in his correct movement rate. Tokens,
stars, lots of praise, or \"math races\" . . . might well make the
difference between a child becoming bored with the task . . . or
accelerating rapidly to the established fluency criterion\" (White &
Haring, 1980, p. 237). Examples of how rapidly fluency can improve when
students are motivated by strong incentives have been provided by a
number of experiments (e.g. Church et al., 2005; Sandford, 1991).
:::

::: referencesList
#### References

-   Church, J., Nixon, J. Williams, D. & Zintl, S. (2005). Building
    decoding fluency in 8- to 9-year old poor readers. Paper presented
    to the NZARE Conference, Dunedin, New Zealand.
-   Kameenui, E. J. & Simmons, D. C. (1990). Designing instructional
    strategies: The prevention of academic learning problems. Columbus,
    OH: Merrill Publishing Co.
-   Mercer, C. D. & Miller, S. P. (1992). Teaching students with
    learning problems in math to acquire, understand, and apply basic
    math facts. Remedial and Special Education, 13(3), 19-35, 61.
-   Sandford, C. (1991). Effects of contingent access to a menu of free
    time activities on the reading rate of two third form boys.
    Unpublished EDUC 650 Case Study report. Christchurch, New Zealand:
    University of Canterbury, Education Department.
-   Smith, D. D., & Lovitt, T. C. (1974). The influence of instructions
    and reinforcement contingencies on children\'s abilities to compute
    arithmetic problems. In T. A. Brigham, R. Hawkins, J. W. Scott,
    & T. F. McLaughlin. (Eds.). Behavior analysis in education: Self
    control and reading (pp.297-311). Dubuque, IA: Kendall/Hunt
    Publishing Co.
-   Van Houten, R., & Thompson, C. (1976). The effects of explicit
    timing on math performance. Journal of Applied Behavior Analysis, 9,
    227-230.
-   White, O. R. & Haring, N. G. (1980). Exceptional teaching (2nd ed.).
    Columbus, OH: Charles E. Merrill.
:::"
".//Theconditionsuponwhichlearningdepends/Fluencybuildingprocesses/index.md","# Fluency building processes \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-66e02aa2c0004c99b7c83dfa9bfcd3c9}
A learner may acquire the ability to respond correctly without prompting
yet still be unable to respond quickly enough for the new skill to be of
much use. For example, a child may be able to respond correctly to all
single digit addition questions, perhaps by counting up to find the
total but, because the child has to count to find the answer, each
response takes a long time to produce (maybe 6 to 8 seconds).
Responding, although correct, is slow because the child has to work out
the answer to each question and this takes time. With practice, correct
responding becomes faster and more automatic. Eventually the learner
reaches the stage where they can respond sufficiently fluently
(speedily) and effortlessly for the skill to be functional in everyday
life.

Much learning, then, involves not only learning how to perform a
particular skill but how to perform the skill with a functional level of
fluency. Children who have mastered the single digit addition facts are
able to give the answer to an addition fact very quickly. The child who
has mastered the addition facts is able to respond much more quickly
because the answers have been memorised and can be provided
\"automatically\", that is, without having to spend time consciously
working out each answer. An answer which has been memorised can usually
be recalled in less than a second (Logan & Klapp, 1991).

Not all of the skills and understandings specified in the curriculum
need to be practised to mastery and there has been little research to
identify which skills should be so practised. It seem logical to assume
that all skills which will be needed again at subsequent steps of the
school curriculum should be built to high levels of fluency when first
taught. This review will refer to these skills as *basic skills*. The
most obvious basic skills are those involved in fluent talking, reading,
handwriting, keyboarding, spelling, compositional writing, mathematical
computation, and recognising examples of critically important concepts.

The importance of the fluency building phase of teaching is not always
recognised by teachers. As a consequence, not all students achieve
mastery of (fluency in) the basic skills upon which later learning will
depend.

Research suggests that fluency building is of vital importance for three
separate reasons.

*Fluency is needed for reinforcement and maintenance*. Most skills do
not begin to generate reinforcement for the user until they can be
performed with a certain degree of fluency. An instrumentalist will get
no reinforcement from playing in a band until he or she can play both
accurately and quickly enough to keep up with the other players. Skills
which can be performed quickly and accurately tend to generate more
reinforcement than skills which can only be performed slowly and
hesitantly. A child who can only read at the rate of 50 words a minute
will get much less reinforcement from reading than the child who can
read at 250 words a minute.

Where the aim of teaching is to develop in the learner a skill or skills
which the learner will continue to use, then it is essential that the
target skills be practised until they can be performed fluently enough
to generate reinforcement. If, by the end of instruction, a skill is not
fluent enough to generate its own reinforcement, then that skill is
unlikely to be used when instruction ends. \"A child who is able to solve
basic addition facts at a rate of one per minute with perfect accuracy
might know *how* to add, but it is unlikely that he will have *time* to
add in most situations. In order to make a skill truly useful for a
child, we must bring the child's performance up to some level of
*fluency*. He must be able to perform the skill quickly and easily, or
he will probably never use it at all\" (White & Haring, 1980, p. 233).

*Fluency is needed for retention.* Skills and understandings which are
practised only to independence are often forgotten. Skills and
understandings which are practised to mastery, on the other hand, tend
to be remembered and to remain functional for a very long time (Bullara,
Kimball & Cooper, 1993; Ivarie, 1986; Olander, Collins, McArthur, Watts
& McDade, 1986; Shirley & Pennypacker, 1994; Singer-Dudeck & Greer,
2005; Sterling, Goetz & Sterling, 1984). Research into remembering is
now quite advanced. The best predictor of remembering, at the conclusion
of instruction and practice, is level of fluency, that is the speed with
which responses can be recalled.

A child who has achieved a high level of fluency in basic multiplication
facts will probably remember these multiplication facts for the rest of
his or her life. The reason for this is that responses cannot be
performed quickly until they have been \"memorised\" and, once something
has been memorised to the point where it can be immediately recalled, it
tends to be remembered for long periods of time. Where the aim of
teaching is to develop in the learner a set of correct responses, or a
set of knowledge responses which must be remembered because they will be
needed again at some later time, then it is essential that these
responses be practised until they can be instantly recalled.

*Fluency needed for subsequent learning.* Not only does level of fluency
predict long term retention it also predicts rate of improvement with
respect to more advanced skills. One of the first demonstrations of the
importance of bringing basic skills to adequate levels of fluency was
provided by Haughton (1972) who studied the effects of a variety of
remedial teaching strategies which could be used with students who were
having difficulty with maths. He found that bringing the students to
fluency on basic skills (e.g. basic addition, subtraction,
multiplication, division and fraction operations) had a far greater
effect in accelerating future learning than any other kind of remedial
work. Since Haughton's initial demonstration there have been a number of
further experimental demonstrations of the rule that, when tool skills
lower in the curriculum hierarchy are practised to high levels of
fluency, skills which build upon these earlier skills are acquired much
more quickly (Clark, 2001; Evans & Evans, 1985; Evans, Mercer & Evans,
1983; Johnson & Layng, 1992; McDowell & Keenan, 2002; Van Houten &
Sharma (nd) cited in Van Houten, 1980). \"Our charts show us again and
again that the higher the prerequisite skill rates, the faster a complex
skill will be learned\" (Johnson & Layng, 1992, p. 1480).

It is thought that new skills are acquired more quickly when the
component skills are fluent for two main reasons. First, the student who
has practised component skills to a high level of fluency is able to
concentrate more completely on learning the new task or procedure.
Secondly, the student who has practised component skills to a high level
of fluency is able to work more quickly and to complete more practice
examples involving the more advanced skill in the time available.
Students who have achieved high levels of fluency in tool skills at the
time when they are first taught also seem to find school work less
effortful and more enjoyable and tend to require less external
reinforcement in order to maintain adequate levels of motivation. Such
students are often referred to as students who are \"intrinsically
motivated\".

In fact, several studies have shown that fluency in the basic skills is
strongly correlated with both current levels of achievement and future
growth. In other words, a student\'s level of fluency in basic skills
can be used to predict future achievement levels. \"The number of words
read aloud correctly and incorrectly from a basal text reliably and
validly discriminates growth in reading proficiency throughout the
elementary school years\" (Deno, 1985, p. 224).
:::

::: referencesList
#### References

-   Bullara, D. T., Kimball, J. W., & Cooper, J. O. (1993). An
    assessment of beginning addition skills following three months
    without instruction or practice. Journal of Precision Teaching,
    11(1), 11-16.
-   Call for Arithmetic Recovery. (1993). Call for \\"arithmetic
    recovery\\". Parent & School, June, p. 26.
-   Clark, B. (2001). Effects of fluency building in multiplication
    tables on the rate of learning to factorise quadratic equations.
    Unpublished M.Ed. research project report. Christchurch, New
    Zealand: University of Canterbury: School of Education.
-   Deno, S. L. (1985). Curriculum-based measurement: The emerging
    alternative. Exceptional Children, 52, 219-232.
-   Evans, S. S., & Evans, W. H. (1985). Frequencies that ensure skill
    competency. Journal of Precision Teaching, 6(2), 25-35.
-   Evans, S. S., Mercer, C. D., & Evans, W. H. (1983). The relationship
    of frequency to subsequent skill acquisition. Journal of Precision
    Teaching, 9(2), 28-34.
-   Haughton, E. (1972). Aims - Growing and sharing. In J. B. Jordan
    & L. S. Robbins (Eds.), Let's try doing something else kind of
    thing: Behavioral principles and the exceptional child (pp. 20-40).
    Arlington, VA: The Council for Exceptional Children.
-   Ivarie, J. J. (1986). Effects of proficiency rates on later
    performance of a recall and writing behavior. Remedial and Special
    Education, 7(5), 25-30.
-   Johnson, K. R., & Layng, T. V. J. (1992). Breaking the structuralist
    barrier: Literacy and numeracy with fluency. American Psychologist,
    47, 1475-1490.
-   Logan, G. D., & Klapp, S. T. (1991). Automatizing alphabet
    arithmetic: 1. Is extended practice necessary to produce
    automaticity? Journal of Experimental Psychology: Learning, Memory
    and Cognition, 17, 179-195.
-   McDowell, C., & Keenan, M. (2002). Comparison of two teaching
    structures examining the effects of component fluency on the
    performance of related skills. Journal of Precision Teaching, 18(2),
    16-29.
-   Olander, C. P., Collins, D. L., McArthur, B. L., Watts, R. O., &
    McDade, C. E. (1986). Retention among college students: A comparison
    of traditional versus precision teaching. Journal of Precision
    Teaching, 6(4), 80-82.
-   Shirley, M. J., & Pennypacker, H. S. (1994). The effects of
    performance criteria on learning and retention of spelling words.
    Journal of Precision Teaching, 12(1), 73-86.
-   Singer-Dudeck, J. & Greer, R. D. (2005). A long term analysis of the
    relationship between fluency and the training and maintenance of
    complex math skills. The Psychological Record, 55, 361-376.
-   Sterling, L. K., Goetz, E. M., & Sterling, T. (1984). Acquisition
    and maintenance of basal and organic words: Effects of repeated
    practice technique. Behavior Modification, 8, 495-519.
-   Van Houten, R. (1980). Learning through feedback: A systematic
    approach for improving academic performance. New York: Human
    Sciences Press.
-   White, O. R. & Haring, N. G. (1980). Exceptional teaching (2nd ed.).
    Columbus, OH: Charles E. Merrill.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivepunishmentcontingenciesandtheireffects/Effectsofnegativefeedback/index.md","# Effects of negative feedback \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-86b1d5cb47024c16a0e9d07b0c1ee808}
Incorrect responses and inappropriate responses can generate feedback
from the physical or social environment. When an incorrect or
unsuccessful response generates feedback this feedback is variously
referred to as \\"error feedback\\", \\"negative feedback\\" or \"corrective
feedback\". There is clear evidence that error feedback functions as an
aversive event (a punisher) for most children and from an early age.
This is indicated by the fact that most children work to avoid mistakes
in their school work and the teacher corrections which result when one
makes a mistake (McWilliams, 2005). For such children, error corrections
are aversive consequences (because the child tries hard to avoid them)
and the delivery of corrections meets the scientific definition of a
punishment contingency for these children (because incorrect responses
are suppressed).

There are two common types of teacher (and parent) responses to
incorrect (or unsatisfactory) responses. The first is that the errors
are simply ignored, that is, neither accepted as correct, nor corrected.
This procedure is very frequently used by teachers. If a student
responds with an incomplete or less than satisfactory answer, the
teacher simply calls upon another pupil to respond to the original
question. The second possibility is that errors result in some kind
consequence. The most commonly observed consequences are: (a) somebody
provides some kind of error feedback (e.g. \"No, that's not right.\"), (b)
somebody provides error feedback and some kind of correction (e.g. tells
the learner the correct response), or (c) somebody provides error
feedback, and a prompt, and another opportunity to respond.

Which of these two types of differential reinforcement (ignoring or
correction) are most effective? Reviews of research into this question
are agreed that errors, if they occur, must not go uncorrected.
Following a review of several of his own experiments, Douglas Carnine
concluded: \"When the teacher corrected errors \[during arithmetic
lessons\], the children said the right answer about 70 per cent of the
time during training and 65 per cent of the time during post-test. When
the teacher ignored errors, the child said the right answer about 15 per
cent of the time during training and 15 per cent during post-test
(Carnine, 1977, p. 177).

In a review of the research into the effects of feedback,
Bangert-Drowns, Kulik, Kulik and Morgan (1991) reached essentially the
same conclusion. \"Feedback\'s primary importance is in correcting
errors. In these studies, the probability that an item on the dependent
measure would be answered correctly when the same item was answered
correctly during instruction was very high regardless of the presence or
absence of feedback. However, when an item was answered incorrectly
during instruction, it was much more likely to be answered correctly (on
the post-test) in the feedback condition than in the no-feedback
condition\" (Bangert-Drowns et al., 1991, p. 232).

The way in which error corrections accelerate the acquisition of new
responses has been demonstrated for a variety of skills: pronunciation
(Radgowski, Douglas, Allen & LeBlanc, 1978), swimming strokes (Koop &
Martin, 1983), spelling (McNeish, Heron & Okyere, 1992; Vargas,
Grskovic, Belfiore & Halbert-Ayala, 1997), compositional writing (Kline,
Schumaker & Deshler, 1991; Stone & Serwatka, 1982) and maths (Carnine,
1977).

Some parents, early childhood educators, and teachers believe that it is
better simply to ignore children\'s errors during practice than it is to
correct them. Research into the effects of error corrections clearly
provides no empirical support for this view as far as the learning of
new skills is concerned.
:::

::: referencesList
#### References

-   Bangert-Drowns, R. L., Kulik, C. C., Kulik, J. A. & Morgan, M. T.
    (1991). The instructional effect of feedback in test-like events.
    Review of Educational Research, 61, 213-238.
-   Carnine, D. W. (1977). Direct instruction: DISTAR. In N.G. Haring
    & B. Bateman (Eds.), Teaching the learning disabled child. Englewood
    Cliffs, NJ: Prentice Hall.
-   Kline, F. M., Schumaker, J. B., & Deshler, D. D. (1991). Development
    and validation of feedback routines for instructing students with
    learning disabilities. Learning Disability Quarterly, 14, 191-207.
-   Koop, S., & Martin, G. L. (1983). Evaluation of a coaching strategy
    to reduce swimming stroke errors with beginning age-group swimmers.
    Journal of Applied Behavior Analysis, 16, 447-460.
-   McNeish, J., Heron, T. E., & Okyere, B. (1992). Effects of
    self-correction on the spelling performance of junior high school
    students with learning disabilities. Journal of Behavioral
    Education, 2, 17-27.
-   McWilliams, K. (2005). An analysis of the variables affecting
    instructional efficiency. Unpublished PhD thesis. Christchurch, New
    Zealand: University of Canterbury, School of Education.
-   Radgowski, T. A., Douglas, P. S., Allen, K. E., & LeBlanc, J. M.
    (1978). A simple teacher intervention program for the remediation of
    the misarticulated \"L\" in a preschool child's speech. Education and
    Treatment of Children, 1, 15-21.
-   Stone, A. K., & Serwatka, T. S. (1982). Reducing syntactic errors in
    written responses of a retarded adolescent through oral patterning.
    Education and Training of the Mentally Retarded, 17, 71-74.
-   Vargas, A. U., Grskovic, J. A., Belfiore, P. J., & Halbert-Ayala, J.
    (1997). Improving migrant students' spelling of English and Spanish
    words with error correction. Journal of Behavioral Education, 7,
    13-23.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivepunishmentcontingenciesandtheireffects/Effectsofnaturallyoccurringaversiveconsequences/index.md","# Effects of naturally occurring aversive consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c0abf0b4c29f4c36b43ba7b83583a55d}
There are many situations where a given behaviour has a consequence and
that consequence is an aversive consequence which motivates the learner
to avoid that behaviour in particular situations in the future. Examples
include risky responses, careless responses, absent minded responses and
other types of responses which result in trips, falls, bruises, burns,
sprains, broken bones and other kinds of injuries. There has been little
in the way of controlled research into they way in which children learn
not to engage in behaviours which result in naturally occurring aversive
consequences. However, the great majority of children learn to avoid the
risky behaviours which adults have learned to avoid and it seems safe to
assume that much of this learning occurs as a result of experiencing the
aversive consequences which are often the natural result of careless
actions.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivepunishmentcontingenciesandtheireffects/index.md","# Positive punishment contingencies and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-88c1d202d4b74fc7b93bb49cd725178f}
A variety of punishment contingencies are possible: positive punishment
contingencies (in which misbehaviour results in an aversive outcome) and
negative punishment contingencies (where misbehaviour results in a loss
of reinforcement or a loss of access to reinforcement). The aversive
outcome in a positive punishment contingency may be a naturally
occurring outcome (such as the pain which results from getting into a
shower which is too hot), a biological aversive consequence (such as the
hangover which results from drinking too much the night before), the
requirement to engage in an effortful, unpleasant or disliked task, a
socially mediated consequence (such as disapproval), or the negative
feedback which often follows incorrect responses and unsuccessful
attempts.

Although widely used as instruments of social control, positive
punishment contingencies have been little studied. This is because
positive punishment is widely discouraged, if not prohibited, in
educational settings and because ethics committees rarely approve
proposals to investigate the effects of punishment on the behaviour of
human subjects.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivepunishmentcontingenciesandtheireffects/Effectsofbiologicalpunishers/index.md","# Effects of biological punishers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-94b282b984594e978cb4f5919d06ee6a}
The biological punishers include unpleasant tastes, smells and sounds,
events which cause discomfort, events which cause pain, events which
cause anxiety and fear, events which cause nausea, and so on. Because of
ethical concerns, experimental analysis of the effects of biological
punishers is largely limited to studies involving laboratory animals.
However, the human learning literature does include half a dozen case
experiments involving biological punishers. The aversive events which
have been studied in these experiments include water sprays to the face,
ammonia sprays to the nose, lemon juice/citric acid sprays to the mouth,
single smacks, and mild electric shock.

Several studies (e.g., Altman, Grahs & Friman, 1982; Watson, Dittmer &
Ray, 2000) have found that thumb sucking is rapidly suppressed when a
bad tasting patch is attached to the child's thumb.

Gross, Berler and Drabman (1982) used a water squirt to the face to
rapidly suppress aggressive responses in a 4 year old boy with
intellectual disabilities. Doke, Wolery and Sumberg (1983) used an
ammonia spray following aggression in a 7 year old boy with profound
intellectual disabilities. Aggression was immediately suppressed and
remained suppressed a year later. Mayhew and Harris (1979) used
contingent application of citric acid to the mouth following self-injury
and tantrum screaming in a 19 year old male with profound intellectual
disabilities and Gross, Wright & Drabman (1980) applied citric acid
following finger knawing in a 5 year old boy with severe intellectual
disabilities. In both cases the punished behaviours were rapidly
suppressed.

Romanczyk, Colletti and Plotkin (1980) describe the treatment of a 13
year old institutionalised boy with profound intellectual disabilities
who used screaming, self-injury and aggression to avoid certain kinds of
tasks. Treatment included a smack on the thigh when a targeted behaviour
occurred. Each behaviour was rapidly suppressed in turn and remained
suppressed without the need for any further physical punishment.

Creer, Chai & Hoffman (1977) report that the chronic coughing of a 14
year old male was rapidly suppressed following a treatment in which
coughing was followed by a mild electric shock to the forearm. There was
no reappearance of the coughing during follow-ups for 2 years. Kircher,
Pear and Martin (1971) found that two 6 year old children with
intellectual disabilities learned picture names when correct responses
were reinforced and learned picture names even more quickly when, in
addition, inattention and errors resulted in a mild electric shock.

Although the number of studies is small, these experiments indicate that
an inappropriate behaviour can be rapidly suppressed, without any
obvious side effects, using positive punishment administered on an FR1
(continuous) schedule. They further demonstrate that because suppression
is rapid and permanent, very few punishments are required and no further
punishment is required once suppression has occurred. However, it is
also the case that this form of treatment is prohibited in most
treatment settings and this has stimulated a search for alternative,
acceptable treatments of similar effectiveness.

It is often argued that punishment contingencies should not be used
because their effects (on the punished behaviour) are only temporary.
The research clearly does not support this claim. While an argument
against punishment can be made on ethical grounds, it cannot be made on
the grounds that punishment is ineffective or that its effects are only
temporary.
:::

::: referencesList
#### References

-   Altman, K., Grahs, C., & Friman, P. (1982). Treatment of unobserved
    trichotillomania by attention-reflection and punishment of an
    apparent covariant. Journal of Behavior Therapy and Experimental
    Psychiatry, 13, 337-340.
-   Creer, T. L., Chai, H., & Hoffman, A. A. (1977). A single
    application of an aversive stimulus to eliminate chronic cough.
    Journal of Behavior Therapy and Experimental Psychiatry, 8, 107-109.
-   Doke, L. A., Wolery, M., & Sumberg, C. (1983). Treating chronic
    aggression: Effects and side effects of response-contingent ammonia
    spirits. Behavior Modification, 7, 531-556.
-   Gross, A. M., Berler, E. S., & Drabman, R. S. (1982). Reduction of
    aggressive behavior in a retarded boy using a water squirt. Journal
    of Behavior Therapy and Experimental Psychiatry, 13, 95-98.
-   Gross, A. M., Wright, B., & Drabman, R. S. (1980). The empirical
    selection of a punisher for a retarded child\'s self-injurious
    behavior: A case study. Child Behavior Therapy, 2, 59-65.
-   Kircher, A. S., Pear, J. J. & Martin, G. L. (1971). Shock as
    punishment in a picture-naming task with retarded children. Journal
    of Applied Behavior Analysis, 4, 227-233.
-   Mayhew, G., & Harris, F. C. (1979). Decreasing self-injurious
    behavior: Punishment with citric acid and reinforcement of
    alternative behavior. Behavior Modification, 3, 322-336.
-   Romanczyk, R. G., Colletti, G., & Plotkin, R. (1980). Punishment of
    self-injurious behavior: Issues of behavior analysis,
    generalization, and the right to treatment. Child Behavior Therapy,
    2, 37-54.
-   Watson, T. S., Dittmer, K. I., & Ray, K. P. (2000). Treating
    trichotillomania in a toddler: Variations on effective treatments.
    Child & Family Behavior Therapy, 22, 29-40.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivepunishmentcontingenciesandtheireffects/Effectsofeffortfultasksasconsequences/index.md","# Effects of effortful tasks as consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0117a395f5814551be367fd81b425515}
One of the penalties commonly employed as a consequence for
inappropriate behaviour in the home setting is the \"extra chore\". There
has been little in the way of experimental analysis of the conditions
under which this penalty acts as a punishment contingency.

Luce, Delquadri and Hall (1980) studied the effects of requiring 7- and
10-yr-old boys with behaviour problems to sit then stand 5-20 times
following aggressive responses. This penalty resulted in rapid
suppression of aggressive responses -- indicating that the penalty was
functioning as a punishment contingency. Carstens (1980) studied the
effects of requiring a 4-year old fire-setting boy to complete 1 hour of
hard work following every instance of fire-setting or matches play and
found that this penalty completely suppressed these behaviours with no
recurrence at a 6 month follow-up. Fischer and Nehs (1978) reported that
the requirement to wash a window as a consequence of each instance of
swearing resulted in rapid and lasting cessation of swearing in an
11-year old boy. Kelly and Drabman (1977) found that positive practice
(being required to perform the appropriate alternative behaviour half a
dozen times in quick succession) resulted in rapidly reduced eye poking
by a 3-year old visually handicapped boy and Gibbs and Luyben (1985)
report that positive practice quickly suppressed self-injury in a
15-year old boy with intellectual disabilities.

The rapid suppression observed in each of these experiments indicates
that having to complete the chore or the positive practice as a penalty
for inappropriate behaviour functioned as a punishment contingency for
each of the behaviours studied in these experiments.
:::

::: referencesList
#### References

-   Carstens, C. (1982). Application of a work penalty threat in the
    treatment of a case of juvenile fire setting. Journal of Behavior
    Therapy and Experimental Psychiatry, 13, 159-161.
-   Fischer, J., & Nehs, R. (1978). Use of a commonly available chore to
    reduce a boy\'s rate of swearing. Journal of Behavior Therapy and
    Experimental Psychiatry, 9, 81-83.
-   Gibbs, J. W., & Luyben, P. D. (1985). Treatment of self-injurious
    behavior: Contingent versus noncontingent positive practice
    overcorrection. Behavior Modification, 9, 3-21.
-   Kelly, J. A., & Drabman, R. S. (1977). Generalizing response
    suppression of self-injurious behavior through an overcorrection
    punishment procedure: A case study. Behavior Therapy, 8, 468-472.
-   Luce, S. C., Delquadri, J., & Hall, R. V. (1980). Contingent
    exercise: A mild but powerful procedure for suppressing
    inappropriate verbal and aggressive behavior. Journal of Applied
    Behavior Analysis, 13, 583-594.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivepunishmentcontingenciesandtheireffects/Effectsofnegativesocialreactions/index.md","# Effects of negative social reactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c09edb34bf064fa6b17edc19a5c4f1bf}
The most commonly used consequence of inappropriate behaviour during
childhood is adult disapproval. The suppressive effects of disapproval
are acquired. (A reprimand has no effect on the behaviour of a baby.)
The social punishers include such events as the negative reactions of
others, insults, jokes at our expense, the unwanted demands of others,
criticism, reprimands, negative feedback, being treated like a younger
person, and any other reaction from others makes us feel foolish,
embarrassed, intimidated, anxious, or fearful.

Social punishers, like all learned punishers are culturally relative. A
particular phrase which functions as an insult or a reprimand in one
society or culture may have no meaning and hence no punishing affect in
another culture. Whether or not a particular event (such as a warning)
will function as a learned punisher also depends upon the age and
learning history of the individual child.

Commonsense descriptions of how to use reprimands suggest that
reprimands have a stronger suppressive effect if the person delivering
the reprimand stands relatively close to the child (within a metre or
so), if they maintain eye contact while delivering the reprimand and if
the reprimand refers to the specific behaviour which has been judged to
be inappropriate (Van Houten & Doleys, 1983).

Training studies with the teachers and parents of misbehaving children
strongly suggest that at least some misbehaviour is a function of the
amount of attention which it receives from the parent (or teacher). For
example when parents are trained to distinguish between appropriate and
inappropriate behaviour, and to respond more accurately to appropriate
and inappropriate behaviour with approval and disapproval, quite rapid
improvements in child behaviour are usually observed (e.g. Moore &
Bailey, 1973).

Because studies of the effects of socially mediated consequences have
tended to be studies of the effects of approval and disapproval
together, little is known about the effects of disapproval on its own.

Several studies have shown that when teachers consistently disapprove of
off-task behaviour or inappropriate behaviour in 4- to 8-year old
children, the effect is to reduce the amount of inappropriate behaviour
engaged in (Morris & Redd, 1975; Pfifner, O'Leary, Rosen & Sanderson,
1985).

Teachers who use a mixture of approving and disapproving reactions (or
disapproving reactions only) tend to maintain higher levels of on-task
behaviour in their children than teachers who use only approving
reactions (Morris & Redd, 1975). The same effect has been observed for
parental management of misbehaviour and antisocial behaviour in the home
(Rolider & Van Houten, 1984). The praise-reprimand tactic has also been
shown to be slightly more effective than the praise only tactic at the
junior high school level (Workman, Kindall & Williams, 1980).

While positive social reactions to appropriate behaviour alone are not
sufficient to motivate adequate levels of on-task behaviour or response
accuracy in 6- to 8-year old children with behaviour problems, they may
do so after a period in which teachers respond to both appropriate and
inappropriate behaviour with approval and disapproval (Pfifner &
O'Leary, 1987).

When the teacher reprimanded the off-task behaviour of four hyperactive
6 and 7-year olds this had the effect of partially suppressing
interactive off-task behaviour but not non-interactive off-task
behaviour (Abramowitz & O'Leary, 1990).

The dilemma is that teachers who use only positive reactions to child
behaviour are better liked by children than teachers who use a mixture
of approving and disapproving reactions to on-task and off-task
behaviour -- at least during the early years (Morris & Redd, 1975). It
is probably this factor which accounts for the strong preference by many
early childhood and early primary school teachers simply to ignore the
misbehaviour and off-task behaviour of younger children even although
this is a much less effective behaviour management tactic than
responding appropriately to both desired behaviour and misbehaviour.
:::

::: referencesList
#### References

-   Abramowitz, A. J., & O\'Leary, S. G. (1990). Effectiveness of
    delayed punishment in an applied setting. Behavior Therapy, 21,
    231-239.
-   Moore, B. L., & Bailey, J. S. (1973). Social punishment in the
    modification of a pre-school child\'s \\"autistic-like\\" behavior
    with a mother as therapist. Journal of Applied Behavior Analysis, 6,
    497-507.
-   Morris, E. K., & Redd, W. H. (1975). Children\'s performance and
    social preference for positive, negative, and mixed adult-child
    interactions. Child Development, 46, 525-531.
-   Pfiffner, L. J., & O\'Leary, S. G. (1987). The efficacy of
    all-positive management as a function of the prior use of negative
    consequences. Journal of Applied Behavior Analysis, 20, 265-271.
-   Pfiffner, L. J., O\'Leary, S. G., Rosén, L. A., & Sanderson, W. C.
    (1985). A comparison of the effects of continuous and intermittent
    response cost and reprimands in the classroom. Journal of Clinical
    Child Psychology, 14, 348-352.
-   Rolider, A., & Van Houten, R. (1984). The effects of DRO alone and
    DRO plus reprimands on the undesirable behavior of three children in
    home settings. Education & Treatment of Children, 7, 17-31.
-   Van Houten, R. & Doleys, D. M. (1983). Are social reprimands
    effective? In S. Axelrod & J. Apsche (Eds.), The effects of
    punishment on human behavior. New York: Academic Press.
-   Workman, E. A., Kindall, L. M., & Williams, R. L. (1980). The
    consultative merits of praise-ignore versus praise-reprimand
    instruction. Journal of School Psychology, 18, 373-380.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positiveandnegativereinforcementandpunishmentcontingencies/index.md","# Positive and negative reinforcement and punishment contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3ad09444f5ce41508d9f2e799b9233ae}
The practice responses (and other behaviours) engaged in by learners can
have no consequence for the learner or they can have a consequence.
Practice responses can produce desired events or they can work to avoid
undesirable consequences. Practice responses can result in undesirable
consequences or they can result in the disappearance of a desirable
state of affairs. Each of these contingencies, that is, each of these
response-consequence relationships, have different effects on the
likelihood that the learner will engage in a particular response or
behaviour again in the future.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positiveandnegativereinforcementandpunishmentcontingencies/Effectsofpositiveversusnegativecontingencies/index.md","# Effects of positive versus negative contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-24065f810a1d478fb4de30759aaa11dd}
It is possible to motivate improvements in performance using either
positive reinforcement contingencies or negative reinforcement
contingencies. Both have a similar effect both on motivation and on
improvements in performance (McGoey & DuPaul, 2000; Morris & Redd, 1975;
Pfiffner & O'Leary, 1987; Trice & Parker, 1983). However, they have
markedly different effects on the development of likes and dislikes.

This is because the only consequence of failing to perform a positively
reinforced behaviour is that the learner does not receive the
reinforcement. This is a fairly neutral consequence. The consequence of
failing to perform a negatively reinforced behaviour, however, is that
the learner fails to avoid the aversive consequence. That is, the
learner is punished. Errors, mistakes, and other kinds of failure often
result in an aversive consequence. Most learners experience even
corrective feedback as aversive. Working to avoid an aversive outcome
(working under the constant threat of punishment) leaves people feeling
anxious and motivates them to look for ways of avoiding either the task
or the situation altogether. Working to earn reinforcement, on the other
hand, leaves people feeling confident and positive about the tasks which
they are being asked to perform and situation in which they are working.

Many people fail to recognise that, when a punishment procedure is
introduced, it may function either as a positive punishment contingency
(suppressing the behaviour which produces the punishment) or as a
negative reinforcement contingency (strengthening any behaviour which
avoids the punishment). Hence attempts to suppress a behaviour (such as
lying) by punishing it introduce the possibility that alternative
behaviours which succeed in avoiding the punishment (such as lying more
convincingly) will be strengthened through negative reinforcement.

Both punishment and negative reinforcement involve the use of aversive
events (or the threat of such events). Both kinds of contingencies
usually make the learner feel anxious and both kinds of contingencies
can result in the development of a dislike for the situation where the
threat of punishment is present (Morris & Redd, 1975). However, the
motivating effects of the two contingencies could not be more different.
Punishment contingencies *suppress* the punished behaviour (e.g.,
Lovittt, Lovitt, Eaton & Kirkwood, 1973; Luce, Delquadri & Hall, 1980)
while negative reinforcement contingencies *strengthen* the avoidance
behaviour (e.g., Leach & Tan, 1996; Pfiffner & O'Leary, 1987).
:::

::: referencesList
#### References

-   Leach, D. J., & Tan, R. (1996). The effects of sending positive and
    negative letters to parents on the classroom behaviour of secondary
    school students. Educational Psychology. Special Issue: Contemporary
    educational psychology and special education, 16, 141-154.
-   Lovitt, T. C., Lovitt, A. O., Eaton, M. D., & Kirkwood, M. (1973).
    The deceleration of inappropriate comments by a natural consequence.
    Journal of School Psychology, 11, 148-154.
-   Luce, S. C., Delquadri, J., & Hall, R. V. (1980). Contingent
    exercise: A mild but powerful procedure for suppressing
    inappropriate verbal and aggressive behavior. Journal of Applied
    Behavior Analysis, 13, 583-594.
-   McGoey, K. E., & DuPaul, G. J. (2000). Token reinforcement and
    response cost procedures: Reducing the disruptive behavior of
    preschool children with attention-deficit/hyperactivity disorder.
    School Psychology Quarterly, 15, 330-343.
-   Morris, E. K., & Redd, W. H. (1975). Children\'s performance and
    social preference for positive, negative, and mixed adult-child
    interactions. Child Development, 46, 525-531.
-   Morris, E. K., & Redd, W. H. (1975). Children\'s performance and
    social preference for positive, negative, and mixed adult-child
    interactions. Child Development, 46, 525-531.
-   Pfiffner, L. J., & O\'Leary, S. G. (1987). The efficacy of
    all-positive management as a function of the prior use of negative
    consequences. Journal of Applied Behavior Analysis, 20, 265-271.
-   Trice, A. D., & Parker, F. C. (1983). Decreasing adolescent swearing
    in an instructional setting. Education & Treatment of Children, 6,
    29-35.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positiveandnegativereinforcementandpunishmentcontingencies/Effectsofreinforcementversuspunishmentcontingencies/index.md","# Effects of reinforcement versus punishment contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bf8fdb6638fd4e95889aa0930c0fe44b}
Most people can distinguish between the use of rewards (which often
function as reinforcers) and punishments. However, it is important to
remember that one cannot classify a consequence as reinforcing or
aversive simply by looking at the consequence. This is because
consequences are classified by their effects -- so classification
requires observation of the response, its consequence, and the effects
of the consequence on response frequency (motivation).

In an experiment by Thomas, Becker and Armstrong (1968), an increase in
teacher reprimands resulted in an increase in student misbehaviour and a
decrease in reprimands produced a reduction in misbehaviour - showing
that teacher reprimands (and the accompanying teacher attention) were
function as a reinforcing consequence for these students. This was quite
the opposite of what the teacher intended and highlights how important
it is that all teachers learn to distinguish between reinforcing and
aversive consequences.

Another reason why it is not possible to classify consequences as
reinforcing or aversive simply by looking at the consequence is because
the same consequence can have different effects on different learners.
While most younger children find praise reinforcing, there are some
children for whom praise is a neutral consequence -- a consequence which
has no effect on their motivation or their learning (e.g., Weissenburger
& Loney, 1977). While most children find teacher attention reinforcing,
there are some children who find teacher attention aversive and who will
work to avoid teacher attention. While most children find being sent
from the room aversive and will work to avoid being sent from the room,
there are some children for whom being sent from the room is reinforcing
because it allows them to escape from having to work on tasks which are
too hard for them.
:::

::: referencesList
#### References

-   Thomas, D. R., Becker, W. C., & Armstrong, M. (1968). Production and
    elimination of disruptive classroom behavior by systematically
    varying teacher\'s behavior. Journal of Applied Behavior Analysis,
    1, 35-45.
-   Weissenburger, F. E., & Loney, J. (1977). Hyperkinesis in the
    classroom: If cerebral stimulants are the last resort, what is the
    first resort? Journal of Learning Disabilities, 10, 339-348.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positiveandnegativereinforcementandpunishmentcontingencies/Effectsoftwotermversusthreetermlearninginteractions/index.md","# Effects of two term versus three term learning interactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-39d4b63245a340a49275ae3fb74634a7}
Practice interactions may take the form of a response to a practice
stimulus (a two-term learning interaction) or a response to a practice
stimulus which is followed in turn by a consequence of some kind (a
three-term interaction). Because consequences function to determine
which behaviours will be remembered and used again in the future it is
hardly surprising to find that students who are studying under
conditions in which the majority of learning interactions are three term
interactions acquire new skills and understandings more rapidly than is
the case with students who are studying under conditions where many
learning interactions are two-term interactions (Albers & Greer, 1991).
:::

::: referencesList
#### References

-   Albers, A. E., & Greer, R. D. (1991). Is the three-term contingency
    trial a predictor of effective instruction? Journal of Behavioral
    Education, 1, 337-354.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positiveandnegativereinforcementandpunishmentcontingencies/Effectsofvariationsinthetimingofconsequences/index.md","# Effects of variations in the timing of consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8be10235a10543448f8d53e3f8357f28}
It is widely argued that that reinforcing consequences have their
strongest effect when they follow the target behaviour or performance
immediately rather than some time later (Alberto & Troutman, 1999). This
effect has been observed with respect to feedback (Alber & Walshe, 2004)
and with respect to rewards (Fowler & Baer, 1981; Mayhew & Anderson,
1980). It is also argued that the same is true for punishing
consequences (Abramowitz & O'Leary, 1990). Apart from these experiments,
however, this effect has been little studied in classroom settings or
with the kinds of learning outcomes which are of interest to teachers.

Where delay is unavoidable (as is the case with preferred activity
reinforcers) the practitioner is usually advised to bridge the gap
between performance and reinforcement using some kind of token
reinforcement system where the child can be reinforced with a token
(e.g. a checkmark or star on a chart) as soon as he or she has met the
performance criterion. The tokens are then traded at a later time for a
given amount of time in the preferred activity (e.g., Mayhew & Anderson,
1980).

However, delayed reinforcement can also have beneficial effects under
certain circumstances. For example, there are experiments which have
found that delayed (rather than immediate) reinforcement results in
better levels of maintenance (Mayhew & Anderson, 1980) and better
generalisation to new settings (Fowler & Baer, 1981) than immediate
reinforcement. However, these effects have yet to be studied in any
systematic fashion.
:::

::: referencesList
#### References

-   Abramowitz, A. J., & O\'Leary, S. G. (1990). Effectiveness of
    delayed punishment in an applied setting. Behavior Therapy, 21,
    231-239.
-   Alber, S. R., & Walshe, S. E. (2004). When to self-correct spelling
    words: A systematic replication. Journal of Behavioral Education,
    13, 51-66.
-   Alberto, P. A., & Troutman, A. C. (1999). Applied behavior analysis
    for teachers (5th ed.). Upper Saddle River, NJ: Prentice-Hall.
-   Fowler, S. A., & Baer, D. M. (1981). \\"Do I have to be good all
    day?\\" The timing of delayed reinforcement as a factor in
    generalization. Journal of Applied Behavior Analysis, 14, 13-24.
-   Mayhew, G. L., & Anderson, J. (1980). Delayed and immediate
    reinforcement: Retarded adolescents in an educational setting.
    Behavior Modification, 4, 527-545.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Thereinforcementorpunishmentofparticulardimensionsofperformance/Effectsofreinforcingdifferentdimensionsofperformance/index.md","# Effects of reinforcing different dimensions of performance \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2838723e34924cbe8043889683005f6b}
**Effects of reinforcing on task behaviour**

Attention to the task at hand is an essential prerequisite for learning
from classroom tasks. When children are engaged in classroom tasks under
condition in which attention to task is reinforced, the level of
attention to task almost always increases. This effect has been
demonstrated for preschool children (Hamblin & Hamblin, 1972). It has
been demonstrated for primary school children with disabilities (Dixon,
Fitzharris & Moore, 1989; Henderson, Jenson & Erken, 1986; Kazdin &
Mascitelli, 1980) and for primary school children without disabilities
(Glynn, 1972; Glynn, Thomas & Shee, 1973; Kazdin, 1973; Rooney, Hallahan
& Lloyd, 1984; Simmons & Wasik, 1976; Surrat, Ulrich & Hawkins, 1969;
Winett, Richards, Krasner & Krasner, 1971; Yawkey, 1971). It has been
demonstrated for secondary school students (Fontenelle & Holliman, 1983;
Workman, Kindall & Williams, 1980). And it is been demonstrated for
children with conduct problems (Sutherland, Wehby & Copeland, 2000;
Thomas, Pohl, Presland & Glynn, 1977).

**Effects of reinforcing productivity**

A second way of motivating attention to classroom tasks and completion
of classroom tasks is to reinforce students for completing the work set,
or to reinforce students for the number of practice exercises completed.
This dimension of academic performance, task completion is most commonly
referred to as productivity. The effect of reinforcing children's
productivity in the classroom is to motivate increased productivity.
This effect has also been demonstrated for children of varying ages and
for children both with and without disabilities (e.g., Drew, Evans,
Bostow & Drash, 1982; Leach & Byrne, 1986; Lovitt & Esveldt, 1970;
McLaughlin, 1984; McLaughlin & Malaby, 1976; Trice, Parker, Furrow &
Iwata, 1983).

**Effects of reinforcing accurate performance**

In many cases practice responses can be classified as correct or
incorrect and, in these cases, it is possible to make classroom feedback
and reinforcement contingent upon responding correctly or contingent
upon the number or proportion of responses which are correct. This
operation (reinforcing accurate responding) almost always results in an
increase in the level of accuracy during practice. This effect has been
demonstrated in more than 130 separate experiments involving children
with and without disabilities at all age levels. The effect has been
observed with children working on pronunciation tasks (e.g. Johnson &
Johnson, 1972), handwriting tasks (e.g., McLaughlin, 1981), maths tasks
(e.g., Hundert & Batstone, 1978), word recognition tasks (e.g., Lahey &
Drabman, 1974), prose reading tasks (e.g., Fry, 1973; Lahey, McNees &
Schnelle, 1977), reading comprehension tasks (e.g., Edwards, Salant,
Howard, Brougher & McLaughlin, 1995; Lib, Sachs & Boyd, 1973), spelling
tasks (e.g., Kapadia & Fantuzzo, 1988), compositional writing tasks
(e.g., Bording, McLaughlin & Williams, 1984; Newstrom, McLaughlin &
Sweeney, 1999), social studies tasks (e.g., Lo & Cartledge, 2004) and
social skills practice (e.g., Falk, Dunlap & Kern, 1996).

Of course, reinforcing accuracy on learning tasks can only result in
increases in the number correct if (a) correct responding is less than
100% and (b) if the student actually knows how to obtain the correct
answer (Duhon, Noell, Witt, Freeland, Dufrene & Gilbertson, 2004).

**Effects of reinforcing low response rates**

Reinforcement can also be made contingent upon responding at a
particular rate. A common procedure for teaching self regulation, for
example, is to reinforce the student for reducing disruptive responses
or antisocial responses to low level. This procedure is referred to as
the differential reinforcement of a low rate of responding (or DRL for
short). The introduction of a DRL contingency almost always motivates a
level of self-regulation sufficient to ensure that the reinforcement is
earned. This effect has been observed with children with behaviour
problems (both mild and severe) at the preschool level (Deitz, Slack,
Schwarzmueller, Wilander, Weatherly & Hilliard, 1978), the primary
school level (Blue, Madsen & Heimburg, 1981; Deitz & Repp, 1973, 1974;
Ellery, Blampied & Black, 1975; Grieger, 1970), the intermediate school
level (Hobs, Halt & Richardson, 1977) and the secondary level (Deitz &
Repp, 1973; Theodore, Bray, Kehle & Jenson, 2001; Zwald & Gresham,
1982).

DRL has several advantages in that it functions to teach self-regulation
without punishing the child for misbehaving and because high levels of
self-regulation can be achieved by successively reducing the criterion
(the number of mistakes allowed) until the child is misbehaving no more
frequently than his or her normally developing peers (Epstein, Repp &
Cullinan, 1978).

**Effects of reinforcing high response rates**

It is also possible to reinforce children for responding with increasing
speed or for completing a task or set of tasks at a criterion speed or
within a criterion time-limit. The effect of reinforcing children for
responding promptly or quickly (without reference to accuracy) has been
little studied -- probably because teachers are more often interested
building faster correct responding than faster responding per se.
However, it is clear that when responding quickly is reinforced, faster
responding usually results (Ferguson, Ashbaugh, O'Reilly & McLaughlin,
2004; Lovitt and Esveldt, 1970).

**Effects of reinforcing fluent performance**

One of the dimensions of classroom performance which is often of
interest to the teacher is fluency, that is, the number of correct
responses per minute or the number of responses completed correctly
within a given time limit. Fluency is of interest because fluent
performances are retained for long periods of time even in the absence
of practice. A number of controlled experiments have examined the
effects of reinforcing correct responses under conditions where
reinforcement is either proportional to the number of correct responses
per minute or else conditional on increases in fluency. Provided the
child has acquired the ability to respond correctly (Daly, Murdoch,
Lillenstein, Webber & Lentz, 2002), reinforcing responding which is both
correct and speedy almost always results in more rapid improvements in
fluency (accuracy rate) than is the case with repetitive practice, that
is, practice without reinforcement for improvements in fluency (Brown,
Copeland & Hall, 1986; Faykus & McCurdy, 1998; McDowell & Keenan, 2001;
McEvoy & Brady, 1988; Pigott, Fantuzzo, Heggie & Clement, 1984; Schloss,
Sedlak, Elliot & Smothers, 1982; Smith & Lovitt, 1974, 1976; Wolfe,
Fantuzzo & Wolter, 1984).

**Effects of reinforcing response diversity**

Sometimes the goal of instruction is to foster response diversity. This
is most commonly referred to as fostering \"creativity\". The effects of
reinforcing children for the diversity of their responses has been
examined experimentally in the free play setting (Holman, Goetz & Baer,
1977), during drawing activities (Fallon & Goetz, 1975), and during
compositional writing activities (Glover & Sautter, 1977; Ryan &
Winston, 1978). In all cases, reinforcing children for the diversity of
their responses has resulted in increased form diversity, that is,
increased creativity. These results challenge the widely held belief
that creativity is an inherited disposition or that it can be fostered
simply by providing opportunities to \"be creative\" (Fallon & Goetz,
1975).
:::

::: referencesList
#### References

-   Blue, S. W., Madsen, C. H., & Heimberg, R. G. (1981). Increasing
    coping behavior in children with aggressive behavior: Evaluation of
    the relative efficacy of the components of a treatment package.
    Child Behavior Therapy, 3, 51-60.
-   Bording, C., McLaughlin, T. F., & Williams, R. L. (1984). Effects of
    free time on grammar skills of adolescent handicapped students.
    Journal of Educational Research, 77, 312-318.
-   Brown, R. E., Copeland, R. E., & Hall, R. V. (1986). Effects of
    principal implemented procedures on student acquisition of
    multiplication facts. Education and Treatment of Children, 9,
    202-220.
-   Daly, E. J., Murdoch, A., Lillenstein, L., Webber, L., &
    Lentz, F. E. (2002). An examination of methods for testing
    treatments: Conducting brief experimental analyses of the effects of
    instructional components on oral reading fluency. Education and
    Treatment of Children, 25, 288-316.
-   Dietz, S. M., & Repp, A. C. (1973). Decreasing classroom misbehavior
    through the use of DRL schedules of reinforcement. Journal of
    Applied Behavior Analysis, 6, 457-463.
-   Deitz, S. M., & Repp, A. C. (1974). Differentially reinforcing low
    rates of misbehavior with normal elementary school children. Journal
    of Applied Behavior Analysis, 7, 622.
-   Deitz, S. M., Slack, D. J., Schwarzmueller, E. B., Wilander, A. P.,
    Weatherly, T. J., & Hilliard, G. (1978). Reducing inappropriate
    behavior in special classrooms by reinforcing average interresponse
    times: Interval DRL. Behavior Therapy, 9, 37-46.
-   Dixon, R. S., Fitzharris, A., & Moore, D. W. (1989). Reinforcement
    delay and across-setting generalization in an intermediate school
    special class. Behaviour Change, 6, 29-34.
-   Drew, B. M., Evans, J. H., Bostow, G. G., & Drash, P. W. (1982).
    Increasing assignment completion and accuracy using a daily report
    card procedure. Psychology in the Schools, 19, 540-547.
-   Duhon, G. J., Noell, G. H., Witt, J. C., Freeland, J. T.,
    Dufrene, B. A., & Gilbertson, D. N. (2004). Identifying academic
    skill and performance deficits: The experimental analysis of brief
    assessments of academic skills. School Psychology Review, 33,
    429-443.
-   Edwards, L., Salant, V., Howard, V. F., Brougher, J., &
    McLaughlin, T. F. (1995). Effectiveness of self-management on
    attentional behavior and reading comprehension for children with
    attention deficit disorder. Child & Family Behavior Therapy, 17,
    1-17.
-   Ellery, M. D., Blampied, N. M., & Black, W. A. M. (1975). Reduction
    of disruptive behaviour in the classroom: Group and individual
    reinforcement contingencies compared. New Zealand Journal of
    Educational Studies, 10, 59-65.
-   Epstein, M. H., Repp, A. C., & Cullinan, D. (1978). Decreasing
    obscene language of behaviorally disordered children through the use
    of a DRL schedule. Psychology in the Schools, 15, 419-423.
-   Falk, G. D., Dunlap, G., & Kern, L. (1996). An analysis of
    self-evaluation and videotape feedback for improving the peer
    interactions of students with externalizing and internalizing
    behavior problems. Behavioral Disorders, 21, 261-276.
-   Fallon, M. P., & Goetz, E. M. (1975). The creative teacher: Effects
    of descriptive social reinforcement upon the drawing behavior of
    three preschool children. SALT: School Applications of Learning
    Theory, 7, 27-45.
-   Faykus, S. P., & McCurdy, B. L. (1998). Evaluating the sensitivity
    of the maze as an index of reading proficiency for students who are
    severely deficient in reading. Education and Treatment of Children,
    21, 1-21.
-   Ferguson, A., Ashbaugh, R., O'Reilly, S., & McLaughlin, T. F.
    (2004). Using prompt training and reinforcement to reduce transition
    times in a transitional kindergarten program for students with
    severe behavior disorders. Child & Family Behavior Therapy, 26,
    17-24.
-   Fontenelle, S., & Holliman, W. (1983). Social management techniques
    for classroom teachers. Psychological Reports, 52, 815-818.
-   Fry, L. (1973). Token reinforcement and the reading ability of
    retarded readers. New Zealand Journal of Educational Studies, 8,
    165-176.
-   Glover, J. A., & Sautter, F. (1977). Procedures for increasing four
    behaviorally defined components of creativity within formal written
    assignments among high school students. SALT: School Applications of
    Learning Theory, 9, 3-22.
-   Glynn, E. L. (1972). Verbal and token reinforcement: Elements of
    behaviour control in a problem class. New Zealand Psychologist, 1,
    13-20.
-   Glynn, E. L., Thomas, J. D., & Shee, S. M. (1973). Behavioral
    self-control of on-task behavior in an elementary classroom. Journal
    of Applied Behavior Analysis, 6, 105-113.
-   Grieger, R. M. (1970). Behavior modification with a total class: A
    case report. Journal of School Psychology, 8, 103-106.
-   Hamblin, J. A., & Hamblin, R. L. (1972). On teaching disadvantaged
    preschoolers to read: A successful experiment. American Educational
    Research Journal, 9, 209-216.
-   Henderson, H. S., Jenson, W. R., & Erken, N. F. (1986). Using
    variable interval schedules to improve on-task behavior in the
    classroom. Education & Treatment of Children, 9, 250-263.
-   Hobbs, T. R., Holt, M. M., & Richardson, R. (1977). Effects of a
    modified DRL schedule with special education students. Psychological
    Reports, 40, 311-314.
-   Holman, J., Goetz, E. M., & Baer, D. M. (1977). The training of
    creativity as an operant and an examination of its generalization
    characteristics. In B. C. Etzel, J. M. LeBlanc, & D. M. Baer (Eds.).
    New developments in behavioral research: Theory, method, and
    application (pp. 441-471). New York: John Wiley & Sons.
-   Hundert, J., & Batstone, D. (1978). A practical procedure to
    maintain pupils\' accurate self-rating in a classroom token program.
    Behavior Modification, 2, 93-110.
-   Johnston, J. M., & Johnston, G. T. (1972). Modification of consonant
    speech-sound articulation in young children. Journal of Applied
    Behavior Analysis, 5, 233-246.
-   Kapadia, E. S., & Fantuzzo, J. W. (1988). Effects of teacher- and
    self-administered procedures on the spelling performance of
    learning-handicapped children. Journal of School Psychology, 26,
    49-58.
-   Kazdin, A. E. (1973). Role of instructions and reinforcement in
    behavior changes in token reinforcement programs. Journal of
    Educational Psychology, 64, 63-71.
-   Kazdin, A. E., & Mascitelli, S. (1980). The opportunity to earn
    oneself off a token system as a reinforcer for attentive behavior.
    Behavior Therapy, 11, 68-78.
-   Lahey, B. B., & Drabman, R. S. (1974). Facilitation of the
    acquisition and retention of sight-word vocabulary through token
    reinforcement. Journal of Applied Behavior Analysis, 7, 307-312.
-   Lahey, B. B., McNees, M. P., & Schnelle, J. F. (1977). The
    functional independence of three reading behaviors: A behavior
    systems analysis. Corrective & Social Psychiatry & Journal of
    Behavior Technology, Methods & Therapy, 23, 44-47.
-   Leach, D. J., & Byrne, M. K. (1986). Some \\"spill-over\\" effects of
    a home-based reinforcement programme in a secondary school.
    Educational Psychology, 6, 265-276.
-   Libb, J. W., Sachs, C. & Boyd, W. (1973). Reinforcement strategies
    for token economies in a special classroom setting. Psychological
    Reports, 32, 831-834.
-   Lo, Y., & Cartledge, G. (2004). Total class peer tutoring and
    interdependent group oriented contingency: Improving the academic
    and task related behaviors of fourth-grade urban students. Education
    and Treatment of Children, 27, 235-262.
-   Lovitt, T. C., & Esveldt, K. A. (1970). The relative effects on math
    performance of single- versus multiple-ratio schedules: A case
    study. Journal of Applied Behavior Analysis, 3, 261-270.
-   McDowell, C., & Keenan, M. (2001). Developing fluency and endurance
    in a child diagnosed with attention deficit hyperactivity disorder.
    Journal of Applied Behavior Analysis, 34, 345-348.
-   McEvoy, M. A., & Brady, M. P. (1988). Contingent access to play
    materials as an academic motivator for autistic and behavior
    disordered children. Education and Treatment of Children, 11, 5-18.
-   McLaughlin, T. F. (1981). An analysis of token reinforcement: A
    control group comparison with special education youth employing
    measures of clinical significance. Child & Family Behavior Therapy,
    3, 43-50.
-   McLaughlin, T. F. (1984). A comparison of self-recording and
    self-recording plus consequences for on-task assignment completion.
    Contemporary Educational Psychology, 9, 185-192.
-   McLaughlin, T. F., & Malaby, J. E. (1976). An analysis of assignment
    completion and accuracy across time under fixed, variable, and
    extended token exchange periods in a classroom token economy.
    Contemporary Educational Psychology, 1, 346-355.
-   Newstrom, J., McLaughlin, T. F., & Sweeney, W. J. (1999). The
    effects of contingency contracting to improve the mechanics of
    written language with a middle school student with behavior
    disorders. Child & Family Behavior Therapy, 21, 39-48.
-   Pigott, H. E., Fantuzzo, J. W., Heggie, D. L., & Clement, P. W.
    (1984). A student-administered group-oriented contingency
    intervention: Its efficacy in a regular classroom. Child & Family
    Behavior Therapy, 6, 41-55.
-   Rooney, K. J., Hallahan, D. P., & Lloyd, J. W. (1984).
    Self-recording of attention by learning disabled students in the
    regular classroom. Journal of Learning Disabilities, 17, 360-364.
-   Ryan, B. A., & Winston, A. S. (1978). Dimensions of creativity in
    children\'s drawings: A social-validation study. Journal of
    Educational Psychology, 70, 651-656.
-   Schloss, P. J., Sedlak, R. A., Elliot, C., & Smothers, M. (1982).
    Application of the changing-criterion design in special education.
    The Journal of Special Education, 16, 359-367.
-   Simmons, J. T., & Wasik, B. H. (1976). Grouping strategies, peer
    influence, and free time as classroom management techniques with
    first- and third-grade children. Journal of School Psychology, 14,
    322-332 .
-   Smith, D. D., & Lovitt, T. C. (1974). The influence of instructions
    and reinforcement contingencies on children\'s abilities to compute
    arithmetic problems. In T. A. Brigham, R. Hawkins, J. W. Scott,
    & T. F. McLaughlin. (Eds.). Behavior analysis in education: Self
    control and reading. (pp. 297-311). Iowa: Kendall/Hunt.
-   Smith, D. D., & Lovitt, T. C. (1976). The differential effects of
    reinforcement contingencies on arithmetic performance. Journal of
    Learning Disabilities, 9, 21-29.
-   Surratt, P. R., Ulrich, R. E., & Hawkins, R. P. (1969). An
    elementary student as a behavioral engineer. Journal of Applied
    Behavior Analysis, 2, 85-92.
-   Sutherland, K. S., Wehby, J. H., & Copeland, S. R. (2000). Effect of
    varying rates of behavior-specific praise on the on-task behavior of
    students with EBD. Journal of Emotional and Behavioral Disorders, 8,
    2-8, 26.
-   Swanson, L. (1981). Modification of comprehension deficits in
    learning disabled children. Learning Disability Quarterly, 4,
    189-202.
-   Theodore, L. A., Bray, M. A., Kehle, T. J., & Jenson, W. R. (2001).
    Randomization of group contingencies and reinforcers to reduce
    classroom disruptive behavior. Journal of School Psychology, 39,
    267-277.
-   Thomas, J. D., Pohl, F., Presland, I., & Glynn, E. L. (1977). A
    behaviour analysis approach to guidance. New Zealand Journal of
    Educational Studies, 12, 17-28.
-   Trice, A. D., Parker, F. C., Furrow, F., & Iwata, M. M. (1983). An
    analysis of home contingencies to improve school behavior with
    disruptive adolescents. Education & Treatment of Children, 6,
    389-399.
-   Winett, R. A., Richards, C. S., Krasner, L., & Krasner, M. (1971).
    Child-monitored token reading program. Psychology in the Schools, 8,
    259-262.
-   Wolfe, J. A., Fantuzzo, J., & Wolter, C. (1984).
    Student-administered group-oriented contingencies: A method of
    combining group-oriented contingencies and self-directed behavior to
    increase academic productivity. Child & Family Behavior Therapy, 6,
    45-60.
-   Workman, E. A., Kindall, L. M., & Williams, R. L. (1980). The
    consultative merits of praise-ignore versus praise-reprimand
    instruction. Journal of School Psychology, 18, 373-380.
-   Yawkey, T. D. (1971). Conditioning independent work behavior in
    reading with seven-year-old children in a regular early childhood
    classroom. Child Study Journal, 2, 23-34.
-   Zwald, L., & Gresham, F. M. (1982). Behavioral consultation in a
    secondary class: Using DRL to decrease negative verbal interactions.
    School Psychology Review, 11, 428-432.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Thereinforcementorpunishmentofparticulardimensionsofperformance/Effectsofreinforcingimprovementsversuscriterionperformance/index.md","# Effects of reinforcing improvements versus criterion performance \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b307f734b082461abb78bcc27f171a94}
It is widely argued that teachers should reinforce improvements. This is
an entirely reasonable suggestion since, if reinforcement was withheld
until the learner achieved criterion performance, the learner would
often receive very little reinforcement.

This is especially true of those skills where the learner must acquire
new levels of motor coordination such as talking, walking, handwriting
and so on. Such skills are acquired only slowly and after considerable
practice. Such skills are normally \"shaped\", that is, practised under
conditions in which improvements in performance are differentially
reinforced. There are many controlled studies of shaping. Almost without
exception these studies demonstrate that new skills which require
considerable practice are acquired much more rapidly under conditions in
which *improvements* are reinforced rather than under conditions which
do not reinforce improvements (Allison, & Ayllon, 1980; Buzas & Ayllon
1981; Fitterling & Ayllon, 1983; Koop & Martin, 1983; Lahey, Busemeyer,
O\'Hara & Beggs, 1977; Shapiro, & Shapiro, 1985; Swanson, 1981; Sweeney,
Salva, Cooper. & Talbert-Johnson, 1993; Trap, Milner-Davis, Joseph &
Cooper, 1978; Ward, Crouch, & Patrick, 1998).

However, none of these studies have directly compared the effects of
reinforcing improvements versus reinforcing the achievement of criterion
performance. This means that we have yet to gain a clear idea of those
learning outcomes for which it is more effective to reinforce
improvements and those learning outcomes where it is more effective to
reinforce criterion levels of performance such as responding correctly.
:::

::: referencesList
#### References

-   Allison, M. G., & Ayllon, T. (1980). Behavior coaching in the
    development of skills in football, gymnastics, and tennis. Journal
    of Applied Behavior Analysis, 13, 297-314.
-   Buzas, H. P., & Ayllon, T. (1981). Differential reinforcement in
    coaching tennis skills. Behavior Modification, 5, 372-385.
-   Fitterling, J. M., & Ayllon, T. (1983). Behavioral coaching in
    classical ballet: Enhancing skill development. Behavior
    Modification, 7, 345-368.
-   Koop, S., & Martin, G. L. (1983). Evaluation of a coaching strategy
    to reduce swimming stroke errors with beginning age-group swimmers.
    Journal of Applied Behavior Analysis, 16, 447-460.
-   Lahey, B. B., Busemeyer, M. K., O\'Hara, C., & Beggs, V. E. (1977).
    Treatment of severe perceptual-motor disorders in children diagnosed
    as learning disabled. Behavior Modification, 1, 123-140.
-   Shapiro, E. S., & Shapiro, S. (1985). Behavioral coaching in the
    development of skills in track. Behavior Modification, 9, 211-224.
-   Swanson, L. (1981). Modification of comprehension deficits in
    learning disabled children. Learning Disability Quarterly, 4,
    189-202.
-   Sweeney, W. J., Salva, E., Cooper, J. O., & Talbert-Johnson, C.
    (1993). Using self-evaluation to improve difficult-to-read
    handwriting of secondary students. Journal of Behavioral Education,
    3, 427-443.
-   Trap, J. J., Milner-Davis, P., Joseph, S., & Cooper, J. O. (1978).
    The effects of feedback and consequences on transitional cursive
    letter formation. Journal of Applied Behavior Analysis, 11, 381-393.
-   Ward, P., Crouch, D. W., & Patrick, C. A. (1998). Effects of
    peer-mediated accountability on opportunities to respond and correct
    skill performance by elementary school children in physical
    education. Journal of Behavioral Education, 8, 103-114.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Thereinforcementorpunishmentofparticulardimensionsofperformance/Effectsofreinforcingtaskengagementversusaccuracy/index.md","# Effects of reinforcing task engagement versus accuracy \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f2a58447d72541058bc348b92235ff1b}
In the classroom, the consequences which are being used to motive
improvements in performance can be made contingent on engagement
(attending to the task in hand), productivity (completing the task in
hand), improvements in performance accuracy, or improvements in fluency.

**Reinforcing time on task and productivity**

Attention to practice stimuli, engagement with learning tasks, and
staying on task until learning activities are completed are essential
prerequisites for learning. Where learning tasks are difficult for the
learner, or disliked by the learner, the teacher may need to begin by
simply reinforcing improvements in time on task or task completion.

Where the aim is to shape task engagement, classroom reinforcers may be
made contingent on time on task, or on the amount of work completed.
This kind of contingency almost always produces rapid and marked
increases in time on task and work completed as indicated earlier in
this section. However, because reinforcement is not contingent upon
accuracy or quality, the reinforcement of task completion may result in
no change or improvement in the quality of the work completed (e.g.,
Ferritor, Buckholdt, Hamblin & Smith, 1972; Hundert, Bucher & Henderson,
1976).

**Reinforcing accurate performance**

It is clear from the earlier section on reinforcing accurate
performances that the reinforcement of correct responses almost always
results in an increase in the proportion of correct responses. A number
of these studies have further demonstrated that the reinforcement of
correct responding nearly always results in an increase in time on task,
task engagement and productivity (Broughton & Lahey, 1978; Ferritor et
al., 1972; Hundert et al., 1976; Marholin & Steinman, 1977). The reason
for this is fairly obvious. Unless the student attends, concentrates,
and works at producing accurate responses, no reinforcement is
forthcoming.

However, reinforcing accurate performance has a down side as well. If
reinforcement is made contingent upon the number of correct responses,
there is no incentive to respond quickly. In fact, the pupil may be
motivated to work conscientiously, that is, *slowly* and carefully in an
attempt to maximise the number of correct responses (Eisenberger,
Mitchell, McDermitt & Masterson, 1984). Reinforcing accuracy, in other
words, may work against the development of mastery. Since mastery is
always a long term aim of instruction (at least in basic skills) it
follows that the reinforcement of accuracy is a procedure which should
only be used during the transition from the initial learning phase to
the independence phase of the learning cycle and not where the teaching
aim is to build mastery, that is, fast and accurate performance.

**Reinforcing fluent performance**

A third dimension of classroom performance is the *fluency dimension*,
that is, fast and accurate responding. Where the objective of practice
is to develop mastery, classroom reinforcers must be made contingent
upon improvements in the *speed* with which the learner can recall
correct responses, that is, contingent on improvements in the rate of
accurate responding. When improvements in fluency are reinforced, speed
improves and accuracy also continues to improve (e.g. Faykus & McCurdy,
1998; McEvoy & Brady, 1988; McDowell & Keenan, 2001; Schloss, Sedlak,
Elliot & Smothers, 1982).

Informal accounts of student performance during fluency building
sessions suggest that, when classroom reinforcers are made contingent
upon improvements in fluency, task engagement tends to be maintained at
a high level. However, there appear to be no experimental demonstrations
of this effect.
:::

::: referencesList
#### References

-   Broughton, S. F., & Lahey, B. B. (1978). Direct and collateral
    effects of positive reinforcement, response cost, and mixed
    contingencies for academic performance. Journal of School
    Psychology, 16, 126-136.
-   Eisenberger, R., Mitchell, M., McDermitt, M., & Masterson, F. A.
    (1984). Accuracy versus speed in the generalized effort of
    learning-disabled children. Journal of the Experimental Analysis of
    Behavior, 42, 19-36.
-   Faykus, S. P., & McCurdy, B. L. (1998). Evaluating the sensitivity
    of the maze as an index of reading proficiency for students who are
    severely deficient in reading. Education and Treatment of Children,
    21, 1-21.
-   Ferritor, D. E., Buckholdt, D., Hamblin, R. L., & Smith, L. (1972).
    The non-effects of contingent reinforcement for attending behavior
    on work accomplished. Journal of Applied Behavior Analysis, 5, 7-17.
-   Hundert, J., Bucher, B., & Henderson, M. (1976). Increasing
    appropriate classroom behavior and academic performance by
    reinforcing correct work alone. Psychology in the Schools, 13,
    195-200.
-   Marholin, D., & Steinman, W. M. (1977). Stimulus control in the
    classroom as a function of the behavior reinforced. Journal of
    Applied Behavior Analysis, 10, 465-478.
-   McEvoy, M. A., & Brady, M. P. (1988). Contingent access to play
    materials as an academic motivator for autistic and behavior
    disordered children. Education and Treatment of Children, 11, 5-18.
-   McDowell, C., & Keenan, M. (2001). Developing fluency and endurance
    in a child diagnosed with attention deficit hyperactivity disorder.
    Journal of Applied Behavior Analysis, 34, 345-348.
-   Schloss, P. J., Sedlak, R. A., Elliot, C., & Smothers, M. (1982).
    Application of the changing-criterion design in special education.
    The Journal of Special Education, 16, 359-367.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Thereinforcementorpunishmentofparticulardimensionsofperformance/Effectsoftimebasedversusresponsebasedcontingencies/index.md","# Effects of time based versus response based contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7e7398b7882148bcbfb91ce43f0ad78f}
There are a number of situations where teachers have a choice between
response-based and time-based contingencies.

**DRL versus punishment**

For example, a teacher or parent can reinforce a child for not engaging
in antisocial behaviour for a given time period (say one hour) or can
apply a punishment or penalty each time that the child engages in
particular antisocial behaviours. When Trice and Parker (1983) compared
the effect of reinforcing two 16-year old boys for not swearing against
the effect of a response cost penalty for each instance of swearing they
found that both procedures were equally effective in suppressing
swearing.

**Reinforcing time on task versus productivity**

When a teacher is attempting to motivate task engagement he or she may
elect to reinforce criterion levels of time on task or to reinforce
criterion levels of productivity. When Lannie and Martens (2004)
compared the effect of reinforcing students for time on task against the
effect of reinforcing students for the number of exercises completed on
maths worksheets they found that the students preferred to earn
reinforcement for being on task when the worksheets contained difficult
exercises but to earn reinforcement for the number completed when the
worksheets contained easy exercises.
:::

::: referencesList
#### References

-   Lannie, A. L., Martens, B. K. (2004). Effects of task difficulty and
    type of contingency on students\' allocation of responding to math
    worksheets. Journal of Applied Behavior Analysis, 37, 53-65.
-   Trice, A. D., & Parker, F. C. (1983). Decreasing adolescent swearing
    in an instructional setting. Education & Treatment of Children, 6,
    29-35.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Thereinforcementorpunishmentofparticulardimensionsofperformance/index.md","# The reinforcement or punishment of particular dimensions of performance \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-aac1835792064c7faea71e72be9bc296}
A response, behaviour or action which is in the process of being
acquired may vary along more than one dimension. The following examples
illustrate this fact.

-   Young children's naming responses may vary with respect to
    pronunciation and they may vary with respect to whether they are
    correct or not and consequences may be contingent on improvements in
    pronunciation, or accuracy, or both.
-   Goal shooting responses may vary with respect to force and with
    respect to accuracy and success may be contingent on improvements in
    accuracy, or force, or both.
-   Academic responding in the classroom may vary along a number of
    dimensions: time on task (academic engaged time), productivity (the
    amount of work completed), accuracy (the proportion of responses
    which are correct) and fluency (e.g., the number of correct
    responses per minute). Reinforcing (and punishing) consequences may
    be contingent on any one or more of these dimensions.

These examples remind us that we can reinforce each occurrence of
responses in a particular response class (e.g., complying) or we can
reinforce just those responses which meet certain dimensional
requirements (e.g., complying promptly).
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/index.md","# The effects of contingency variables \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bd91c5737a704d648ddf369ff941945a}
Research into the effects of various kinds of consequences and
contingency operations on motivation and learning is extensive. The
effects of reinforcing pupils for their effort, their productivity, and
their correct responses have been studied in many hundreds of controlled
experiments. As a result we know more about the effects of consequences
than we do about the effects of almost any other teaching variable.
Lysakowski and Walberg reviewed some of this research in 1981 and
concluded that reinforcement variables have a stronger effect on
learning than almost any other variable apart from practice itself. They
further concluded that: \\"Contrary to previous theory and opinions, the
strong effects of instructional reinforcement appear constant across
grades (kindergarten through college), socio-economic levels, race,
private and public schools, and community types\\" (Lysakowski & Walberg,
1981, p. 69).

Since then researchers have continued to study the effects of different
types of reinforcing (and aversive) consequences, the effects of
different types of contingencies, the effects of different schedules of
reinforcement (and punishment) and the effects of reinforcing different
dimensions of performance.

In this chapter we will review the effects on motivation and learning of
introducing and removing positive and negative reinforcement
contingencies, the effects of introducing and removing positive and
negative punishment contingencies, the effects of differentially
reinforcing differing dimensions of performance and the effects of
differing schedules of reinforcement and punishment.
:::

::: referencesList
#### References

-   Lysakowski, R. S. & Walberg, H. J. (1981). Classroom reinforcement
    and learning: A quantitative synthesis. Journal of Educational
    Research, 75, 69-77.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/Effectofconcurrentschedulesofreinforcementandpunishment/index.md","# Effect of concurrent schedules of reinforcement and punishment \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-52c1dcbc72f24b9d9b3852c7912b685c}
When responses can be grouped into two mutually exclusive classes such
as appropriate/ inappropriate or correct/incorrect or easy/difficult
three interventions are possible. The teacher can (a) increase the
reinforcement for appropriate responses (e.g. complying), (b) increase
the punishment for inappropriate responses (e.g. not complying) or (c)
do both of these things. The question which arises under these
circumstances is the question regarding the relative effectiveness of
each of these alternatives.

There is no doubt that the differential reinforcement of appropriate
behaviour can result in both an increase the level of appropriate
responding while at the same time producing collateral reductions in
antisocial responses and this has been demonstrated with preschool
children (Conyers, Miltenberger, Romaniuk, Kopp & Himle, 2003; Didden,
de Moor & Bruyns, 1997), with primary school children (Gwinn, Derby,
Fisher, Kurtz, Fahs, Agustine et al., 2005), and with secondary school
students (Workman, Kindall & Williams, 1980).

However, this strategy does not always work. There are a number of
experiments where reinforcing pro-social behaviour on its own has failed
to result in any reduction in the levels of antisocial behaviour engaged
in by the non-compliant child -- especially with older children (e.g.
Rosén, Gabardi, Miller & Miller, 1990).

In these cases, the introduction of a concurrent reinforcement
contingency for appropriate behaviour together with a punishment
contingency for antisocial responses almost always results in a rapid
reduction in antisocial responses and their replacement by appropriate
pro-social responses (Kelley & McCain, 1995; Morris & Redd, 1975; Osnes,
Guevremont & Stokes, 1987; Perry & Fisher, 2001; Pfiffner & O'Leary,
1987; Rosén et al., 1990; Workman, et al., 1980).

Subsequent experimental analyses have identified some of the factors
which operate to determine whether the differential reinforcement of a
prosocial response alone will function to strengthen that response to
the point where antisocial ways of obtaining the same outcome are
abandoned by the learner. The experiments by Perry and Fisher (2001) and
Gwinn et al. (2005) indicate that the effects of differential
reinforcement alone depend upon the degree of response effort required
in making the change from inappropriate (e.g. antisocial) to appropriate
(e.g. pro-social) modes of responding. As the level of response effort
which is involved in making the change increases, differential
reinforcement alone is unlikely to work unless an extremely powerful
reinforcer can be employed. This effect can also be seen in the
experiment by Connors et al. (2003). Strong reinforcers are rarely
available for use in educational settings. If response effort is
considerable, and only reinforcers of moderate strength are available,
then the only way of providing the level of motivation required is to
both reinforce the appropriate social responses and to place an
effective penalty (punishment contingency) on continued use of the
inappropriate or antisocial responses. In the Perry and Fisher
experiment \"increasing the price associated with destructive behaviour
by adding a punishment procedure overrode the effects of response effort
and allowed us to rapidly increase the amount of work Anne completed\"
(Perry & Fisher, 2001, p. 215).

A second factor which needs to be taken into account is the question of
whether the child is being asked to comply with \"do\" requests or \"don't
requests\". A stronger reinforcer is required in motivating compliance
with \"don't requests\" (Houlihan & Jones, 1990). The reason for this is
unclear but may be because \"do requests\" explecitly identify the desired
alternative behaviour, that is, the behaviour which will be reinforced.

In situations where response effort is uncontrolled (which is the case
in almost all of these experiments to date), uncontrolled variations in
response effort can be expected to result in variations in experimental
results and this seems to be what is happening in the above cited
experiments.

While the concurrent reinforce-appropriate/punish-inappropriate
contingency usually produces the most rapid change to prosocial
responding, there is some evidence that, once the change has occurred, a
reinforce-appropriate/ignore-inappropriate contingency may be sufficient
to ensure maintenance of the change (Pfiffner & O'Leary, 1987). In fact,
Workman et al. (1980) observed better maintenance of appropriate
responding following concurrent praise-appropriate/ignore-inappropriate
behaviour than following concurrent praise/reprimand contingencies with
poorly behaved junior high school students. This may be because the move
from praise/ignore to normal classroom contingencies was less obvious
than the move from praise/reprimand to normal contingencies.

One of the dilemmas in motivating poorly behaved children to switch from
antisocial to pro-social modes of responding is the fact that while the
concurrent reinforce-prosocial/punish-antisocial contingency is the most
effective across the age range, students usually prefer the
reinforce-prosocial/ignore-antisocial contingency at least during the
early years (Morris & Redd, 1975).
:::

::: referencesList
#### References

-   Conyers, C., Miltenberger, R., Romaniuk, C., Kopp, B., & Himle, M.
    (2003). Evaluation of DRO schedules to reduce disruptive behavior in
    a preschool classroom. Child & Family Behavior Therapy, 25, 1-6.
-   Didden, R., de Moor, J., & Bruyns, W. (1997). Effectiveness of DRO
    tokens in decreasing disruptive behavior in the classroom with five
    multiply handicapped children. Behavioral Interventions, 12, 65-75.
-   Gwinn, M. M., Derby, K. M., Fisher,W., Kurtz, P., Fahs, A.,
    Augustine, M., et al. (2005). Effects of increased response effort
    and reinforcer delay on choice and aberrant behavior. Behavior
    Modification, 29, 642-652.
-   Houlihan, D., & Jones, R. N. (1990). Exploring the reinforcement of
    compliance with \\"do\\" and \\"don\'t\\" requests and the side effects:
    A partial replication and extension. Psychological Reports, 67,
    439-448.
-   Kelley, M., & McCain, A. P. (1995). Promoting academic performance
    in inattentive children: The relative efficacy of school-home notes
    with and without response cost. Behavior Modification, 19, 357-375.
-   Morris, E. K., & Redd, W. H. (1975). Children\'s performance and
    social preference for positive, negative, and mixed adult-child
    interactions. Child Development, 46, 525-531.
-   Osnes, P. G., Guevremont, D. C., & Stokes, T. F. (1987). Increasing
    a child\'s prosocial behaviors: Positive and negative consequences
    in correspondence training. Journal of Behavior Therapy and
    Experimental Psychiatry, 18, 71-76.
-   Perry, A. C., & Fisher, W. W. (2001). Behavioral economic influences
    on treatments designed to decrease destructive behaviour. Journal of
    Applied Behavior Analysis, 34, 211-215.
-   Pfiffner, L. J., & O\'Leary, S. G. (1987). The efficacy of
    all-positive management as a function of the prior use of negative
    consequences. Journal of Applied Behavior Analysis, 20, 265-271.
-   Rosén, L. A., Gabardi, L., Miller, C. D., & Miller, L. (1990).
    Home-based treatment of disruptive junior high school students: An
    analysis of the differential effects of positive and negative
    consequences. Behavioral Disorders, 15, 227-232.
-   Workman, E. A., Kindall, L. M., & Williams, R. L. (1980). The
    consultative merits of praise-ignore versus praise-reprimand
    instruction. Journal of School Psychology, 18, 373-380.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/Proceduresfortransferringcontrolfromcontinuoustointermittentschedulesandtheireffects/index.md","# Procedures for transferring control from continuous to intermittent schedules and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8d4acafc613b417eb6038b45b9371e4a}
The aim of any teaching sequence is always to produce independent
performance in the learner. Similarly, the aim of any procedure designed
to improve self-regulation is always to produce a level of
self-regulation such that programmed punishment contingencies are no
longer required. In both of these cases, the task facing the teacher is
that of moving from the continuous or frequently occurring contingencies
of marking/checking and consequential reinforcement and correction to
the intermittent (and infrequent) schedules of naturally occurring
consequences which typically operate in the classroom. How is this to be
achieved? It is usually argued that the transfer from frequent
reinforcement to intermittent reinforcement should be gradual, that is,
that the schedule should be gradually thinned. Good levels of
maintenance following the gradual thinning of programmed contingencies
of reinforcement has been demonstrated for a number of learning outcomes
in a variety of classroom settings (Bailey, Wolf & Phillips, 1970;
Christensen, Young & Marchant, 2004; Fry & Thomas, 1976; Hagopian,
Contrucci Kuhn, Long & Rush, 2005; McNaughton, 1975).

Having demonstrated that new levels of skill and of self-regulation can
be maintained, and extinction avoided, when programmed contingencies of
reinforcement (and punishment) are gradually thinned, researchers now
need to turn their attention to identifying the conditions which must be
present in order for this effect to occur. Is it dependent upon the
level of mastery or fluency which has been achieved, for example? How
rapidly can the schedule be thinned while still achieving maintenance,
and so on?
:::

::: referencesList
#### References

-   Bailey, J. S., Wolf, M. M., & Phillips, E. L. (1970). Home-based
    reinforcement and the modification of pre-delinquents\' classroom
    behavior. Journal of Applied Behavior Analysis, 3, 223-233.
-   Christensen, L., Young, K. R., & Marchant, M. (2004). The effects of
    a peer-mediated positive behavior support program on socially
    appropriate classroom behavior. Education and Treatment of Children,
    27, 199-234.
-   Fry, L., & Thomas, J. (1976). A behaviour modification approach to
    rehabilitating behaviourally disordered children in an adjustment
    class. New Zealand Journal of Educational Studies, 11, 124-131.
-   Hagopian, L. P., Contrucci Kuhn, S. A., Long, E. S., & Rush, K. S.
    (2005). Schedule thinning following communication training: Using
    competing stimuli to enhance tolerance to decrements in reinforcer
    density. Journal of Applied Behavior Analysis, 38, 177-193.
-   McNaughton, S. S. (1975). Some implications of a technique designed
    to produce rapid and generalized modification of out-of-seat
    behaviour. New Zealand Journal of Educational Studies, 10, 120-127.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/index.md","# Schedules of reinforcement and punishment \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c6740897b38d45ac884c98037eb83cef}
A particular response may be successful in generating reinforcement or
in avoiding punishment every time that it is used or it may be
successful on only some occasions. A teacher or parent may correct or
punish a particular behaviour every time that it occurs or they may
detect and correct the behaviour only on some occasions. The number or
proportion of occasions when a particular response has a reinforcing (or
punishing) outcome is referred to as the schedule of reinforcement (or
punishment). Schedules of reinforcement and punishment may vary in a
number of ways. For example, consequences may be scheduled to occur
frequently or infrequently, to occur continuously or intermittently and
to occur predictably or unpredictably.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/Effectofconcurrentschedulesofpunishmentforappropriateandinappropriatebehaviour/index.md","# Effect of concurrent schedules of punishment for appropriate and inappropriate behaviour \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6f1dc89f90474f7fb84e3b36d7739e31}
It is possible for appropriate behaviour to have punishing as well as
reinforcing outcomes. A child may attempt to negotiate an unreasonable
demand but be punished for failing to comply. A child may work hard at a
very difficult task which they find very difficult, only to be
reprimanded for failing to complete the task.

One of the major causes of motivational problems in the classroom (for
children of all ages) is the setting of tasks which are too difficult.
Being asked repeatedly to work on learning tasks which are too difficult
to complete successfully tends to produce reduced levels of interest,
motivation, and self-confidence (e.g. Schumm, Moody & Vaughn, 2000).

There is some evidence to suggest that classroom teachers experience
difficulty in ensuring that all of the children in a diverse classroom
are placed on reading materials of the appropriate level of difficulty
(Schumm et al., 2000) and the same problem has been observed in New
Zealand studies (Shearer, 1999). Schumm et al. (2000) reported that in
23 of the 29 third grade classrooms in their sample, the reading
programme was class-based with all of the children working on the same
reading materials. As a result \\"the students with reading and learning
disabilities demonstrated minimal gains. In general, students\'
self-concept about themselves also plateaued, while their attitudes
toward reading declined\\" (Schumm et al., 2000, p. 486).

Little research has been undertaken into the effects of placing students
(or failing to place students) on learning tasks which result in
adequate levels of success. (Possibly this is because the need to employ
learning tasks at an appropriate level of difficulty is so self-evident
that it appears not to require experimental analysis.) Kameenui, Carnine
and Freschi (1982) examined the effect of changing a difficult text so
that it was more readily understood by 60 9- to 11-year old students.
This was achieved by replacing the most difficult words with words
likely to be understood by this age group. The effect of making the text
more comprehensible to the students was to increase both post-study
comprehension scores and retention scores. Morris, Blanton, Blanton,
Nowacek and Perney (1995) compared the effects of assigning 48 3rd grade
poor spellers to either a 2nd grade spelling curriculum (experimental
group) or 3rd grade spelling curriculum (contrast group) for one school
year. At the end of the year, the experimental group students obtained
higher scores than the contrast group on the 2nd grade end-of-year
spelling test and obtained similar scores to the contrast students on
the 3rd grade end-of-year spelling test. Daly, Martens, Kilmer and
Massie (1996) instructed four students with mild disabilities using
passages at two levels of text difficulty (instructionally matched and
instructionally mismatched). Students' oral reading accuracy and fluency
on subsequent test passages showed a greater degree of generalization
when instructional materials were matched to the students' skill level.

There is, then, some experimental evidence to support the commonly held
view that classroom tasks which are too difficult result in declining
motivation and declining achievement -- presumably because of the
elevated rates of punishment (failure) which they generate.
:::

::: referencesList
#### References

-   Daly, E. J., Martens, B. K., Kilmer, A., & Massie, D. R. (1996). The
    effects of instructional match and content overlap on generalized
    reading performance. Journal of Applied Behavior Analysis, 29,
    507-518.
-   Kameenui, E. D., Carnine, D., & Freschi, R. (1982). Effects of text
    construction and instructional procedures for teaching word meanings
    on comprehension and recall. Reading Research Quarterly, 17,
    367-388.
-   Morris, D., Blanton, L., Blanton, W. E., Nowacek, J., & Perney, J.
    (1995). Teaching low-achieving spellers at their \"instructional
    level\". The Elementary School Journal, 96, 163-177.
-   Schumm, J. S., Moody, S. W., & Vaughn, S. (2000). Grouping for
    reading instruction: Does one size fit all? Journal of Learning
    Disabilities, 33, 477-488.
-   Shearer, P. M. (1999). Learning to teach: First year teacher
    experiences. Unpublished M.Ed. dissertation. Christchurch, N.Z.:
    University of Canterbury, Education Department.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/Effectsofcontinuousversusintermittentschedulesofconsequences/index.md","# Effects of continuous versus intermittent schedules of consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bfe9032e7b0548729e9d6ff7547143d3}
Generally speaking the introduction of schedules in which particular
low-rate responses are reinforced frequently rather than infrequently
result in the most rapid behaviour changes (McLaughlin & Malaby, 1975b;
Zanolli & Daggett, 1998).

The schedule which results in the most frequent reinforcement is the
continuous schedule -- where every occurrence of a particular response
is reinforced (or punished). Generally speaking continuous reinforcement
produces faster behaviour change and faster acquisition than schedules
in which target responses are only intermittently reinforced (Olendick &
Pear, 1980).

The same is true with respect to punishment contingencies. If every
error is corrected, the correct responses are learned more rapidly than
if only some errors are corrected (Morton, Heward & Alber, 1998). If
every misbehaviour is punished, misbehaviours are suppressed much more
rapidly than is the case where misbehaviours are punished only from time
to time (Clark, Rowberry, Baer & Baer, 1973; Pfiffner, O'Leary, Rosén &
Sanderson, 1985).

However, continuous schedules of reinforcement, although they tend to
produce rapid changes in performance, also result in performances which
are the least resistant to extinction (Kazdin & Polster, 1973). This is
because a change from continuous reinforcement to non-reinforcement is
very easy for the learner to recognise.

Intermittent schedules of reinforcement on the other hand tend to
produce performances which are more resistant to extinction.
Intermittent reinforcement produces more persistent responding --
responding which is likely to continue even in the face of
non-reinforcement (Kazdin & Polster, 1973).

However, it is clear from the research that if the reinforcement
generated by a particular behaviour becomes too infrequent, the learner
may simply cease to engage in that behaviour (Martens, Ardoin, Hilt,
Lannie, Panahon & Wolfe, 2002; McLaughlin & Malaby, 1975a, 1975b; Simon,
Ayllon & Milan, 1982). This is the extinction effect reviewed above. Not
only does the learner abandon behaviours which are only infrequently
reinforced, they may also lose interest in that particular activity. If
the learner ceases to make progress as a result of practising a
particular skill, they may lose interest in practising that skill.

Extinction effects are a persistent problem in the classroom. This is
because teachers simply cannot maintain high rates of social
reinforcement for each and every child in a class of 25-30 children.
Thomas, Presland, Grant and Glynn (1978) found that N.Z. teachers gave
explicit approval not much more than about 12 times an hour. Rossiter\'s
observations of N.Z. Year 1 and Year 2 teachers revealed that the
teachers who were observed provided positive reactions something less
than 25 times an hour (Rossiter, 1982).

The research into schedule effects has very important implications for
teaching. During the initial phase of learning it is almost always
appropriate to continuously reinforce improvements and to correct each
error as it occurs. In the long term, however, persistence and repeated
effort even in the face of failure is also an important teaching goal.
This means that once a new behaviour has been acquired, the
reinforcement of that behaviour must gradually be made less regular and
less predictable. Otherwise, the desired persistence will not develop.
The makes the ability to thin the reinforcement for individual students
as they move from one phase of learning to the next a very important
teaching skill.
:::

::: referencesList
#### References

-   Clark, H. B., Rowbury, T., Baer, A. M., & Baer, D. M. (1973).
    Timeout as a punishing stimulus in continuous and intermittent
    schedules. Journal of Applied Behavior Analysis, 6, 443-455.
-   Kazdin, A. E., & Polster, R. (1973). Intermittent token
    reinforcement and response maintenance in extinction. Behavior
    Therapy, 4, 386-391.
-   Martens, B. K., Ardoin, S. P., Hilt, A. M., Lannie, A. L.
    Panahon, C. J., & Wolfe, L. A. (2002). Sensitivity of children's
    behavior to probabilistic reward: Effects of a decreasing-ratio
    lottery system on math performance. Journal of Applied Behavior
    Analysis, 35, 403-406.
-   McLaughlin, T. F., & Malaby, J. E. (1975a). Increasing and
    maintaining note-taking behavior in a sixth grade token classroom:
    An analysis of consequences presented in a delayed manner.
    Psychology: A Journal of Human Behavior, 12, 15-23.
-   McLaughlin, T. F., & Malaby, J. E. (1975b). The effects of various
    token reinforcement contingencies on assignment completion and
    accuracy during variable and fixed token exchange schedules.
    Canadian Journal of Behavioural Science, 7, 411-419.
-   Morton, W. L., Heward, W. L., & Alber, S. R. (1998). When to
    self-correct: a comparison of two procedures on spelling
    performance. Journal of Behavioral Education, 8, 321-335.
-   Olendick, D. L., & Pear, J. J. (1980). Differential reinforcement of
    correct responses to probes and prompts in picture-name training
    with severely retarded children. Journal of Applied Behavior
    Analysis, 13, 77-89.
-   Pfiffner, L. J., O\'Leary, S. G., Rosén, L. A., & Sanderson, W. C.
    (1985). A comparison of the effects of continuous and intermittent
    response cost and reprimands in the classroom. Journal of Clinical
    Child Psychology, 14, 348-352.
-   Rossiter, A. (1982). The difficult to teach junior school pupil:
    Identification and teaching strategies. Research Report No 82-1.
    Education Department, University of Canterbury.
-   Simon, S. J., Ayllon, T., & Milan, M. A. (1982). Behavioral
    compensation: Contrast like effects in the classroom. Behavior
    Modification, 6, 407-420.
-   Thomas, J. D., Presland, I. E., Grant, M. D. & Glynn, T. L. (1978).
    Natural rates of teacher approval and disapproval in Grade 7
    classrooms. Journal of Applied Behavior Analysis, 11, 91-94.
-   Zanolli, K., & Daggett, J. (1998). The effects of reinforcement rate
    on the spontaneous social initiations of socially withdrawn
    preschoolers. Journal of Applied Behavior Analysis, 31, 117-125.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/Effectsofpredictableversusunpredictableschedulesofconsequences/index.md","# Effects of predictable versus unpredictable schedules of consequences \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c67a38b7d91d4d4c9dfffa4511134470}
As stated in the previous section, intermittent schedules of
reinforcement tend to produce responses which are more resistant to
extinction. Intermittent schedules, however, may be predictable (as when
answers are marked after, say, every 10th response) or they may be
unpredictable (as when answers are checked from time to time). As might
be expected, it is the unpredictable intermittent schedules which
produce the highest levels of persistence. The clearest demonstration of
this effect is in the behaviour of the habitual gambler but it has also
been demonstrated in the classroom (McLaughlin & Malaby 1976; Saudergas,
Madsen, & Scott, 1977; Theodore, Bray, Kehle & Jensen, 2001).
:::

::: referencesList
#### References

-   McLaughlin, T. F., & Malaby, J. E. (1976). An analysis of assignment
    completion and accuracy across time under fixed, variable, and
    extended token exchange periods in a classroom token economy.
    Contemporary Educational Psychology, 1, 346-355.
-   Saudargas, R. W., Madsen, C. H., & Scott, J. W. (1977). Differential
    effects of fixed- and variable-time feedback on production rates of
    elementary school children. Journal of Applied Behavior Analysis,
    10, 673-678.
-   Theodore, L. A., Bray, M. A., Kehle, T. J., & Jensen, W. R. (2001).
    Randomization of group contingencies and reinforcers to reduce
    classroom disruptive behavior. Journal of School Psychology, 39,
    267-277.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Schedulesofreinforcementandpunishment/Effectofconcurrentschedulesofreinforcementforappropriateandinappropriatebehaviour/index.md","# Effect of concurrent schedules of reinforcement for appropriate and inappropriate behaviour \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-20771138cef04fc793a528b94910d411}
There are many occasions when people find themselves in a situation
where there are several different actions which can be taken to achieve
a particular goal. In this kind of situation the various actions which
can be taken are said to be on *concurrent schedules* of reinforcement.
This is one of the situations where we say that the individual \"has a
choice.\"

How are choices made in this kind of situation? The basic research into
this question indicates that responses in this situation are distributed
according to what Richard Herrnstein refers to as the *Matching Law*
(Herrnstein, 1961). \"The matching law states that an individual will
distribute his or her behavior between alternatives in the same ratio
that reinforcements have been obtained for these alternatives\" (Myerson
& Hale, 1984, p. 367). A considerable amount of basic research supports
the view that the matching law describes a fundamental learning process
within the mammalian brain (Myerson & Hale, 1984). The learner uses past
experience to choose the behaviour which is most likely to generate
reinforcement (or likely to generate the most reinforcement) in the
current situation.

The Matching Law provides a powerful source of guidance any teacher (or
parent) who is faced with a child who engages in high rates of
non-compliant, inappropriate, or antisocial behaviour. This pattern of
behaviour indicates that the learning history of the misbehaving child
is one in which both prosocial and antisocial responses have worked to
get the child what he/she wants, that is, both have been reinforced, in
the past. That this is so is confirmed by observational studies of the
home life of children who engage in elevated rates of tantrums. These
studies have repeatedly found that, for these children, tantrums work
just as well as pro-social responses to get them what they want
(Patterson, 1982; Church, 2003).

That Matching Law predicts that a misbehaving child will continue to
misbehave until the child discovers that appropriate behaviour generates
more reinforcement than inappropriate behaviour and many experiments
have demonstrated that this is the case. When parents (or teachers)
succeed in their attempts to ensure that prosocial behaviours generate
more attention and more reinforcement than antisocial behaviours, the
misbehaving child almost immediately switches to prosocial modes of
behaviour in all situations where the new contingencies are operating
(Ayllon, Garber & Pisor, 1975; Baer, Rowbury & Baer, 1973; Blue, Madsen
& Heimberg, 1981; Coleman, 1973; Ducharme & DiAdamo, 2005; Goetz,
Homberg & LeBlanc, 1975; Houlihan & Jones, 1990; Kern, Ringdahl, Hilt &
Sterling-Turner, 2001; Lalli, Browder, Mace & Brown, 1993; Libb, Sachs &
Boyd, 1973; McGoey & DuPaul, 2000; Stephens, Wacker, Cooper, Richman &
Kayser, 2003; Witt, Hannafin & Martens, 1983; Workman, Kindall &
Williams, 1980).

An understanding of the effects of the Matching Law on motivation and
behaviour is essential for anyone who is involved in behaviour
management or the design of remedial interventions for inappropriate
behaviour. This is because, while interventions in which desirable
behaviour is reinforced on a richer schedule than inappropriate
behaviour will motivate a complete cessation of the inappropriate
behaviour, the reverse is also true. *Interventions which fail to
achieve this goal will invariably be found to be completely ineffective*
(Myerson & Hale, 1984).

It is important to note also that it is possible for incorrect academic
responses to generate reinforcement in the classroom. In a classic study
by Hasazi and Hasazi (1972), a child who appeared to be having
difficulty in mastering simple computational processes was receiving
individualised tuition by the teacher each day on the problems which had
been incorrectly answered. When this individualised tuition was
withdrawn, the student\'s accuracy on a daily maths work sheets climbed
from about 20 per cent correct to 100 per cent correct within a few
days. The experiment demonstrated that, by providing individualised
assistance, the teacher had mistakenly been providing more reinforcement
for error responses than for correct responses.
:::

::: referencesList
#### References

-   Ayllon, T., Garber, S., & Pisor, K. (1975). The elimination of
    discipline problems through a combined school-home motivational
    system. Behavior Therapy, 6, 616-626.
-   Baer, A. M., Rowbury, T. & Baer, D. M. (1973). The development of
    instructional control over classroom activities of deviant preschool
    children. Journal of Applied Behavior Analysis, 6, 289-298.
-   Blue, S. W., Madsen, C. H., & Heimberg, R. G. (1981). Increasing
    coping behavior in children with aggressive behavior: Evaluation of
    the relative efficacy of the components of a treatment package.
    Child Behavior Therapy, 3, 51-60.
-   Church, R. J. (2003) The definition, diagnosis and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Report prepared for the Ministry of Education. University
    of Canterbury: School of Education.
-   Coleman, R. G. (1973). A procedure for fading from
    experimenter-school-based to parent-home-based control of classroom
    behavior. Journal of School Psychology, 11, 71-79.
-   Ducharme, J. M., & DiAdamo, C. (2005). An errorless approach to
    management of child noncompliance in a special education setting.
    School Psychology Review, 34, 107-115.
-   Goetz, E. M., Holmberg, M. C., & LeBlanc, J. M. (1975). Differential
    reinforcement of other behavior and noncontingent reinforcement as
    control procedures during the modification of a preschooler\'s
    compliance. Journal of Applied Behavior Analysis, 8, 77-82.
-   Hasazi, J. E. & Hasazi, S. E. (1972). Effects of teacher attention
    on digit-reversal behavior in an elementary school child. Journal of
    Applied Behavior Analysis, 5, 151-162.
-   Herrnstein, R. J. (1961). Relative and absolute strength of response
    as a function of frequency of reinforcement. Journal of the
    Experimental Analysis of Behavior, 4, 267-272.
-   Houlihan, D., & Jones, R. N. (1990). Exploring the reinforcement of
    compliance with \\"do\\" and \\"don\'t\\" requests and the side effects:
    A partial replication and extension. Psychological Reports, 67,
    439-448.
-   Kern, L., Ringdahl, J. E., Hilt, A., & Sterling-Turner, H. E.
    (2001). Linking self-management procedures to functional analysis
    results. Behavioral Disorders, 26, 214-226.
-   Lalli, J. S., Browder, D. M., Mace, F. C., & Brown, D. K. (1993).
    Teacher use of descriptive analysis data to implement interventions
    to decrease students\' problem behaviors. Journal of Applied
    Behavior Analysis, 26, 227-238.
-   Libb, J. W., Sachs, C. & Boyd, W. (1973). Reinforcement strategies
    for token economies in a special classroom setting. Psychological
    Reports, 32, 831-834.
-   McGoey, K. E., & DuPaul, G. J. (2000). Token reinforcement and
    response cost procedures: Reducing the disruptive behavior of
    preschool children with attention-deficit/hyperactivity disorder.
    School Psychology Quarterly, 15, 330-343.
-   Myerson, J., & Hale, S. (1984). Practical implications of the
    matching law. Journal of Applied Behavior Analysis, 17, 367-380.
-   Patterson, G. R. (1982). A social learning approach Vol. 3: Coercive
    family process. Eugene, OR: Castalia.
-   Stephens, T. J., Wacker, D. P., Cooper, L., Richman, D., &
    Kayser, K. (2003). Brief experimental analysis of antecedent
    variables related to noncompliance in young children in an
    outpatient clinic. Child & Family Behavior Therapy, 25, 1-18.
-   Witt, J. C., Hannafin, M. J., & Martens, B. K. (1983). Home-based
    reinforcement: Behavioral covariation between academic performance
    and inappropriate behavior. Journal of School Psychology, 21,
    337-348.
-   Workman, E. A., Kindall, L. M., & Williams, R. L. (1980). The
    consultative merits of praise-ignore versus praise-reprimand
    instruction. Journal of School Psychology, 18, 373-380.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivereinforcementcontingenciesandtheireffects/Effectsofpositivefeedback/index.md","# Effects of positive feedback \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5a6cee2745c54f7b898ccf1988d41d13}
Positive feedback is the information which signals that a practice
response is correct or appropriate or that a task has been performed in
a satisfactory manner. Much of the positive feedback which occurs in
classrooms tends to go largely unnoticed by teachers (although not by
students). The feedback which is provided by others during the course of
social interactions is often quite subtle. If a child says something
which the teacher judges to be incorrect during a classroom discussion
the child will often not be told that the answer is unsatisfactory.
Rather the teacher will elaborate the question or ask another child what
she thinks. Most children very quickly learn that, when the teacher
repeats what they have said and asks a new question, these events signal
that the contribution was accepted by the teacher whereas \\"question
redirected to another pupil\\" or \"question elaborated\" are feedback
events which indicate that the previous answer was less than
satisfactory.

The approving reactions of others often include a positive feedback
component. But feedback can also be provided independently of the
reactions of others. Responses to exercises and classroom activities can
be marked as correct or incorrect without, necessarily, praising the
correct responses.

Commonsense accounts of feedback tend to argue that feedback is most
effective when students themselves are involved in the evaluation of
performance, when even small improvements generate feedback, and when
the feedback is informative and precise (Van Houten, 1984).

It is widely believed that feedback events which inform the learner that
their performance was correct, or satisfactory, or improved, are events
which function as reinforcing consequences, that is, as events which
result in increased retention and motivation to continue practising and
improving, and there is some evidence to suggest that this may be the
case (Hillman, 1970; Manos, 1983; McLaughlin, 1992). However, the
research into feedback tends to be research which is not well controlled
and which, as a result, suggests very little in the way of definitive
conclusions. The main problem with the feedback research is that it
simply fails to control the variables which need to be controlled if the
effects of different kinds of feedback contingencies are to be
identified. There are four main classes of events which have been left
uncontrolled in almost all of the research into the effects of feedback.

1.First, feedback may follow correct responses, or incorrect responses,
or both. In most experimental studies of feedback, feedback information
has been provided following both correct and incorrect responses. While
these experiments provide some information about the effects of feedback
in general, they provide no information regarding the effects of
*positive* feedback, that is, feedback following *correct responses*.

2.When feedback is provided following correct and incorrect responses,
it is to be expected that its effects on both learning and motivation
will depend upon the ratio of correct to incorrect responses provided by
each learner. For example, error corrections might be much more
important if the error rate is high than if the error rate is low.
However, difficulty level and error rate are hardly ever controlled in
the feedback research and, in the great majority of cases, the error
rates of individual learners are not even reported.

3.Classroom studies of feedback almost invariably fail to separate out
the effects of the feedback and the effects of the positive and negative
teacher reactions in which the feedback is embedded -- making it
impossible to determine the effects of the feedback component and the
social reinforcement component (e.g., Kastelen, Nickel & McLaughlin,
1984; Luiselli & Downing, 1980).

4.It seems highly unlikely that positive feedback could have an effect
on learning or remembering in those situations where the learner is
able, by whatever means, to determine whether or not their response is
correct without feedback. It is almost certainly this factor which
accounts for the fact that, when new responses are well prompted, the
addition of feedback may have no additive effect on rate of learning
(McWilliams, 2005; Messer, Mohamedali & Fletcher, 1996; Messer, Norgate,
Joiner, Littleton & Light, 1996). However, there are few, if any,
feedback experiments which have been limited to learning tasks where all
of the learners are unable to determine (by themselves) which of their
responses are correct and which are not.

Provided it is recognised than we cannot as yet identify the relative
contributions of positive feedback and error feedback to feedback's
effects on learning and motivation, the results of the research into the
effects of feedback during classroom tasks may be summarised as follows.

The provision of performance feedback regarding classroom behaviour can
result in improvements in time on task and reduced levels of
inappropriate behaviour (Greenwood, Hops, Delquadri & Guild, 1974; Maggs
& Morgan, 1986; Scriven & Glynn, 1983).

The provision of feedback following student responses on worksheets and
other kinds of written exercises usually results in an increase in the
proportion of correct responses on such exercises (Conlon, Hall &
Hanley, 1972; Hillman, 1970; Luiselli & Downing, 1980; Maags & Morgan,
1986; McLaughlin, 1992; Robinson, DePascale & Roberts, 1989).

The provision of feedback during oral reading can result in an increase
in the accuracy level and the fluency level of that reading (Eckert,
Ardoin, Daley & Martens, 2002; Thorpe, Chiang & Darch, 1981) and the
provision of feedback regarding the content of children's writing can
result in an improvement in both the amount written and the quality of
the writing (Jerram, Glynn, & Tuck, 1988; Scriven & Glynn, 1983).

The provision of performance feedback following 1 minute maths sprints
(time trials) has been shown to result in an increase in number of
correct responses per minute (Miller, Hall, & Heward, 1995; Rhymer,
Dittmer, Skinner & Jackson, 2000).

These effects have been observed for oral feedback and written feedback
delivered not only by teachers but also by peers (Conlon et al, 1972),
and by computers (McWilliams, 2005; Messer, Mahamedali et al., 1996;
Robinson et al., 1989).

Generally speaking, children who are working on acquisition tasks and
who receive feedback following each response show greater improvement
than children who receive feedback following a block of practice
responses and children who receive feedback following a block of
responses show greater improvement than children who receive feedback
some time later (such as the following day) (Hillman, 1970).
:::

::: referencesList
#### References

-   Conlon, M. F., Hall, C., & Hanley, E. M. (1972). The effects of a
    peer correction procedure on the arithmetic accuracy for two
    elementary school children. In G. Semb (Ed.), Behavior analysis and
    education (pp. 205-210). Kansas: University of Kansas.
-   Eckert, T. L., Ardoin, S. P., Daly, E. J., & Martens, B. K. (2002).
    Improving oral reading fluency: A brief experimental analysis of
    combining an antecedent intervention with consequences. Journal of
    Applied Behavior Analysis, 35, 271-281.
-   Greenwood, C. R., Hops, H., Delquadri, J., & Guild, J. (1974). Group
    contingencies for group consequences in classroom management: A
    further analysis. Journal of Applied Behavior Analysis, 7, 413-425.
-   Hillman, B. W. (1970). The effect of knowledge of results and token
    reinforcement on the arithmetic achievement of elementary school
    children. The Arithmetic Teacher, 17, 676-682.
-   Jerram, H., Glynn, T., & Tuck, B. (1988).Responding to the message:
    Providing a social context for children learning to write.
    Educational Psychology. Special Issue: Changing academic behaviour,
    8, 31-40.
-   Kastelen, L., Nickel, M., & McLaughlin, T. F. (1984). A performance
    feedback system: Generalization of effects across tasks and time
    with eighth-grade English students. Education & Treatment of
    Children, 7, 141-155.
-   Luiselli, J. K., & Downing, J. N. (1980). Improving a student\'s
    arithmetic performance using feedback and reinforcement procedures.
    Education and Treatment of Children, 3, 45-49.
-   Maggs, A. M., & Morgan, G. (1986). Effects of feedback on the
    academic engaged time of behaviour disordered learners. Educational
    Psychology, 6, 335-347.
-   Manos, M., & J. (1983). Effects of verbal elaborations and social
    reinforcement on children\'s discrimination learning. Education &
    Treatment of Children, 6, 263-275.
-   McLaughlin, T. F. (1992). Effects of written feedback in reading on
    behaviorally disordered students. Journal of Educational Research,
    85, 312-316.
-   McWilliams, K. (2005). An analysis of the variables affecting
    instructional efficiency. Unpublished PhD thesis. Christchurch, New
    Zealand: University of Canterbury, School of Education
-   Messer, D. J., Mohamedali, M. H., & Fletcher, B.C. (1996). Using
    computers to help pupils tell the time, is feedback necessary?
    Educational Psychology, 16, 281-296.
-   Messer, D., Norgate, S., Joiner, R., Littleton, K., & Light, P.
    (1996). Development without learning. Educational Psychology, 16,
    5-19.
-   Miller, A. D., Hall, S. W., & Heward, W. L. (1995). Effects of
    sequential 1-minute time trials with and without inter-trial
    feedback and self-correction on general and special education
    students' fluency with math facts. Journal of Behavioral Education,
    5, 319-345.
-   Rhymer, K. N., Dittmer, K. I., Skinner, C. H., & Jackson, B. (2000).
    Effectiveness of a multi-component treatment for improving
    mathematics fluency. School Psychology Quarterly, 15, 40-51.
-   Robinson, S. L., DePascale, C., & Roberts, F. C. (1989).
    Computer-delivered feedback in group-based instruction: Effects for
    learning disabled students in mathematics. Learning Disabilities
    Focus, 5, 28-35.
-   Scriven, J., & Glynn, T. (1983). Performance feedback on written
    tasks for low-achieving secondary students. New Zealand Journal of
    Educational Studies, 18, 134-145.
-   Thorpe, H. W., Chiang, B., & Darch, C. B. (1981). Individual and
    group feedback systems for improving oral reading accuracy in
    learning disabled and regular class children. Journal of Learning
    Disabilities, 14, 332-334, 367.
-   Van Houten, R. (1984). Setting up performance feedback systems in
    the classroom. In W. L. Heward, T. E. Heron, D. S. Hill, & J.
    Trap-Porter (Eds.), Focus on behavior analysis in education.
    Columbus, OH: Charles E. Merrill Publishing Co.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivereinforcementcontingenciesandtheireffects/Effectsofnaturalreinforcers/index.md","# Effects of natural reinforcers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-02e4735c742f459c923cfacfdaa5ad70}
Much reinforcement arises naturally as a result of successful
performance. Successful meal preparation results in a reinforcing meal.
Successful navigation gets us to a reinforcing social event, on time, on
the other side of town. A successful library search finds the report, or
the novel, which we were looking for.

Whether or not a particular learning activity will generate any natural
reinforcement depends upon the level of difficulty or challenge posed by
the current learning activity. It is widely recognised that tasks which
lack any kind of challenge (tasks which are too easy) are experienced as
unmotivating, boring, or even aversive, that is, they are tasks which
generate little or no reinforcement.

If bored students are moved from activities which are too easy onto
tasks which pose some challenge, then task engagement, work output, and
attitude often improve (Umbriet, Lane & Dejud, 2004). Clifford (1990, p.
22) explains the positive attitude which results from success on
challenging tasks in the following terms \"We attribute the success we
experience on easy tasks to task ease; we attribute the success we
experience on extremely difficult tasks to luck. Neither type of success
does much to enhance self-image. It is only success at moderately
difficult or truly challenging tasks what we explain in terms of
personal effort . . . and these explanations give rise to feelings of
pride, competence, determination, satisfaction, persistence and personal
control.\"

A second kind of behaviour which produces its own reinforcement is
completion of a task at which we have become competent. Successful
performance in a competition results in a win -- which motivates
continued competition. Successful test performance results in a passing
mark -- which may motivate continued study. Competent reading results in
the sensory stimulation of an interesting story -- which motivates
further reading, and so on. Learning researchers have yet to figure out
whether the motivating effects of successful performance are due to
\"intrinsic reinforcement\", whether they are due to the reinforcing
effects of the feedback which signals a job well done, or whether they
are due to some other, as yet unrecognised, cause.
:::

::: referencesList
#### References

-   Clifford, M. M. (1990). Students need challenge, not easy success.
    Educational Leadership, 48(1), 22-26.
-   Umbreit, J., Lane, K. L., & Dejud, C. (2004). Improving classroom
    behavior by modifying task difficulty: Effects of increasing the
    difficulty of too-easy tasks. Journal of Positive Behavior
    Interventions, 6, 13-20.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivereinforcementcontingenciesandtheireffects/Effectsofsocialreinforcement/index.md","# Effects of social reinforcement \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-0a7ac4bed4fd4e52b7d30f3d16dcd510}
The reinforcing consequence which is most commonly used by teachers and
parents is the positive social reaction which we refer to as praise or
approval. Common sense accounts of praise usually argue that praise
should be descriptive and refer to the particular behaviour which is
being praised, should take a variety of different forms, should appear
to be sincere and spontaneous, should include feedback regarding the
quality of the performance, should attribute success to effort (rather
than to ability or luck), and should be used in a way which does not
interfere with on-going learning activities (Gage & Berliner, 1988).

Because praise and other types of positive reactions from other people
*acquire* reinforcing properties as a result of experience, they have
different effects on the behaviour and motivation of children with
different learning histories (e.g., O'Leary, Becker, Evans & Saudergas,
1969). For example, the effects of praise are *culturally relative*. A
particular phrase which functions as a commendation and hence as a
reinforcer in one culture may have no meaning and hence no reinforcing
properties outside that culture. In Western cultures it is considered
appropriate to praise younger children for responding correctly. In many
Asian cultures it is considered inappropriate to praise children simply
for responding correctly because this may make them \\"conceited\\". In
addition, the effects of a social reaction such as praise tend to vary
with the age of the learner. Praise has no effect on the behaviour of a
baby. For many adolescents, praise from a parent or teacher is far from
reinforcing (and in some contexts may be quite aversive). Thirdly, the
effects of praise and other forms of positive attention depend upon the
child rearing experiences of the learner. A child who is being raised in
an environment where adults are behaving in a highly punitive manner or
in a highly inconsistent manner may be unaffected by praise because it
has no meaning for them (Church, 2003).

While there have been many studies of praise and its effects on a range
of learning outcomes, many of these studies have combined praise and
feedback or praise and rewards with the result that the effects of the
praise (on its own) cannot be determined. However, a number of
experimental analyses which have controlled these confounding variables
can be found and these experiments suggest a number of conclusions.

First, reminders about rules and praise for following classroom rules
results in greater improvements in classroom behaviour than reminders
about rules on their own (Everett, Olmi, Edwards & Tingstrom, 2005;
Greenwood, Hops, Delquadri & Guild, 1974).

Secondly, praise tends to be a relatively weak reinforcer. Most other
types of reinforcement (contingent rewards, contingent access to
preferred activities, and so on) tend to result in higher levels of
motivation and more rapid improvements in time-on task, productivity,
and correct responding than contingent positive attention from the
teacher alone (Glynn, 1972; O'Leary et al., 1969) and this is especially
true for children with behaviour problems.

Thirdly, there have been a number of studies of what happens when
teachers attempt to shape improvements in performance by watching out
for improvements and praising these when they occur. For example
teachers have used positive attention to improvements to produce
increased compliance in pre-school children (Goetz, Holmberg & LeBlanc,
1975) and in Grade 1 children (Schutte & Hopkins, 1970), to produce
increased response diversity (creativity) in pre-school children (Fallon
& Goetz, 1975), and to produce increased levels of concentration and
work completion in normally developing primary school children (Yawkey,
1971), in children with behaviour problems (Sutherland, Wehby &
Copeland, 2000) and in children with learning disabilities (Maag,
Rutherford & DiGangi, 1992). Differential attention has also be used to
shape reduced levels of disruptive behaviour in junior secondary school
classrooms (Workman, Kindall & Williams, 1980).

Fourthly, more rapid improvements in task completion and more rapid
reductions in disruptive behaviour occur with differential attention
(that is, when the teacher approves appropriate behaviour and shows
disapproval for inappropriate behaviour) than when the teacher simply
gives positive attention for appropriate behaviour -- especially at the
secondary level (McAllister, Stachowiak, Baer, & Conderman, 1969;
Workman et al., 1980).

Given that positive teacher attention plays an important role in
strengthening the student behaviour which the teacher attends to, it is
disappointing to discover that the majority of classroom teachers, even
in the early grades, respond relatively infrequently with positive
remarks about improvements in student performance (Rossiter, 1982;
Thomas, Presland, Grant & Glynn, 1978; White, 1975; Wyatt & Hawkins,
1987). White (1975) observed a sample of 100 U.S. teachers. The Grade 1
teachers reacted positively to student behaviour at a rate of .66
approvals per minute, the Grade 3 teachers reacted at the rate of .38
approvals per minute, and the Grade 4 teachers at the rate of .32
approvals per minute. Wyatt and Hawkins (1987) observed 35 U.S.
teachers. The Grade 1 teachers used positive reactions at a rate of .58
per minute. The data from New Zealand classrooms is closely similar.
Rossiter (1982) observed a sample of 11 New Zealand junior school
teachers and found approval rates of .62 per minute. Thomas et al.
(1978) reported that the mean approval rate for a sample of 10 Year 6
teachers was 0.2 approvals per minute.

Faced with these findings, teacher educators sometimes argue that
teacher trainees need to learn to be \"more positive\" or to use \"praise
more often\". However, training teachers to increase the frequency of
their positive reactions to students has proved to be difficult both in
the preservice settting (Rose, 1994) and in the inservice setting
(Rossiter, 1982).

An alternative approach is to teach the children who are being ignored
to recruit teacher attention. Teaching students to recruit teacher
attention is based on the assumption that \"a potentially effective
natural contingency of reinforcement is 'asleep' and needs to be 'woken
up' (Alber & Heward, 2000, p. 177). To date there have been ten
controlled evaluations of this procedure. These evaluations have been
reviewed by Alber and Heward who conclude that \"Students who are taught
to recruit receive more praise and instructional assistance from
teachers. Recruiting attention for targeted academic or work tasks can
increase the productivity and accuracy with which a student performs
those tasks\" (Alber & Heward, 2000, p 193). A wide range of students
have been trained to recruit teacher attention: at-risk preschoolers
(Stokes, Fowler & Baer, 1978), normally developing primary school
children (Hrydowy, Stokes & Martin, 1984), primary students with
learning disabilities (Alber, Heward & Hippler, 1999), primary students
with behaviour problems (Morgan, Young & Goldstein, 1983) and primary
students with intellectual disabilities (Craft, Alber & Heward, 1988).
:::

::: referencesList
#### References

-   Alber, S. R. , & Heward, W. L. (2000). Teaching students to recruit
    attention: A review and recommendations. Journal of Behavioural
    Education, 10, 177-204.
-   Alber, S. R., Heward, W. L., & Hippler, B. J. (1999). Teaching
    middle school students with learning disabilities to recruit
    positive teacher attention. Exceptional Children, 65, 253-270.
-   Church, R. J. (2003). The definition, diagnosis, and treatment of
    children and youth with severe behaviour difficulties: A review of
    research. Report prepared for the Ministry of Education.
    Christchurch, NZ: University of Canterbury, Education Department.
-   Craft, M. A., Alber, S. R., & Heward, W. L. (1998). Teaching
    elementary students with developmental disabilities to recruit
    teacher attention in a general education classroom: Effects on
    teacher praise and academic productivity. Journal of Applied
    Behavior Analysis, 31, 399-415.
-   Everett, G. E., Olmi, D. J., Edwards, R. P., & Tingstrom, D. H.
    (2005). The contributions of eye contact and contingent praise to
    effective instruction delivery in compliance training. Education and
    Treatment of Children, 28, 48-62.
-   Fallon, M. P., & Goetz, E. M. (1975). The creative teacher: Effects
    of descriptive social reinforcement upon the drawing behavior of
    three preschool children. SALT: School Applications of Learning
    Theory, 7, 27-45.
-   Gage, N. L. & Berliner, D. C. (1988). Educational psychology (4th
    Ed.). Boston: Houghton Mifflin.
-   Glynn, E. L. (1972). Verbal and token reinforcement: Elements of
    behaviour control in a problem class. New Zealand Psychologist, 1,
    13-20.
-   Goetz, E. M., Holmberg, M. C., & LeBlanc, J. M. (1975). Differential
    reinforcement of other behavior and noncontingent reinforcement as
    control procedures during the modification of a preschooler\'s
    compliance. Journal of Applied Behavior Analysis, 8, 77-82.
-   Greenwood, C. R., Hops, H., Delquadri, J., & Guild, J. (1974). Group
    contingencies for group consequences in classroom management: A
    further analysis. Journal of Applied Behavior Analysis, 7, 413-425.
-   Hrydowy, E. R., Stokes, T. F., & Martin, G. L. (1984). Training
    elementary students to prompt teacher praise. Education & Treatment
    of Children, 7, 99-108.
-   Maag, J. W., Rutherford, R. B., & DiGangi, S. A. (1992). Effects of
    self-monitoring and contingent reinforcement on on-task behavior and
    academic productivity of learning-disabled students: A social
    validation study. Psychology in the Schools, 29, 157-172.
-   McAllister, L.W., Stachowiak, J. G., Baer, D. M., & Conderman, L.
    (1969). The application of operant conditioning techniques in a
    secondary school classroom. Journal of Applied Behavior Analysis, 2,
    277-285.
-   Morgan, D. Young, K. R., & Goldstein, S. (1983). Teaching
    behaviorally disordered students to increase teacher attention and
    praise in mainstreamed classrooms. Behavioral Disorders, 8, 265-273.
-   O\'Leary, K. D., Becker, W. C., Evans, M. B., & Saudargas, R. A.
    (1969). A token reinforcement program in a public school: A
    replication and systematic analysis. Journal of Applied Behavior
    Analysis, 2, 3-13.
-   Rose, D. J. (1994). The effect of practice on the acquisition and
    maintenance of teaching skills. Unpublished PhD thesis. University
    of Canterbury.
-   Rossiter, A. (1982). The difficult to teach junior school pupil:
    Identification and teaching strategies. Research Report No 82-1.
    Christchurch, New Zealand: University of Canterbury, Education
    Department.
-   Schutte, R. C., & Hopkins, B. L. (1970). The effects of teacher
    attention on following instructions in a kindergarten class. Journal
    of Applied Behavior Analysis, 3, 117-122.
-   Stokes, T. F., Fowler, S. A., & Baer, D. M. (1978). Training
    preschool children to recruit natural communities of reinforcement.
    Journal of Applied Behavior Analysis, 11, 285-303.
-   Sutherland, K. S., Wehby, J. H., & Copeland, S. R. (2000). Effect of
    varying rates of behavior-specific praise on the on-task behavior of
    students with EBD. Journal of Emotional and Behavioral Disorders, 8,
    2-8, 26.
-   Thomas, J. D., Presland, I. E., Grant, M. D., & Glynn, T. L. (1978).
    Natural rates of teacher approval and disapproval in Grade 7
    classrooms. Journal of Applied Behavior Analysis, 11, 91-94.
-   White, M.A. (1975). Natural rates of teacher approval and
    disapproval in the classroom. Journal of Applied Behavior Analysis,
    8, 367-372.
-   Workman, E. A., Kindall, L. M., & Williams, R. L. (1980). The
    consultative merits of praise-ignore versus praise-reprimand
    instruction. Journal of School Psychology, 18, 373-380.
-   Wyatt, W. J. & Hawkins, R. P. (1987). Rates of teachers\' verbal
    approval and disapproval. Behavior Modification, 11, 27-51.
-   Yawkey, T. D. (1971). Conditioning independent work behavior in
    reading with seven-year-old children in a regular early childhood
    classroom. Child Study Journal, 2, 23-34.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivereinforcementcontingenciesandtheireffects/Effectsofbiologicalreinforcers/index.md","# Effects of biological reinforcers \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3e79cf5542a94eaab22f4b6ad2724557}
By and large, the use of biological reinforcers is considered to be
inappropriate in early childhood centres and schools in New Zealand.
However, some exceptions can be found. It is sometimes considered
appropriate to use food rewards or food voucher rewards to motivate
improvements in work habits, concentration, homework completion and so
on in poorly motivated, underachieving or antisocial secondary school
students and most studies have found that such rewards motivate large
and rapid improvements in task engagement and work completion with these
types of students (e.g., Lloyd & Hilliard, 1989; Wolf, Giles & Hall,
1986). There are also a number of examples of the use of small edibles
such as chips, nuts and raisins to motivate attention and responding in
special education settings in children with intellectual disabilities or
autism (e.g., Egel, 1981; Mayhew & Anderson, 1980).

Of the biological reinforcers, sensory stimulation is probably the most
useful in the classroom setting. The main way to maintain reinforcing
levels of sensory stimulation in the classroom is to ensure adequate
levels of variety both within and across learning activities from hour
to hour and day to day (Church, 1999). When student interest begins to
flag sensory stimulation may be increased by changing the content of
instruction (e.g. from reading to science to physical education and so
on), by changing the type of learning activity (e.g. from whole class to
group work to individual work and so on), by changing the type of
learning outcome being pursued (e.g. from prompted practice to fluency
building and vice versa), or by changing the mode of the activity (e.g.
from watching a DVD, to discussion, to independent practice, and so on).

Interestingly, this is a very neglected area. We have been unable to
find any controlled experimental analyses of the effects of changing
levels of sensory stimulation or variety on learning or motivation in
the classroom setting.
:::

::: referencesList
#### References

-   Church, R. J. (1999). Instructional processes. Christchurch, N.Z.:
    University of Canterbury, Education Department.
-   Egel, A. L . (1981). Reinforcer variation: Implications for
    motivating developmentally disabled children. Journal of Applied
    Behavior Analysis, 14, 345-350.
-   Lloyd, M. E., & Hilliard, A. M. (1989). Accuracy of self-recording
    as a function of repeated experience with different self-control
    contingencies. Child & Family Behavior Therapy, 11, 1-14.
-   Mayhew, G. L., & Anderson, J. (1980). Delayed and immediate
    reinforcement: Retarded adolescents in an educational setting.
    Behavior Modification, 4, 527-545.
-   Wolf, M. M., Giles, D. K., & Hall, R. V. (1968). Experiments with
    token reinforcement in a remedial classroom. Behaviour Research and
    Therapy, 6, 51-64.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivereinforcementcontingenciesandtheireffects/PremacksRule/index.md","# Premack's Rule \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-299531f5c35944f6af74e2d5d4653a13}
Given a choice, all human beings engage in certain behaviours more often
than others. In everyday language we refer to these behaviours as
\"preferred activities\". The technical term is *high probability
behaviours*. In 1959, the behaviour analyst David Premack demonstrated
that high probability behaviours function as reinforcers for all
behaviours with a lower probability of occurrence (Premack, 1959, 1961,
1963a, 1963b). In other words, if access to a preferred activity is made
contingent upon completion of any less preferred activity, the chances
that the learner will complete the less preferred activity are very
greatly increased. This general principle has come to be known as
\\"Premack\'s Rule\\".

From a teaching point of view, Premack identified a general principle of
motivation which is now known to be of very wide generality. There are
always some behaviours which even poorly motivated learners engage in
more often than others (even if it is just sitting and doing
\\"nothing\\"). This means that sources of reinforcement can be identified
for all learners, no matter how poorly motivated.

Because preferred activity reinforcement is so easy to implement, there
are numerous reports of its use in the scientific literature. Preferred
activity reinforcement has been used to motivate reductions in
disruptive behaviour in the classroom (e.g., Marholin, McInnis & Heads,
1974; Moreno & Hovell, 1982), to motivate increases in attention to task
in the classroom (e.g., Edwards, Salant, Howard, Brougher & McLaughlin,
1995), to motivate increased task completion (e.g., Lovitt & Esveldt,
1970), and to motivate increased oral language use (Dolley & Wheldall,
1991; Hart & Risley, 1974). Preferred activity reinforcement has also be
used to shape language (Nordquist & Wahler, 1973), to motivate
improvements in reading (e.g., Cook & White, 1977; Edwards, et al.,
1995), to shape improvements in printing and handwriting (e.g., Hopkins,
Schutte & Garton, 1971; Salzberg, Wheeler, Devar & Hopkins, 1971), to
motivate improvements in spelling (e.g., Lovitt, Guppy & Blattner, 1969)
and compositional writing (Bording, McLaughlin & Williams, 1984;
Newstrom, McLaughlin & Sweeney, 1999) and to motivate improvements in a
variety of different kinds of mathematical skills (e.g., Flaman &
McLaughlin, 1986; Hundert & Batstone, 1978; Lovitt & Esveldt, 1970;
McEvoy & Brady, 1988).

A wide variety of preferred activities have been used to motivate
improvements during practice: self-selected activities during periods of
free time (e.g. Bording et al., 1984), access to educational games
(e.g., Hopkins et al., 1971), access to pre-school play activities
(e.g., Dolley & Wheldall, 1991), access to toys (e.g., Hart & Risley,
1974), access to computers (e.g., Flaman & McLaughlin, 1986), access to
television (e.g., Nordquist & Wahler, 1973), access to listening post
stories (e.g., Cook & White, 1977), and so on.

The motivational effects of contingent access to preferred activities
has been demonstrated across the age range from 3 year olds (Dolley &
Wheldall, 1991) to 16 year olds (e.g. Bording, McLaughlin & Williams,
1984).

The motivational effects of access to preferred activities are just as
strong for children with severe behaviours problems such as conduct
disorder and ADHD (e.g., Edwards et al., 1995; Marholin et al., 1974),
for children with learning disabilities (e.g., Bording et al, 1984) and
for children with intellectual disabilities or autism (e.g., McEvoy &
Brady, 1988; Nordquist & Whaler, 1973) as they are for children without
any kind of disability (e.g. Hopkins et al., 1971; Salzberg et al.,
1971).

Of course, the particular activities which are preferred by individual
children (and which will function as reinforcers for particular
individuals) vary from one learner to the next. Some children will work
hard to earn the opportunity to engage in art activities. Other children
do not find art activities at all reinforcing. This problem is easily
solved in the classroom by asking children to list the things which they
like doing best and by providing contingent access to a menu of high
probability activities so that there is always at least one activity
which will function as a reinforcer for each child in the class.

One characteristic of skilled performance is that it enables the learner
to gain access to other reinforcing activities - activities which
hitherto were inaccessible. The outcome to a child of learning to ride a
bike is the additional, new, reinforcing activities (such as visiting
friends' houses) which become accessible once one has learned how to
ride a bike. It is this kind of outcome which often motivates people to
practise, and eventually to master, new skills.
:::

::: referencesList
#### References

-   Bording, C., McLaughlin, T. F., & Williams, R. L. (1984). Effects of
    free time on grammar skills of adolescent handicapped students.
    Journal of Educational Research, 77, 312-318
-   Cook, V. J., & White, M. A. (1977). Reinforcement potency of
    children\'s reading materials. Journal of Educational Psychology,
    69, 231-236.
-   Dolley, D., & Wheldall, K. (1991). Applying incidental teaching
    (including contingent access to materials) with second language
    learners in a multi-ethnic nursery unit: Effects on child-teacher
    initiations and child language use. Educational Psychology, 11,
    35-58.
-   Edwards, L., Salant, V., Howard, V. F., Brougher, J., &
    McLaughlin, T. F. (1995). Effectiveness of self-management on
    attentional behavior and reading comprehension for children with
    attention deficit disorder. Child & Family Behavior Therapy, 17,
    1-17.
-   Flaman, F., & McLaughlin, T. F. (1986). Token reinforcement: Effects
    for accuracy of math performance and generalization to social
    behavior with an adolescent student. Techniques: A Journal for
    Remedial Education and Counseling, 2, 39-47.
-   Hart, B., & Risley, T. R. (1974). Using preschool materials to
    modify the language of disadvantaged children. Journal of Applied
    Behavior Analysis, 7, 243-256.
-   Hopkins, B. L., Schutte, R. C., & Garton, K. L. (1971). The effects
    of access to a playroom on the rate and quality of printing and
    writing of first and second-grade students. Journal of Applied
    Behavior Analysis, 4, 77-87.
-   Hundert, J., & Batstone, D. (1978). A practical procedure to
    maintain pupils\' accurate self-rating in a classroom token program.
    Behavior Modification, 2, 93-110.
-   Lovitt, T. C., & Esveldt, K. A. (1970). The relative effects on math
    performance of single- versus multiple-ratio schedules: A case
    study. Journal of Applied Behavior Analysis, 3, 261-270.
-   Lovitt, T. C., Guppy, T. E., & Blattner, J. E. (1969). The use of a
    free-time contingency with fourth graders to increase spelling
    accuracy. Behaviour Research and Therapy, 7, 151-156.
-   Marholin II, D., McInnis, E. T., & Heads, T. B. (1974). Effect of
    two free-time reinforcement procedures on academic performance in a
    class of behavior problem children. Journal of Educational
    Psychology, 66, 872-879.
-   McEvoy, M. A., & Brady, M. P. (1988). Contingent access to play
    materials as an academic motivator for autistic and behavior
    disordered children. Education and Treatment of Children, 11, 5-18.
-   Moreno, R., & Hovell, M. F. (1982). Teaching survival English skills
    and assessment of collateral behavior. Behavior Modification, 6,
    375-388.
-   Newstrom, J., McLaughlin, T. F., & Sweeney, W. J. (1999). The
    effects of contingency contracting to improve the mechanics of
    written language with a middle school student with behavior
    disorders. Child & Family Behavior Therapy, 21(1), 39-48.
-   Nordquist, V. M., & Wahler, R. G. (1973). Naturalistic treatment of
    an autistic child. Journal of Applied Behavior Analysis, 6, 79-87.
-   Premack, D. (1959). Toward empirical behavior laws: I. Positive
    reinforcement Psychological Review, 66, pp. 219-233.
-   Premack, D. (1961). Predicting instrumental performance from the
    independent rate of the contingent response. Journal of Experimental
    Psychology, 61, pp. 163-171.
-   Premack, D. (1963a). Prediction of the comparative reinforcement
    values of running and drinking. Science, 139 (Whole No. 3559), pp.
    1062-1063.
-   Premack, D. (1963b). Rate differential reinforcement in monkey
    manipulation. Journal of the Experimental Analysis of Behavior. 6,
    pp. 81-89.
-   Salzberg, B. H., Wheeler, A. J., Devar, L. T., & Hopkins, B. L.
    (1971). The effect of intermittent feedback and intermittent
    contingent access to play on printing of kindergarten children.
    Journal of Applied Behavior Analysis, 4, 163-171.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Positivereinforcementcontingenciesandtheireffects/index.md","# Positive reinforcement contingencies and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9543c69c57e24d5499eb2cf2224ac093}
The effects of positive reinforcement contingencies have been more
extensively studied than the effects of any other type of contingency.
As a consequence a wide variety of events have been found to have
reinforcing properties. In this section we will group these reinforcing
events under five headings: biological reinforcers, natural reinforcers,
preferred activity reinforcers (Premack's Rule), social reinforcers and
positive feedback. The study of reinforcement has also involved a study
of the effects of reinforcing a variety of different dimensions of
performance: perseverance, productivity, responding correctly, fluency,
and so on, across a range of different tasks such as attending,
complying, handwriting, reading, writing, maths, athletic skills, social
skills, and so on. The great majority of this experimental work has been
replicated across both younger and older children, both with and without
special teaching needs.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Effectsofremovingapre-existingcontingency/Effectsofremovingapunishmentcontingencyrecovery/index.md","# Effects of removing a punishment contingency (recovery) \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-03e83fa4c5944dada5c2d5fce1d64ddb}
*Recovery* refers to operations where a punishment contingency which
previously operated ceases to operate and the learner begins once again
to engage in the behaviour which had been suppressed by the punishment
contingency. The recovery effect has been observed following the removal
of both positive punishment contingencies and negative punishment
contingencies.

When a punishment contingency ceases to operate in the classroom, the
recovery effect is sometimes observed (e.g., Ramp, Ulrich & Dulaney,
1971) and sometimes not observed (e.g., Luce, Delquadri & Hall, 1980).
This raises the question of when a punishment contingency is likely to
lead to permanent suppression and when it is likely to result in only
temporary suppression of the punished response.

At the present time, it is not possible to answer this question by
examining the research on punishment. This is because there is so little
research into punishment in classroom settings.

It seems reasonable to hypothesise that the recovery effect (temporary
suppression) is most likely to occur in cases where an alternative
appropriate response (which the learner can use to avoid punishment) is
not acquired while the punishment contingency is operating and in cases
where the inappropriate behaviour continues to generate reinforcement
for the person using it both while the punishment contingency is
operating and following its withdrawal.
:::

::: referencesList
#### References

-   Luce, S. C., Delquadri, J., & Hall, R. V. (1980). Contingent
    exercise: A mild but powerful procedure for suppressing
    inappropriate verbal and aggressive behavior. Journal of Applied
    Behavior Analysis, 13, 583-594.
-   Ramp, E., Ulrich, R., & Dulaney, S. (1971). Delayed timeout as a
    procedure for reducing disruptive classroom behavior: A case study.
    Journal of Applied Behavior Analysis, 4, 235-239.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Effectsofremovingapre-existingcontingency/Effectsofremovingareinforcementcontingencyextinction/index.md","# Effects of removing a reinforcement contingency (extinction) \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3f047a97f6254d0b817cde03ad0374b4}
It is possible for the reinforcement which has motivated continued use
of a particular behaviour to be removed. The term *extinction* is the
term which we use to refer to cases where the learner's environment
undergoes a change such that a previously reinforced response no longer
works to produce the reinforcement which it used to produce. Under these
circumstances the behaviour which no longer works to produce
reinforcement is usually abandoned in favour of a behaviour which does
work. The extinction effect can occur following the withdrawal of
positive reinforcement and following the withdrawal of negative
reinforcement contingencies.

The extinction effect is sometimes observed following the withdrawal of
a programmed reinforcement contingency (e.g., McLaughlin & Malaby,
1975a, 1975b; Simon, Ayllon & Milan, 1982) and sometimes not observed
(e.g., Baer, Fowler, & Carden-Smith, 1984; Bailey Wolf & Phillips, 1970;
McNaughton, 1975).

Whether or not the extinction effect occurs seems to depend upon whether
or not the response is being maintained by a single source of
reinforcement or whether it is being maintained by multiple sources of
reinforcement. If the response is being maintained by a single source of
reinforcement, removal of that reinforcement results in extinction
(Simon et al., 1982). If the response is being maintained by several
sources of reinforcement, then the removal of one of these reinforcement
contingencies is unlikely to result in the response being abandoned. A
number of studies have shown that when the teacher first introduces a
strong reinforcement contingency to motivate performance of a particular
class of responses, and then carefully fades this contingency while
continuing to provide adequate levels of social reinforcement and
positive feedback, extinction is unlikely to occur.
:::

::: referencesList
#### References

-   Baer, M., Fowler, S. A., & Carden-Smith, L. (1984). Using
    reinforcement and independent-grading to promote and maintain task
    accuracy in a mainstreamed class. Analysis & Intervention in
    Developmental Disabilities, 4, 157-169.
-   Bailey, J. S., Wolf, M. M., & Phillips, E. L. (1970). Home-based
    reinforcement and the modification of pre-delinquents\' classroom
    behavior. Journal of Applied Behavior Analysis, 3, 223-233.
-   McLaughlin, T. F., & Malaby, J. E. (1975a). Increasing and
    maintaining note-taking behavior in a sixth grade token classroom:
    An analysis of consequences presented in a delayed manner.
    Psychology: A Journal of Human Behavior, 12, 15-23.
-   McLaughlin, T. F., & Malaby, J. E. (1975b). The effects of various
    token reinforcement contingencies on assignment completion and
    accuracy during variable and fixed token exchange schedules.
    Canadian Journal of Behavioural Science, 7, 411-419.
-   McNaughton, S. S. (1975). Some implications of a technique designed
    to produce rapid and generalized modification of out-of-seat
    behaviour. New Zealand Journal of Educational Studies, 10, 120-127.
-   Simon, S. J., Ayllon, T., & Milan, M. A. (1982). Behavioral
    compensation: Contrast like effects in the classroom. Behavior
    Modification, 6, 407-420.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Effectsofremovingapre-existingcontingency/index.md","# Effects of removing a pre-existing contingency \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e7f24b670de44e73ae39dbda43befa50}
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Negativereinforcementcontingenciesandtheireffects/Effectsofescapecontingencies/index.md","# Effects of escape contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-799e4bd2449e4629b681231d40824102}
The effects of escape contingencies in educational settings appears to
have been little studied. This is probably because such studies would
involve the application of an aversive stimulus which would continue in
effect until the child engaged in the desired escape response. It is
probable that many of the off-task behaviours and disruptive behaviours
in which children engage in the classroom are escape responses which
have the effect of terminating contact with aversive classroom tasks (at
least briefly) and a number of functional analyses of children's
tantrums have shown this to be the case both in children with persistent
behaviour problems (Heckaman, Conroy, Fox & Chait, 2000) and in children
without behaviour problems (e.g. Lee Wilder, Chen, Atwell, Pritchard &
Weinstein, 2006).
:::

::: referencesList
#### References

-   Heckaman, K., Conroy. M., Fox, J., & Chait, A. (2000). Functional
    assessment-based intervention research on students with or at risk
    for emotional and behavioural disorders in school settings.
    Behavioral Disorders, 25, 196-210.
-   Wilder, D. A., Chen, L., Atwell, J., Pritchard, J., & Weinstein, P.
    (2006). Brief functional analysis and treatment of tantrums
    associated with transitions in preschool children. Journal of
    Applied Behavior Analysis, 39, 103-107.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Negativereinforcementcontingenciesandtheireffects/index.md","# Negative reinforcement contingencies and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-643ad93e93754da0aa4f7c14c220ec3e}
Negative reinforcement contingencies are of two general types: escape
and avoidance. With an escape contingency, satisfactory performance is
necessary in order to escape from an aversive state of affairs. With an
avoidance contingency, satisfactory performance is required in order to
avoid an aversive outcome (in order to avoid punishment). Negative
reinforcement contingencies have been studied extensively in the
laboratory, are quite common in the secondary school setting, and are
even more common in the home setting. However, because they involve the
introduction of punishment contingencies (or the threat of punishment)
they have been the subject of very little experimental analysis in
either the school or the home setting.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Negativereinforcementcontingenciesandtheireffects/Effectsofavoidancecontingencies/index.md","# Effects of avoidance contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-53662eed594945f5bab3d6f91df1f28e}
Our search for applied examples of avoidance contingencies identified
six experimental analyses. Four of these demonstrated the reinforcing
(motivating) effects of negative reinforcement contingencies in school
settings. Cote, Thompson and McKerchar (2005) found, in an experiment in
an early childhood setting, that the toddlers in that setting were more
likely to comply with teacher instructions when compliance avoided loss
of access to a toy. Hall, Cristler, Cranston & Tucker (1970) describe
(in Experiment 2) an arrangement in which Grade 10 (Year 11) students
could avoid \"after school tutoring\" provided they obtained a score of at
least 72% on daily quizzes testing that day's French vocabulary words.
This contingency motivated all students to engage in sufficient homework
to avoid the after school contingency. Witt and Elliott (1982) found
that three Year 5 students were strongly motivated to stay on task in
order to avoid being entered into a response cost lottery in which they
lost a fraction of their tickets to a reinforcing activity for drifting
off task. However, in a replication study involving Year 9 students
Proctor and Morgan (1991) found that the response cost lottery motivated
two of four students to stay on task but had much weaker effects on the
other two students.

Two further experiments compared the relative effectiveness of positive
reinforcement and negative reinforcement contingencies. Leach and Tan
(1996) found that students in two Grade 8 (Year 9) classes were more
motivated to stay on task when this was necessary in order to avoid a
negative note home to parents than when targeted levels of on-task
behaviour earned a positive note home to parents. Kidd and Saudergas
(1988) describe an experiment in which they measured the effects on task
completion and accuracy level in maths of the introduction of (a) a
positive reinforcement contingency (for meeting the daily target) plus a
negative contingency (for failing to meet the target) and (b) the
positive reinforcement contingency on its own. In contrast to the
results of the previous experiment, Kidd and Saudergas found that the
positive reinforcement contingency on its own was sufficient to maintain
high levels of completion and accuracy on daily maths assignments by two
upper primary school students.

These experiments show that negative reinforcement contingencies can
have powerful motivating effects and that, in certain cases, these
effects may be even more powerful than the effects of a positive
reinforcement contingency. It is this factor that probably accounts for
their widespread use. The results of these experiments also suggest that
the effect is likely to depend to some extent on the student's
perception of the likelihood that the punishing outcome will actually
occur if requirements are not met. However, these experiments have
little to say about the effects of negative reinforcement arrangements
on attitudes and long term motivation.
:::

::: referencesList
#### References

-   Cote, C. A., Thompson, R. H., & McKerchar, P. M. (2005). The effects
    of antecedent interventions and extinction on toddlers' compliance
    during transitions. Journal of Applied Behavior Analysis, 38,
    235-238.
-   Hall, R. V., Cristler, C., Cranston, S. S., & Tucker, B. (1970).
    Teachers and parents as researchers using multiple baseline designs.
    Journal of Applied Behavior Analysis, 3, 247-255.
-   Kidd, T. A., & Saudargas, R. A. (1988). Positive and negative
    consequences in contingency contracts: Their relative effectiveness
    on arithmetic performance. Education and Treatment of Children, 11,
    118-126.
-   Leach, D. J., & Tan, R. (1996). The effects of sending positive and
    negative letters to parents on the classroom behaviour of secondary
    school students. Educational Psychology. Special Issue: Contemporary
    educational psychology and special education, 16, 141-154.
-   Proctor, M. A., & Morgan, D. (1991). Effectiveness of a response
    cost raffle procedure on the disruptive classroom behavior of
    adolescents with behavior problems. School Psychology Review, 20,
    97-109.
-   Witt, J. C., & Elliott, S. N. (1982). The response cost lottery: A
    time efficient and effective classroom intervention. Journal of
    School Psychology, 20, 155-161.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Negativepunishmentcontingenciesandtheireffects/Effectsoftimeoutfromreinforcement/index.md","# Effects of time out from reinforcement \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-20e728276789444ea20bb52a9f753f8c}
Time out from the current activity is widely used by parents as a
punishment for defiance and other kinds of misbehaviour. It is also the
punishment procedure recommended in most modern books on parenting
(e.g., Sanders, 1992**)** and in most evidence-based parent management
training programmes (e.g., McMahon & Forehand, 2003**)**.

While much of the research into time out has been undertaken within the
context of parenting training where it is just one of the skills which
parents are acquiring, there have been at least 15 controlled studies of
time out from reinforcement which have been undertaken in classroom
settings.

Sherburne, Utley, McConnell & Gannon (1988) found that a well designed
time out contingency for antisocial behaviour motivated more rapid
suppression of antisocial behaviour than reminders to play nicely in 3-
to 5-year old children with behaviour problems. Baer, Rowberry and Baer
(1973) found that time out for noncompliance accelerated the development
of compliance in two 4- to 6-year olds whose compliance was not strongly
affected by a positive reinforcement contingency alone. When Osnes,
Guevremon and Stokes (1987) attempted to teach appropriate social
interaction to a 4 year old girl with intellectual disabilities using
positive consequences alone, they had little success until they added a
brief time-out for inappropriate social responses. Northup et al. (1999)
found that time out reduced the disruptive and off task behaviour of
three boys with ADHD and that this effect occurred regardless of whether
the students were receiving methyphenidate or a placebo.

Both inclusionary and exclusionary time out have been studied with
inclusionary time out having suppressive effects which are similar to
those observed with exclusionary time out (Foxx & Shapiro, 1978).

The effectiveness of time out depends to some extent to the punishment
schedule with time-out following each disruptive response producing
faster suppression than is the case with more intermittent schedules
(Clark, Rowberry, Baer & Baer, 1973).
:::

::: referencesList
#### References

-   Baer, A. M., Rowbury, T. & Baer, D. M. (1973). The development of
    instructional control over classroom activities of deviant preschool
    children. Journal of Applied Behavior Analysis, 6, 289-298.
-   Clark, H. B., Rowbury, T., Baer, A. M., & Baer, D. M. (1973).
    Timeout as a punishing stimulus in continuous and intermittent
    schedules. Journal of Applied Behavior Analysis, 6, 443-455.
-   Foxx, R. M., & Shapiro, S. T. (1978). The timeout ribbon: A
    nonexclusionary timeout procedure. Journal of Applied Behavior
    Analysis, 11, 125-136.
-   McMahon, R. J., & Forehand, R. L. (2003). Helping the noncompliant
    child: Family-based treatment for oppositional behavior. (2nd ed.).
    New York: Guilford Press.
-   Northup, J., Fusilier, I., Swanson, V., Huete, J., Bruce, T.,
    Freeland, J., Gulley, V., & Edwards, S. (1999). Further analysis of
    the separate and interactive effects of methylphenidate and common
    classroom contingencies. Journal of Applied Behavior Analysis, 32,
    35-50.
-   Osnes, P. G., Guevremont, D. C., & Stokes, T. F. (1987). Increasing
    a child\'s prosocial behaviors: Positive and negative consequences
    in correspondence training. Journal of Behavior Therapy and
    Experimental Psychiatry, 18, 71-76.
-   Sanders, M. R. (1992). Every parent: A positive approach to
    children\'s behaviour. Sydney, Australia: Addison-Wesley.
-   Sherburne, S., Utley, B., McConnell, S., & Gannon, J. (1988).
    Decreasing violent or aggressive theme play among preschool children
    with behavior disorders. Exceptional Children, 55, 166-172.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Negativepunishmentcontingenciesandtheireffects/Effectsofresponsecostcontingencies/index.md","# Effects of response cost contingencies \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2a1fcf85bbe9467c91fa20357a7707ae}
A number of classroom experiments have shown rapid suppression of
disruptive behaviour and antisocial behaviour in 3- to 16-year olds as a
result of the introduction of a response cost contingency (Ramp, Ulrich
& Delaney, 1971; Salend & Allen, 1985; Simons & Wasik, 1973; Trice &
Parker, 1983). For example, Ramp et al. used a light on the child's desk
to signal to a 9 year old boy with severe behaviour problems that he was
engaging in a prohibited behaviour and that he had just lost a part of
his scheduled free time later in the day (Ramp et al., 1971).

The effects of a well designed response cost contingency for drifting
off task tends to motivate more rapid improvements in attention to task
than verbal reminders for drifting off task in primary school children
with behaviour problems (Pfiffner, O'Leary, Rosen & Sanderson, 1985).

It is possible for parents to provide the consequences for appropriate
and inappropriate behaviour in the classroom. These procedures are often
referred to as \"school-home notes\" because a note from the teacher is
used to report to parents on the extent to which the student has met
expectations in the classroom and the amount of reinforcement or
reinforcement time which has been earned. In general school-home note
schemes which include both an incentive for meeting expectations and a
penalty for inappropriate or antisocial behaviour in the classroom
result in faster and longer lasting improvements in attention to task,
work done, and standard of work than school-home notes which depend on
home incentives alone (Kelley & McCain, 1995; Rosén, Gabardi, Miller &
Miller, 1990).

However, there have been some cases where reinforcement interventions
have been found to be just as effective as response cost interventions
in motivating reductions in disruptive behaviour (e.g. McGoey & DuPaul,
2000).
:::

::: referencesList
#### References

-   Kelley, M., & McCain, A. P. (1995). Promoting academic performance
    in inattentive children: The relative efficacy of school-home notes
    with and without response cost. Behavior Modification, 19, 357-375.
-   McGoey, K. E., & DuPaul, G. J. (2000). Token reinforcement and
    response cost procedures: Reducing the disruptive behavior of
    preschool children with attention-deficit/hyperactivity disorder.
    School Psychology Quarterly, 15, 330-343.
-   Pfiffner, L. J., O\'Leary, S. G., Rosén, L. A., & Sanderson, W. C.
    (1985). A comparison of the effects of continuous and intermittent
    response cost and reprimands in the classroom. Journal of Clinical
    Child Psychology, 14, 348-352.
-   Ramp, E., Ulrich, R., & Dulaney, S. (1971). Delayed timeout as a
    procedure for reducing disruptive classroom behavior: A case study.
    Journal of Applied Behavior Analysis, 4, 235-239.
-   Rosén, L. A., Gabardi, L., Miller, C. D., & Miller, L. (1990).
    Home-based treatment of disruptive junior high school students: An
    analysis of the differential effects of positive and negative
    consequences. Behavioral Disorders, 15, 227-232.
-   Salend, S. J., & Allen, E. M. (1985). Comparative effects of
    externally managed and self-managed response-cost systems on
    inappropriate classroom behavior. Journal of School Psychology, 23,
    59-67.
-   Simmons, J. T., & Wasik, B. H. (1973). Use of small group
    contingencies and special activity times to manage behavior in a
    first-grade classroom. Journal of School Psychology, 11, 228-238.
-   Trice, A. D., & Parker, F. C. (1983). Decreasing adolescent swearing
    in an instructional setting. Education & Treatment of Children, 6,
    29-35.
:::"
".//Theeffectsofinstructionalevents/Theeffectsofcontingencyvariables/Negativepunishmentcontingenciesandtheireffects/index.md","# Negative punishment contingencies and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-5b614fe371c94e55a5777d4558f836eb}
Just as access to a desired activity will function as a reinforcing
consequence, so loss of access to a desired activity will function as an
aversive consequence. Let us say for example, that a particular child
completes more work when work completion allows that child to work with
her friend. This observation suggests that working with the friend is
reinforcing for this pupil. If this is the case, then we can expect that
loosing the right to work with the friend will function as an aversive
consequence for this pupil and this is what happens (Lovitt, Lovitt,
Eaton & Kirkwood, 1973).

The two most commonly used and most widely studied punishment operations
are the response cost operation and the time-out operation. Response
cost refers to the removal of a certain amount of previously earned or
previously scheduled reinforcement or time in reinforcement as a penalty
for engaging in a particular prohibited behaviour. Response cost, like
all fining operations, functions as a punishment contingency only as
long as the learner has reinforcement, or reinforcement time to lose.
Time out is short for *time out from reinforcement* and refers to loss
of access to the currently reinforcing activity as a penalty for
engaging in a particular prohibited activity. Time out only functions as
a punishment contingency if the child is engaged in, or is about to
engage in, an activity which is a desired activity or high probability
activity as far as he or she is concerned.
:::

::: referencesList
#### References

-   Lovitt, T. C., Lovitt, A. O., Eaton, M. D., & Kirkwood, M. (1973).
    The deceleration of inappropriate comments by a natural consequence.
    Journal of School Psychology, 11, 148-154.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practiceschedulesandtheireffects/Effectsofvaryingthenumberofpracticeopportunitiesperresponsepersession/index.md","# Effects of varying the number of practice opportunities per response per session \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ae134a7318b8427c902eef94bfd35e45}
There appear to have been no experimental studies of the effects of
varying the number of times which a particular response is practised
within each practice session.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practiceschedulesandtheireffects/Effectsofvaryingthesizeofthepracticeset/index.md","# Effects of varying the size of the practice set \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3243f1fbf90f474e894c8f3966efe6a2}
Several variables operate to determine the distribution of practice
responses in time. One of these is the size of the practice set.
Students may engage in learning activities in which they are set to
learn and practice small numbers or larger numbers of responses. For
example a spelling activity may set a child to learn and remember the
spelling of two new words or 10 new words. This variable, size of the
practice set interacts with the time allocated to the practice session
to determine how many times each recently acquired response will be
practised during that session.

How many items should be taught and practised at one time? In an
experiment by Bryant, Drabin, and Gettinger (1981) three groups of
10-year old students studied new spelling words in groups of three, four
or five words at a time. All three groups learned the same number of
spelling words over a three day period. In an experiment by Gleason,
Carnine & Vala (1991) 8-year old children with learning disabilities
worked two versions of a CAI programme. One version introduced all seven
to-be-learned items of information at the outset and the other
introduced smaller \\"chunks\\" of information sequentially. Both groups
learned and remembered all of the information but students in the
sequential introduction treatment made fewer errors, spent one-third the
time, required fewer practice responses on average, and showed less
frustration during practice than the students in the \"all at once
group\". Johnson, Gersten and Carnine (1987) compared the rate of
acquisition of two groups of secondary school students studying new
vocabulary words. Students who worked on sets of 10 words at a time
learned the new words in much less time than students who worked on sets
of 25 words.

Clearly, not enough research has been done on this question to come to
any conclusions regarding the optimal size of the practice set for
different kinds of learning outcomes. What the three experiments suggest
is that smaller practice sets (in the range of 5 to 10 new items) result
in more rapid acquisition and less frustration than larger set sizes
(sets with more than 10 items).

However, there will be many exceptions to this conclusion. First, it is
possible to have a practice set with too few items in it. If a child can
hold three items in working memory and the practice set contains only
three items, practice responses can be produced from working memory and
little or no learning is likely to occur. It seems safe to assume that
the practice set should always contain more items than the number which
the learner can hold in working memory.

Secondly, practical experience suggests that older learners who have
acquired self-rehearsal skills can easily handle practice sets with 12
to 16 items. Setting such students to learn fewer items than this may
delay the rate at which new facts, concepts and knowledge propositions
will be mastered. Once way of guarding against this is to increase the
set size until the student is no longer getting a score of 100% on tests
given 24 hours following practice.

Thirdly, the practice set for fluency building must consist of more
responses than the learner will be producing when the fluency criterion
is achieved. If the aim is to build single digit addition responses to
60 correct answers per minute then the practice set should contain a
minimum of 80 addition questions so that no ceiling is placed on the
degree of improvement which the student can achieve.

Bryant, N. D., Drabin, I. R., & Gettinger, M. (1981). Effects of varying
unit size on spelling achievement in learning disabled children.
*Journal of Learning Disabilities*, *14*, 200-203.

Gleason, M., Carnine, D., & Vala, N. (1991). Cumulative versus rapid
introduction of new information. *Exceptional Children*, *57*, 353-358.

Johnson, G., Gersten, R., & Carnine, D. (1987). Effects of instructional
design variables on vocabulary acquisition of LD students: A study of
computer-assisted instruction. *Journal of Learning Disabilities*, *20*,
206-213.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practiceschedulesandtheireffects/Effectsofvaryingtheinterspersalratio/index.md","# Effects of varying the interspersal ratio \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-86d6c237a9464914a121a5f1c26ced8a}
Practice activities often consist of a mixture of new and previously
acquired responses. The technical name for this is *interspersal
training* -- because new (yet-to-be-acquired) and old (previously
acquired) items are interspersed within the practice set. The effects of
various interspersal ratios on a variety of learning outcomes have been
reviewed by Skinner (2002) and by Cates (2005).

Most of the studies of the effects of interspersing yet-to-be-learned
and previously learned responses have involved the learning of spelling
words, sight words, or maths facts. Experimental studies of interspersal
training sometimes find that it results in more rapid acquisition of new
responses (Cook & Reichard, 1996; Cooke, Guzakas, Pressley & Kerr, 1993;
Dunlap, 1984; Koegel & Koegel, 1986; Neef, Iwata & Page, 1977, 1980) and
sometimes find that interspersal formats result in similar (or slower)
rates of acquisition than practice with all new items (Cooke, Guzakas,
Pressley & Kerr, 1993; Cuvo, Davis & Gluck, 1991; Joseph & Nist, 2006).

Several parametric studies of interspersal ratios been undertaken.
Roberts, Turco, and Shapiro (1991) measured the effects of four
interspersal ratios (50% unknown, 40% unknown, 20% unknown and 10%
unknown) on a sight word learning task presented on flash cards over a
series of 24 sessions. Students in the 50/50 condition learned to
recognise the largest number of words and students in the 10/90
condition learned the smallest number of words. In a follow-up
experiment, Roberts and Shapiro (1996) studied the effects of
interspersal ratios of 90%, 50% and 20% unknown sight words and found
that rate of acquisition increased as the ratio of unknown to known
words increased. Cook and Reichard (1996) compared the effects of three
interspersal ratios (70% unknown, 50%, unknown, 30% unknown) on the
acquisition of multiplication and division facts in six 10- to 12-year
old students with learning disabilities. Reciprocal peer-tutoring was
used to deliver flashcard sessions. Most of the students made more rapid
gains in the 70% unknown condition.

A number of recent studies have explored the effects of interspersal
training activities on student liking for these activities and have
found that students express a preference for learning tasks where
exercises which take some time to complete are interspersed with simpler
exercises which can be quickly completed (Cates, Skinner, Watkins,
Rhymer, McNeil & McCurdy, 1999; Johns, Skinner & Nail, 2000; Wildmon,
Skinner & McDade, 1998; Wildmon, Skinner, McCurdy & Sims, 1999; Skinner,
Hall-Johnson, Skinner, Cates, Weber & Johns, 1999; Skinner, Fletcher,
Wildmon & Belfiore, 1996; Skinner, Robinson, Johns, Logan & Belfiore,
1996). In all of these studies, the shorter exercises are additional, to
the main exercises so the preference for the interspersal learning tasks
is a preference for interspersal activities even although this actually
involves more work. Although many of these studies have involved college
students, three have involved high school students (Cates & Skinner,
2000; Johns et al., 2000; Wildmon et al., 1999) and one (Logan &
Skinner, 1998) has involved primary school students.

The interspersal procedure has also been observed to result in increased
levels of on-task behaviour in the classroom (McCurdy, Skinner,
Grantham, Watson & Hindman, 2001).

Why does the interspersal procedure have these effects? The majority
view at the present time is that the faster learning which occurs with
interspersal practice is due to the fact that the learner experiences a
higher accuracy level during practice with interspersal sets, that
getting answers correct is reinforcing, and that working on interspersal
sets is, therefore, more reinforcing than working on \"all new\" practice
tasks (Skinner, 2002). \"While working on . . . assignments with many
discrete tasks, the completion of each task may be a conditioned
reinforcer (Logan & Skinner, 1998). Thus by interspersing additional
brief problems, educators may increase rates of problem completion and
rates of reinforcement\" (Skinner, Wallace & Neddenriep, 2002, p. 61).
Strong support for this point of view is provided by the fact that, when
given a choice, students choose interspersal practice activities over
\"all new\" activities even when the interspersal activity involves extra
work (for example, a larger number of exercises to complete) (Cates
2005).

However, it may also be the case that interspersal training provides
more effective and error-free discrimination training. It will be
recalled that, in learning to respond correctly to new stimuli, the
learner must not only learn which response to give to the new stimulus
but must also learn to discriminate the new stimulus from other stimuli
in the set. Practice sets which include old as well as new items provide
the learner with both kinds of practice (practice in discriminating the
new stimulus from other stimuli as well as practice in responding
correctly). By including previously mastered items in the current
practice set, it is possible for the teacher to include (previously
mastered) stimulus items which are similar in appearance to the new
items. This hastens development of the discrimination between similar
looking items. It may be that this is why the strongest effect of the
interspersal procedure on rate of acquisition is seen when students are
practising basic maths facts.

During practice we want the student to get more practice with new items
than with previously learned items. This can be achieved in a number of
ways. One way (if flashcards are being used) is to return the new items
(once they have been responded to) to the middle of the set of, say, 10
cards (instead of returning them to the end of the pack). In this way,
the student gets twice as much practice with new items as they get with
old items. A variation of this procedure is to return *incorrectly
answered* items to the middle of the pack and correctly answered items
to the end of the pack (Van Houten & Rolider, 1989).
:::

::: referencesList
#### References

-   Cates, G. L. (2005). A review of the effects of interspersing
    procedures on the stages of academic skill development. Journal of
    Behavioral Education, 14, 305-325.
-   Cates, G. L., & Skinner, C. H. (2000). Getting remedial mathematics
    students to prefer homework with 20% and 40% more problems: An
    investigation of the strength of the interspersing procedure.
    Psychology in the Schools, 37, 339-347.
-   Cates, G. L., Skinner, C. H., Watkins, C. E., Rhymer, K. N.,
    McNeil, S. L., & McCurdy, M. (1999). Effects of interspersing
    additional brief math problems on student performance and perception
    of math assignments: Getting students to prefer to do more work.
    Journal of Behavioral Education, 9, 177-192.
-   Cooke, N. L., Guzakas, R., Pressley, J. S., & Kerr, K. (1993).
    Effects of using a ratio of new items to review items during drill
    and practice: Three experiments. Education and Treatment of
    children, 16, 213-234.
-   Cooke, N. L., & Reichard, S. M. (1996). The effects of different
    interspersal drill ratios on acquisition and generalization of
    multiplication and division facts. Education and Treatment of
    Children, 19, 124-142.
-   Cuvo, A. J., Davis, P. K., & Gluck, M. S. (1991). Cumulative and
    interspersal task sequencing in self-paced training for persons with
    mild handicaps. Mental Retardation, 29, 335-342.
-   Dunlap, G. (1984). The influence of task variation and maintenance
    tasks on the learning and affect of autistic children. Journal of
    Experimental Child Psychology, 37, 41-64.
-   Haavik, S. F., Spradlin, J. E., & Altman, K. I. (1984).
    Generalization and maintenance of language responses: A study across
    trainers, schools, and home settings. Behavior Modification, 8,
    331-359.
-   Johns, G. A., Skinner, C. H., & Nail, G. L. (2000). Effects of
    interspersing briefer mathematics problems on assignment choice in
    students with learning disabilities. Journal of Behavioral
    Education, 10, 95-106.
-   Joseph, L. M., & Nist, L. M. (2006). Comparing the effects of
    unknown-known ratio on word reading learning versus learning rates.
    Journal of Behavioral Education, 15, 69-79.
-   Koegel, L. K., & Koegel, R. L. (1986). The effects of interspersed
    maintenance tasks on academic performance in a severe childhood
    stroke victim. Journal of Applied Behavior Analysis, 19, 425-430.
-   Kryzanowski, J., & Carnine, D. (1980). The effects of massed versus
    spaced formats in teaching sound-symbol correspondences to young
    children. Journal of Reading Behavior, 12, 225-229.
-   Logan, P., & Skinner, D. H. (1998). Improving students' perceptions
    of mathematics assignment by increasing problem completion rates: Is
    problem completion a reinforcement event? School Psychology
    Quarterly, 13, 322-331.
-   McCurdy, M., Skinner, C. H., Grantham, K., Watson, T., & Hindman, P.
    (2001). Increasing on-task behaviour in an elementary student during
    mathematics seatwork by interspersing additional brief problems.
    School Psychology Review, 30, 23-32.
-   Neef, N. A., Iwata, B. A., & Page, T. J. (1977). The effects of
    known-item interspersal on the acquisition and retention of spelling
    and sight reading words. Journal of Applied Behavior Analysis, 10,
    738.
-   Neef, N. A., Iwata, B. A., & Page, T. J. (1980). The effects of
    interspersal training versus high-density reinforcement on spelling
    acquisition and retention. Journal of Applied Behavior Analysis, 13,
    153-158.
-   Roberts, M. L., & Shapiro, E. S. (1996). Effects of instructional
    ratios on students' reading performance in a regular education
    classroom. Journal of School Psychology, 34, 73-91.
-   Roberts, M. L., Turco, T. L., & Shapiro, E. S. (1991). Differential
    effects of fixed instructional ratios on students' progress in
    reading. Journal of Psychoeducational Assessment, 9, 308-318.
-   Skinner, C. H. (2002). An empirical analysis of interspersal
    research evidence, implications and applications of the discrete
    task completion hypothesis. Journal of School Psychology, 40,
    347-368.
-   Skinner, C. H., Fletcher, P. A., Wildmon, M., & Belfiore, P. J.
    (1996). Improving assignment preference through interspersing
    additional problems: Brief versus easy problems. Journal of
    Behavioral Education, 6, 427-436.
-   Skinner, C. H., Hall-Johnson, K., Skinner, A. L., Cates, G., Weber,
    J., & Johns, G. A. (1999). Enhancing perceptions of mathematics
    assignments by increasing relative rates of problem completion
    through the interspersal technique. Journal of Experimental
    Education, 68, 43-59.
-   Skinner, C. H., Robinson, S. L., Johns, G. A., Logan, P., &
    Belfiore, P. J. (1996). Applying Herrnstein's Matching Law to
    influence students' choice to complete difficult academic tasks.
    Journal of Experimental Education, 65, 5-27.
-   Skinner, C. H., Wallace, M. A., & Neddenriep, C. E., (2002).
    Academic remediation: Educational applications of research on
    assignment preference and choice. Child & Family Behavior therapy,
    23, 51-65.
-   Van Houten, R., & Rolider, A. (1989). An analysis of several
    variables influencing the efficacy of flash card instruction.
    Journal of Applied Behavior Analysis, 22, 111-118.
-   Wildmon, M. E., Skinner, C. H., McCurdy, M., & Sims, S. (1999).
    Improving secondary students' perception of the \"dreaded mathematics
    word problem assignment\" by giving them more word problems.
    Psychology in the Schools, 36, 319-325.
-   Wildmon, M. E., Skinner, C. H., & McDade, A. (1998). Interspersing
    additional brief, easy problems to increase assignment preference on
    mathematics reading problems. Journal of Behavioral Education, 8,
    337-346.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practiceschedulesandtheireffects/Effectsofmassedversusspacedpractice/index.md","# Effects of massed versus spaced practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-7e6e4640a1bb4988a42c946b7e6ab7ea}
Given that a certain amount of practice will be required in order to
achieve a given learning outcome, the next question to be addressed is
the question of how practice sessions should be scheduled in the days
and weeks following initial teaching.

The first observation which we can make in this regard is that it is the
first few minutes of any given practice session which result in the
greatest improvement. Early research (involving relatively meaningless
tasks) showed that, as a practice session progresses, the amount of
improvement which occurs gradually declines until little or no
improvement is occurring. This is consistent with practical experience.
If practice sessions are too long people get fatigued or bored and
performance drops away.

The implication of this observation is that practice sessions should be
kept relatively short. \\"Short\\" is usually interpreted to mean a
practice session of 5 to 10 minutes in duration (or less for very young
children). Mayhall and Jenkins (1977) found that 10 minutes practice per
day of 80 sight words and 100 single digit addition facts resulted in
more rapid improvements in speed and accuracy than a 20 minute practice
session every two days.

The suggestion that practice periods should be kept relatively short
seems to contradict the practice commonly adopted by students of lengthy
\\"cramming\\" periods immediately prior to tests and exams. However, this
apparent contradiction disappears when it is realised that the aims of
the two activities are quite different. The aim of \\"cramming\\" is to
remember certain material for a very short period of time, typically one
or two days. The fact that most of the \\"crammed\\" material will be
forgotten almost immediately is of no concern to the student. The aim of
practice in the early years, on the other hand, is to develop skills and
understandings which will be remembered for many months - perhaps
remembered for a lifetime - and this is a rather different learning
goal.

Given that the most effective practice sessions are relatively short (5
to 10 minutes) in duration, the next question to be addressed is how
they should be scheduled in time. The research is relatively clear on
this question. *Practice sessions should be spaced*. There should be a
substantial \\"rest\\" period between each practice session. A one-day
interval between practice sessions is the most commonly used \\"rest\\"
period. When two (spaced) practice sessions are held a day apart,
students learn much more (sometimes twice as much) than they do when
those same practice sessions are held one after the other (massed).

The finding that practice sessions should be distributed in time
(spaced) has a large amount of research support. After reviewing the
research into the scheduling of practice sessions, Frank Dempster
concluded that \"This phenomenon - known as the 'spacing effect' - is one
of the most robust and dependable phenomena yet documented by
psychologists. The spacing effect also is remarkable in the scope of its
application: with students of all ages and ability levels, in all sorts
of situations, and with a wide variety of materials and procedures.
Spacing effects have been found in a variety of instructional modes,
including learning from text, lecture presentations, and computer
assisted instruction. Subject matter has included historical facts,
arithmetical rules, addition facts, science concepts and vocabulary\"
(Dempster, 1991, p. 72).

The spacing effect has never been satisfactorily explained. Possibly it
is related in some way to the fact that the brain continues to change as
a result of new experiences for up to 12 hours following the experience
(Rose, 1993). With knowledge learning tasks, on the other hand, if the
interval between practice sessions is more than 2 days, then there is a
good chance that previously learned material will be forgotten again
(Nuthall & Alton-Lee, 1993).
:::

::: referencesList
#### References

-   Dempster, F. N. (1991). Synthesis of research on reviews and tests.
    Educational Leadership, 48(7), 71-76.
-   Mayhall, W. F. & Jenkins, J. R. (1977). Scheduling daily or
    less-than-daily instruction: Implications for resource programs.
    Journal of Learning Disabilities, 10, 159-
-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Rose, S. (1993). The making of memory. Toronto: Bantam Books.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practiceschedulesandtheireffects/index.md","# Practice schedules and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-be11232b8fa84127a17f3ff5ad4d8ed5}
Practice occurs across time. Practice opportunities can be scheduled
across time in many different ways. The way in which individual practice
responses are distributed in time can vary. The way in which practice
sessions are distributed in time can vary. The number of different
responses or skills which are to be practiced in a particular practice
session and the number of practice opportunities provided for each of
these different responses in a practice session can vary. The ratio of
practice responses which involve yet to be acquired, partially acquired
and previously acquired responses can vary.

Early studies of practice schedules were largely limited to comparing
the relative benefits of \"massed practice\" against various types of
\"spaced practice\". More detailed studies of what children remember
suggest that a much more fine grained analysis of the relationship
between practice responses and their distribution in time will be
necessary in order to identify optimal schedules of practice for
different kinds of learning outcomes.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practiceschedulesandtheireffects/Effectsofvaryingthedistributionofpracticeresponsesintime/index.md","# Effects of varying the distribution of practice responses in time \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-6d7ca94fe21c4037ac7272f52aea5067}
Most practice is distributed across several days or weeks. Based on the
results from several studies which tracked every lesson concept which
was learned and remembered or learned and forgotten by individual
children, Nuthall and Alton Lee (1993) concluded that practice responses
with a particular fact or concept are likely to be remembered if no more
than 2 days elapses between practice responses with that concept but
forgotten if practice sessions are more than two days apart.

We also know that the mammalian brain continues to show changes at the
neuronal level for up to 12 hours following a single learning
experience.

Much of what we know about the brain changes which occur during learning
has come from a series of experiments by the British neuroscientist
Steven Rose and his colleagues. Rose has studied the changes which occur
in the brains of day-old chicks who have learned to avoid pecking silver
coloured beads covered with a bitter tasting liquid -- something which
most day-old chicks learn to do following a single experience with the
bitter taste. Postmortem comparisons of the brains of trained and
untrained chicks have revealed that experience with the bitter bead
leads to changes in several distinct regions of the chick's brain --
changes which continue for up to 12 hours. The earliest changes begin
immediately following experience with the bitter bead and include an
increased blood flow, increased glucose uptake (for energy), increased
electrical activity, and changes to the structure of the synapse. These
are followed by the manufacture of new synaptic chemicals, especially
glycoproteins. In the hours which follow, these glycoproteins are
inserted into the walls of the synapses to produce a 60 per cent
increase in the number of dendritic spines (receptor sites) and synapses
(Rose 1993). Changes in one part of the chick's brain are then followed
by changes in several other parts of the brain. Rose believes that the
occurrence of changes at several different sites is evidence that the
brain is classifying the experience under several different headings
(Rose, 1993).

At the present time, research into the most effective distribution of
specific practice responses across time is almost non-existent because
very few learning researchers have taken the trouble to track the
occurrence of specific practice responses across time. However, if the
distribution of particular practice responses in time is a critical
learning variable (as is suggested by the Rose research and the Nuthall
research) then this has fairly profound implications not only for
teaching practice but also for research on teaching.

One of the research implications is, that in order to accurately
interpret the results of learning and/or teaching experiments, the
experimenter will need either to track, or else to control the
distribution in time of all practice events with respect to each
to-be-learned response. Failure to control the number of practice
opportunities and their distribution in time may leave the teaching
researcher with uninterpretable experimental results.
:::

::: referencesList
#### References

-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Rose, S. (1993). The making of memory. Toronto: Bantam Books.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofdifferenttypesofstimulusprompts/index.md","# Effects of different types of stimulus prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-01db21031cb3440cb15858e4645d6f17}
There are only half of dozen experimental studies of stimulus prompting
procedures during instruction and most of these are studies of stimulus
fading procedures involving children and adults with intellectual
disabilities. While these studies demonstrate that errorless
discrimination learning is possible (Hively, 1966) the research does not
yet allow us to draw any conclusions regarding the relative
effectiveness or efficiency of different stimulus prompting procedures
in the classroom.
:::

::: referencesList
#### References

-   Hively, W. (1962). Programming stimuli in matching to sample.
    Journal of the Experimental Analysis of Behavior, 5, 279-298.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofvaryingthenumberofresponsespromptedatonetime/index.md","# Effects of varying the number of responses prompted at one time \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b8430e6fa796414fb676616685f00ced}
How many responses should be prompted at one time? The answer to this
question depends upon the attentional capacity of the learner.

The biological structure of the human brain places limits on the
learner\'s ability to attend to and to process new information. Put
simply, there are limits to the number of things which can be attended
to and \\"held in mind\\" at any one time. Limits to the number of things
which can be attended to at one time are commonly referred to as \\"the
limited capacity of short term memory\\" or \\"the limited capacity of
working memory\\".

The limits to human attention have been the subject of a number of
experimental investigations. During the 1950s for example, several
researchers observed that when words, letters, or digits are read at a
constant rate, adult listeners can recall (i.e. repeat) only six or
seven of the items on the list. In 1956, George Miller summarised the
evidence from a number of these experiments and concluded that adults
can attend to or \\"hold in mind\\" only about seven items of information
at the same time (Miller, 1956).

Sensory input that the person recognises as important \... is
transferred \... to short-term memory, where it can be retained longer
(up to 15 to 20 seconds without active rehearsal and \... longer if the
person keeps repeating it. However, short term memory has a very limited
capacity. Most people can remember about seven items (numbers, words,
phrases on a list) without making errors or omissions if the items are
unrelated to one another. Thus even a single phone number may be
difficult to remember for even 20 seconds unless it is repeated
continually or written down (Good & Brophy, 1990, p. 214).

Note that the 7-item rule refers to the upper limit of attention for
*adult learners*. For younger children, the restrictions imposed by
\\"working memory\\" are even more severe.

The severity of the limitations under which young children operate can
be illustrated by describing their performance on the following task.
The object of the task is a simple one: it is to count a number of sets
of objects that have been laid out on a table, and to remember the
number of objects in each set. As each set is counted it is covered up
so that no visual cues to quantity remain. An additional requirement is
that the arrays be counted in immediate succession, with no intervening
time for rehearsing previous answers. Under these conditions, young
children show a remarkable deficit by comparison with adults or
teenagers. Prior to the age of five they are capable of remembering the
number of items in only one set. By the age of five or six their
performance has improved but they can still only remember the number of
items in two sets. It is not until the age of seven or eight that they
can remember the number of items in as many as three sets (Case, 1978,
p. 446).

The inherent limitation to the number of things which the young child
can attend to (or hold in \\"working memory\\") at one time has important
implications for teaching. It means that the number of presentations and
the number of prompts which can be presented at one time, and still be
remembered by the learner, is extremely limited. With younger learners,
the most effective procedure is to prompt one response or step at a
time. With older learners it may be possible to prompt several steps at
one time. However, the number of steps which are prompted should not be
greater than the number of steps which the learner can \\"hold in mind\\"
at the one time.

Garry Margolius and Fred Sheffield refer to the number of steps which
the learner can hold in mind at one time as the learner\'s
*demonstration-assimilation span*. Margolius and Sheffield (1961)
suggest that, when teaching a new procedure (a skill which involves a
number of steps), the teacher should reduce the number of steps which
are prompted at one time until the learner is responding correctly at
least 75 per cent of the time. The size of the
demonstration-assimilation span will also vary with the extent to which
the learner has practised the new procedure. During the initial stages
of instruction in a new procedure, the demonstration-assimilation span
may need to be limited to two or three steps at a time. As the learner
begins to master some of the steps in the sequence of responses, the
demonstration-assimilation span can be increased.

Where the aim of instruction is to teach the correct responses to new
stimuli, the same rule holds. In teaching the names of the letters, for
example, the teacher should prompt the correct response to only one or
two unknown letters at a time before arranging for the learner to make
some kind of practice response or responses.
:::

::: referencesList
#### References

-   Case, R. (1978). A developmentally based theory and technology of
    instruction. Review of Educational Research, 48, 439-463.
-   Good, T. L. & Brophy, J. E. (1990). Educational psychology: A
    realistic approach (4th Ed.). New York: Longman.
-   Margolius, G. J. & Sheffield, F. D. (1961). Optimum methods of
    combining practice with filmed demonstration in teaching complex
    response sequences: Serial learning of a mechanical-assembly task.
    In R. C. Anderson, G. W. Faust, R. C. Roderick, D. J. Cunningham,
    & T. Andre (Eds.) Current research on instruction. Englewood Cliffs:
    Prentice Hall.
-   Miller, G. (1956). The magical number seven, plus or minus two: Some
    limits on our capacity for processing information. Psychological
    Review, 63, 81-97.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofvariationsintheratioofpromptedtounpromptedresponses/index.md","# Effects of variations in the ratio of prompted to unprompted responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d0bf9f117c3d43e1a75c10dc75fd7eee}
There have been few experimental studies of the effects of prompting
just some, rather than all unknown responses during the initial
acquisition phase. Presumably this is because it is fairly self-evident
that correct responses can only be acquired if the child is assisted to
make a correct response in the first instance. This was confirmed by
Noell, Gresham and Gansle (2002) in an experiment involving 7 year olds
who were learning new addition and subtraction operations. Continuous
delivery of instructional prompts was the most effective treatment for
all participants.
:::

::: referencesList
#### References

-   Noell, G. H., Gresham, F. M., & Gansle, K. A. (2002). Does treatment
    integrity matter? A preliminary investigation of instructional
    implementation and mathematics performance. Journal of Behavioral
    Education, 11, 51-67.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofvaryingthepromptdelayinterval/index.md","# Effects of varying the prompt delay interval \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-032828a905454b1f96e473ffce0873e7}
The experimental research into delayed prompting procedures tends to use
a prompt delay interval of between 3 and 6 seconds. Since learners who
are just beginning to acquire a new response may take some time to
recall the correct response, the prompt delay interval must be long
enough to allow this process to occur. However, there do not appear to
be any parametric studies of the effects on rate of acquisition of
varying the prompt delay interval during the acquisition of different
kinds of learning outcomes or with learners at different stages of
development.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/index.md","# Prompting variables and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-13421d65fc1446a3aa913d7af9e64688}
Prompting procedures (sometimes referred to as scaffolding) show the
learner how to respond or how to respond correctly. They therefore play
a critical role in all situations where the learner does not yet know
how to respond. Prompting procedures may vary with respect to the number
of responses prompted, the proportion of responses prompted, whether or
not the prompt remains in view during practice, whether the prompt
occurs before or after the practice stimulus and the degree to which the
prompting procedure results in the learner practising correct responses
rather than errors. Prompts can also vary according to whether they are
stimulus prompts or behaviour prompts, there are different types of
stimulus prompts and behaviour prompts, and there a number of ways of
fading prompts once they are no longer necessary.

Because prompts play a critical role during the initial phases of
instruction, it is not surprising to find that prompting procedures have
been the focus of a considerable amount of controlled experimental
research. As a result, learning researchers now have a reasonably good
understanding of the effects of different types of prompting
arrangements.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofstimuluspromptsandbehaviourprompts/index.md","# Effects of stimulus prompts and behaviour prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d81f916b46b54a12aec0b65b88dc5dd6}
It seems reasonable to assume that, if the aim is to teach a student how
to perform a new response, behaviour, or action then the type of prompt
required will be some kind of behaviour prompt and not a stimulus
prompt. If, on the other hand, the learner is failing to distinguish
between two things which should be distinguished, or failing to
generalise across the several members of a stimulus class, then the type
of prompt required will be some kind of stimulus prompt (not a behaviour
prompt). In one of the few studies of this assumption, Summers, Rincover
and Feldman (1993) attempted to teach five 3 to 4-year olds with
developmental disabilities to discriminate between \\"in\\" instructions
and \\"on\\" instructions using two kinds of prompts: (a) behaviour
prompts (modelling, physical guidance or instructions) and (b) stimulus
prompts (repeating the word \"in\" or \"on\"). The stimulus prompts resulted
in acquisition while the behaviour prompts did not.
:::

::: referencesList
#### References

-   Summers, J. A., Rincover, A., & Feldman, M. A. (1993). Comparison of
    extra- and within-stimulus prompting to teach prepositional
    discriminations to preschool children with developmental
    disabilities. Journal of Behavioral Education, 3, 287-298.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofdifferentproceduresforfadingstimulusprompts/index.md","# Effects of different procedures for fading stimulus prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3afe14cfaae4424189fb267a931fe0d0}
The relative effectiveness of different procedures for fading stimulus
prompts has yet to be studied in any detail.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofdifferentproceduresforfadingbehaviourprompts/index.md","# Effects of different procedures for fading behaviour prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ad68edf9f2074199a3ac4832336b19d7}
In order to shape independent performance of a new response or skill,
any prompts which were used during the initial learning phase must be
removed so that the learner has the opportunity to engage in independent
practice (unprompted practice). It is widely argued that any prompts
which were initially required should be faded, that is, gradually
removed. Three prompt fading procedures have been the subject of
scientific analysis. These are delayed prompting, decreasing assistance
and increasing assistance.

Delayed prompting has been most extensively studied. More than 55
controlled experiments have used delayed prompting to teach a variety of
different kinds of responses and skills to both normally developing and
developmentally delayed learners ranging in age from preschoolers to
adults (e.g. Chandler, Schuster & Stevens, 1993; Doyle, Gast, Wolery,
Ault & Farmer, 1990; Kinney, Stevens & Schuster, 1988; Koscinski & Gast,
1993; McCurdy, Cundari & Lentz, 1990; Stevens & Schuster, 1987; Wolery,
Werts, Snyder & Caldwell, 1994). An analysis of the Pause-Prompt-Praise
tutoring procedure by Houghton and Glynn (1993) suggests that the
delayed prompting feature is a critically important part of the
procedure. Pause-Prompt-Praise is a reading tutoring procedure which has
been shown to accelerate reading development in a number of studies
(Glynn & McNaughton, 1985).

Following a review of the research into delayed prompting to 1988,
Stevens and Schuster (1988, p. 21) concluded that \\"the time delay
procedure has proven effective in teaching many skills\.... The
procedure offers a nearly errorless learning experience by 'setting the
student up' to succeed. This procedure eliminates the failure cycle by
offering the student the correct response until the behavior is
performed independently\\".

Which of the three fading procedures is most effective? The answer seems
to be that all three procedures, when used correctly, are effective.
There does not appear to be any research to suggest that one of the
three procedures is more effective than the others. What the research
does suggest is that delayed prompting is more *efficient* than
decreasing assistance (Miller & Test, 1989) and considerably more
efficient than increasing assistance (Bennett, Gast, Wolery & Schuster,
1986; Gast, Ault, Wolery, Doyle & Belanger, 1988; Wolery, Ault, Gast &
Doyle, 1990). A possible reason for the greater efficiency of delayed
prompting is suggested below.

There have been some exceptions to the above conclusion. For example
Hendrickson, Roberts and Shores (1978) found that simultaneous prompting
resulted in fewer errors and more rapid acquisition of unknown reading
words than delayed prompting in two normally developing 8-year old boys
and McDonnell and Ferguson (1989) observed that decreasing assistance
resulted in four teenagers learning two banking skills (use of an
automatic teller machine and cashing a cheque) with less practice than
was required when time delayed prompting was employed.

The three fading procedures are not all equally easy to use correctly.
All fading procedures require a certain amount of teacher skill. The
teacher must make an informed judgement about when to start fading her
prompts, a judgement which will only be accurate if it is made on an
individual child-by-child basis. The delayed prompting procedure is the
easiest to learn and to use. Even primary aged children have learned to
use it (e.g. Houghton & Glynn, 1993; Miracle, Collins, Schuster &
Grisham-Brown, 2001; Tekin & Kircaali-Iftar, 2002; Telecsan, Slaton &
Stevens, 1999; Wolery, Werts, Snyder & Caldwell, 1994). The increasing
assistance and decreasing assistance procedures are much more difficult
to learn and to use correctly. Because they are more difficult there is
much greater scope for them to be used inappropriately.

A common error of judgement with the increasing assistance procedure is
to use a weaker prompt (to provide less assistance) than the learner
actually requires. For example, a student may make a reading error on an
unknown word, the teacher may respond with a hint or some other kind of
weak prompt and the child may make a second error. The teacher who uses
increasing assistance and who makes this kind of mistake will generate
many more student errors than the teacher who is using delayed prompting
(or using increasing assistance more accurately). It is probably this
factor more than anything else which results in the reduced efficiency
of increasing assistance compared to other fading procedures.

A common error of judgement with decreasing assistance is to remove
assistance too quickly. Let us say, for example, that the teacher shows
a student how to perform a particular maths operation, the student
demonstrates performance of the procedure, and the teacher then sets the
student to independently work some further examples while she attends to
another child. Later it is observed that few of the independently worked
problems are correct because the student has forgotten part of the
procedure. If prompts are faded before the learner can respond
independently, errors will occur. It may be this factor which results in
the reduced efficiency of decreasing assistance compared to delayed
prompting.

The main advantage of the delayed prompting procedure is that the
learner has the opportunity from the outset to demonstrate independent
performance on those steps or items that she has already learned. This
means that the parent, peer tutor or teacher can clearly see whether or
not a prompt is necessary and can judge very accurately when prompting
is no longer required. This makes the premature removal of prompts, and
the use of unnecessary prompts, much less likely.
:::

::: referencesList
#### References

-   Bennett, D. L., Gast, D. L., Wolery, M., & Schuster, J. (1986). Time
    delay and system of least prompts: A comparison in teaching manual
    sign production. Education and Training of the Mentally Retarded,
    21, 117-129.
-   Chandler, W., Schuster, J. W., & Stevens, K.B. (1993). Teaching
    employment skills to adolescents with mild and moderate disabilities
    using a constant time delay procedure. Education and Training in
    Mental Retardation, 28, 155-168.
-   Doyle, P. M., Gast, D. L., Wolery, M., Ault, M. J., & Farmer, J. A.
    (1990). Use of constant time delay in small group instruction: A
    study of observational and incidental learning. The Journal of
    Special Education, 23, 369-385.
-   Gast, D. L., Ault, M. J., Wolery, M., Doyle, P. M., & Belanger, S.
    (1988). Comparison of constant time delay and the system of least
    prompts in teaching sight word reading to students with moderate
    retardation. Education and Training in Mental Retardation, 23,
    117-128.
-   Glynn, T. & McNaughton, S. (1985). The Mangere Home and School
    Remedial Reading procedures: Continuing research on their
    effectiveness. New Zealand Journal of Psychology, 14, 66-77.
-   Hendrickson, J., Roberts, M., & Shores, R. E. (1978). Antecedent and
    contingent modeling to teach basic sight word vocabulary to learning
    disabled children. Journal of Learning Disabilities, 11, 524-528.
-   Houghton, S. & Glynn, T. (1993). Peer tutoring of below average
    secondary school readers using pause, prompt, and praise: The
    successive introduction of tutoring components. Behavior Change,10,
    75-85.
-   Kinney, P. G., Stevens, K. B., & Schuster, J. W. (1988). The effects
    of CAI and time delay: A systematic program for teaching spelling.
    Journal of Special Education Technology, 9, 61-72.
-   Koscinski, S. T., & Gast, D. L. (1993). Use of constant time delay
    in teaching multiplication facts to students with learning
    disabilities. Journal of Learning Disabilities, 26, 533-544.
-   McCurdy, B. L., Cundari, L., & Lentz, F. E. (1990). Enhancing
    instructional efficiency: An examination of time delay and the
    opportunity to observe instruction. Education and Treatment of
    Children, 13, 226-238.
-   McDonnell, J., & Ferguson, B. (1989). A comparison of time delay and
    decreasing prompt hierarchy strategies in teaching banking skills to
    students with moderate handicaps. Journal of Applied Behavior
    Analysis, 22, 85-91.
-   Miller, U. C., & Test, D. W. (1989). A comparison of constant time
    delay and most-to-least prompting in teaching laundry skills to
    students with moderate retardation. Education and Training in Mental
    Retardation, 24, 363-370.
-   Miracle, S. A., Collins, B. C., Schuster, J. W., & Grisham-Brown, J.
    (2001). Peer versus teacher-delivered instruction: Effects on
    acquisition and maintenance. Education and Training in Mental
    Retardation and Developmental Disabilities, 36, 373-385.
-   Stevens, K. B., & Schuster, J. W. (1987). Effects of a constant time
    delay procedure on the written spelling performance of a learning
    disabled student. Learning Disability Quarterly, 10, 9-16.
-   Stevens, K. B. & Schuster, J. W. (1988). Time delay: Systematic
    instruction for academic tasks. Remedial and Special Education,
    9(5), 16-21.
-   Tekin, E., & Kircaali-Iftar, G. (2002). Comparison of the
    effectiveness and efficiency of two response prompting procedures
    delivered by sibling tutors. Education and Training in Mental
    Retardation and Developmental Disabilities, 37, 283-299.
-   Telecsan, B. L., Slaton, D. B., & Stevens, K. B. (1999). Peer
    tutoring: Teaching students with learning disabilities to deliver
    time delay instruction. Journal of Behavioural Education, 9,
    133-154.
-   Wolery, M., Ault, M. J., Gast, D. L., & Doyle, P. M. (1990).
    Comparison of constant time delay and the system of least prompts in
    teaching chained tasks. Education and Training in Mental
    Retardation, 25, 243-257.
-   Wolery, M., Werts, M. G., Snyder, E. D., & Caldwell, N. K. (1994).
    Efficacy of constant time delay implemented by peer tutors in
    general education classrooms. Journal of Behavioral Education, 4,
    415-436.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofcopyingandnon-copyingprompts/index.md","# Effects of copying and non-copying prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-a335116e69c24805b129db837bde2fd4}
It is possible for a prompt to be presented and then removed from view
prior to responding (a non-copying prompt) or for the prompt to stay in
view while the learner responds (a copying prompt). Examples of copying
prompts are spelling words which stay in view while the learner copies
the word, permanent models of mathematical operations which stay in view
while the learner performs the operation, and so on.

It is usually argued that behaviour prompts should always be removed
prior to responding so that the learner has to attend to the practice
stimulus while responding rather than simply attending to the prompt.

Early research into this question involved programmed sequences of
instruction in which older secondary or tertiary level students were
required to write short responses to complete single proposition
\"frames\" presented in a linear sequence. In a series of experiments in
which students were either allowed to copy or prevented from copying the
answers from feedback frames, it was found that the students who were
required to construct an answer prior to viewing the feedback frame
tended to recall more on average than the students who were allowed to
copy responses from the feedback frame (Anderson, Kulhavy & Andre, 1971,
1972).

However, this may not be the case with respect to all learning outcomes.
It is clear that, when young children are learning to spell, they are
often unable to retain the complete spelling of a new word in working
memory if the model of the correct word is removed prior to the practice
response (McWilliams, 2005). In this case leaving the prompt in view can
result in more rapid acquisition than is the case when non-copying
prompts are used (Van Daal, & Van der Leij, 1992).
:::

::: referencesList
#### References

-   Anderson, R. C., Kulhavy, R. W., & Andre, T. (1971). Feedback
    procedures in programmed instruction. Journal of Educational
    Psychology, 62, 148-156.
-   Anderson, R. C., Kulhavy, R. W., & Andre, T. (1972). Conditions
    under which feedback facilitates learning from programmed lessons.
    Journal of Educational Psychology, 63, 186-188.
-   McWilliams, K. 2005. An analysis of variables affecting
    instructional efficiency. Unpublished PhD thesis. University of
    Canterbury, School of Education.
-   Van Daal, V. H. P., & Van der Leij, A. (1992). Computer-based
    reading and spelling practice for children with learning
    disabilities. Journal of Learning Disabilities, 25, 186-195.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofdifferenttypesofbehaviourprompts/index.md","# Effects of different types of behaviour prompts \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-bb6fb590e5db44d89118f7390c9ae7e8}
The research into behaviour prompting is extensive. Controlled studies
of behaviour prompting procedures have demonstrated that the
introduction of models of correct responding greatly increases the rate
of acquisition of new pronunciation responses (Camarata, 1993; Mann &
Baer, 1971), animal names (Tekin & Kircaali-Iftar, 2002), vocabulary
words (Lahey, 1971), reading responses, (Heron, Heward, Cooke, & Hill,
1983), spelling responses (McWilliams, 2005; Telecsan, Slaton, &
Stevens, 1999), procedures (Werts, Caldwell, & Wolery, 1996),
mathematical operations (Rivera & Smith, 1988; Smith & Lovitt, 1975),
various self-care skills (e.g. Haring, Breen, Weiner, Kennedy, &
Bednersh, 1995), and various kinds of social skills (e.g. Simpson,
Langone, & Ayres, 2004).

Behaviour prompts in the form of models of correct performance have been
shown to accelerate acquisition not only when delivered by teachers but
also when delivered by videotape (Haring et al., 1995; Simpson, et al.,
2004), by trained peers (Heron et al., 1983; Telecsan, 1999; Werts et
al., 1996), and by computers (McWilliams, 2005).

Other studies have demonstrated accelerated acquisition following the
introduction of instruction prompts during the learning of a variety of
different kinds of procedures including everyday tasks (McAdam & Cuvo,
1994; Mechling & Gast, 1997; Mitchell, Schuster, Collins, & Gassaway,
2000; Trask-Tyler, Grossi, & Heward. 1994), and mathematical operations
(Noell, Gresham, & Gansle, 2002).

Instruction prompts have been delivered not only by teachers but also as
written instructions (Nietupski, Clancy & Christiansen, 1984), tape
recorded instructions (Trask-Tyler et al., 1994), and computer presented
instructions (Noell et al., 2002). It is also possible to teach even
quite young children to recite the sequence of steps to be performed and
for the child to then self-prompt their way through a new procedure
(Vintere, Hemmes, Brown & Poulson, 2004).

The research on prompting includes research into the use of various
kinds of technology to deliver prompts in an accurate and timely fashion
in busy environments. For example Shabani, Katz, Wilder, Beauchamp,
Taylor and Fischer (2002) explored the use of a remote pager to prompt
social initiation responses in children with autism and there are a
number of studies in which parents have acquired new responses to child
misbehaviour as a result of instruction prompts delivered via a radio
microphone to a bug-in-the-ear receiver (Forehand, Sturgis, McMahon,
Aguar, Green, Wells et al., 1979; Forehand, Wells & Griest, 1980).

In many studies the teacher has combined instructions and modelling or
combined instructions with a permanent model during the teaching of new
skills. The combined show and tell procedure has several advantages. A
demonstration usually provides a better indication than a verbal
description of *how* to perform each of the component responses. At the
same time, the verbal instructions can be used to direct the learner\'s
attention to critical features of the performance, to review the order
in which the steps should be performed, and to explain why certain steps
have to be taken. Generally speaking research confirms that this type of
prompting procedure can result in the very rapid acquisition of new
procedures and operations (e.g. Rivera & Smith, 1987).

There have been few attempts to compare the relative effectiveness of
different types of behaviour prompts. Schunk (1981) in an experiment
which was more concerned with questions regarding self-efficacy found
that demonstrations of how to complete division operations were slightly
more effective than written descriptions of the procedure with 8 to 11
year olds. Vintere et al. (2004) report that once the sequence of
instructions had been memorised, self-instruction was slightly more
efficient than teacher modelling in teaching dance step sequences to 4
year olds.

There are, of course, practical limitations to the type of behaviour
prompts which can be used with different learners. For example, the
effectiveness of a verbal instruction depends upon the learner\'s
ability (and motivation) to follow the instruction. Verbal instructions
cannot be used to prompt the performance of new behaviours in pre-verbal
learners, or in learners who have not yet learned to comply with the
instructions of other people, or with learners who do not understand the
instruction.
:::

::: referencesList
#### References

-   Camarata, S. (1993). The application of naturalistic conversation
    training to speech production in children with speech disabilities.
    Journal of Applied Behavior Analysis, 26, 173-182
-   Forehand, R., Sturgis, E. T., McMahon, R. J., Aguar, D., Green, K.,
    Wells, K. C., & Breiner, J. (1979). Parent behavioral training to
    modify child noncompliance: Treatment generalization across time and
    from home to school. Behavior Modification, 3, 3-25.
-   Forehand, R., Wells, K. C., & Griest, D. L. (1980). An examination
    of the social validity of a parent training program. Behavior
    Therapy, 11, 488-502.
-   Haring, T. G., Breen, C. G., Weiner, J., Kennedy, C. H., &
    Bednersh, F. (1995). Using videotape modeling to facilitate
    generalized purchasing skills. Journal of Behavioral Education, 5,
    29-53.
-   Heron, T. E., Heward, W. L., Cooke, N. L., & Hill, D. S. (1983).
    Evaluation of a classwide peer tutoring system: First graders teach
    each other sight words. Education and Treatment of Children, 6,
    137-152.
-   Lahey, B. B. (1971). Modification of the frequency of descriptive
    adjectives in the speech of Head Start children through modeling
    without reinforcement. Journal of Applied Behavior Analysis, 4,
    19-22.
-   Mann, R. A., & Baer, D. M. (1971). The effects of receptive language
    training on articulation. Journal of Applied Behavior Analysis, 4,
    291-298.
-   McAdam, D. B., & Cuvo, A. J. (1994). Textual prompts as an
    antecedent cue self-management strategy for persons with mild
    disabilities. Behavior Modification, 18, 47-65.
-   McWilliams, K. 2005. An analysis of variables affecting
    instructional efficiency. Unpublished PhD thesis. University of
    Canterbury, School of Education.
-   Mechling, L. C., & Gast, D. L. (1997). Combination audio/visual
    self-prompting system for teaching chained tasks to students with
    intellectual disabilities. Education and Training in Mental
    Retardation and Developmental Disabilities, 32, 138-153
-   Mitchell, R. J., Schuster, J. W., Collins, B. C., & Gassaway, L. J.
    (2000). Teaching vocational skills with a faded auditory prompting
    system. Education and Training in Mental Retardation and
    Developmental Disabilities, 35, 415-427
-   Nietupski, J., Clancy, P., & Christiansen, C. (1984). Acquisition,
    maintenance and generalization of vending machine purchasing skills
    by moderately handicapped students. Education and Training of the
    Mentally Retarded, 19, 91-96.
-   Noell, G. H., Gresham, F. M., & Gansle, K. A. (2002). Does treatment
    integrity matter? A preliminary investigation of instructional
    implementation and mathematics performance. Journal of Behavioral
    Education, 11, 51-67
-   Rivera, D. M., & Smith, D. D. (1987). Influence of modeling on
    acquisition and generalization of computational skills: A summary of
    research findings from three sites. Learning Disability Quarterly,
    10, 69-80.
-   Rivera, D., & Smith, D. D. (1988). Using a demonstration strategy to
    teach midschool students with learning disabilities how to compute
    long division. Journal of Learning Disabilities, 21, 77-81.
-   Schunk, D. H. (1981). Modeling and attributional effects on
    children\'s achievement: A self-efficacy analysis. Journal of
    Educational Psychology, 73, 93-105.
-   Shabani, D. B., Katz, R. C., Wilder, D. A., Beauchamp, K.,
    Taylor, C. R., & Fischer, K. J. (2002). Increasing social
    initiations in children with autism: Effects of a tactile prompt.
    Journal of Applied Behavior Analysis, 35, 79-83.
-   Simpson, A., Langone, J., & Ayres, K. M. (2004). Embedded video and
    computer based instruction to improve social skills for students
    with autism. Education and Training in Developmental Disabilities,
    39, 240-252.
-   Smith, D. D., & Lovitt, T. C. (1975). The use of modeling techniques
    to influence the acquisition of computational arithmetic skills in
    learning-disabled children. In E. Ramp, & G. Semb (Eds.), Behavior
    analysis: Areas of research and application (pp. 283-308). Kansas:
    University of Kansas.
-   Tekin, E., & Kircaali-Iftar, G. (2002). Comparison of the
    effectiveness and efficiency of two response prompting procedures
    delivered by sibling tutors. Education and Training in Mental
    Retardation and Developmental Disabilities, 37, 283-299.
-   Telecsan, B. L., Slaton, D. B., & Stevens, K. B. (1999). Peer
    tutoring: Teaching students with learning disabilities to deliver
    time delay instruction. Journal of Behavioural Education, 9,
    133-154.
-   Trask-Tyler, S. A., Grossi, T. A., & Heward, W. L. (1994). Teaching
    young adults with developmental disabilities and visual impairments
    to use tape-recorded recipes: Acquisition, generalization, and
    maintenance of cooking skills. Journal of Behavioral Education, 4,
    283-311.
-   Vintere, P., Hemmes, N. S., Brown, B. L., & Poulson, C. L. (2004).
    Gross-motor skill acquisition by preschool dance students under
    self-instruction procedures. Journal of Applied Behavior Analysis,
    37, 305-322.
-   Werts, M. G., Caldwell, N. K., & Wolery, M. (1996). Peer modeling of
    response chains: Observational learning by students with
    disabilities. Journal of Applied Behavior Analysis, 29, 56-66.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofpromptingbeforeduringandafterpresentationofthepracticestimulus/index.md","# Effects of prompting before, during, and after presentation of the practice stimulus \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c546dddcb3374e1eb962dcc6c3c967a5}
It is possible for a prompt to be presented prior to the practice
stimulus to which the learner is attempting to respond (premature
prompting), at the same time as the practice stimulus (simultaneous
prompting) or following presentation of the practice stimulus (delayed
prompting).

It is usually argued that prompts should be presented after the practice
stimulus so that the learner has to attend to the practice stimulus
(rather than simply attending to the prompt) and a number of experiments
have explored this assumption. These experiments have tended to involve
8- to 12-year old students either learning to read sight words (Didden,
Prinsen & Sigafoos, 2000) or learning the English translations of French
vocabulary words or Chinese characters (Adepoju & Elliott, 1997; Chung,
2002; Singh & Solman, 1990; Solman & Adepoju, 1995; Soman & Chung,
1996). In these experiments, students presented with picture prompts or
verbal prompts prior to or at the same time as they are presented with
the stimulus word have tended to remember fewer correct responses on
average than students in delayed prompting conditions. These experiments
tend to support the view that prompts should be introduced following the
practice stimulus, presumably because the student is more likely to
attend to the practice stimulus under these conditions.
:::

::: referencesList
#### References

-   Adepoju, A. A., & Elliott, R. T. (1997). Comparison of different
    feedback procedures in second language vocabulary learning. Journal
    of Behavioral Education, 7, 477-495.
-   Chung, K. K. H. (2002). Effective use of Hanyu pinyin and English
    translations as extra stimulus prompts on learning of Chinese
    characters. Educational Psychology, 22, 149-164.
-   Didden, R., Prinsen, H., & Sigafoos, J. (2000). The blocking effect
    of pictorial prompts on sight-word reading. Journal of Applied
    Behavior Analysis, 33, 317-320.
-   Singh, N. N., & Solman, R. T. (1990). A stimulus control analysis of
    the picture-word problem in children who are mentally retarded: The
    blocking effect. Journal of Applied Behavior Analysis, 23, 525-532.
-   Solman, R. T., & Adepoju, A. A. (1995). The effect of aural feedback
    in second language vocabulary learning. Journal of Behavioral
    Education, 5, 433-445.
-   Solman, R. T., & Chung, K. K. H. (1996). Language transfer and
    blocking in second language vocabulary learning. Journal of
    Behavioral Education, 6, 173-190.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Promptingvariablesandtheireffects/Effectsofvariationsintheaccuracylevelofrespondingduringinstruction/index.md","# Effects of variations in the accuracy level of responding during instruction \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-143ce984f4224052b351a1375fa121a0}
Prompts have a crucial role to play during the initial learning phase of
any new skill because they function to increase the level of correct
responding (and to reduce the number of errors) made by the learner. The
cue which is used to prompt the correct response may function as a
strong prompt making the correct response highly likely, or it may
function is a weak prompt which provides only a small degree of
assistance. Learners make many more practice errors following weak
prompts than they do following strong prompts.

There is considerable debate amongst teachers and teacher educators
regarding the relative merits of scaffolding with strong prompts and
scaffolding with weak prompts. A majority of teachers of reading, for
example, argue that the first prompt following a hesitation or a miscue
should always be a weak cue, clue, or prompt.

There has been some controlled research into this question. For example,
a number of studies have compared the relative efficiency of the
increasing assistance procedure (which always begin with a weak prompt)
against more directive prompting procedures such as time delay in
teaching students to read sight words (Gast, Ault, Wolery, Doyle, &
Belanger, 1988), to produce manual signs (Bennett, Gast, Wolery &
Schuster, 1986), to operate household appliances (Steege, Wacker, &
McMahon, 1987) and to complete everyday tasks (Wolery, Ault, Gast, &
Doyle, 1990).

In every one of these comparisons the increasing assistance procedure
(the procedure which begins by providing only a weak prompt) proved to
be the least efficient. That is, it proved to be the procedure which
resulted in the greatest number of incorrect responses and hence, the
procedure which required the greatest number of practice responses.

There appears to be a direct relationship between the accuracy level
during instruction and the scores obtained on post-experimental measures
of learning or retention. McWilliams (2005) reviewed 39 controlled
experiments in which the experimental treatments had resulted in at
least a 5 per cent difference in the accuracy level during instruction.
These experiments generated 44 comparisons. In 32 cases, the condition
with the higher accuracy rate during instruction produced the higher
post-experimental score. In 8 cases the post experimental differences
were too small for any conclusions to be drawn. There were only 4 cases
where the correlation was negative: two experiments where the high
accuracy treatment involved far more prompting than was necessary but
the students were unable to skip unnecessary steps as they were in the
comparison treatment, one experiment in which the high accuracy rate was
a function of copying responses, and one experiment in which the high
accuracy treatment involved practising a small number of responses over
and over.

Not only do learner errors delay acquisition, tasks with high error
rates are often experienced by students as \"difficult\". If error rates
are too high (because the level of assistance is too low), students may
become discouraged, motivation to practise may be reduced, and the
student may begin to avoid the apparently difficult task. It follows
that an appropriate prompting procedure which produces an adequate level
of correct responding during instruction may be a determinant of student
motivation. Barak Rosenshine, who has written a number of reviews of
research on teaching, is of the opinion that teachers should use
prompting procedures which ensure that the learner is responding
correctly at least 80 per cent of the time (Rosenshine, 1983, p. 341).
:::

::: referencesList
#### References

-   Bennett, D. L., Gast, D. L., Wolery, M., & Schuster, J. (1986). Time
    delay and system of least prompts: A comparison in teaching manual
    sign production. Education and Training of the Mentally Retarded,
    21, 117-129.
-   Gast, D. L., Ault, M. J., Wolery, M., Doyle, P. M., & Belanger, S.
    (1988). Comparison of constant time delay and the system of least
    prompts in teaching sight word reading to students with moderate
    retardation. Education and Training in Mental Retardation, 23,
    117-128.
-   McWilliams, K. 2005. An analysis of variables affecting
    instructional efficiency. Unpublished PhD thesis. University of
    Canterbury, School of Education.
-   Rosenshine, B. (1983). Teaching functions in instructional programs.
    The Elementary School Journal, 83, 335-351.
-   Steege, M. W., Wacker, D. P., & McMahon, C. M. (1987). Evaluation of
    the effectiveness of two stimulus prompt strategies with severely
    handicapped students. Journal of Applied Behavior Analysis, 20,
    293-299.
-   Wolery, M., Ault, M. J., Gast, D. L., & Doyle, P. M. (1990).
    Comparison of constant time delay and the system of least prompts in
    teaching chained tasks. Education and Training in Mental
    Retardation, 25, 243-257.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/index.md","# Presentation, prompting and practice variables \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2ce8d5470f6c47eca43b2485eb52990a}
The antecedent variables which provide opportunities for learners to
work with new content and to practice new responses can vary in many
ways. In this chapter we summarise experimental research which has
analysed the effects of variations in the mode and content of teacher
presentations, variations in procedures for prompting new responses and
skills, and variations in the type of practice, amount of practice and
scheduling of practice opportunities.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Amountofpracticeanditseffects/Thenumberofpracticeresponsesrequiredforacquisition/index.md","# The number of practice responses required for acquisition \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-756fa6c3333e42f4aa42f73d1c2030e2}
The experiments cited in the preceding section show that increasing
student engagement in a lesson by requiring a response to every question
increases student retention of lesson content but the experiments do not
tell us how many practice responses are required in order to ensure
acquisition or retention. As teaching researchers begin to identify the
important questions which need to be addressed, investigators are
beginning to track the number of practice responses which are actually
required in order to learn and remember a new response. One of the
startling findings which has emerged from the research so far is the
discovery that the human brain can learn and remember meaningful
propositions with rather fewer response opportunities than was
previously thought.

McLay (2003) found that normally developing four year olds required
three practice opportunities per name, on average, to learn and remember
the names of 20 model animals and that this was the case regardless of
whether learning opportunities were child initiated or experimenter
initiated. Keel and Gast (1992) report that three learning disabled
11-year olds required an average of 3 trials per word in order to learn
to recognise the words in sets of 15 unknown sight words.

As part of his PhD investigations, McWilliams (2005) found that 6- to
7-year olds required, on average, five practice responses in order to
learn and remember a correct spelling response for 24 hours. The words
were words which commonly occur in written prose and which the child
could not yet spell. The five practice responses figure was quite stable
across a variety of prompting and error correction procedures and, in
the majority of cases, occurred over a two- to three-day period. Nulman
and Gerber (1984) also found that an 8-year old student with learning
disabilities required five trials per word in order to learn and
remember the words in a set of 10 unknown spelling words.

Based on extensive analyses of everything which individual children say
and do during the course of samples of social studies lessons, Nuthall
and Alton Lee have concluded from their descriptive study that 10- to
11-year old children learn and remember only those items of information
which they have experienced on at least four occasions with no more than
two days between any two of the four experiences (Nuthall, 1999; Nuthall
& Alton-Lee, 1993). It appears that the experience has to be with the
complete proposition although experience with definitions, analogies,
examples and non-examples can suffice provided that the pupil also
experiences the complete proposition on one or more occasions. The
\\"four experiences with no more than two days between each\\" rule has
identified, with 82 to 85 per cent accuracy, the previously unknown
items of information which individual children have learned and
remembered across half a dozen separate lesson samples.
:::

::: referencesList
#### References

-   Keel, M. C., & Gast, D. L. (1992). Small group instruction for
    students with learning disabilities: Observational and incidental
    learning. Exceptional Children, 58, 357-368.
-   McLay, L. K (2003). Acquisition, retention and generalisation of
    object names in 4 year old children during child initiated and adult
    initiated learning interactions. Unpublished M.Ed. dissertation.
    Christchurch, NZ: University of Canterbury, School of Education.
-   McWilliams, K. 2005. An analysis of variables affecting
    instructional efficiency. Unpublished PhD thesis. University of
    Canterbury, School of Education.
-   Nulman, J. A. H., & Gerber, M. M. (1984). Improving spelling
    performance by imitating a child\'s errors. Journal of Learning
    Disabilities, 17, 328-333.
-   Nuthall, G. A. (1999). The way students learn: Acquiring knowledge
    from an integrated science and social studies unit. Elementary
    School Journal, 99, 303-341.
-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Amountofpracticeanditseffects/index.md","# Amount of practice and its effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-3a38b6462e9b49beacb30f66bcb67962}
Everyone knows from practical experience than in order to remember
something new a certain amount of practice is required. Practical
experience also teaches us that in order to master a new skill a
considerable amount of practice is often required. The critical question
is \"How much practice?\" Sometimes this problem is solved by setting a
performance criterion or \"exit criterion\" and by requiring students to
practice until they meet this criterion. This simply changes the
question to \"How is the performance criterion to be determined?\"
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Amountofpracticeanditseffects/Effectsofvariationsinexitcriteria/index.md","# Effects of variations in exit criteria \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-e064cbc430124b4c87132963080bb4dc}
While the research reviewed in the preceding section begins to provide
answers to the practical question of how much practice and review a
teacher should provide, it is research which will be difficult to apply
in practice. This is because a classroom consists of dozens of learners
practising dozens of knowledge items and skills every day and it is
impossible for the classroom teacher to monitor and record the learning
opportunities experienced by each individual student from day to day. A
more practical approach is to select some kind of performance criterion
and to ask students to continue practising until they reach that
performance criterion. The performance criterion which is most important
is the *exit criterion* which is used to determine when an individual
student should cease practising a particular set of academic responses,
exit that unit of work, and move on to the next unit of work.

The most widely cited example of a teaching programme which uses
specified exit criteria for each of the teaching objectives in each of
the basic skills contained in the primary school curriculum is that
developed by Kent Johnson for a private school called Morningside
Academy in Seattle. The curriculum, the teaching procedures, and the
rates of progress of Morningside students have been described in several
reports (Johnson & Layng, 1992, 1994). Almost all of the students who
enrol at Morningside are students with diagnosed learning difficulties
or attention deficit disorder or both. In general terms, these students
make rates of progress in reading, language arts and maths (as measured
by standardised achievement tests) which are two times to three times
faster than that made by the average American child.

The exit criteria used at Morningside are fluency criteria and there is
an emerging consensus amongst those who are studying fluency building
that the exit criteria for basic literacy and numeracy skills should
always be fluency criteria (e.g., Binder, 1996; Binder, Haughton &
Bateman, 2002; Johnson & Layng, 1992; Kubina & Morrison, 2000). This is
because fluency, not achievement or accuracy, is the best predictor of
long term recall (Bullara, Kimball & Cooper, 1993; Ivarie, 1986;
Olander, Collins, McArthur, Watts, & McDade, 1986; Shirley &
Pennypacker, 1994; Sterling, Goetz & Sterling, 1984).

As the research into fluency has evolved, practitioners have developed
lists of fluency-based exit criteria (e.g., Binder et al., 2002) which
can be used by teachers who seek to ensure that basic skills have been
sufficiently well practised for them to be remembered over the long
term.

It is important to note, however, that there is little or no parametric
research into fluency, that is, almost no research comparing the level
of retention which results from variations in fluency-based exit
criteria. Studies of the long term effects of building basic skills to
differing levels of fluency must be considered to be one of the most
important next steps in the research into learning and teaching.
:::

::: referencesList
#### References

-   Binder, C. (1996). Behavioral fluency: Evolution of a new paradigm.
    The Behavior Analyst, 19, 163-197.
-   Binder, C., Haughton, E., & Bateman, B. (2002). Fluency: Achieving
    true mastery in the learning process. Retrieved January 29, 2004,
    from http://www.haughtonlearningcenter.com
-   Bullara, D. T., Kimball, J. W., & Cooper, J. O. (1993). An
    assessment of beginning addition skills following three months
    without instruction or practice. Journal of Precision Teaching,
    11(1), 11-16.
-   Ivarie, J. J. (1986). Effects of proficiency rates on later
    performance of a recall and writing behavior. Remedial and Special
    Education, 7(5), 25-30.
-   Johnson, K. R., & Layng, T. V. J. (1992). Breaking the structuralist
    barrier: Literacy and numeracy with fluency. American Psychologist,
    47, 1475-1490.
-   Johnson, K. R., & Layng, T. V. J. (1994). The Morningside model of
    generative instruction. In R. Gardner et al. (Eds.), Behavior
    analysis in education: Focus on measurably superior instruction (pp.
    173-197). Pacific Grove, CA: Brooks/Cole.
-   Kubina, R. M. Jr., & Morrison, R. S. (2000). Fluency in education.
    Behavior & Social Issues, 10, 83-99.
-   Olander, C. P., Collins, D. L., McArthur, B. L., Watts, R. O., &
    McDade, C. E. (1986). Retention among college students: A comparison
    of traditional versus precision teaching. Journal of Precision
    Teaching, 6(4), 80-82.
-   Shirley, M. J., & Pennypacker, H. S. (1994). The effects of
    performance criteria on learning and retention of spelling words.
    Journal of Precision Teaching, 12(1), 73-86.
-   Sterling, L. K., Goetz, E. M., & Sterling, T. (1984). Acquisition
    and maintenance of basal and organic words: Effects of repeated
    practice technique. Behavior Modification, 8, 495-519.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Amountofpracticeanditseffects/Effectsofvariationsinthenumberofpracticeopportunities/index.md","# Effects of variations in the number of practice opportunities \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9e6d8b4489f04795ab681f03407466e0}
Assuming that the teacher has selected a developmentally appropriate
teaching aim, that is one which the child can achieve given suitable
assistance, research suggests that the number of practice opportunities
experienced by the child with respect to each of the to-be-learned
responses will be a major determinant of whether or not these responses
will be acquired (learned) and remembered. The term *practice
opportunity* refers to each occasion where the child gets to practice
(either with or without assistance) one of the responses, skills or
understandings contained in their current teaching aim. Most teachers
know, at least intuitively, that remembering depends upon practice which
is why they include some kind of practice or \\"consolidation\\" activity
within most units of work. Of course acquisition and remembering are two
different processes and the research into practice suggests that whether
or not acquisition itself will occur is also closely dependent upon the
number of learning opportunities experienced by the child.

The relationship between opportunity to learn and learning has been
demonstrated for achievement in general (e.g., Thurlow, Ysseldyke,
Graden & Algozzine, 1984), vocabulary development (e.g., Elley, 1989;
Hart & Risley, 1995; McKeown, Beck, Omanson, & Pople, 1985), reading
readiness on entry to school (Bus, van Izjendoorn & Pellegrini, 1995),
growth in reading and reading comprehension (e.g., Allen, Cipielewski &
Stanovich, 1992; Anderson, Wilson & Fielding, 1988; Gettinger, 1991;
Martin, 1991), spelling (e.g., Delquadri, Greenwood, Stretton & Hall,
1983; Greenwood, Delquadri & Hall, 1984; McLaughlin, Reiter, Mabee, &
Byram, 1991), maths (e.g., Albers & Greer, 1991), and general subject
matter areas such science, social studies, and health (e.g., Gardner,
Heward & Grossi, 1994; Nuthall & Alton-Lee, 1993; Sterling, Barbetta,
Heward & Heron, 1997).

The relationship between number of response opportunities and rate of
acquisition was first demonstrated in experimental studies of what
happens when the teacher increases the number of response opportunities
experienced by each child using such procedures as self-practice,
response cards, and choral responding.

**Self-directed practice**

The self-directed practice procedure which has been most extensively
analysed is \"cover-copy-compare\" This is a generic procedure for
practising equivalence relations and other forms of correct responding.
Typically it involves examining the stimulus (e.g., a new spelling word)
covering it, attempting to write it, and self-checking this response by
comparing it against the original (uncovered) stimulus. If the response
is incorrect, the student repeats the cover-copy-compare process and, if
the response is correct, the student moves to the next item to be
practised.

The research on cover-copy-compare has been reviewed by Skinner,
McLaughlin & Logan (1997) who summarised the results of 17 separate
experiments. Skinner et al. (1997, p. 304) concluded that
cover-copy-compare was \"an effective, efficient procedure for improving
students' academic performance across a variety of curricula objectives
and skills domains.\" Controlled studies of cover-copy-compare and its
effects included demonstrations of accelerated rates of acquisition in
spelling (McLaughlin et al., 1991; Murphy, Hern, Williams & McLaughlin,
1990; Pratt-Struthers, Bartalamay, Williams & McLaughlin, 1989;
Schemerhorn & McLaughlin, 1997), sight words (Conley, Derby,
Roberts-Gwinn, Weber & McLaughlin, 2004), maths facts (Skinner, Ford &
Yunker, 1991; Skinner, Shapiro, Turco, Cole & Brown, 1992; Skinner,
Beatty, Turco & Rasafage, 1989; Stading, Williams & McLaughlin, 1996),
and geography facts (Skinner, Belfiore & Pierce, 1992).

Introduction of cover-copy-compare in the learning of new spelling words
typically results in a 2-fold increase in rate of acquisition in both
normally developing children and in children with learning disabilities
(Church, 1990). The procedure has also been shown to produce accelerated
fluency development (Skinner, Bamburg, Smith & Powell, 1993).

**Response card procedures**

A number of studies have attempted to measure what happens when the
classroom teacher requires every child in the classroom to respond to
every classroom question -- usually by writing down the answer to each
question. In some studies, the students are required to hold up their
response cards for the teacher to see. The response card research has
been reviewed by Randolph (2007) who reviewed 18 experiments. The
effects of the response card treatment have been measured using 9 year
olds engaged in maths lessons (Christie & Schuster, 2003) and health
science lessons (Sterling, Barbetta, Heward & Heron, 1997), with 10 year
old students engaged in science lessons (Church, 1976; Gardner, Heward &
Grossi, 1994), with 12 year olds in writing lessons (Davis & O'Neil,
2004), with 14-year old students engaged in earth science lessons
(Cavanaugh, Heward & Donelson, 1996), and with university students
(Miller & Malott, 1997). In every single experiment the results have
been the same. When students are required to produce a written answer to
every teacher question their scores on next day quizzes and weekly tests
increase dramatically. Several of these experiments have also documented
a collateral increase in on task behaviour during the course of the
experimental lessons (e.g. Christie & Schuster 2003). The behaviour and
attention of children with behaviour problems also improves markedly
(Randolph, 2007).

**Unison responding**

One of the features of the small group teaching procedure used in Direct
Instruction classrooms is rapid-paced unison responding to teacher
questions. The unison responding requires every child to respond to
every teacher question. The introduction of Direct Instruction
procedures into the classroom invariably results in accelerated student
progress (Adams & Engelmann, 1996). While this accelerated progress
cannot be directly attributed to the greatly increased number of
response opportunities experienced by all children, the Direct
Instruction evaluations in conjunction with the research already
reviewed in this section suggests that the greatly increased number of
response opportunities which occur in Direct Instruction classrooms
almost certainly plays a role in the accelerated progress produced by
the teaching procedure employed by Direct Instruction teachers.
:::

::: referencesList
#### References

-   Adams, G. L., & Engelmann, S. (1996). Research on Direct
    Instruction: 25 years beyond DISTAR. Seattle, WA: Educational
    Achievement Systems.
-   Albers, A. E., & Greer, R. D. (1991). Is the three-term contingency
    trial a predictor of effective instruction? Journal of Behavioral
    Education, 1, 337-354.
-   Allen, L., Cipielewski, J., & Stanovich, K. E. (1992). Multiple
    indicators of children's reading habits and attitudes: Construct
    validity and cognitive correlates. Journal of Educational
    Psychology, 84, 487-503.
-   Anderson, R. C., Wilson, P. T., & Fielding, L. B. (1988). Growth in
    reading and how children spend their time outside of school. Reading
    Research Quarterly, 27, 285-303.
-   Bus, A. G., van Izjendoorn, M. H., Pellegrini, A. D. (1995). Joint
    book reading makes for success in learning to read: A meta-analysis
    on intergenerational transmission of literacy. Review of Educational
    Research, 65, 1-21.
-   Cavanaugh, R.A., Heward, W.L., & Donelson, F. (1996). Effects of
    response cards during lesson closure on the academic performance of
    secondary students in an earth science course. Journal of Applied
    Behavior Analysis, 29, 403-406.
-   Church, R. J. (1976). The components of an effective teaching
    strategy. Unpublished PhD thesis. Christchurch, NZ: University of
    Canterbury, Education Department.
-   Church, R. J. (1990). The use of within-subject designs to measure
    the effects of teaching on learning. Paper presented to the 1990
    conference of the New Zealand Association for Research in Education,
    Auckland, New Zealand.
-   Christie, C. A., & Schuster, J. W. (2003). The effects of using
    response cards on student participation, academic achievement, and
    on-task behavior during whole-class, math instruction. Journal of
    Behavioral Education, 12, 147-165.
-   Conley, C. M., Derby, K. M., Roberts-Gwinn, M., Weber, K. P., &
    McLaughlin, T. F. (2004). An analysis of initial acquisition and
    maintenance of sight words following picture matching and copy,
    cover, and compare teaching methods. Journal of Applied Behavior
    Analysis, 37, 339-350.
-   Davis, L. L., & O'Neill, R. E. (2004). Use of response cards with a
    group of students with learning disabilities including those for
    whom English is a second language. Journal of Applied Behavior
    Analysis, 37, 219-222.
-   Delquadri, J. C., Greenwood, C. R., Stretton, K., & Hall, R. V.
    (1983). The peer tutoring spelling game: A classroom procedure for
    increasing opportunity to respond and spelling performance.
    Education and Treatment of Children, 6, 225-239.
-   Elley, W. B. (1989). Vocabulary acquisition from listening to
    stories. Reading Research Quarterly, 24, 175-187.
-   Gardner, R., Heward, W. L., & Grossi, T. A. (1994). Effects of
    response cards on student participation and academic achievement: A
    systematic replication with inner-city students during whole-class
    science instruction. Journal of Applied Behavior Analysis, 27,
    63-71.
-   Gettinger, M. (1991). Learning time and retention differences
    between nondisabled students and students with learning
    disabilities. Learning Disability Quarterly, 14, 179-189.
-   Greenwood, C. R., Delquadri, J. C., & Hall, R. V. (1984).
    Opportunity to respond and student academic performance. In W. L.
    Heward, T. E. Heron, D. S. Hill, & J. Trap-Porter (Eds.), Focus on
    behavior analysis in education (pp 58-88). Columbus: Charles E.
    Merrill Publishing Company.
-   Hart, B., & Risley, T. R. (1995). Meaningful differences in the
    everyday experience of young American children. Baltimore: Paul H.
    Brookes.
-   Martin, T. R. (1991). Evaluation of a co-operative reading resource
    for low progress Standard 2 pupils. Research Report No 91-2.
    Christchurch, NZ: University of Canterbury, Education Department.
-   McKeown, M. G., Beck, I. L., Omanson, R. C., & Pople, M. T. (1985).
    Some effects of the nature and frequency of vocabulary instruction
    on the knowledge and use of words. Reading Research Quarterly, 20,
    522-535.
-   McLaughlin, T. F., Reiter, S. M., Mabee, W. S., & Byram, B. J.
    (1991). An analysis and replication of the Add-A-Word spelling
    program with mildly handicapped middle school students. Journal of
    Behavioral Education, 1, 413-426.
-   Miller, M. L., & Malott, R. W. (1997). The importance of overt
    responding in programmed instruction even with added incentives for
    learning. Journal of Behavioral Education, 7, 497-503.
-   Murphy, J. F., Hern, C. L., Williams, R. L., & McLaughlin, T. F.
    (1990). The effects of the cover, copy, compare approach in
    increasing spelling accuracy with learning disabled students.
    Contemporary Educational Psychology, 15, 378-386.
-   Nuthall, G., & Alton-Lee, A. (1993). Predicting learning from
    student experience of teaching: A theory of student knowledge
    construction in classrooms. American Educational Research Journal,
    30, 799-840.
-   Pratt Struthers, J., Bartalamay, H. R., Williams, R. L., &
    McLaughlin, T. F. (1989). Effects of the Add-a-Word spelling program
    on spelling accuracy during creative writing: A replication across
    two classrooms. British Columbia Journal of Special Education, 13,
    151-157.
-   Randolph, J. J. (2007). Meta-analysis of the research on response
    cards: Effects on test achievement, quiz achievement, participation,
    and off-task behavior. Journal of Positive Behavior Interventions,
    9, 113-128.
-   Schermerhorn, P. K., & McLaughlin, T. F. (1997). Effects of the
    add-a-word spelling program on test accuracy, grades, and retention
    of spelling words with fifth and sixth grade regular education
    students. Child & Family Behavior Therapy, 19, 23-35.
-   Skinner, C. H., Bamburg, H. W., Smith, E, S., & Powell, S. S.
    (1993). Cognitive cover, copy, and compare: Subvocal responding to
    increase rates of accurate division responding. Remedial and Special
    Education, 14, 49-56.
-   Skinner, C. H., Beatty, K. L., Turco, T. L., & Rasavage, C. (1989).
    Cover, copy, and compare: A method for increasing multiplication
    performance. School Psychology Review, 18, 412-420.
-   Skinner, C. H., Belfiore, P. J. & Pierce, N. (1992). Cover, copy,
    and compare: Increasing geography accuracy in students with behavior
    disorders. School Psychology Review, 21, 73-81.
-   Skinner, C. H., Ford, J. M., & Yunker, B. D. (1991). A comparison of
    instructional response requirements on the multiplication
    performance of behaviorally disordered students. Behavioral
    Disorders, 17, 56-65.
-   Skinner, C. H., McLaughlin, T. E. & Logan, P. (1997). Cover, copy
    and compare: A self-managed academic intervention effective across
    skills, students, and settings. Journal of Behavioral Education, 7,
    295-306.
-   Skinner, C. H., Shapiro, E. S., Turco, T. L., Cole, C. L., &
    Brown, D. K. (1992). A comparison of self- and peer-delivered
    immediate corrective feedback on multiplication performance. Journal
    of School Psychology, 30, 101-116.
-   Stading, M., Williams, R. L., & McLaughlin, T. F. (1996). Effects of
    a copy, cover, compare procedure on multiplication facts mastery
    with a third grade girl with learning disabilities in a home
    setting. Education and Treatment of Children, 19, 425-434.
-   Sterling, R. M., Barbetta, P. M., Heward, W. L., & Heron, T. E.
    (1997). A comparison of active student response and on-task
    instruction on the acquisition and maintenance of health facts by
    fourth grade special education students. Journal of Behavioral
    Education, 7, 151-165.
-   Sterling, R. M., Barbetta, P. M., Heward, W. L., & Heron, T. E.
    (1997). A comparison of active student response and on-task
    instruction on the acquisition and maintenance of health facts by
    fourth grade special education students. Journal of Behavioral
    Education, 7, 151-165.
-   Thurlow, M. L., Ysseldyke, J. E., Graden, J., & Algozzine, B.
    (1984). Opportunity to learn for LD students receiving different
    levels of special education services. Learning Disability Quarterly,
    7, 55-67.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/Effectsofvariationsinresponsesizeandresponseeffort/index.md","# Effects of variations in response size and response effort \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2d77b64d4bac4eaf9ecae48a1778f0d5}
The research on response effort has been reviewed by Friman & Poling
(1995). Most of the research on response effort has involved children
and adults with severe intellectual disabilities and non-academic
learning outcomes and it is not yet clear whether the results of this
research will be applicable to performance in the mainstream classroom.

One of the ways of demonstrating the effect of response effort in the
classroom is to compare what happens when students are required to
respond in writing, rather than orally. This comparison has been made
several times (Skinner, Belfiore, Mace, Williams-Wilson & Johns, 1997;
Skinner, Ford & Yunker, 1991). In both of these experiments the
acquisition of maths facts as the learning outcome. When the number of
response opportunities is kept constant in this kind of experiment, oral
responding and written responding produce similar levels of acquisition,
that is, there is no response mode effect. However, when time is held
constant, oral responding results in faster rates of acquisition --
because the children who are responding orally complete larger numbers
of practice responses in the time available (Skinner et al., 1997).

It is to be expected that there will be a reciprocal relationship
between reinforcer strength and response effort. If so, it should be
possible to require considerable response effort from the learner if the
reinforcer for successful task completion is a powerful reinforcer for
the individual concerned. Where the reinforcer is a weak one, it is to
be expected that it will motivate continued effort only if response
effort required for reinforcement is also small. We have located one
test of this assumption so far. The results of an experiment by Gwinn,
Derby, Fisher, Kurtz, Fahs, Augustine and McLaughlin (2005) are
consistent with this view.
:::

::: referencesList
#### References

-   Gwinn, M. M., Derby, K. M., Fisher, W., Kurtz, P., Fahs, A.,
    Augustine M., & McLaughlin, T. F. (2005). Effects of response effort
    and reinforcer delay on choice and aberrant behavior. Behavior
    Modification, 29, 642-652.
-   Skinner, C. H., Belfiore, P. J., Mace, H. W., Williams-Wilson, S., &
    Johns, G. A. (1997). Altering response topography to increase
    response efficiency and learning rates. School Psychology Quarterly,
    12, 54-64.
-   Skinner, C. H., Ford, J. M., & Yunker, B. D. (1991). A comparison of
    instructional response requirements on the multiplication
    performance of behaviorally disordered students. Behavioral
    Disorders, 17, 56-65.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/Effectsofovertversuscovertpracticeresponses/index.md","# Effects of overt versus covert practice responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-c69c95a56a874ee8b5cac1e469754ebc}
The traditional classroom lesson -- in which the teacher asks a question
and calls upon a single child to respond -- rests on the assumption that
students learn as much from listening to a question-and-answer sequence
as they do from participating in that question-and-answer sequence.
Practical experience suggests that this is sometimes the case, and the
research on incidental learning indicates that even children with
intellectual disabilities can learn and remember quite a lot from simply
listening to the responses of others (Cromer, Schuster, Collins &
Grisham-Brown, 1998; Doyle, Gast, Wolery, Ault & Farmer, 1990; Gast,
Doyle, Wolery, Ault, & Kolenda, 1994).

However, it is also clear from the research into classroom participation
that there are many occasions where the onlookers in a classroom lesson
learn much less than they would if they were participants. For example,
when every child in the class is required to respond to every question
either in writing, or else by holding up a response card, they remember
more on end-of-lesson and end-of-unit tests than when the teacher adopts
the traditional practice of calling on just one student at a time (e.g.,
Church, 1976; Gardner, Heward & Grossi, 1994; Randolph, 2007). Overt
answering in the form of unison responding to every teacher question is
also required during the small group lessons of Direct Instruction and
this, it has been claimed, is one of the reasons for the accelerated
progress which almost always occurs when children move into Direct
Instruction classrooms (Adams & Engelmann, 1996).

The question which is not answered by these studies is the question of
whether the inferior acquisition of the onlookers in a traditional
lesson is due to their covert (rather than overt) responding or whether
it is due to the fact that there is no requirement to actually frame a
response to every question. At the present time it seems more likely
that that the superior acquisition which results when every child is
required to respond overtly is a function of the requirement to respond
(that is, increased task engagement) than it is to the requirement to
respond overtly (rather than covertly).
:::

::: referencesList
#### References

-   Adams, G. L., & Engelmann, S. (1996). Research on Direct
    Instruction: 25 years beyond DISTAR. Seattle, WA: Educational
    Achievement Systems.
-   Church, R. J. (1976). The components of an effective teaching
    strategy. Unpublished PhD thesis. University of Canterbury:
    Education Department.
-   Cromer, K., Schuster, J. W., Collins, B. C., & Grisham-Brown, J.
    (1998). Teaching information on medical prescriptions using two
    instructive feedback schedules. Journal of Behavioral Education, 8,
    37-61.
-   Doyle, P. M., Gast, D. L., Wolery, M., Ault, M. J., & Farmer, J. A.
    (1990). Use of constant time delay in small group instruction: A
    study of observational and incidental learning. The Journal of
    Special Education, 23, 369-385.
-   Gardner, R., Heward, W. L., & Grossi, T. A. (1994). Effects of
    response cards on student participation and academic achievement: a
    systematic replication with inner-city students during whole-class
    science instruction. Journal of Applied Behavior Analysis, 27,
    63-71.
-   Gast, D. L., Doyle, P. M., Wolery, M., Ault, M. J., & Kolenda, J. L.
    (1994). Instructive feedback: Effects of number and type. Journal of
    Behavioral Education, 4, 313-334.
-   Randolph, J. J. (2007). Meta-analysis of the research on response
    cards: Effects on test achievement, quiz achievement, participation,
    and off-task behavior. Journal of Positive Behavior Interventions,
    9, 113-128.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/index.md","# Practice variables and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2435eaed13034f18b6f39c1dd65f73ef}
Most learning requires a certain amount of practice. This practice may
be of various kinds. Practice may be child initiated or teacher
initiated, practice responses may be overt (visible) or covert
(invisible), practice may involve constructed responses or selection
responses, practice responses may vary with respect to effort (size),
practice opportunities may vary with respect to how closely they
simulate test conditions or real life conditions, and practice may
involved untimed responding or timed responding.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/Effectsofconstructedversusselectionresponses/index.md","# Effects of constructed versus selection responses \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8876d41ef1964054b7e726538fe3ad4f}
It seems reasonable to assume that practice responses should closely
simulate the responses which will be required after training has been
completed. If this is the case, then selection responses will be more
efficient when the child is learning new discriminations and
generalisations as in, for example, learning to tell the difference
between adverbs and adjectives, or the difference between addition word
problems and multiplication word problems. In contrast, constructed
responses will be more efficient when the child is learning how to
perform a new response, procedure or skill as in, for example, learning
to spell or to write or to calculate. However, there appears to have
been no controlled research into this assumption.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/Effectsofvariationsinthematchbetweenresponsemodeandintendedlearningoutcome/index.md","# Effects of variations in the match between response mode and intended learning outcome \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-b19b49c9407d4a6584e9a3b08347c103}
It seems reasonable to assume that a learner is more likely to learn how
to do something new if practice responses closely resemble the terminal
performance which is being aimed for. For example, it seem reasonable to
assume that a student is more likely to acquire new spelling responses
if they engage in spelling (hear--\>write) practice than if they engage
in reading or working crossword puzzles or completing word find puzzles.

There has been a limited amount of research into this question. One line
of research has involved comparing the relative effectiveness of written
versus oral responses during the learning of new spelling words (e.g.
Bradley, 1981; Cuvo, Ashley, Marso, Zhang & Fry, 1995; Van Houten & Van
Houten, 1991) and new number facts (Skinner, Ford & Yunker, 1991).
Because of differences in experimental procedures, these experiments
allow of no clear cut conclusion. When lesson time is controlled,
students tend to make about twice as many oral responses as written
responses and to obtain higher levels of accuracy following practice
(Skinner et al., 1991). When responses are controlled students learn
about the same number of new responses but the \"say the answer\"
condition takes much less time (Cuvo et al., 1995; Van Houten & Van
Houten, 1991). However, Bradley (1981) reports that students who engaged
in cover-*write*-compare practice recalled many more spellings on a 4
week recall test than students who engaged in cover-*say*-compare
practice.

A second line of research has compared the relative effectiveness of
written spelling practice against reading the words (Van Daal & Van der
Liej, 1992) or listening to the words being spelled (Sears & Johnson,
1986). In both of these experiments, written practice resulted in the
students learning more correct spellings than reading or listening.

There appears to have been one experimental analysis of the common
practice of teaching the learner to recite the steps which are involved
in the performance of a new procedure (Jones, Ollendick & Shinske,
1989). The Jones et al. experiment, which involved groups of twelve 7-
to 10-year olds learning a fire evacuation procedure found that students
who practised the steps performed better on the post-test (mean=66) than
those who just engaged in verbal rehearsal (mean=12).
:::

::: referencesList
#### References

-   Bradley, L. (1981). The organisation of motor patterns for spelling:
    An effective remedial strategy for backward readers. Developmental
    Medicine and Child Neurology, 23, 83-91.
-   Cuvo, A. J., Ashley, K. M., Marso, K. J., Zhang, B. L., & Fry, T. A.
    (1995). Effect of response practice variables on learning spelling
    and sight vocabulary. Journal of Applied Behavior Analysis, 28,
    155-173.
-   Jones, R. T., Ollendick, T. H., & Shinske, F. K. (1989). The role of
    behavioral versus cognitive variables in skill acquisition. Behavior
    Therapy, 20, 293-302.
-   Sears, N. C., & Johnson, D. M. (1986). The effects of visual imagery
    on spelling performance and retention among elementary students.
    Journal of Educational Research, 79, 230-233.
-   Skinner, C. H., Ford, J. M., & Yunker, B. D. (1991). A comparison of
    instructional response requirements on the multiplication
    performance of behaviorally disordered students. Behavioral
    Disorders, 17, 56-65.
-   Van Daal, V. H. P., & Van der Leij, A. (1992). Computer-based
    reading and spelling practice for children with learning
    disabilities. Journal of Learning Disabilities, 25, 186-195.
-   Van Houten, R., & Van Houten, J. (1991). The effects of breaking new
    spelling words into small segments on the spelling performance of
    students with learning disabilities. Journal of Behavioral
    Education, 1, 399-411.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/Effectsofchildinitiatedandteacherinitiatedlearninginteractions/index.md","# Effects of child initiated and teacher initiated learning interactions \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-09a8159c458b46ecb3046e5fad4c52f6}
Learning interactions may be initiated by the learner or by the teacher.
Child-initiated learning interactions are strongly preferred by early
childhood educators and are justified by arguing (a) that it is
important not to teach anything until the child is \"ready\" and (b) it is
important to allow the child to select and initiate learning activities
so that the teacher can determine when the child is \"ready\". Early
childhood educators also tend to argue that the use of incidental
teaching in contexts where stimuli are the same as those in typical
environments is much more likely to result in generalisation (e.g.
Warren & Kaiser, 1986).

These claims have been the subject of almost no experimental analysis.

The earliest analysis of child initiated learning is a series of
\"incidental teaching\" experiments by Hart and Risley (1968, 1974, 1975,
1980). In these studies, which involved 5-year olds in low achieving
urban schools, child-initiated interactions were primed by placing
desired toys and materials on a shelf and requiring any child who wanted
an item from the shelf to request it by name. If the child said nothing,
the teacher prompted an appropriate request. If the child made an
appropriate verbal request, he or she was immediately reinforced by
being given the requested toy or materials. This intervention resulted
in greatly increased use by the children of names (when names were
required), descriptive adjectives (when these were required) and so on.
These studies included no control condition and the child initiated
requests were frequently prompted by the teachers.

Since the Hart and Risley studies there appear to have been four
attempts to measure the relative effectiveness of child initiated versus
teacher initiated learning interactions (Cavallaro & Bambara, 1982;
McGee, Krantz & McClannahan, 1985; Miranda-Linne & Melin, 1992; McLay,
2003). Cavallaro and Bambara (1982) report that incidental teaching
produced a higher rate and variety of two-word utterances in
language-delayed preschool children but the experiment did not control
for the number of practice opportunities in each condition.. McGee et
al. (1985) provided 20 practice opportunities for each condition each
day and found that there was no difference between the rates of
acquisition and retention resulting from the two teaching conditions.
There was, however, somewhat greater generalisation of spontaneous
preposition use to free play settings. Miranda-Linne and Melin (1992)
provided 20 trials each day for each condition and found that teacher
directed, discrete-trial teaching produced faster acquisition and
greater generalisation of the colour adjectives that were being taught.

McLay (2003) compared the rate of learning of seven 4-year old children
under two conditions: a Child's Game in which all learning interactions
were initiated by the child (who had been taught to ask \"What is the
name of this animal?\") and a Teacher's Game in which all interactions
were initiated by an adult asking \"What is the name of this animal?\" The
child was free to ask such questions as many times as they liked and in
any order until they either became bored or until 8 minutes had passed.
To control the number of learning opportunities across both teaching
conditions, each experiment began with the Child's Game, the number of
question and answer interactions which occurred during each Child's Game
was recorded, and the number of questions the experimenter asked during
the next Teacher's Game was the same as the number that the child had
asked during the previous, same-numbered Child's Game. The Teacher's
Game also differed from the Child's Game in that the experimenter
targeted only four animals at a time and asked questions repeatedly
about these animals until their names had been learned. It was found
that acquisition, maintenance and generalisation were closely similar
across the two conditions for almost all of the children.

The McLay results are consistent with those of McGee et al. (1985) who
found no significant difference in rates of acquisition or retention
when comparing an incidental teaching condition against a discrete-trial
teaching condition with the number of learning opportunities controlled.
Like the McLay experiment, the McGee et al. experiment controlled for
the difficulty of stimulus material, it controlled for the number of
teaching trials in each experimental condition and it controlled the
reinforcement values and schedule of reinforcement across both teaching
conditions.

The results from these two experiments provide support for the notion
that, if the number of learning opportunities are kept constant the
question of whether learning opportunities are child initiated or
teacher initiated may be of much less importance than that claimed by
the proponents of developmentally appropriate practice. What does appear
to be very important is the number of learning opportunities provided
for each name or concept which the child is expected to learn.

If it is the number of learning opportunities which is the critical
variable, this would explain the contrary results reported by Cavallaro
and Bambara (1982) and Miranda-Linne and Melin (1992) who failed to
control the number of learning opportunities which occurred during each
teaching condition.

There is as yet no consistent pattern across these four studies with
respect to stimulus generalisation. This is almost certainly a function
of a lack of agreement as to how generalisation should be measured. In
the McLay experiment, generalisation was assessed only with respect to
the names which had been acquired. However, this requirement was not met
by Cavallaro and Bambara (1982) or by Miranda-Linne & Melin (1992).
There seems to be little logic in testing for stimulus generalisation
when the responses involved have yet to be acquired and are still being
prompted in the training setting.

The results of the research reviewed in this section indicate that there
is a place for both child initiated and adult initiated learning
interactions in the preschool setting. This position is consistent with
the position which has been adopted by both the National Association for
the Education of Young Children (NAEYC, 1997) and the Division of Early
Childhood of the Council for Exceptional Children. The most recent
guidelines from both of these organisations recommend an appropriate mix
of child and adult initiated learning activities in the preschool
setting.
:::

::: referencesList
#### References

-   Cavallaro, C. & Bambara, L. (1982). Two strategies for teaching
    language during free play TASH Journal, 7, 80-92.
-   Hart, B. & Risley, T. (1968). Establishing use of descriptive
    adjectives in the spontaneous speech of disadvantaged preschool
    children. Journal of Applied Behavior Analysis, 1, 109-120.
-   Hart, B. & Risley, T. (1974). Using preschool materials to modify
    the language of disadvantaged children. Journal of Applied Behavior
    Analysis, 7, 243-256.
-   Hart, B. & Risley, T. (1975). Incidental teaching of language in the
    preschool setting. Journal of Applied Behavior Analysis, 8, 411-420.
-   Hart, B. & Risley, T. (1980). In vivo language intervention:
    Unanticipated general effects. Journal of Applied Behavior Analysis,
    13, 407-432.
-   McLay, L. K (2003). Acquisition, retention and generalisation of
    object names in 4 year old children during child initiated and adult
    initiated learning interactions. Unpublished M.Ed. dissertation.
    University of Canterbury, School of Education.
-   McGee, G. G., Krantz, P. J., & McClannahan, L. E. (1985). The
    facilitative effects of incidental teaching on preposition use by
    autistic children. Journal of Applied Behavior Analysis, 18, 17-31.
-   Miranda-Linne, F. & Melin, L. (1992). Acquisition, generalisation
    and spontaneous use of color adjectives: A comparison of incidental
    teaching and traditional discrete-trial procedures for children with
    autism. Research in Developmental Disabilities, 13, 191-210.
-   NAEYC Position Statement. (1996). Developmentally appropriate
    practice in early child-hood programs serving children from birth
    through to age 8. National Association for the Education of Young
    Children. Retrieved from naeyc.org/resources/position_statements.
-   Warren, S. F. & Kaiser, A. P. (1986). Incidental language teaching:
    A critical review. Journal of Speech and Hearing Disorders, 51,
    291-299.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Practicevariablesandtheireffects/Effectsofuntimedversustimedpractice/index.md","# Effects of untimed versus timed practice \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-918034be6f064724a7490094f51a862f}
It is only possible to learn to execute particular responses more
quickly if practice is timed. In other words, practice which is designed
to build fluency must always be timed practice. Unless practice is timed
neither the teacher nor the student will be able to determine whether
practice responses are faster than was previously the case, that is,
essential performance feedback (regarding improvement in speed) will be
absent. As far as we can determine, however, this assumption appears
never to have been tested experimentally -- presumably because it is
self-evident.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationvariablesandtheireffects/Effectsofpresentationmode/index.md","# Effects of presentation mode \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2d8d7fc39df14de698e113d5396c8e1e}
Obviously there are circumstances where the presentation mode is a
matter of some importance. Until the learner can read proficiently, new
information must be presented in the aural mode, that is, in the form of
talk. Written presentations become possible only when the learner can
read with a reasonable level of expertise.

Research into the effects of presentation mode is extensive. This is
because each new technological advance -- the development of radio
broadcasts to schools, educational films, educational videos, computer
mediated instruction, and so on -- has resulted in a rush of
experimentation designed to show that the new technology does a better
job than the \"traditional\" teacher directed classroom lesson. Much of
this research is uninformative because it fails to control the *content*
presented in each of the modes which are being compared.

When lesson content is carefully controlled, the results of research
into presentation mode are relatively clear cut. Variations in the mode
of presentation have little or no effect on acquisition. Following a
review of the experimental evaluations of educational media which had
been carried out during the preceding 30 years, Richard Clark concluded
that \"the best current evidence is that media are mere vehicles that
deliver instruction but do not influence student achievement any more
than the truck that delivers our groceries causes changes in our
nutrition. Basically, the choice of vehicle might influence the cost or
extent of distributing instruction, but only the content of the vehicle
can influence achievement\" (Clark, 1983, p. 445).

This conclusion obviously conflicts with the widely held belief that
different learners have different \\"learning styles\\" (e.g. auditory,
visual, kinaesthetic) and that some people learn more quickly from aural
presentations, some learn more quickly from visual presentations, and so
on.
:::

::: referencesList
#### References

-   Clark, R. E. (1983). Reconsidering research on learning from media.
    Review of Educational Research, 53, 445-459
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationvariablesandtheireffects/index.md","# Presentation variables and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-87f75d5c03344e539b69ba8870a02889}
The presentations which are used to define new terms, explain things,
and provide information for students to learn may vary in a number of
ways. Individual presentations can vary with respect to mode (e.g. oral,
written audio-visual), meaningfulness, and length.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationvariablesandtheireffects/Effectsofpresentationlength/index.md","# Effects of presentation length \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8642792ff0814ac8bc575c4291c35fcc}
Presentations contain information, information which may or may not be
remembered and recalled by the learner at a later time. Younger children
can \\"hold in mind\\" only one to three new items of information at one
time (Case, 1978). It follows that the most effective procedure for
presenting new information to young children is one in which small sets
of one to three items of information are immediately followed by the
opportunity to talk about that new information. If more than one to
three items of information are delivered sequentially, the likelihood
that the younger learner will \\"forget\\" one or more of these rises
dramatically. It can be seen, therefore, that the common practice of
introducing new information within the context of the
\\"question-and-answer\\" lesson is good teaching practice. Only if the
younger learner has the opportunity to work with new information in some
way, to talk about it, to practise it or to mentally rehearse it, is it
likely to be remembered.

This raises the question of whether it is ever appropriate to present a
large amount of information at one time as during a lecture or a video
presentation on some topic. There is almost no scientific research into
this question and that which has been undertaken has almost exclusively
involved tertiary students (who may be expected to have acquired highly
developed study skills). The classic analysis of lecturing (Bligh, 1972)
reviewed 91 between groups experiments comparing the effects on recall
of lecturing compared to something else and concluded that \"the lecture
is as effective as any other method for transmitting information but not
more effective\" and \"most lectures are not as effective as more active
methods for the promotion of thought\" (Bligh, 1972, p. 20). There appear
to have been no recent reviews of lecturing and a 1983 review by Oddi
contains only 15 references.

Given what we know from practical experience, it seem reasonable to
assume that the effects of a lecture will depend to a very large extent
on the information processing and self-instructional skills which have
been acquired by the listener. We would expect a lecture to be followed
by evidence of learning only for those listeners who have acquired the
ability to:

1.distinguish between relevant and irrelevant information,

2.write quickly and take adequate notes which record each important item
of information,

3.review these notes at regular intervals, and

4.use, during these reviews, study strategies which will be effective in
learning and remembering the noted information for future use or
examination performance.

With learners who have not yet acquired all of these study skills,
sequences of presentations should be kept short and should be
interspersed with practice activities which involve talking about,
writing about, or responding to questions about the information
contained in the presentations. We will consider the number of practice
opportunities required in the section on the effects of different
amounts of practice, below.
:::

::: referencesList
#### References

-   Bligh, D. A. (1972). What's the use of lectures? Harmondsworth:
    Penguin Books.
-   Case, R. (1978). A developmentally based theory and technology of
    instruction. Review of Educational Research, 48, 439-463.
-   Oddi, L. (1983). The lecture: An update on research. Adult Education
    Quarterly, 33, 222-229.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationvariablesandtheireffects/Effectsofpresentationmeaningfulness/index.md","# Effects of presentation meaningfulness \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-8b3026031a4d4106b8270b7d8bf070c3}
It is widely believed that the content of a meaningful presentation,
that is a presentation which consist of words that are understood by the
learner, is more likely to be remembered than the content of a
presentation which are not completely understood by the learner. There
is some research which supports this belief. For example, Marks,
Doctorow & Wittrock (1974) found that the substitution of one familiar
word for one unfamiliar word (e.g. \\"religious leader\\" for \\"shaman\\")
in each sentence of a reading text in common use in schools \\"increased
story comprehension an amazing 50 per cent and retention an amazing 100
per cent. \...The familiar words make things more meaningful for
students\\" (Gage & Berliner, 1988, p. 295).

Of course, it is not always possible for a presentation to be completely
meaningful. If the teacher is introducing a new concept, the concept
name may not be meaningful initially. Considerable discussion of the
concept's definition and of concept examples and non-examples may be
necessary before the new name acquires meaning.
:::

::: referencesList
#### References

-   Gage, N. L. & Berliner, D. C. (1988). Educational psychology (4th
    Ed.). Boston: Houghton Mifflin.
-   Marks, C. B., Doctorow, M. J., & Wittrock, M. C. (1974). Word
    frequency and reading comprehension. Journal of Educational
    Research, 67, 259-262, 295.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationcontentvariablesandtheireffects/Effectsofgeneralcaseteachingprocedures/index.md","# Effects of general case teaching procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-9abcaf1656d14da1831d6abf0bad4132}
Analyses of the concept learning task by a number of authors (e.g.
Becker & Carnine, 1980; Church, 1999; Engelmann & Carnine, 1991) suggest
that, in order to teach generalised correct responding to the members of
a stimulus class, the learner must have the opportunity to work with
both examples and non-examples of the concept.

Critical to teaching the difference between examples and non-examples of
a new concept is the sequencing of examples and non-examples during
instruction. Research suggests that the most efficient procedure for
doing this is the procedure known as *general case programming.* A
detailed account of general case programming will be found in Engelmann
and Carnine (1991). With general case programming examples are sequenced
so that adjacent positive examples are maximally different*.* This is
the most efficient procedure for teaching the student the outer
boundaries of the stimulus class (Carnine, 1980a). With general case
programming example/non-example pairs are sequenced so that minimally
different example/non-example pairs occur together. Minimally different
example/non-example pairs result in faster learning of the
discrimination between examples and non-examples than
example/non-example pairs which are more obviously different (Carnine,
1980b). With general case programming examples and non-examples are
sequenced in such a way that only one feature changes from one example
(or non-example) to the next. In a third experiment, students who were
taught concepts with simultaneously presented minimally different
positive and negative examples reached criterion in about half as many
trials as students who were presented with the same examples, but
successively and with multiple differences between adjacent examples
(Carnine, 1980b).

A number of separate experiments have demonstrated that both normal and
learning disabled students acquire new concepts more rapidly when these
rules are followed (e.g. Becker & Carnine, 1980; Carnine, 1980a;
Carnine, 1980b; Engelmann & Carnine, 1991; Granzin & Carnine, 1977;
Kelly, Gersten & Carnine, 1990; Williams & Carnine, 1981).
:::

::: referencesList
#### References

-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
-   Church, R. J. (1999). Instructional processes. University of
    Canterbury, Education Department.
-   Carnine, D. (1980a). Relationships between stimulus variation and
    the formation of misconceptions. Journal of Educational Research,
    74, 106-110.
-   Carnine, D. (1980b). Three procedures for presenting minimally
    different positive and negative instances. Journal of Educational
    Psychology, 72, 452-456.
-   Engelmann, S., & Carnine, D. (1991). Theory of instruction:
    Principles and applications (Rev. ed.). Eugene, OR: ADI Press.
-   Granzin, A. C., & Carnine, D. W. (1977). Child performance on
    discrimination tasks: Effects of amount of stimulus variation.
    Journal of Experimental Child Psychology, 24, 332-342.
-   Kelly, B., Gersten, R., & Carnine, D. (1990). Student error patterns
    as a function of curriculum design: Teaching fractions to remedial
    high school students and high school students with learning
    disabilities. Journal of Learning Disabilities, 23, 23-29.
-   Williams, P. B., & Carnine, D. W. (1981), Relationship between range
    of examples and of instructions and attention in concept attainment.
    Journal of Educational Research, 74, 144-148.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationcontentvariablesandtheireffects/Effectsofpositiveexamplerange/index.md","# Effects of positive example range \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-804ea90cce804d0990624223369313d4}
In order to acquire a new concept or generalisation, the learner must
have the opportunity to work with a range of examples of the concept.
Research suggests that, in order to acquire an accurate understanding of
the concept, these positive examples must illustrate the full range of
the generalisation which is to be acquired. In a series of experiments
undertaken by Carnine and his colleagues, students who were presented
with a full range of positive examples of how to convert fractions into
decimals performed higher on a generalisation test (82% correct) than
students who were presented with only a restricted range of examples
(40% correct) (Becker & Carnine, 1980).
:::

::: referencesList
#### References

-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationcontentvariablesandtheireffects/Effectsofnegativeexamplerange/index.md","# Effects of negative example range \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-ce1170d946c6473c9749dc0b204f7a98}
In order to acquire a new concept or generalisation the learner must
learn to distinguish between (and to respond differently to) instances
which are, and which are not, members of the stimulus class. There are
few concepts which can be taught using positive examples alone. The
great majority of concepts can only be mastered if the learner
experiences both examples and non-examples. Non-examples are necessary
to teach what the concept is *not*. In the Carnine experiments referred
to above, one of three groups of students was presented with a
restricted range of negative examples. When presented with transfer
items, these students made three times as many errors on negative
examples as did the students in the other two groups (Becker & Carnine,
1980).
:::

::: referencesList
#### References

-   Becker, W. C., & Carnine, D. (1980). Direct Instruction: An
    effective approach to educational intervention with the
    disadvantaged and low performers. In B. B. Lahey & A. E. Kazdin
    (Eds.), Advances in clinical child psychology (Vol. 3). New York:
    Plenum Press.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationcontentvariablesandtheireffects/Effectsofdifferentexamplesequencingprocedures/index.md","# Effects of different example sequencing procedures \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-96b0a161929642a9a215a6906faf69ae}
The task of teaching new concepts and generalisations is simplified by
virtue of the fact that human beings appear to have an in-built ability
to detect and to respond to samenesses in the world around them
(Carnine, 1990). This means that new concepts and principles can often
be taught using a relatively small number of examples and non-examples.

Research into concept learning is extensive. However, most of this
research involves older adolescent or adult learners and learning tasks
in which the definition of the concept is withheld so that the
investigator can study the processes which are involved in deriving an
unknown classification rule from different sequences of examples (e.g.
Bourne, 1966). Given that it is good teaching practice to begin
instruction with the definition of new concepts, most of the research on
concept formation is largely irrelevant to the question of how best to
teach new concepts to younger learners.
:::

::: referencesList
#### References

-   Bourne, L. E., Jr. (1966). Human conceptual behavior. Boston: Allyn
    and Bacon.
-   Carnine, D. W. (1990). New research on the brain: Implications for
    instruction. Phi Delta Kappan, 72, 372-377.
:::"
".//Theeffectsofinstructionalevents/Presentationpromptingandpracticevariables/Presentationcontentvariablesandtheireffects/index.md","# Presentation content variables and their effects \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-82bedbbf489143deb59abc3fcb600fc9}
Because the purpose of a teacher presentation is to provide learners
with information about important curriculum content, the content of
individual presentations and the way in which that content is structured
and arranged is likely to be the major determinant of the learning which
results from the presentation. While there has been some research into
the effects of different ways of arranging content, to date this
research has been limited largely to studies of different ways of
organising teaching examples during the teaching of new concepts.
:::"
".//Theeffectsofinstructionalevents/index.md","# The effects of instructional events \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-2b7e12d083164c158d467333c9eaa98a}
In Book 2 we identified and defined a number of instructional events
which are thought to affect motivation, learning, retention and the
development of likes and dislikes. These events included the various
types of presentations, prompts and practice opportunities which occur
within each learning interaction, and the various types of presentation,
prompting, practice, contingency management and scheduling operations
which occur during instructional sequences.

In this book we review the results of scientific research into the
effects of these events. Although this research is in its infancy, the
experimentation undertaken to date tells us much about the events which
do and do not play a critical role in the development of motivation,
learning, retention, likes and dislikes. In the reviews which follows we
will also identify a number of commonly occurring instructional events
about which little is known.
:::"
".//index.md","---
title: Welcome to Teacher Education's Core Knowledge and Skills.
layout: home
---

# Welcome to Teacher Education's Core Knowledge and Skills. \n

::: {#parent-fieldname-description .documentDescription}
Please note that this site is under construction.
:::

::: {#parent-fieldname-text-cadb8950340044adb344a7e5c2b4baa9}
In this site we have attempted to bring together in one place the
scientific research on learning and teaching so that teachers, teacher
educators, and teaching researchers have a well organised and accessible
source of scientific information regarding what works and what doesn't
work in the classroom.

Creation of this site was motivated by three observations.

First, the teaching practices which occur in classrooms have changed
little during the past 80 years. Unlike medical practice, where the
traditional craft philosophy of patient care was gradually replaced by
the revolutionary new clinical science during the first half of the 20th
century, teaching practice has remained, to this day, a craft which has
been little influenced by the scientific research on learning and
teaching.

Secondly, very considerable advances have been made in the scientific
analysis of both learning and teaching.  However, this research tends to
be buried under a mountain of pre-scientific research and this makes it
difficult to find and difficult to use in the development of more
effective classroom teaching practices and programmes.

Thirdly, the most accurate and reliable knowledge presently being
generated is that which is being generated by investigations which are
using controlled experimental procedures to study learning and teaching
processes.  Of course, this kind of research into learning and teaching
is just one of the many different kinds of research undertaken by
educational researchers. In this site, however, the primary focus will
be on the results of scientifically oriented investigations because it
is these which allow us to make predictions about what will work (and
who it will work for) and it is these results which speak most directly
to questions about how best to teach particular kinds of skills and
understandings to particular kinds of children and youth.

-   -   By bringing together the scientific research into learning and
        teaching in a single site we hope to:
    -   provide teacher educators with a well organised and highly
        accessible source of reliable information regarding what works
        and what doesn't work -- reliable information which can be used
        as the basis for improvements in teacher education programmes.
    -   provide teachers and teacher educators who are interested in
        research with a clear road map regarding the questions which
        have already been studied by learning and teaching researchers
        and the questions which have yet to be studied in any systematic
        manner.
    -   demonstrate that it is possible for teachers (as well as
        researchers) to contribute to the advancement of knowledge by
        engaging in controlled experimental analysis of teaching and
        learning in their own classrooms.
    -   keep alive the possibility that teaching researchers might learn
        from the mistakes of the past 100 years by challenging those
        teachers and teacher educators whose thinking is still governed
        by pre-scientific ideas of human ability, learning, and teaching
        practice.

## Organisation of this site

Teacher Education's Core Knowledge and Skills is divided into nine major
areas (or \"books\") addressing nine key questions. These are as follows.

![ Figure 0001. Organisation of the TECKS
site.](../../../assets/images/tecks-fig-0001 \"TECKS Fig 0001\"){.image-inline}\
Figure 0001. Organisation of the TECKS site.

**Book 1:** The problem to be solved. Why has the scientific study of
learning lagged so far behind the other sciences?  Is a scientific study
of learning possible? Is a move from craft-based to evidence-based
teaching practice possible at this time?

**Book 2:** Key terms and concepts. What are the important learning and
teaching events which a science of learning and a technology of teaching
will need to distinguish between?

**Book 3:** Which research methods are proving to be most productive?
How has learning been studied in the past? What is to count as reliable
knowledge about the conditions necessary for learning?  Which research
methods result in new knowledge about learning processes and about the
relative effectiveness of different teaching procedures?

**Book 4:** Results of the research on learning. What have we discovered
so far about the conditions which function to maintain motivation, bring
about different kinds of learning, ensure remembering, and develop a
liking for particular kinds of learning activities?

**Book 5:** Results of the research on teaching.  What have we
discovered so far about the effects of particular teaching events and
teaching procedures on the development of motivation, on learning, on
remembering and on the development of a liking for particular learning
activities?

**Book 6:** Evidence-based teaching procedures and programmes. This
section will present the results of well controlled evaluations of the
various motivational and teaching procedures and programmes which have
been systematically evaluated to date.

**Book 7:** Learning how to teach. This section will address questions
about the conditions which must be provided in order for teacher
education students to acquire new knowledge about teaching and new
teaching competencies.

**Book 8:** Resources. This section is reserved for the fast publication
of learning experiments which have been undertaken by classroom
teachers, education students and teacher educators.

**Book 9:** Critical reviews.  This section is reserved for experiments
and literature reviews which challenge some of the pre-scientific ideas
and practices which stand in the way of evidence-based improvements in
classroom practice.
:::"
