# Measurement validity, threats to validity and the assessment of validity \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-d73ed7ec19db412cb7d561af7e18f4e3}
A third question which may be asked of research data is the question "Is
the conclusion which the researcher has drawn from his or her data a
valid conclusion given the nature of the data and the conditions under
which it was collected?" Note that the validity question is not so much
a question about the adequacy of the observation procedure employed or
the data which it has produced as it is a question about the conclusions
which are being drawn from the data collected (Martella, Nelson, &
Marchand-Martella, 1999; Popham, 1981).

The validity question recognises that all data sets are but tiny samples
of the events which might have been observed. Imagine a study of the
language interactions and vocabulary development of a sample of 20
6-year olds. Ten hours observation of the language interactions of each
child represents but a tiny fraction of time in the life of a 6-year
old; a 30 item vocabulary test samples but a tiny fraction of the
thousands of words which 6-year olds know and can use, and a sample of
20 children is but a tiny fraction of all possible English speaking
6-year olds. Any conclusions which are drawn from small data sets, no
matter how accurate the data in the set, must be framed in such a way as
to recognise that the conclusion is based on a very small sample of the
observations which might have been made and that a different sample
might well lead to a different conclusion.

Note that a researcher can collect highly accurate data but still draw
an invalid conclusion from that data. I may observe a child during
mathematics lessons and accurately record the number of aggressive
responses during mathematics as 0. However, if I were to conclude on the
basis of this observation, that the child never engaged in aggressive
responses (when in fact the child hits other children in settings which
I did not observe) then my conclusion would be not be a valid
conclusion.

**Threats to the validity of data-based conclusions.** There are many
factors which can lead investigators into drawing invalid
(unjustifiable) conclusions from the data which they have collected.

The main threat to the validity of the conclusions being drawn by the
researcher is inaccurate data. If the data do not accurately represent
what happened or what was learned, the chances are high that the
researcher will draw an invalid (that is, an unjustified) conclusion
from that data. Because educational researchers have developed no agreed
procedures for routinely assessing the accuracy of their data, invalid
data-based conclusions are extremely difficult to detect and may well be
quite common.

Investigator expectations constitute a second common threat to
measurement validity. The investigator may have developed a belief
(prior to the investigation) regarding how the results should turn out
and, as a result of that belief, analyse or interpret the data which
have been collected in a way which is consistent with that belief. This
source of invalidity may also be difficult to detect - especially if the
investigator\'s expectations have not been disclosed.

A third common threat to validity is sampling bias, that is, the
collection of a non-representative set of observations. For example, the
sample of occasions which are selected for observation may not be
representative of occasions in general thus leading to conclusions
(based on the sample) which differ from those which would have been
drawn if a more representative sample had been drawn. Or the sample of
students or participants may not be representative of the larger group
of students which are of interest to the investigator. Or the sample of
test items included in a test of learning may not be representative of
the skills which were taught and practised during a period of teaching
thus leading to erroneous conclusions about the effects of that teaching
on student learning. (The adequacy of the content covered by a test is
usually referred to as the *content validity* of the test.)

The simplest way to avoid drawing invalid conclusions from a set of
observations or test results is simply to report the conclusions which
are directly indicated (and only the conclusions which are directly
indicated) by the data. The researcher can also minimise the likelihood
of unjustified conclusions by providing an adequate description of the
sampling procedures which were employed. If a sample of learners has
been drawn from a population of learners, then the defining
characteristics of the class of learners should be listed and the
selection procedure described. If a sample of competencies has been
drawn from a class of competencies (as is the case with most achievement
tests) then the class of competencies should be adequately defined and
the procedure which was used to select particular competencies from this
class of competencies should be described. If a sample of observation
sessions has been drawn from all of the occasions when observations
might have been made (as is often the case in ethnographic and behaviour
analytic investigations) then the way in which these observation
sessions were selected should be described. Only if this information is
provided will be reader be able to make a judgement regarding the
representativeness of any samples which have been drawn and, hence, the
validity of the conclusions which the investigator has drawn from the
data collected.

**Assessing the validity of the conclusions which have been drawn.**
There are no established procedures which investigators can follow in
order to prevent themselves from drawing biased, overgeneralised or
invalid conclusions from the data which they have collected. "It is
immensely difficult to provide compelling evidence of validity" (Zeller,
1997, p. 823). Generally speaking, evaluating validity is something
which is done by the readers of a research report. Readers evaluate
conclusions in the light of the information which has been provided
regarding the selection procedures used, and the characteristics of any
sample of occasions, participants, or test items selected by the
researcher.
:::

::: referencesList
#### References

-   Martella, R. C., Nelson, R. & Marchand-Martella, N. E. (1999).
    Research methods: Learning to become a critical research consumer.
    Boston: Allyn and Bacon.
-   Popham, W. J. (1981). Modern educational measurement. Englewood
    Cliffs, NJ: Prentice Hall.
-   Zeller, R. A. (1997). Validity. In J. P. Keeves (Ed.), Educational
    research, methodology, and measurement: An international handbook
    (2nd ed., pp. 822-829). Oxford, England: Pergamon/Elsevier Science
    Inc.
:::
