# Evidence collected at what level of specificity? \n

::: documentByline
Prepared by John Church, PhD, School of Educational Studies and Human
Development

University of Canterbury, Christchurch, New Zealand.
:::

::: {#parent-fieldname-text-f1ad33480d104c7386e247a314a978a5}
Claims about what works in the classroom need to specify the particular
teaching practice under consideration, the particular types of learning
outcome which are affected by this practice, the strength of this
effect, and the particular kinds of learners who are affected in this
way. Only if these four elements are specified does it become possible
to examine the truth or otherwise of the claim.

Research into teaching typically contains one or more claims about the
effects of particular classroom practices on student learning. These
claims are almost always over-generalisations in the sense that they
hardly ever specify the practice *and* the particular learning
outcome(s) which were observed *and* the strength of the effect *and*
the developmental level of the learners who were so affected.

Claims about teaching can lie anywhere on a continuum from highly
specific to highly generalized. To simplify discussion of the
specificity-generality continuum we will divide this continuum into
three parts: 1) specific, 2) general, and 3) overgeneralised. Let us
define these three levels as follows.

**Level 1. The specific level**

At Level 1 (the specific level) the great majority of the effectiveness
claims in the report or review are claims where (a) the particular
teaching practice under consideration is specified in concrete terms,
(b) the particular learning outcome or outcomes are specified using an
agreed or defined classification, (c) the size of the effect is given
either in absolute terms or else relative to an alternate practice of
known effect, and (d) the particular population of learners under
discussion are described in terms of their pre-instructional levels with
respect to each of the learning outcomes studied.

**Level 2. The general level**

At Level 2 (the general level) effectiveness claims are claims in which
one of the four necessary parts of a claim about teaching effectiveness
are missing. For example, there may be no reference to the developmental
level of the students -- implying that all students are similarly
affected by the particular teaching practice under discussion. Or the
particular learning outcome which is affected may be left unspecified --
implying that all learning outcomes are affected in the manner
described.

**Level 3. The overgeneralisation**

Level 3 (the overgeneralisation) includes all claims regarding teaching
effectiveness in which only one or two of the four necessary elements
are present while the remaining elements are either missing or else are
given in such general terms that the reader has no way of working out
which particular teaching practice and/or learning outcome and/or
student population the writer is talking about.

The following claims from three different reviews of research on
teaching illustrate Level 3 overgeneralisations.

-   *"Students learn best within cohesive and caring learning
    communities"* (Brophy, 2001, p. 6). This conclusion is regularly
    repeated in New Zealand's BES reviews (see for example Alton-Lee,
    2003; Anthony & Walshaw, 2007). It is clearly an overgeneralisation
    for, by failing to specify any categories of students and any
    categories of learning outcomes, it implies that the claim is true
    for all students and all learning outcomes. The absurdity of the
    claim will be quickly recognised by anyone who was a high achieving
    secondary or tertiary student who learned most rapidly when studying
    on their own.
-   *"Pedagogies that emphasise, embed and enable metacognitive
    strategy-use through curriculum engagement for class groups, are
    associated with much higher achievement and enable marked
    improvements for low achievers"* (Alton Lee, 2003, p. 84). This
    claim immediately raises a number of questions. How much higher?
    Much higher than what? Only low achievers? At which age levels? For
    which kinds of learning outcomes? Clearly this claim meets our
    definition of an overgeneralisation.
-   *"The long term use of concrete materials is positively related to
    increases in student mathematics achievement and improved attitudes
    toward mathematics"* (Grouws, 2004, p. 172). Although this
    conclusion is based on a meta-analysis of 60 between-groups
    experiments by Sowell (1989), the claim by Grouws leaves out all of
    the limiting conditions listed in the original review. For example,
    Sowell found that the effect was very small and that it varied by
    grade level, learning outcome and study length. For example, the
    mean effect size for concrete materials vs. symbolic materials in
    studies of 1 year or longer was 0.29 for rate of acquisition in
    Grades 1-4 and was 0.38 for retention in grades 1 to 8. The
    meta-analysis "could not answer questions about the nature of the
    situations in which manipulatives might be appropriate. Nor was it
    possible to find out which manipulatives are most appropriate in
    particular situations" (Sowell, 1989, p. 504).
-   *"Accomplishing the most significant instructional goals requires
    open-ended questions that call for students to apply, analyze,
    synthesize, or evaluate what they are learning"* (Brophy, 2001, p.
    13). Here again, Brophy is guilty of overgeneralisation. He has
    failed to specify which kinds of students he is talking about and he
    has failed to define "significant instructional goals". It needs to
    be remembered that "significant instructional goals" is a very large
    category given that there are very few "insignificant instructional
    goals". The overgeneralisation also ignores a very substantial
    corpus of scientific research demonstrating that there are many
    groups of children who learn more rapidly and develop higher levels
    of understanding under conditions of well structured, step-by-step
    questioning (Adams & Engelmann, 1996; Klahr & Nigam, 2004).
-   *"Peer tutoring (tutoring of slower or younger students by more
    advanced students) appears to work nearly as well as teacher
    tutoring"* (Walberg & Paik, 2004). In the absence of closer
    examination this appears to be a plausible summary of the peer
    tutoring literature. However, it fails to specify any categories of
    learning outcomes (implying that it applies to all learning
    outcomes), fails to specify any categories of students (implying
    that it applies to all students), and fails to define "nearly as
    well". This makes the claim an overgeneralisation.

It can be seen that the kinds of conclusions which research might
generate (regarding the relative effectiveness of different classroom
practices and different instructional materials) may be presented at
various levels of specificity and that a certain degree of expertise is
required in order to evaluate the research base which is being cited in
favour of a particular teaching practice. We will consider in some
detail the level of specificity which is required if the research base
is to be of any practical value in Book 2 of this website.
:::

::: referencesList
#### References

-   Adams, G.L. & Engelmann, S. (1996). Research on Direct Instruction:
    25 years beyond DISTAR. Seattle: Educational Achievement Systems.
-   Alton-Lee, A. (2003). Quality teaching for diverse students in
    schooling: Best evidence synthesis. Wellington, New Zealand:
    Ministry of Education.
-   Anthony, G. & Walshaw, M. (2007). Effective pedagogy in
    mathematics/PÃ¤ngarau. Best evidence synthesis Iteration. Wellington,
    New Zealand: Ministry of Education. Retrieved 16 June 2007 from
    http://educationcounts.edcentere.govt.nz/goto/BES.
-   Brophy, J. (2001). Introduction. Advances in Research on Teaching:
    Subject-Specific Instructional Methods and Activities, 8, 1-23.
-   Grouws, D. A. (2004). Mathematics. In G. Cawelti (Ed.), Handbook of
    research on improving student achievement (3rd ed.). Arlington, VA:
    Educational Research Service.
-   Klahr, D., & Nigam, M. (2004). The equivalence of learning paths in
    early science instruction: Effects of direct instruction and
    discovery learning. Psychological Science, 15, 661-667.
-   Sowell, E. J. (1989). Effects of manipulative materials in
    mathematics instruction. Journal for Research in Mathematics
    Education, 20, 498-505.
-   Walberg, H. J., & Paik, S. J. (2004). Effective general practices.
    In G. Cawelti (Ed.) Handbook of research on improving student
    achievement (3rd ed.). Arlington, VA: Educational Research Service.
:::
